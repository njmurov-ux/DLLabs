{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks Laboration\n",
    "\n",
    "### **Quick introduction to Jupiter notebooks**\n",
    "* Each cell in this notebook contains either code or text.\n",
    "* You can run a cell by pressing Ctrl-Enter, or run and advance to the next cell with Shift-Enter.\n",
    "* Code cells will print their output, including images, below the cell. Rerunning it deletes the previous output, so be careful if you want to save some results.\n",
    "* You don't have to rerun all cells to test changes, just rerun the cell you have made changes to. Some exceptions might apply, for example if you overwrite variables from previous cells, but in general this will work.\n",
    "* If all else fails, use the \"Kernel\" menu and select \"Restart Kernel and Clear All Output\". You can also use this menu to run all cells.\n",
    "* A useful debug tool is the console. You can right-click anywhere in the notebook and select \"New console for notebook\". This opens a python console which shares the environment with the notebook, which let's you easily print variables or test commands."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:01.626042Z",
     "start_time": "2026-02-27T09:49:00.996967Z"
    }
   },
   "source": [
    "import keras.src.utils\n",
    "# Setups\n",
    "# Automatically reload modules when changed\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 154
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Your task**\n",
    "Your task is to make a DNN that can classify benign or malicious networks attacks using the Mirai dataset (see below). \n",
    "\n",
    "**You need to answer all the questions in the notebook.** Also, for all classification tasks that you will explore, you should always answer these two questions:\n",
    "- How good classification accuracy can a naive classifier obtain? The naive classifier will assume that all examples belong to one class.\n",
    "- What is random chance classification accuracy if you randomly guess the label of each (test) example? For a balanced dataset and binary classification this is easy (50%), but in many cases it is more complicated and a Monte Carlo simulation may be required to estimate random chance accuracy.\n",
    "\n",
    "If your classifier cannot perform better than a naive classifier or a random classifier, you are doing something wrong.\n",
    "\n",
    "If the training is too slow on your own computer, use the smaller datasets (*half or *quarter).\n",
    "\n",
    "Dense networks are not optimal for tabular datasets like the one used here, but here the main goal is to explore and get a a hands-on experience with deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The Dataset #\n",
    "\n",
    "Data used in this laboration are from the [Kitsune Network Attack Datase](https://archive.ics.uci.edu/ml/datasets/Kitsune+Network+Attack+Dataset). We will focus on the 'Mirai' part of the dataset. Your task is to make a DNN that can classify if each attack is benign or malicious. The dataset has 116 covariates, but to make it a bit more difficult we will remove the first 24 covariates.\n",
    "\n",
    "### **1.1 Load the data**\n",
    "Complete and run the following cell to to load the the `Mirai_data.npy` and the `Mirai_labels.npy` files and remove the first 24 covariances to make the classification task harder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:18.147891Z",
     "start_time": "2026-02-27T09:49:17.281320Z"
    }
   },
   "source": [
    "import os\n",
    "from numpy import genfromtxt  # ! Not needed if you load data from numpy arrays !\n",
    "import numpy as np\n",
    "\n",
    "keras.src.utils.set_random_seed(42)\n",
    "\n",
    "# Load data from numpy arrays, choose reduced files if the training takes too long\n",
    "# Load the dataset\n",
    "X = np.load('Mirai_data.npy')\n",
    "Y = np.load('Mirai_labels.npy')\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Remove the first 24 covariates (columns)\n",
    "X = X[:, 23:]\n",
    "\n",
    "# Print the size of the covariates and labels\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(764137, 93)\n",
      "(764137,)\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Explore the data (NaNs)**\n",
    "It is common to have NaNs (not a number) in the data, lets check for it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:24.654963Z",
     "start_time": "2026-02-27T09:49:23.609687Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# It is common to have NaNs in the data, lets check for it. Hint: np.isnan()\n",
    "# Fist check for NaNs in the data and then in the labels\n",
    "print(sum(np.isnan(X)))\n",
    "print(sum(np.isnan(Y)))\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:26.122761Z",
     "start_time": "2026-02-27T09:49:24.656216Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Convert covariates to floats\n",
    "X = X.astype(float)\n",
    "\n",
    "# Convert labels to integers\n",
    "Y = Y.astype(int)\n",
    "\n",
    "# Remove mean of each covariate (column)\n",
    "X = np.subtract(X, X.mean(axis=0))\n",
    "\n",
    "# Divide each covariate (column) by its standard deviation\n",
    "X = np.divide(X, X.std(axis=0))\n",
    "\n",
    "# Check that mean is 0 and standard deviation is 1 for all covariates, by printing mean and std\n",
    "print(\"Column means:\", np.round(X.mean(axis=0), 5))\n",
    "print(\"Column sds:\", X.std(axis=0))\n",
    "# ============================================\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column means: [-0. -0. -0.  0.  0.  0.  0.  0. -0. -0.  0. -0. -0. -0. -0. -0.  0.  0.\n",
      "  0. -0.  0. -0.  0. -0. -0. -0. -0.  0.  0.  0. -0. -0.  0. -0.  0.  0.\n",
      "  0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0.  0.  0.  0. -0.  0.  0.\n",
      "  0.  0.  0.  0.  0. -0. -0. -0.  0. -0. -0. -0. -0. -0.  0.  0. -0.  0.\n",
      "  0. -0. -0. -0.  0.  0.  0.  0. -0. -0. -0.  0. -0. -0.  0. -0. -0.  0.\n",
      "  0.  0. -0.]\n",
      "Column sds: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.4 Data split**\n",
    "Use the first 70% of the dataset for training, leave the other 30% for validation and test, call the variables:\n",
    "- `Xtrain` and `Ytrain`  (70% of the dataset)\n",
    "- `Xtemp` and `Ytemp`  (30% of the dataset)\n",
    "\n",
    "We use a function from scikit learn (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for more details)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:26.815267Z",
     "start_time": "2026-02-27T09:49:26.151400Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# split the original dataset into 70% Training and 30% Temp\n",
    "Xtrain, Xtemp, Ytrain, Ytemp = train_test_split(X, Y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the number of examples of each class, for the training data and the remaining 30%\n",
    "classes_train = np.unique(Ytrain)\n",
    "classes_temp = np.unique(Ytemp)\n",
    "[print(\"Sum of Class {} in Ytrain: {}\".format(c, np.sum(Ytrain == c))) for c in classes_train]\n",
    "[print(\"Sum of Class {} in Ytemp: {}\".format(c, np.sum(Ytemp == c))) for c in classes_temp]\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Xtrain has size {}.'.format(Xtrain.shape))\n",
    "print('Ytrain has size {}.'.format(Ytrain.shape))\n",
    "\n",
    "print('Xtemp has size {}.'.format(Xtemp.shape))\n",
    "print('Ytemp has size {}.'.format(Ytemp.shape))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Class 0 in Ytrain: 85248\n",
      "Sum of Class 1 in Ytrain: 449647\n",
      "Sum of Class 0 in Ytemp: 36373\n",
      "Sum of Class 1 in Ytemp: 192869\n",
      "Xtrain has size (534895, 93).\n",
      "Ytrain has size (534895,).\n",
      "Xtemp has size (229242, 93).\n",
      "Ytemp has size (229242,).\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split your non-training data (`Xtemp`, `Ytemp`) into 50% validation (`Xval`, `Yval`) and 50% testing (`Xtest`, `Ytest`), we use a function from scikit learn. In total this gives us 70% for training, 15% for validation, 15% for test."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:28.699978Z",
     "start_time": "2026-02-27T09:49:28.271402Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# split the remaining 30% into 50% Validation and 50% Test\n",
    "Xval, Xtest, Yval, Ytest = train_test_split(Xtrain, Ytrain, train_size=0.5, test_size=0.5, random_state=42)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Xval has size {}.'.format(Xval.shape))\n",
    "print('Yval has size {}.'.format(Yval.shape))\n",
    "\n",
    "print('Xtest has size {}.'.format(Xtest.shape))\n",
    "print('Ytest has size {}.'.format(Ytest.shape))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xval has size (267447, 93).\n",
      "Yval has size (267447,).\n",
      "Xtest has size (267448, 93).\n",
      "Ytest has size (267448,).\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "1. Do all variables (`Xtrain`,`Ytrain`), (`Xval`,`Yval`), (`Xtest`,`Ytest`) have the shape that you expect?\n",
    "2. Given the number of examples from each class, how high classification performance can a naive classifier obtain? The naive classifier will assume that all examples belong to one class. Note: you do not need to make a naive classifier, this is a theoretical question, just to understand how good performance we can obtain by guessing that all examples belong to one class.\n",
    "\n",
    "Note, that if your classifier cannot perform better than a naive classifier or a random classifier, you are doing something wrong.\n",
    "\n",
    "\n",
    "#### **<span style=\"color:green\">Answer</span>**\n",
    "1. Yes, all variables have the correct shape.\n",
    "2. The naive classifier will pick the class with the most labels occurring in the train dataset. resulting in (449647 / 534895) $\\approx\n",
    "0.84$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T09:49:29.958544Z",
     "start_time": "2026-02-27T09:49:29.687762Z"
    }
   },
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# This sets the GPU to allocate memory only as needed\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) != 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "else:\n",
    "    print('No GPU available.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available.\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: DNN classification\n",
    "In this next section you will define utilities for building the deep learning networks that will be used later and for visualizing the model training. You will also train several model experimenting with different model architecture configurations and methods for model regularization.\n",
    "\n",
    "### **2.1 Build DNN model**\n",
    "Implement the `build_DNN` and `plot_results` functions in the `utilities.py` file. Note that for the changes in the `utilities.py` definitions to be visible by the notebook, you need to save the file. \n",
    "\n",
    "Here are some relevant functions that you should use in `build_DNN`. For a complete list of functions and their definitions see the [keras documentation](https://keras.io/api/):\n",
    "\n",
    "- `model.add()`, adds a layer to the network;\n",
    "- `Dense()`, a dense network layer. See the [documentation](https://keras.io/api/layers/core_layers/dense/) what are the input options and outputs of the `Dense()` function. \n",
    "- `model.compile()`, compiles the model. You can set the input metrics=['accuracy'] to print the classification accuracy during the training.\n",
    "- cost and loss functions: check the [documentation](https://keras.io/losses/) and chose a loss function for binary classification.\n",
    "\n",
    "To get more information in model [compile](https://keras.io/api/models/model_training_apis/#compile-method), [training](https://keras.io/api/models/model_training_apis/#fit-method) and [evaluation](https://keras.io/api/models/model_training_apis/#evaluate-method) see the relevant documentation.\n",
    "\n",
    "After defining the`build_DNN` function use it to create the your first DNN classifier. Start with a simple network with 2 dense layers (with 20 nodes each), using sigmoid activation functions. The final dense layer should have a single node and a sigmoid activation function. We start with the SGD optimizer.\n",
    "\n",
    "Make sure that the last layer always has a sigmoid activation function (why?)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:03:45.250254Z",
     "start_time": "2026-02-27T10:03:44.760302Z"
    }
   },
   "source": [
    "from utilities import build_DNN, train_DNN\n",
    "# import a suitable loss function from keras.losses and use as input to the build_DNN function.\n",
    "from tf_keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Build a DNN model following the specifications above\n",
    "model = build_DNN(input_shape=Xtrain.shape[1],\n",
    "                  n_hidden_layers=2,\n",
    "                  n_hidden_units=20,\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  act_fun=\"sigmoid\",\n",
    "                  optimizer=\"sgd\",\n",
    "                  print_summary=True)\n",
    "# use sigmoid act fct in last layer to perform classification based on regressive model\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 20)                1880      \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 20)                420       \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2321 (9.07 KB)\n",
      "Trainable params: 2321 (9.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 177
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Train DNN model**\n",
    "\n",
    "Time to train the DNN!\n",
    "Start simple with 2 hidden layers with 20 nodes each.\n",
    "\n",
    "Build set the different hyper-parameters, build the model and run the training. Use the following training and hyper-parameters:\n",
    "- `batch_size=20` (using 10000 due to graphics card limitations)\n",
    "- `epochs=20`\n",
    "- `learning_rate=0.1`\n",
    "\n",
    "Make sure that you are using learning rate 0.1 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers with 20 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:00.866228Z",
     "start_time": "2026-02-27T10:00:54.848976Z"
    }
   },
   "source": [
    "# Setup some training and hyper-parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Specify the learning rate, the input shape and the loss function\n",
    "learning_rate = 0.1\n",
    "input_shape = (Xtrain.shape[1],)\n",
    "loss = BinaryCrossentropy()\n",
    "\n",
    "# Build the model\n",
    "model1 = build_DNN(input_shape=input_shape,\n",
    "                   n_hidden_units=20,\n",
    "                   n_hidden_layers=2,\n",
    "                   loss=loss,\n",
    "                   learning_rate=learning_rate)\n",
    "# Train the model, provide training data and validation data\n",
    "history1 = model1.fit(Xtrain, Ytrain,\n",
    "                      validation_data=(Xval, Yval),\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=1)\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 1s 7ms/step - loss: 0.4368 - accuracy: 0.8285 - val_loss: 0.3944 - val_accuracy: 0.8405\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8406 - val_loss: 0.3477 - val_accuracy: 0.8405\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8406 - val_loss: 0.2937 - val_accuracy: 0.8405\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8406 - val_loss: 0.2495 - val_accuracy: 0.8409\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.8603 - val_loss: 0.2224 - val_accuracy: 0.8718\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.8850 - val_loss: 0.2073 - val_accuracy: 0.8954\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.9005 - val_loss: 0.1985 - val_accuracy: 0.9027\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9031 - val_loss: 0.1928 - val_accuracy: 0.9036\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1909 - accuracy: 0.9035 - val_loss: 0.1888 - val_accuracy: 0.9038\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9041 - val_loss: 0.1856 - val_accuracy: 0.9046\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1845 - accuracy: 0.9049 - val_loss: 0.1831 - val_accuracy: 0.9053\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1822 - accuracy: 0.9056 - val_loss: 0.1809 - val_accuracy: 0.9060\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1802 - accuracy: 0.9061 - val_loss: 0.1790 - val_accuracy: 0.9065\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9066 - val_loss: 0.1774 - val_accuracy: 0.9070\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9070 - val_loss: 0.1760 - val_accuracy: 0.9075\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9074 - val_loss: 0.1747 - val_accuracy: 0.9077\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1745 - accuracy: 0.9077 - val_loss: 0.1736 - val_accuracy: 0.9081\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9079 - val_loss: 0.1726 - val_accuracy: 0.9083\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9083 - val_loss: 0.1717 - val_accuracy: 0.9086\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9085 - val_loss: 0.1708 - val_accuracy: 0.9088\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:04.846145Z",
     "start_time": "2026-02-27T10:01:01.702735Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Evaluate the model on the test data\n",
    "score = model1.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.8f' % score[0])\n",
    "print('Test accuracy: %.8f' % score[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.17145565\n",
      "Test accuracy: 0.90835977\n"
     ]
    }
   ],
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:06.114612Z",
     "start_time": "2026-02-27T10:01:05.739116Z"
    }
   },
   "source": [
    "from utilities import plot_results\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAF4CAYAAABXZWgEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABjyUlEQVR4nO3dB3hUVf7G8XfSeyih996L0gRBpUiRpdgAV0XUFf+21UUsrApiQ7EsrrIWVuyr2LsgoFhBEKQpvffQ0kmf/3POZEICCSQzQ+r38zzXuffOnZOTYQx5Oef8rsPpdDoFAAAAAPCYn+cvBQAAAAAYBCsAAAAA8BLBCgAAAAC8RLACAAAAAC8RrAAAAADASwQrAAAAAPASwQoAAAAAvESwAgAAAAAvEawAAAAAwEsEKwAAAAAo78Fq5syZaty4sUJCQtSjRw8tXbq0SK9799135XA4NHLkyHznx40bZ8/n3QYPHnyGeg8AAAAApRys5syZowkTJmjKlClasWKFOnXqpEGDBik2NvaUr9u+fbsmTpyoPn36FPi8CVL79u3L3d55550z9B0AAAAAQCkHq2eeeUY33HCDrr32WrVt21YvvviiwsLCNHv27EJfk5WVpSuvvFJTp05V06ZNC7wmODhYtWvXzt2qVq16Br8LAAAAAJVdQGl94fT0dC1fvlyTJk3KPefn56cBAwZo8eLFhb7uoYceUs2aNXX99dfrxx9/LPCaRYsW2WtMoOrXr58eeeQRVa9evdA209LS7OaWnZ2tI0eO2NeYqYQAAAAAKien06nExETVrVvX5pUyF6wOHTpkR59q1aqV77w5Xr9+fYGv+emnn/TKK69o5cqVhbZrpgFecsklatKkibZs2aJ//vOfGjJkiA1r/v7+Bb5m2rRpdgQMAAAAAAqya9cu1a9fX2UuWBWXSYlXX321Zs2apZiYmEKvGzNmTO5+hw4d1LFjRzVr1syOYvXv37/A15hRM7PWyy0+Pl4NGza0b15UVJSPvxMAAAAA5UVCQoIaNGigyMjIU15XasHKhCMzgnTgwIF8582xWRd1IjP6ZIpWDBs2LN+UPSMgIEAbNmywAepEZh2W+VqbN28uNFiZNVlmO5EJVQQrAAAAAI7TLBEqteIVQUFB6tKlixYuXJgvKJnjnj17nnR969attWbNGjsN0L0NHz5cffv2tfsmRRZk9+7dOnz4sOrUqXNGvx8AAAAAlVepTgU00++uueYade3aVd27d9eMGTOUnJxsqwQaY8eOVb169ewaKHOfq/bt2+d7fZUqVeyj+3xSUpJdK3XppZfaUS8zynX33XerefPmtow7AAAAAFS4YDV69GgdPHhQkydP1v79+9W5c2fNnTs3t6DFzp07T1l540RmauHq1av1+uuvKy4uzlbuGDhwoB5++OECp/oBAAAAgC84nKZ+IE5aoBYdHW2LWLDGCgAAAHmZX58zMzNthWuUf/7+/rZmQ2FrqIqaDcpNVUAAAACgtJl7se7bt08pKSml3RX4UFhYmK3JYOpAeIpgBQAAABSBKbS2bds2O8JhlpyYX8JPVykOZX/00YRlszzJ/Nm2aNGiWEuR8iJYAQAAAEVgfgE34cpUozYjHKgYQkNDFRgYqB07dtg/Y1M0zxOlVm4dAAAAKI88HdFAxf4z5VMBAAAAAF4iWJVx2w4l69Wft5V2NwAAAACcAsGqDItNSNWgf/2gqZ//qdW740q7OwAAAECuxo0ba8aMGUW+ftGiRbbYh7nfbEVEsCrDakaFaGjHOnb/sa/W2aolAAAAQHGYMHOq7cEHH/So3WXLlmn8+PFFvr5Xr162VL25J1RFRFXAMu7OgS315Zp9WrL1iL5dH6v+bWqVdpcAAABQjpgw4zZnzhxNnjxZGzZsyD0XERGRu2/+Id/c+NjcMPd0atSoUax+BAUFqXbt2qqoGLEq4+pXDdO1vRrb/ce/Xq/MrOzS7hIAAADyBJGU9MwS34ozk8mEGfdmRovMKJX7eP369YqMjNTXX3+tLl26KDg4WD/99JO2bNmiESNGqFatWjZ4devWTQsWLDjlVECHw6H//ve/uvjii205enNPqM8++6zQqYCvvfaaqlSponnz5qlNmzb26wwePDhfEMzMzNTf//53e1316tV1zz336JprrtHIkSNV1jBiVQ7c3Le55vy2S5tik/T+8t26onvD0u4SAAAAJB3LyFLbyfNK/Ov++dAghQX57lf5e++9V0899ZSaNm2qqlWrateuXbrooov06KOP2rD1xhtvaNiwYXakq2HDwn8XnTp1qqZPn64nn3xSzz33nK688kp7f6hq1aoVeH1KSor9um+++aYteX7VVVdp4sSJevvtt+3zTzzxhN1/9dVXbfh69tln9cknn6hv374qaxixKgeiQwN1W78Wdv+Z+Rvtv1IAAAAAvvLQQw/pwgsvVLNmzWwI6tSpk2688Ua1b9/ejjw9/PDD9rm8I1AFGTdunK644go1b95cjz32mJKSkrR06dJCr8/IyNCLL76orl276uyzz9att96qhQsX5j5vwtmkSZPsKFjr1q31/PPP29GrsogRq3LiqnMa6rVftmnXkWOa9cM23T7AFbQAAABQekID/e3oUWl8XV8ywSYvE4hMUYsvv/zSTs0zU/KOHTumnTt3nrKdjh075u6Hh4crKipKsbGxhV5vpgyawOZWp06d3Ovj4+N14MABde/ePfd5f39/O2UxO7vsLY8hWJUTwQH+untQa932zu966YctuqJHA9WMDCntbgEAAFRqZs2QL6fklRYTgvIy0/Hmz59vp+mZ0afQ0FBddtllSk9PP2U7gYGBJ70/pwpBBV1fXithMxWwHPlLxzrqVD9aKelZenbBptLuDgAAACqon3/+2U7rM1PwOnToYAtdbN++vUT7EB0dbYtnmLLubqZi4YoVK1QWEazKEZPg/3lRG7v/7rJd2hybVNpdAgAAQAVk1lV99NFHWrlypVatWqW//vWvpTL97rbbbtO0adP06aef2sIZt99+u44ePWp/Ly5rCFblTI+m1TWgTS1lZTtt+XUAAADA15555hlbHdDc1NdUAxw0aJAtLlHS7rnnHlsMY+zYserZs6ctyW76EhJS9pbEOJzldRLjGZSQkGCHHs2CObPgrqzZHJuoQTN+tOFqzvhzbNgCAADAmZWamqpt27apSZMmZfIX+8ogOzvbll0fNWqUrVRYEn+2Rc0GjFiVQ81rRmp0twZ2/7Gv15fbBX4AAADAqZh7YM2aNUsbN27UmjVrdNNNN9kAZKYmljUEq3LqjgEtFBbkr1W74vTlmuN3pwYAAAAqCj8/P7322mvq1q2bzj33XBuuFixYYEetypryXxuykjKl1sef11QzFmzS9LkbdGHbWrYkOwAAAFBRNGjQwFYoLA8YsSrHbujTVDUig7XzSIreWnLqm7UBAAAAOHMIVuVYeHCAJlzY0u4/9+0mxR/LKO0uAQAAAJUSwaqcu7xLfTWvGaG4lAz9Z9Hm0u4OAAAAUCkRrMq5AH8/TRrS2u6/+vN27T6aUtpdAgAAACodglUF0K91TZ3TtJrSM7P1zDcbS7s7AAAAQKVDsKoAHA6H/nmRq+Tkxyv3aO2e+NLuEgAAAFCpEKwqiI71q2h4p7oy9wqe9vU6bhoMAAAAn7ngggt0xx135B43btxYM2bMOO0//n/yySdef21ftXOmEawqkLsGtVKQv59+3nxY3288WNrdAQAAQBkwbNgwDR48uMDnfvzxRxtcVq9eXaw2ly1bpvHjx8uXHnzwQXXu3Pmk8/v27dOQIUNU1hGsKpAG1cI0tmcjuz/tq/XKymbUCgAAoLK7/vrrNX/+fO3evfuk51599VV17dpVHTt2LFabNWrUUFhYmEpC7dq1FRwcrLKOYFXB3NqvuaJCArThQKI+XHHy/zwAAADwIbP8Ij255LdiLPv4y1/+YoPQa6+9lu98UlKS3n//fY0cOVJXXHGF6tWrZ8NShw4d9M4775yyzROnAm7atEnnnXeeQkJC1LZtWxvkTnTPPfeoZcuW9ms0bdpUDzzwgDIyXPdhNX2bOnWqVq1aZUfQzObu74lTAdesWaN+/fopNDRU1atXtyNn5ntxGzdunP2ennrqKdWpU8dec8stt+R+rTMl4Iy2jhJXJSzIhqvHvlqvp7/ZoGEd6yo0yL+0uwUAAFAxZaRIj9Ut+a/7z71SUHiRLg0ICNDYsWNtULnvvvtsUDFMqMrKytJVV11l903wiYqK0pdffqmrr75azZo1U/fu3U/bfnZ2ti655BLVqlVLv/76q+Lj4/Otx3KLjIy0fahbt64NRzfccIM9d/fdd2v06NFau3at5s6dqwULFtjro6OjT2ojOTlZgwYNUs+ePe10xNjYWP3tb3/Trbfemi84fvfddzZUmcfNmzfb9s00Q/M1zxRGrCqgsT0bq16VUB1ISNMrP20t7e4AAACglF133XXasmWLvv/++3zTAC+99FI1atRIEydOtMHDjCTddtttdk3We++9V6S2TRBav3693njjDXXq1MmOXD322GMnXXf//ferV69edrTLrPsyX9P9NczoU0REhA2BZuqf2cy5E/3vf/9Tamqq/Vrt27e3I1fPP/+83nzzTR04cCD3uqpVq9rzrVu3tiN2Q4cO1cKFC3UmMWJVAYUE+uvuwa10+7sr9eL3WzWme0PFRJT9eakAAADlTmCYa/SoNL5uMZiAYULN7NmzbYU/M4pjClc89NBDdtTKBCETcvbs2aP09HSlpaUVeQ3VunXr1KBBAzsS5WZGlE40Z84c/fvf/7YBz0zdy8zMtCNkxWG+lglv4eHHR+vOPfdcO2q2YcMGO2pmtGvXTv7+x2dtmdErM0p2JjFiVUGZKYDt60UpKS1T/164qbS7AwAAUDGZaXVmSl5JbznT+YpbxOLDDz9UYmKiHa0yU/3OP/98Pfnkk3r22WftVEAzdW7lypV2up0JWL6yePFiXXnllbrooov0xRdf6Pfff7fTEn35NfIKDAzMd2ymP5rwdSYRrCooP7/jNw3+3687tfXg8QV9AAAAqHxGjRolPz8/O53OTKUz0wNN4Pj55581YsQIu9bKjAaZ6YAbN24scrtt2rTRrl27bFl0tyVLluS75pdffrFTDk2YMlUIW7RooR07duS7JigoyI6ene5rmQIXZq2Vm+m/+b5atWql0kSwqsB6NYtR31Y1lJnt1PS5G0q7OwAAAChFZg2TKeIwadIkG4JM9TzDhBxTxc+EHzPV7sYbb8y3Xul0BgwYYKv9XXPNNTb0mCmGJkDlZb7Gzp079e6779qpgGZK4Mcff5zvGrP2atu2bXbE7NChQ3Y64onMqJepPGi+lil2YUbYzJowU2zDPQ2wtBCsKrhJF7WRn0Oa+8d+/bb9SGl3BwAAAKXITAc8evSonernXhNlikqcffbZ9pxZf2UKR5hy5UVlRos+/vhjHTt2zFYRNFX6Hn300XzXDB8+XP/4xz9s9T5TJMOEOFNuPS9TSMMUzejbt68tD19QyXez7mvevHk6cuSIunXrpssuu0z9+/e3hSpKm8PpLEYR/EoiISHBlnc0pSKLu6CuLLr3w9V6d9kund2wij68qVduiU0AAAAUnalGZ0ZUmjRpYkdNUDn+bBOKmA0YsaoE/nFhS4UG+mvFzjjNXbu/tLsDAAAAVDgEq0qgVlSIbujTxO4/MXe90jPPbEUUAAAAoLIhWFUS489vppiIIG0/nKJ3lu4s7e4AAAAAFUqpB6uZM2faCiBmLmOPHj20dOnSIr3OVBQxa4VOXFhnloxNnjzZ3gTM3K3ZVCnZtIn7OEUEB+j2AS3t/rMLNykhNaO0uwQAAABUGKUarMzdlydMmKApU6ZoxYoVtm6+qUYSGxt7ytdt375dEydOVJ8+fU56bvr06bZ844svvqhff/3V3pXZtGkWpFV2Y7o1UNMa4TqSnK6Xvt9S2t0BAAAol6j9VvE4ffBnWqrB6plnntENN9yga6+9Vm3btrVhyJRQnD17dqGvMTcNM/Xrp06dam9eduIbMmPGDFsy0tzkrGPHjvbmZ3v37tUnn3xSaJumRr6p9pF3q4gC/f10z+DWdv+/P27Tvvhjpd0lAACAciMwMNA+pqSklHZX4GPuP1P3n7EnAlRK0tPTtXz5cnuDsrw18M3UvcWLFxf6uoceekg1a9a0NfjNzcfyMiUS9+/fb9twM6URzRRD0+aYMWMKbHPatGk2qFUGA9vWUrfGVbVs+1E9/c1GPXV5p9LuEgAAQLng7++vKlWq5M6uMgMC3MamfHM6nTZUmT9T82dr/ozLXbAyd1M2o08n3iHZHK9fv77A1/z000965ZVX7N2YC2JClbuNE9t0P1cQE+7MlEQ3M2LVoEEDVUTmf/5/XtRGF//nF324Yreu791EbeqU/3t1AQAAlARz81zjdEtXUL6YUOX+sy13waq4EhMTdfXVV2vWrFmKiYnxadvBwcF2qyzOalhVQzvU0Zdr9mna1+v1xnXdS7tLAAAA5eYfqU2RNDODKiODYmAVQWBgoFcjVaUerEw4Mt/AgQMH8p03xwWlxS1bttiiFcOGDcs9l53tuh9TQECANmzYkPs604b5wOdts3Pnzmfwuyl/7h7cSt/8uV8/bDyoHzcdVJ8WNUq7SwAAAOWG+T3WF7+Mo+IoteIVQUFB6tKlixYuXJgvKJnjnj17nnR969attWbNGjsN0L0NHz5cffv2tftm6l6TJk1suMrbppnWZ6oDFtRmuZGZ5vMmG1UP11XnNLL7j321XtnZVLcBAAAAyuVUQLOu6ZprrlHXrl3VvXt3W9EvOTnZVgk0xo4dq3r16tniEuY+V+3btz9pLqSR9/wdd9yhRx55RC1atLBB64EHHlDdunVPut9VuZCVKX33iLR1kXTtXCkwxKfN39avhT74bbfW7UvQx7/v0aVd6vu0fQAAAKCyKNVgNXr0aB08eNDe0NcUlzDT9ebOnZtbfGLnzp22UmBx3H333TacjR8/XnFxcerdu7dt0wSzcif5oLT8denYEemb+6WhT/m0+WrhQbq5b3M9MXe9nv5mg4Z2rKOQQIa0AQAAgOJyOLnD2UnM9EFTpj0+Pl5RUaVcMW/TfOnty1z7l70qtb/Ep82nZmSp31OLtDc+1d7j6qYLmvm0fQAAAKAyZINSvUEwiqDFhVLvnFLwn/1dOrzFp82bEao7B7ay+//5brOOJKf7tH0AAACgMiBYlQd975Ma9pLSE6X3r5EyUn3a/MVn1bP3skpMy9Rz327yadsAAABAZUCwKg/8A6TLXpHCYqT9a6S59/q0eT8/c9Pg1nb/rSU7tONwsk/bBwAAACo6glV5EVVXuuRlsyxOWv6qtOYDnzZv7mN1XssayshyavrcDT5tGwAAAKjoCFblSfP+0nkTXfuf3y4d8u20vUlDWsvhkL5cs0+/7zzq07YBAACAioxgVd5cMElq3EdKT5LeHydlHPNZ02ad1aVnu+5l9dhX60TBSAAAAKBoCFbljZ+/dOl/pfAa0oG10td3+7T5Owe2VEign5ZtP6r5fx7wadsAAABARUWwKo8ia7vClVlvteINadUcnzVdJzpU1/duYvcfn7teGVnZPmsbAAAAqKgIVuVV0wuk8+9x7X9xh3TQdwUnbjy/maqFB2nrwWS9u2yXz9oFAAAAKiqCVXl2/t1Sk/OljBTpvWuk9BSfNBsVEqjb+7ew+88u2KiktEyftAsAAABUVASrirDeKqKWdHCd9NVdPmv6iu4N1bh6mA4lpevl77f4rF0AAACgIiJYlXcRNV3hyuEnrXxLWvk/nzQbFOCnewa7bho868dtOpCQ6pN2AQAAgIqIYFURNDnPVYbd+GKCFLvOJ80Obl9bZzesomMZWfrX/I0+aRMAAACoiAhWFUWfO6WmfaXMY671VmlJXjfpcDh039A2dv+933Zp44FEH3QUAAAAqHgIVhVpvdUls6TIOtKhDdKXd0o+uMFvl0bVNLhdbWU7pce/Xu+TrgIAAAAVDcGqIomoIV36imu91ep3pd/f8kmzdw9upQA/h75dH6tfthzySZsAAABARUKwqmganyv1vc+1/9VE6cAfXjfZtEaE/tqjod1/7Kt1yjbDVwAAAAByEawqot4TpOYDpMzUnPVW3q+N+nv/FooIDtDaPQn6fPVen3QTAAAAqCgIVhWRn5908ctSZF3p8Cbpi394vd4qJiJY/3d+U7s/fe4GpWZk+aizAAAAQPlHsKqowqtLl78qOfylNe9LK173usnrezdV7agQ7Yk7pjcX7/BJNwEAAICKgGBVkTU8R+o/2bX/1d3S/jVeNRca5K8JA1va/ee+3aQjyem+6CUAAABQ7hGsKrpef5daDJKy0lzrrVITvGru0rPrq3XtSCWkZuqBT9bK6YOS7gAAAEB5R7CqFOutXpSi6ktHtkif3+7Veit/P4eevKyTLb/+5Zp9+mwVhSwAAAAAglVlEFbNtd7KL0D64yPpt1e8aq5D/Wjd1q+F3TejVvvjU33UUQAAAKB8IlhVFg26SwMedO3PnSTtW+VVczf3baZO9aPtlMC7PljFlEAAAABUagSryqTnrVKri6Ss9Jz1VvEeNxXo76enR3VWcICfftx0SG/9utOnXQUAAADKE4JVZeJwSCNmStENpaPbpM9u82q9VfOaEbpncGu7/9iX67T9ULIPOwsAAACUHwSrSrveKlD681Np6SyvmhvXq7F6Nq2uYxlZmvDeSmVlMyUQAAAAlQ/BqjKq31W68CHX/rx/SntWeNyUn59DT43qpMjgAK3YGaeXftjiu34CAAAA5QTBqrI65yap9V+k7Azp/XHSsTiPm6pXJVRThrez+/+av1F/7vXuXlkAAABAeUOwquzrrao0kuJ2SJ/e4tV6q0vPrqcL29ZSRpbTTglMy8zyaXcBAACAsoxgVZmFVpEuf8213mr9F9KvL3rclMPh0LRLOqh6eJDW70/UjAWbfNpVAAAAoCwjWFV29c6WBj3q2v/mAWn3co+biokI1qMXd7D7L32/Rb9tP+KrXgIAAABlGsEKUvfxUtsRx9dbpXgeiAa3r61Lz64vUxzwzvdXKTkt06ddBQAAAMoighVc662GPydVbSLF7/R6vdWU4W1VNzpEOw6naNrX63zaVQAAAKAsIljBJSTatd7KP0ja8JW0eKbHTUWFBOrJyzvZ/beW7NT3Gw/6sKMAAABA2UOwwnF1O0uDp7n2F0yRdi3zuKlzm8fYmwcbd3+wSnEp6b7qJQAAAFDmEKyQX9frpXaXSNmZXq+3umdwazWtEa4DCWma/OkfPu0mAAAAUJYQrHDyeqthz0rVmkkJu6WP/0/KzvaoqdAgfz0zqrP8/Rz6bNVefbF6r8+7CwAAAJQFBCucLCQqZ71VsLRpnrT4OY+b6tygim65oJndv/+TtYpNSPVhRwEAAICygWCFgtXpKA15wrW/YKq0c4nHTd3ar4Xa14tSXEqG7vlwtZxeVBwEAAAAyqJSD1YzZ85U48aNFRISoh49emjp0qWFXvvRRx+pa9euqlKlisLDw9W5c2e9+eab+a4ZN26cHA5Hvm3w4MEl8J1UQF3GSR0ul5xZ0vvXSsmHPWomKMDPTgk0j99tOKh3l+3yeVcBAACAShus5syZowkTJmjKlClasWKFOnXqpEGDBik2NrbA66tVq6b77rtPixcv1urVq3Xttdfabd68efmuM0Fq3759uds777xTQt9RBVxv9ZcZUvUWUuJe6ePxHq+3alkrUncNbGX3H/niT+08nOLjzgIAAACVNFg988wzuuGGG2w4atu2rV588UWFhYVp9uzZBV5/wQUX6OKLL1abNm3UrFkz3X777erYsaN++umnfNcFBwerdu3auVvVqlVL6DuqgIIjXOutAkKkzQukn//lcVPX9W6i7k2qKTk9SxPfX6WsbKYEAgAAoGIotWCVnp6u5cuXa8CAAcc74+dnj82I1OmYdToLFy7Uhg0bdN555+V7btGiRapZs6ZatWqlm266SYcPn3oKW1pamhISEvJtyKN2e+miJ1373z4i7fjFo2ZMdcCnL++k8CB/Ld1+RK/8tNW3/QQAAAAqW7A6dOiQsrKyVKtWrXznzfH+/fsLfV18fLwiIiIUFBSkoUOH6rnnntOFF16YbxrgG2+8YUPXE088oe+//15DhgyxX6sw06ZNU3R0dO7WoEEDH32XFchZV0sdx0jObOmD66Skgx4106BamCYPa2v3n5q3URv2J/q4owAAAEAlLF5RXJGRkVq5cqWWLVumRx991K7RMiNUbmPGjNHw4cPVoUMHjRw5Ul988YW9Nu81J5o0aZINbO5t1y6KKxS83uoZKaaVlLjPq/VWo7o2UP/WNZWela1/zFmp9EzP2gEAAABU2YNVTEyM/P39deDAgXznzbFZF1UYM12wefPmtiLgnXfeqcsuu8yOOBWmadOm9mtt3ry50GvMmqyoqKh8GwoQFC6Nel0KCJW2fCstfdmjZkylxmmXdlDVsED9uS9Bz327yeddBQAAACpFsDJT+bp06WKn7LllZ2fb4549exa5HfMas0aqMLt377ZrrOrUqeN1nyGpZhtp0COu/YVTpaPbPWsmMkSPXtzB7s/8brNW7Dzqy14CAAAAlWcqoJnGN2vWLL3++utat26dLTSRnJxsqwQaY8eOtdP03MzI1Pz587V161Z7/dNPP23vY3XVVVfZ55OSknTXXXdpyZIl2r59uw1pI0aMsCNcpow7fKTLdVKjc6WMFOnz200lEY+auahDHY3sXFemOOCd763SsfTC18EBAAAAZVlAaX7x0aNH6+DBg5o8ebItWGGm982dOze3oMXOnTvt1D83E7puvvlmOwoVGhqq1q1b66233rLtGGZqobm/lQlqcXFxqlu3rgYOHKiHH37YTveDj5g/k+HPSS+cK21dJP3+pnT2WI+amjq8vZZsPaJth5L1+NfrNHVEe593FwAAADjTHE5Ttxz5mHLrpjqgKWTBeqtT+OU56Zv7peBo6ZYlUlRdj5r5YeNBjZ291O6/dX0P9W4R4+OOAgAAAGc2G5S7qoAoQ865WarXRUqLl76Y4PGUwPNa1tDV5zSy+3d9sErxxzJ83FEAAADgzCJYwXN+/tKImZJfoLTxa2nthx43Nemi1mpcPUz74lM19bM/fNpNAAAA4EwjWMH7KoHn3eXa//puKfmQR82EBQXo6VGd5eeQPvp9j+au3efbfgIAAABnEMEK3uv9D6lWeynlsCtceahLo6r6v/Ob2f1/frxWBxMLL6MPAAAAlCUEK3gvIEga8bzk8HdNB1z/lcdN3TGgpdrUidKR5HRN+mi1qK0CAACA8oBgBd+oe5bU6zbX/hf/kI7FedRMUICfnhnVSUH+flqwLlbvL9/t234CAAAAZwDBCr5zwb1S9eZS0n7pm/s8bsaMWE0Y2NLuP/T5n9p1JMWHnQQAAAB8j2AF3wkMlYY/b26PJv3+lrTlW4+buqFPU3VtVFVJaZm2BHt2NlMCAQAAUHYRrOBbjXpK3W9w7X92u5SW5FEz/n4OPT2qk8KC/LVk6xG9+st23/YTAAAA8CGCFXyv/xQpuqEUv1Na+JDHzTSqHq77hrax+0/MXa9NBxJ92EkAAADAdwhW8L3gCGn4s679pS9LOxZ73NRfuzfU+S1rKD0zWxPeW6WMrGzf9RMAAADwEYIVzoxm/aSzrpLklD67Vco45lEzDodD0y/rqOjQQK3ZE6/nv93s864CAAAA3iJY4cwZ+KgUUVs6vFla9LjHzdSKCtHDI9vb/ee/26zVuz0r5Q4AAACcKQQrnDmhVaS/POPa/+U5ae/vHjc1vFNd/aVjHWVlO/WPOSuVmpHlu34CAAAAXiJY4cxqPVRqf6nkzJI+vVXKTPe4qYdHtFfNyGBtOZis6XM3+LSbAAAAgDcIVjjzhkyXwqpLB9ZKP8/wuJmq4UF64rKOdn/2z9v0y5ZDPuwkAAAA4DmCFc688BhXuDK+ny7FrvO4qb6tauqK7g3t/l3vr1ZiaoavegkAAAB4jGCFkmGmA7YcImVnSJ/eImV7vkbq/qFt1LBamPbEHdNDn//p024CAAAAniBYoWQ4HK5CFsFR0p7l0pL/eNxUeHCAnh7VyTb5/vLd+uaP/T7tKgAAAFBcBCuUnKi60qBHXfvfPiId3uJxU90aV9P485ra/X9+vEaHk9J81UsAAACg2AhWKFlnXS01vUDKTJU++7uUne1xUxMubKlWtSJ1KCndhiun0+nTrgIAAABFRbBCyTLz94Y9KwWGSTt+kpa/6nFTwQH+emZ0JwX6OzTvjwP6+Pc9Pu0qAAAAUFQEK5S8qo2l/lNc+/OnSHG7PG6qXd1o3TGgpd2f8ukftqAFAAAAUNIIVigd3cdLDXpI6YnSF3dIXkzju/G8pjqrYRUlpmVq4nurlJ3NlEAAAACULIIVSoefnzT8eck/WNq8QFr1rsdNBfj76ZlRnRUa6K/FWw/bmwcDAAAAJYlghdJTo6V0wb2u/bn3SokHPG6qSUy4HvhLW7s/fd4Gbdif6KteAgAAAKdFsELp6vV3qU4nKTVO+mqiV01d0b2B+rWuqfTMbN0xZ6XSMj2/CTEAAABQHAQrlC7/AGnETMkvQFr3mfTHJx435XA49PilHVQtPEjr9iXomfkbfdpVAAAAoDAEK5S+2h2k3v9w7ZtRq5QjHjdVMzJE0y7pYPdf/mGrft162Fe9BAAAAApFsELZcN5dUo3WUvJBae4kr5oa1K62RnWtbwsNTnhvlRJTM3zWTQAAAKAgBCuUDQHBrimBDj9p9bvSxm+8am7ysHZqUC3U3tfqwc/+9Fk3AQAAAJ8Fq127dmn37t25x0uXLtUdd9yhl19+2ZPmAJf6XaVzbnbtm3tbpSZ43FREcID+Naqz/BzShyt26+s1+3zXTwAAAMAXweqvf/2rvvvuO7u/f/9+XXjhhTZc3XfffXrooYc8aRJw6XufVLWJlLBHWjDFq6a6Nq6m/zu/md3/58drFJuQ6qNOAgAAAD4IVmvXrlX37t3t/nvvvaf27dvrl19+0dtvv63XXnvNkyYBl6Awafhzrv3fZkvbfvSquTsGtFS7ulE6mpKhuz5YLadZeAUAAACUhWCVkZGh4OBgu79gwQINHz7c7rdu3Vr79jHlCl5q0kfqcq1r/7PbpPQUj5sKCvDTjNGdFRzgp+83HtRbS3b4rp8AAACAN8GqXbt2evHFF/Xjjz9q/vz5Gjx4sD2/d+9eVa9e3ZMmgfwufEiKqicd3SZ996hXTbWoFal7h7S2+49+tU5bDib5qJMAAACAF8HqiSee0EsvvaQLLrhAV1xxhTp16mTPf/bZZ7lTBAGvhERJw5517S/5j7T7N6+au6ZnY/VuHqPUjGxNmLNSGVnZvuknAAAAIMnh9HDRSVZWlhISElS1atXcc9u3b1dYWJhq1qyp8sx8X9HR0YqPj1dUVFRpd6dy++hGV/l1c4+rG39wlWX30L74Yxr0rx+UkJqpv/dvoQkXtvRpVwEAAFDxFDUbeDRidezYMaWlpeWGqh07dmjGjBnasGFDuQ9VKGMGT5PCa0gH10s/POVVU3WiQ/XoxR3s/szvNmvFzqM+6iQAAAAqO4+C1YgRI/TGG2/Y/bi4OPXo0UNPP/20Ro4cqRdeeMHXfURlFlZNuignUP30jLR/jVfNDetUVyM611VWttNOCUxOy/RNPwEAAFCpeRSsVqxYoT59+tj9Dz74QLVq1bKjViZs/fvf//Z1H1HZtRsptRkuZWdKn94iZXkXhh4a0V51okO0/XCKLWYBAAAAlEqwSklJUWRkpN3/5ptvdMkll8jPz0/nnHOODViAz5lRq5Aq0r5V0i/ehffo0EA9fbmr4Mr/ft2pb9cf8FEnAQAAUFl5FKyaN2+uTz75RLt27dK8efM0cOBAez42NrbYxR5mzpypxo0bKyQkxE4pXLp0aaHXfvTRR+ratauqVKmi8PBwde7cWW+++Wa+a0wtjsmTJ6tOnToKDQ3VgAEDtGnTJk++TZQlkbWkwY+79hc9Lh3y7s+0V/MYXd+7id2/+4M1OpyU5oteAgAAoJLyKFiZ4DJx4kQbiEx59Z49e+aOXp111llFbmfOnDmaMGGCpkyZYqcXmrLtgwYNsgGtINWqVdN9992nxYsXa/Xq1br22mvtZsKd2/Tp0+10RHOfrV9//dUGMNNmamqqJ98qypJOY6TmA6SsNOnTW6Vs70qm3zWolVrWitChpDRN+miNDeUAAABAiZZb379/v/bt22fDkJkGaJjRJjNi1bq162asp2NGqLp166bnn3/eHmdnZ6tBgwa67bbbdO+99xapjbPPPltDhw7Vww8/bH8xrlu3ru68804b/AxTFtGsAXvttdc0ZsyYIrVJufUyLG6X9J9zpPQkach0qceNXjX3594EjZj5kzKynJp+aUeN6tbAZ10FAABA+XdGy60btWvXtqNTe/fu1e7du+05M3pV1FCVnp6u5cuX26l6uZ3x87PHZkTqdEyIWrhwoS3xft5559lz27Zts4Evb5vmTTAB7lRtmtLx5g3Lu6GMqtJAunCqa3/Bg9LR7V4117ZulO4c2MruT/38D+08nOKLXgIAAKCS8ShYmZGlhx56yIaWRo0a2c2sezKjRua5ojh06JC9ybAZTcrLHJtwVBiTFCMiIhQUFGRHqp577jldeOGF9jn364rb5rRp0+z34t7MqBnKsC7XSY16Sxkp0ue3m5TtVXM39Gmq7o2rKTk9SxPeW2lLsQMAAABnPFiZdU5m+t7jjz+u33//3W6PPfaYDTkPPPCAziRTjXDlypVatmyZHn30UbtGa9GiRV61OWnSJBvY3JspyoEyzEw9Hf5vKSBU2rpI+j1/AZPi8vdz6OlRnRQRHKDfdhzVi99v8VlXAQAAUDl4FKxef/11/fe//9VNN92kjh072u3mm2/WrFmz7FqmooiJiZG/v78OHMhf6tocm2mGhXbYz89WJTQVAc1aqssuu8yOOBnu1xW3zeDgYDtfMu+GMq56M6nffa79efdLCfu8aq5BtTA9OLyd3f/X/I1auyfeF70EAABAJeFRsDpy5EiBa6nMOfNcUZipfF26dLHrpNzMNEJz7K4yWBTmNWaNlNGkSRMboPK2adZLmeqAxWkT5cQ5N0v1ukhp8dKXE7yeEnjp2fU0uF1tZWY7dceclUrNyPJZVwEAAFCxeRSsTCVAdyW/vMw5M3pVVGYanxnlMiNg69atsyNgycnJtoS6MXbsWDtNz82MTM2fP19bt2611z/99NP2PlZXXXWVfd7hcOiOO+7QI488os8++0xr1qyxbZhKgSNHjvTkW0VZ5ucvjZgp+QVKG76S1n7oVXPm8/PYJR1UIzJYm2OT9MTc9T7rKgAAACq2AE9eZO4VZQpHLFiwIHckyFTdM2uTvvrqqyK3M3r0aB08eNDeF8sUlzDT++bOnZtbfGLnzp25pdwNE7rMlENThdDc/NeMkL311lu2Hbe7777bXjd+/HjFxcWpd+/etk1zA2JUQDXbSOffLX33qPT13VKT86SImh43Vy08SNMv66hrX12mV3/erv6ta6l3ixifdhkAAAAVj8f3sTJl1mfOnKn1613/qt+mTRsbZsxo0csvv6zyjPtYlTNZGdLLF0gH1rqqBY79RPIP9KrJ+z9Zo7eW7FTtqBDNvaOPqoQF+ay7AAAAqHjZwONgVZBVq1bZG/aaMurlGcGqHDq4UZrVT0pPdK29GuwqaOKplPRM/eXfP2nroWQN61RXz11xls+6CgAAgPLjjN8gGChTarSULn7Rtb/kP9KqOV41FxYUoGdGd7al2D9ftVefrtzjm34CAACgQiJYoeJo8xfpvLtc+5//Xdq3yqvmOjeoor/3a2H37/9krfbGHfNFLwEAAFABEaxQsVwwSWoxUMpMld69Sko+7FVzt/Rtpk4NqigxNVMT31+l7GyfzZwFAABAZa0KeMkll5zyeVOFDyj1EuyXzJJm9ZWObJU+uFa66iPJ36MCmArw99OM0Z110bM/6pcthzX75236W5+mPu82AAAAKtGIlVm0daqtUaNG9r5RQKkKrSKNflsKDJe2fS8tnOpVc01iwnX/X9rY/enzNmjD/kQfdRQAAAAVhU+rAlYUVAWsIP74WHp/nGv/stlS+0s9bsr8b3L967/p2/WxalMnSp/c0kvBAf6+6ysAAADKJKoCAu0uls69w7X/6a3SgT88bsrhcOjxSzvYGwiv25egf83f5Lt+AgAAoNwjWKFi6z9ZatZPykiR3v2rlHLE46ZqRobosYs72P2XftiiX7d6VxgDAAAAFQfBChW/mMWlr0hVGkpHt0sf3SBle34D68Hta+vyLvVlJtBOeG+VElMzfNpdAAAAlE8EK1R8YdVcxSwCQqXNC6TvHvWquSnD26lBtVDtiTumqZ//6bNuAgAAoPwiWKFyqNNRGv6ca//Hp6U/P/O4qYjgAD0zqrP8HNIHy3dr7tp9vusnAAAAyiWCFSqPjpdL59zi2v/kJil2vcdNdWtcTf93fjO7P+mjNYpNSPVVLwEAAFAOEaxQuVz4kNS4j5Se5CpmkRrvcVN3DGiptnWidDQlQ3d/uNqWZAcAAEDlRLBC5eIfIF3+mhRVXzqyRfpovJSd7VFTQQF+mjGms31ctOGg3vp1p8+7CwAAgPKBYIXKJzxGGvOW5B8sbZwr/TDd46Za1orUvYNb2/1Hv/xTWw8m+bCjAAAAKC8IVqic6p4lDZvh2l80TVr/lcdNjevVWOc2r67UjGz9Y85KZWR5NgIGAACA8otghcqr81+l7uNd+x/fKB3a5FEzfn4OPXV5J0WFBGjV7ng9/+1m3/YTAAAAZR7BCpXboMekhr2ktATp3SultESPmqkTHapHLu5g95//brN+33nUxx0FAABAWUawQuXmHyiNel2KrCsd2iB9/H8eF7MY3qmuRnSuq6xsp50SmJKe6fPuAgAAoGwiWAERNaXRb0r+QdL6L6SfnvG4qYeGt1ed6BBtP5yiR79c59NuAgAAoOwiWAFG/a7SRU+59r99RNo036NmosMC7Xor4+1fd+rb9Qd82UsAAACUUQQrwK3LNVKXayU5pQ+vlw5v8aiZc5vH6PreTez+3R+s0cHENB93FAAAAGUNwQrIa8gTUv3uUmq8NOcqKc2z+1LdNaiVWtaK0KGkNF39yq86kpzu864CAACg7CBYAXkFBEuj3pAiakmxf0qf3So5ncVuJiTQXy9e1UU1IoO1fn+irvrvr4pLIVwBAABUVAQr4ERRdVzhyi9A+uNj6Zd/e9RM0xoReueGHoqJCNKf+xJ01Su/Kj4lw+fdBQAAQOkjWAEFaXiOa1qgseBBacu3HjXTvGak/nfDOaoWHqS1exI0dvavSkglXAEAAFQ0BCugMF2vl866SnJmSx9cJx3d7lEzLWtF6u2/9VDVsECt2h2va2YvVSLhCgAAoEIhWAGFcTiki56W6p4tHTvqKmaRnuJRU23qROmtv/VQlbBA/b4zTuNeXaakNG4gDAAAUFEQrIBTCQxx3Tw4LEbav0b6/HaPilkY7epG663reygqJEDLdxzVda8uU0o64QoAAKAiIFgBpxNdXxr1uuTwl9a8Jy15weOm2teLtiNXkSEBWrr9iK57bZmOpWf5tLsAAAAoeQQroCga95YGPeba/+Z+adsPHjfVsX4VvXFdd0UEB2jJ1iP62xvLlJpBuAIAACjPCFZAUfW4Ueo4WnJmSe9fK8Xt8ripsxpW1evXdVN4kL9+3nxYN7zxG+EKAACgHCNYAcUpZvGXGVLtjlLKIVcxi4xjHjfXpVE1vXZdd4UF+evHTYf0f28tV1om4QoAAKA8IlgBxREUJo1+SwqtJu1bKX0xweNiFka3xtU0e1w3hQT6adGGg7r5rRVKz8z2aZcBAABw5hGsgOKq2ki6bLbk8JNW/U9a9l+vmjunaXXNvqabggP8tHB9rG753wplZBGuAAAAyhOCFeCJZn2lAVNd+3PvlXYs9qq5Xs1j9N9ruioowE/z/zygv7/zO+EKAACgHCFYAZ7qdZvU7hIpO1N6b6yUsNer5vq0qKGXr+6iIH8/fb12v+6Ys1KZhCsAAIBygWAFeFPMYsTzUs12UnKsNOdqKTPNqyYvaFVTL159tgL9Hfpy9T5NeG+VsrI9X8MFAACAkkGwArwRFC6NeUsKiZb2/CZ9dZfXTfZrXUv/ubKLAvwc+mzVXk18n3AFAABQ1hGsAG9VaypdOtsMYUkrXpd+e9XrJi9sW0vP//Vs+fs59PHve3T3B6uVTbgCAAAoswhWgC+0GCD1f8C1b0atdi31usnB7Wvr32POsuHqwxW7NemjNYQrAACAMqrUg9XMmTPVuHFjhYSEqEePHlq6tPBfSGfNmqU+ffqoatWqdhswYMBJ148bN04OhyPfNnjw4BL4TlDp9Z4gtRkuZWe41lsl7ve6yaEd62jG6M7yc0hzftul+z5ZS7gCAAAog0o1WM2ZM0cTJkzQlClTtGLFCnXq1EmDBg1SbGxsgdcvWrRIV1xxhb777jstXrxYDRo00MCBA7Vnz55815kgtW/fvtztnXfeKaHvCKrsxSxG/keq0VpK2i+9d42Ume51s8M61dW/csLVO0t3aspnf8jpxU2JAQAA4HsOZyn+hmZGqLp166bnn3/eHmdnZ9uwdNttt+nee+897euzsrLsyJV5/dixY3NHrOLi4vTJJ58UuR9paWl2c0tISLD9iI+PV1RUlEffGyqxQ5ulWX2ltASp2w3S0Kd80uyHy3dr4gerZP6PHdersaYMa2tHZAEAAHDmmGwQHR192mxQaiNW6enpWr58uZ3Ol9sZPz97bEajiiIlJUUZGRmqVq3aSSNbNWvWVKtWrXTTTTfp8OHDp2xn2rRp9s1ybyZUAR6LaS5dMsu1v2yW9M0DUlam181e2qW+nri0o91/7ZfteuTLdYxcAQAAlBGlFqwOHTpkR5xq1aqV77w53r+/aGtT7rnnHtWtWzdfODPTAN944w0tXLhQTzzxhL7//nsNGTLEfq3CTJo0ySZQ97Zr1y4vvjNAUqvB0oAHXfu//Ft6Y4SUeMDrZkd1baBpl3Sw+6/8tE2Pf72ecAUAAFAGBKicevzxx/Xuu+/a0SlT+MJtzJgxufsdOnRQx44d1axZM3td//79C2wrODjYboBP9f6HVLWJ9Omt0o6fpJf6SJe9KjU+16tmr+je0N7X6v5P1uqlH7baqoF3DWrFtEAAAIDKOGIVExMjf39/HTiQ/1/xzXHt2rVP+dqnnnrKBqtvvvnGBqdTadq0qf1amzdv9km/gWJpN1Ia/51Uo42UdEB6fZj087OyC6W8cNU5jTR1eDu7/59FW/SvBZt81GEAAACUq2AVFBSkLl262Cl7bqZ4hTnu2bNnoa+bPn26Hn74Yc2dO1ddu3Y97dfZvXu3XWNVp04dn/UdKJaYFtINC6WOoyVnljR/sjTnKik13qtmr+nVWA/8pa3d//fCTXqWcAUAAFA5y62bUuvm3lSvv/661q1bZwtNJCcn69prr7XPm0p/Zv2Tm1kz9cADD2j27Nn23ldmLZbZkpKS7PPm8a677tKSJUu0fft2G9JGjBih5s2b2zLuQKkJCpcufkka+ozkHySt/0J66Xxp/xqvmr2+dxPdd1Ebu/+vBRs18ztGZgEAACpdsBo9erSd1jd58mR17txZK1eutCNR7oIWO3futPehcnvhhRdsNcHLLrvMjkC5N9OGYaYWrl69WsOHD1fLli11/fXX21GxH3/8kTVUKH1mDVS366Xr5knRDaWj26T/DpB+f9urZm84r6nuGdza7j85b4Ne/H6LjzoMAACAcnEfq/Jeqx7wWMoR6aPx0ub5ruOzx0pDpkuBoR43+fy3m/TUNxvt/v1D2+hvfZr6qrcAAACVVkJZv48VUKmFVZP++p7U937z7xvSijekVwZKR7Z53OSt/VrojgEt7L65x9WrP3veFgAAAIqHYAWUFj8/6fy7pKs/ksKqS/tXSy+fL2342uMmb+/fQrf1a273p37+p95YvN2HHQYAAEBhCFZAaWvWT7rxB6l+N1elwHfGSAselLIyi92UuZfVhAtb6qYLmtnjyZ/+obd/3XEGOg0AAIC8CFZAWRBdXxr3ldTj/1zHP/1LenOklBTrUbi6e1ArjT/Ptcbqvo/Xas6ynb7uMQAAAPIgWAFlRUCQNOQJ6bLZUlCEtP1H6cU+0o7FHoWrSUNa23Lsxr0frdH7v+06A50GAACAQbACypr2l0o3fCfVaC0l7ZdeGyr98rxUzAKeJlyZ6oDjejW2L737w9X6aMXuM9ZtAACAyoxgBZRFNVpKf1sodbhccmZJ39wnvTdWSk0odriaMqytrjqnoQ1XE99fpU9X7jlj3QYAAKisCFZAWRUcIV0yS7roKckvUFr3mfTyBdKBP4odrh4a3l5XdG+obKf0jzkr9eyCTUrNyDpjXQcAAKhsCFZAWeZwSN1vkK6bK0XVl45skWb1l1a+U6xm/PwcenRke43u2sCGq38t2KgBz3yvuWv3iXuEAwAAeM/h5Lcqj++uDJSo5MPSRzdIWxa6jruMkwY/IQWGFLkJ87/7l2v26dEv12lffKo9d27z6poyrJ1a1oo8Uz0HAACo8NmAYFUAghXKrOws6YcnpUWPm5gk1eksjXpdqtq4WM2kpGfqxUVb9OIPW5WemS1/P4fG9mykOwa0VHRo4BnrPgAAQHlDsPICwQpl3uYF0oc3SMeOSCFVpEtelloOKnYzu46k6JEv/9S8Pw7Y42rhQfYeWJd3bWDDFgAAQGWXQLDyHMEK5ULcLun9cdKe31zHfSZKff8p+fkXu6kfNx3U1M//1ObYJHvcoV60HhzeVl0aVfN1rwEAAMoVgpUXCFYoNzLTXaXYl77sOm5yvnTpK1JEjWI3lZGVrTcW79CM+RuVmJZpz11yVj3dM6S1akUVfR0XAABARUKw8gLBCuXOmg+kz/4uZSRLkXWly1+TGvbwqKlDSWl6at4Gzfltl733VXiQv27r30LXnttYwQHFHw0DAAAozwhWXiBYoVyKXS+9d7V0aKPkFyBd+LB0zk2uku0eWL07TlM++0O/74yzx42rh2nysLbq17qWjzsOAABQdhGsvECwQrmVlugaufrjI9dx25HSiOelYM9KqWdnO/XJyj2a9vV6HUxMs+f6tqqhB/7SVk1rRPiy5wAAAGUSwcoLBCuUa+Z/abPmat59UnaGVL2FNPpNqWYbj5tMSsvUc99u0uyftikjy6lAf4eu691Et/VroYjgAJ92HwAAoCwhWHmBYIUKYdcy6f1rpIQ9UmCYNOxZqeMor5rcejBJD33xpxZtOGiPa0QGa9KQ1hrZuZ78KM8OAAAqIIKVFwhWqDCSD0kf/k3a+p3ruOv10uBpUkCwV81+u/6AHvr8T20/nGKPz25YRQ8Ob6eO9av4otcAAABlBsHKCwQrVCjZWdL3T0jfTzfzBKW6Z0tDnpDqd/O4sIWRlpmlV3/erucWblJyepZtanTXBpo4qJViIrwLbgAAAGUFwcoLBCtUSJsWSB/9TTp21HVcp7PU40ap3SVSoOf3qTqQkKonvl6vj37fY48jQwJ0x4CWGtuzkQL9/XzVewAAgFJBsPICwQoVVtwuadHj0pr3pSxXlT+FxUhdxkldr5Oi63nc9PIdR2x59rV7Euxx85oRenBYO/VuEeOr3gMAAJQ4gpUXCFao8JIPSytel5a9IiXsdp1z+EtthrlGsRr29GiaYFa2U+//tkvT523QkeR0e25Qu1q6f2hbNagW5uvvAgAA4IwjWHmBYIVKIytT2vCl9OvL0o6fjp+v3UHqfqPU4TIpMLTYzcanZGjGwo16Y/EOG7aCAvz0f+c11U0XNFdokL9vvwcAAIAziGDlBYIVKqX9a133v1r9npR5zHUutJp09lip29+kKg2K3eTGA4ma+vkf+nnzYXtcNzpE/xzaRkM71JHDi8IZAAAAJYVg5QWCFSq1lCPS729KS/8rxe90nXP4Sa2HukaxGvcu1jRB8yNm3h/79ciX67T7qCuw9WhSzZZnb1OH/78AAEDZRrDyAsEKyCnTvnGu9OtL0rbvj5+v2U7qfoPUcbQUVPR1U6kZWXr5h636z6LNSs3Ilrmf8FXnNNKEC1uqSljQmfkeAAAAvESw8gLBCjhB7DrXNMFV70oZrpsCK6SKdPbVrmmCVRsXuak9ccf02Ffr9OXqffa4Slig7hzYyt4Dy6zFAgAAKEsIVl4gWAGFOBYnrXzbFbKObs856ZBaDXFVE2xyfpGnCS7ectiuv1q/PzH3/lcXtq2li9rXsSXaQwIpcgEAAEofwcoLBCugCNMEN82Xlr4kbfn2+PkarXOmCY6RgiNO20xmVrb+t3SnZn63WQcScu6rJSkiOEAD2tTUkA51dH7LGoQsAABQaghWXiBYAcVwcGPONMF3pPQk17ngaOmsK13TBKs3O20T2dlOLd95VF+t2aev1+zX/oTU3OfCgvzVr3VNXdShjvq2qkm5dgAAUKIIVl4gWAEeSI2XVr7jGsU6sjXnpENqMVDqMV5q2k/y8ytSyFq5O05frd6nr9fut2uy3EID/dW3dQ0NaV/Hhq3w4IAz+A0BAACIYOUNghXghexsactCVzXBzfOPn6/e3FWuvfMVUnBkkZoyP55W747XV2v32dGsXUeOh6zgAD9d0KqGHckyISsyJPBMfDcAAKCSSyBYeY5gBfjIoc3SslnS729L6a4iFQqKlDr/Veo+XoppXuSmzI+qP/Ym2IBltu2Hc6oTmiYD/HReCxOyaqt/m1qKDiVkAQAA3yBYeYFgBfhYWqKrVLtZi3Vo4/HzzQe4RrHMYxGmCbqZH1vr9iXq67X79OWafdp6MDn3uUB/h3o3j7EjWabKIPfIAgAA3iBYeYFgBZwh5sfN1u9c0wQ3zjMnXOerNpFaD5Ua95EaniOFVilGk05tPJCUO5K1KTangIakAD+HejWP0dAOtXVh29qqFk7IAgAAxUOw8gLBCigBpsDFslekFW9KafF5nnBIdTq6Qlbj3lLDnsUKWpsOmJGs/TZkue+RZfj7OdSzaXU7kjWwXS3FRAT7+BsCAAAVEcHKCwQroASlJ0vrv5K2/yht/0k6suWEC3KCVqPerqDVyAStqkVqesvBJM3NCVlmfZabn0Pq0cSErNoa1L62akaG+PibAgAAFQXBygsEK6AUJeyVtv8s7fjJFbQObz7hAodUu0POiNa5UqNeRQpa2w8l25Essy7LVBrMbc0hdWtcTRe1r63B7euodjQhCwAAHEew8gLBCihDEvZJO37OGdH6WTq8qYCg1T7/1MGwaqdscteRFBuwvlqzXyt3xeV7rmujqhrSoY6GtK+tulVCz8A3BAAAypNyE6xmzpypJ598Uvv371enTp303HPPqXv37gVeO2vWLL3xxhtau3atPe7SpYsee+yxfNebb2fKlCn22ri4OJ177rl64YUX1KJFiyL3iWAFlGGJ+10jWWYzgStvlcG8QSt36mCvUwYtcwPir9e4bka8fMfRfM81qh6mDvWiXVv9aLWvF60o7pcFAEClklAegtWcOXM0duxYvfjii+rRo4dmzJih999/Xxs2bFDNmjVPuv7KK6+0QalXr14KCQnRE088oY8//lh//PGH6tWrZ68x56ZNm6bXX39dTZo00QMPPKA1a9bozz//tK8pCoIVUI4kHjg+bdBsBQWtWmZEq3fO1MFzCw1a++NT7UjW12v2a9mOI7aI4YmaxITbgNWxnitota8Xxc2JAQCowMpFsDJhqlu3bnr++eftcXZ2tho0aKDbbrtN995772lfn5WVpapVq9rXm4BmvpW6devqzjvv1MSJE+015g2oVauWXnvtNY0ZM6ZI/SJYAeU9aP2cJ2htOPma3KDVu9CgFZeSrjV74l3bbtfj7qPHCvySTWPC7YiWe3SrXb1oRQQHnInvDgAAlLCiZoNS+5s/PT1dy5cv16RJk3LP+fn5acCAAVq8eHGR2khJSVFGRoaqVXP9UrRt2zY7pdC04WbeBBPgTJuFBau0tDS75X3zAJRTkbWk9pe4NiMpNn/QOrheOrDWtf364vGgZQKWO2iFV7c3Fu7Toobd3I4kp2vtCWHLTCXceijZbp+u3JtbEMOGLTuFsIorbNWNUjhhCwCACqvU/pY/dOiQHXEyo0l5meP169cXqY177rnHjlC5g5QJVe42TmzT/VxBzNTBqVOnevBdACjzImpK7S52bUbSwROC1rrjQWvpS65rarZzTRus3VGq0Vqq0VIKibY3GD6vZQ27uR1OSrMBywQuU23QPO6NT9WWg8l2+yRP2GpWIyJ3CmHH+tFqWzdKYUGELQAAKoJy+zf6448/rnfffVeLFi0q8tqpwphRswkTJuQbsTJTEgFUQBE1pHYjXVveoOUOW7F/SrF/uLZ8r6st1Wh1fItxPVYPr6ELWtW0m9uhnLDlHtUyj/sTUrU5NsluH/2+J/d+Ws1rRuSu2TLTCdvWiVZokH+JviUAAKAcB6uYmBj5+/vrwIED+c6b49q1a5/ytU899ZQNVgsWLFDHjh1zz7tfZ9qoU6dOvjY7d+5caHvBwcF2A1AJnRi0kg+5QtbOJVLsOlcxjIQ9UtJ+17bt+/yvN/fQiskfuGJqtFLflvXVN0/Yik1MdU0j3J2gNXvibOA6kJCmjQeS7PbRiuNhq0XNyONrtmzYilJIIGELAICyrNSCVVBQkC2XvnDhQo0cOTK3eIU5vvXWWwt93fTp0/Xoo49q3rx56tq1a77nTBVAE65MG+4gZUaffv31V910001n+DsCUCGEx0htR7g2t9QE6dAm1/osUwzjYM52dLt07Ki0a4lryysw3DWFMCd01azRSv1iWqlfiyaSv+tHb2xCqg1Y7imEq/fE62BimjYcSLTbB8t32+v8/RxqUTPCBi0zwmXKwDesFm4fWbcFAEDZUOrl1q+55hq99NJL9l5Uptz6e++9Z9dYmXVRptKfKaNu1kC5S6lPnjxZ//vf/2zZdbeIiAi7ua8xo1l5y62vXr2acusAfC/jmHR48/Gg5Q5dh7dI2RkFv8Y/SKrePM90wpaudVzmXECwDiSk2qDlmkJoRrYS7NTCwsREBKlhtTA1qh6e8xiWG7zMcw6zuAsAAFTcqoDG6NGjdfDgQRuWTHEJM8o0d+7c3OITO3futJUC3cyNfk01wcsuuyxfO+aGwA8++KDdv/vuu5WcnKzx48fbGwT37t3btuntOiwAOElgqFS7g2vLKyvDNZplRrjyha6NUuaxnHVcf+Z/jcNPqtpEtWq00oU5m9q2lDOmh/anBth1Wmv3Jmj7oWTtOJKinYeTdTQlQ4eS0u22YmfcSd0LC/LPE7byBK9q4apbJUQB/sd/vgIAgHI8YlVWMWIF4IzIzpbid+Uf3XLvp8YX/rqo+sfXcFVtLEXXl6LqKTGktnakhGjHkWPacSRZOw+naMfhFO08kqK98ccKvMGxm5leWK9KaM7o1vFRLveIF9UKAQAoRzcILqsIVgBKlPkxnHTg5CmFZkuOPfVrA0Kl6HqusGUDl+sxPaKu9qu6tqVX1bb47JxRrhTX45EUpWdmn7LZmIjgnNGtMDXMM73QPFYPZ4ohAKDySCBYeY5gBaDMSDniqkxoA9dGKW6nq0ph/G5XGCuKsOp2hEvRDWzoyo6qp/igmtrjjNG2tCrakBKm7UfSbOAyI17xxwpZH5Yj3EwxrB5uQ5cJWnWrhKpWVLBqRoWoVlSIakQEKyiAaYYAgIqBYOUFghWAciEzTUrY6wpZZkvIebSbCV+7pPSk07fj8M8JXq6Rr9SwujrsH6Pd2dW1LaOa1qVEav1RP+08eszej6sof2uYUS1X0ApWrciQfMHLnosKsdewzgsAUNYRrLxAsAJQIZgf72btlnuEywQtG7jyBDETzLIzT99WUIQNXVmRdZUUUluH/GpqT3Y1bc2oqu1pkdqSEqqtiYGKTUpTRlbR/lox9+wyUw7dYcsGr5wQZs7VzHmsFhYkP3MxAAClgGDlBYIVgEojO8s1pdA9wmUD1wlBLOVQ0dryD5IzvIayQmOUGlxdif5VFedXRYecUdqXFald6ZHafixMm5LDtDk5SJnZRQtLAX4O1Yx0j3i5g1iIPefeN+ejQwNZ+wUA8DmClRcIVgBwwv26TMDKN9Uwz5YUK6WdoqphAZwOf2WHVVd6cIxSgqopwa+qDitasdmR2psZqR2p4dpyLFybU0J12BmlLPmftk2zrss99bB6RJCqhQfb6YZVw4MKfAwJPH2bAAAklIf7WAEAysn9umKau7bCZKRKyQddVQyTDp6wbx5jXefM47Ejcjiz5J8cq1CzmTVZkpoU1G6w5JRDWSFVdSyoupICqirOUUUHndHanxWp3ekR2pYapu2pETqUGa0DR6K068ixIn1boYH+qmZCVkSQqoYdD13VCtjMc1EhgUxJBAAUimAFAPBeYIhUpYFrOx1zA+XkQwWEsDzhy/2YckgOZ7YCUo8o0myS6khqc2Kbwcd3MwKjdCywipL9o5ToiFScM0KHneE6mBmuAxmh2pMWqsPZ4TqaGaG4+EhtjQtXko13pw5N5t5fVcMCbQg7MXQVFsiCAxgVA4DKgmAFAChZ/oFSVB3XVpQ1YKbkfG7wOlRACMsT0LIzFJiRYDczWaNOEf/my3IEKC0wWil+kUrwi1K8M1xHnBGKzQrXgfRQHcgMswEtLiVCR5MjtSM2XCsVqTQFnbY0fbWcaYlVQgPtOrATt6i8x2GuR/M61osBQPlCsAIAlF1+/lJEDddWq92przVLho8ddQUsE8aOHcl5POraN4+5x+79I1JmqvydmQpLP6wwHVbMie2afBNY8JfM8AtWSs7IWLwidCQ7QgezwxWbYUbFIhSXFaG4uAgdPRqhvYrQemeYEhWmFDvE5jhlwY6ogoJXaECBwcxMU3QHs8jgAEIZAJQCghUAoGIwYSKsmmsrbnGOvAHspP24E4JZzn52pgKz0xSdfVDROqj6eds0MwBPMQvQFOM45h+uFEe4EhWueGeY4rJDdCQrVHHZYUp0hikhNUwJx8zzoUpQuLaYcwpTgjNMSQpTtgq+B5hZBpY/jJ0YzvKcDwlUZEiAIkIC7GNkcKBCAv0IZgDgAYIVAKByM8U57M2R6xX9NWZ0LC3xFCNhBYQ0c08xs2Vnyl9ZishKUIQSVDNvuyYrFfGeycccYUqywSzMBrOjJpSZETFnqBLSw5WQFqbEOFcQi1e4duWMliXkPKYXMgxnRstM0IoINmHLNQKWN3xFBLvCWGSeY9e17s11bKo0AkBlQrACAKC4zIhOSJRrq9q4eIEsIyUnZCUcD1tpZj/u5PO5z7mPE6RMV9XDUGeK3Wq42y5mjjHrw5IdYUpWqBKdIUrIDrGhLFkhSkoPdW0JOccKVZIzVDsUqmRniA1m5tGeV2iBo2fBAX75glZk3rCWu+8ObMcDXHiw67mwIH+7b9phBA1AeUCwAgCgpJiAEBTu2qLqetZGZporYBUWxvIFsQKeM5stpJiuYGe6qinO1a4XA0zHFKwUG9DMFqwkO10xRElpoUpONQEsTEnOkNyQdsAZqi1FDGlmBM0dsuyWsx8WZAKYv8LyBrGgnGuCXfthwf45z+Vck3PeVHgEAF8jWAEAUJ4EBB8v6OEJU2nRHb7MdMa0JNdjeuIJx0k5QSzvcc45u58oZaXbJkOVZrfqjrjTVa0/rVQzkmZCmDPYBjET2pKzQpSSEqLklBClOE2IC7EFQMx1Zv9gzjlzvfv5ZBP2csKcaTNvx8w6MnfgMoHMFbpygpo7hLnDXJArvJljs4UG5tm3j65jRtYAEKwAAKhslRZDq7o2b5nRMxO2TgplJwY09/N5j/OGtCQpK802GaJ0hTjSVd2HGSVbjuOByxmsY+YxPVgpaSHHw1tOSDPPm8ejCtbunHMmxKU6g+z+MQXpmG3DbEHKzPlVygyCmZtOhwadGLxODmPmOtd+3sDmCmnu1+QNbuY5RtmAso9gBQAAPB89M1t4de/bykw/PkqWnuJai2aO05ML2JJyns/Zt48nHLtfb2c5OhXhSFWEUr0eUTtRhtM/N2TZwJVuNte+DWTKux+sYzagBWt/znMm8B07Yd/VVk6IU7CdHmlGxFyB63j4Cgl0baGBfjZ85R6b5wLMo+t8sL3Gtbme98vz2uPnzdfwI8ABHiNYAQCA0hcQJAV4UC7/VLKzXcU+cgNXIeGrwPBmns+7b8LeMddmjp1Z9ksEOrIUqBRFKcXnoc0tzRnoCllZwUpJCVZqiitwpToDbSAzgc0+5h67wlyCAm2REvdxqnKed7rOnbSvIAUGBuYLXK5Q5pcb1kJOCG15A5pr34RA16M7rOU9H5zn+SB/pk+iYiFYAQCAisnP73ixkPyF7b1jqjtmZbiCV96wZfdzRtvc++7RtxOfK+j6E6+V0365YEeGgpWhKko+Y+HNLd3pr9SsIKVlBSn1mAlwhYSwPPvmmkN5jk0QTNPxzVzr2g/Kd5zuCLQjngGBwTasmdBlw1sBIaygkFZQiDNBMG9brjbytkegw5lDsAIAACgO80u5HWEL8s1atcLCW2ZqISEsJ7C5n8/3aJ5PdY3UZeQc2/MFnct5jdlyBDmybFQytR7PdIhzy8zyU1pWoNLScsJXzshbbjgr4NgV0oIUl3uc55rcYHf82Ny3zYzYpStA6c5AOXOmsTr8QxQQGOgKXDnBLNjfL18gs+dzNte+O8S5Qpp9TQHXmvNBhbRlzjPtsuIhWAEAAJTF8GZuXm02X06PLHTKZGoRA1qeIGf3c57PdB+n5bTlfszZt9ekyplz7MgpVmIEOLIVoDSFK+dcSeaNLCkr02GDlx1Fyw1iAbnn7HlnwPHn7bHrGrOfkie8uc+lFXDu+GuC7KPTL1BO/yDJ34S8IDkCguTnH6SgQNcNtk3AM492y9kPzHkMPuH8ifvBp33OFfLyPh/o72Akz0sEKwAAAFX2KZNhru0Mc+QNcyZc5QavwkJZnuOccHby86e7Jk1Oc2sAu+96dOSskTP8HU6FKt1u+TtZQsyMz4ycLWdNXZoClJET7kyoM4+uY1dIM0VTXKHNFdbMc2k515mglyH/nCDnDokntuV6vTs0ur+W/Mz0zCAb+uTvCnsOG/6C7MieCV/ucOcKY3kDn6OAc8dDW+CJAdGct/sOG/bMuRPbNmv7okMDVV4QrAAAAFDyYc4vZ0SuBDgKup+bO3ydELpcxwU8Z4NgWjGeyznOec6Zmecxy4zaZbgendn5uuZeU1d450so7GXmbDmynI7ccJfh3px5j/1zz+cNg64Q57o2VQFKzNtGbqhzBb385wJUt34jTb75OpUXBCsAAABUvvu5ldAo3Yn56KSclJXpCl82jOWENBO6ckOZOZd+wn5OcMt3bd7z7kdXeMu/7/4a6XJmph8PfNkZOWHPPJ8hv+ycEbw8I3smOoWUYOhbm9BFEsEKAAAAwOn4B7g2meqVJctxqmzkrn7pDmwF7rsf3cHtVNfm2c8Neqe+tl29s1WeEKwAAAAAFF79srS6oPLFr7Q7AAAAAADlHcEKAAAAALxEsAIAAAAALxGsAAAAAMBLBCsAAAAA8BLBCgAAAAC8RLACAAAAAC8RrAAAAADASwQrAAAAAPASwQoAAAAAvESwAgAAAAAvBXjbQEXkdDrtY0JCQml3BQAAAEApcmcCd0YoDMGqAImJifaxQYMGpd0VAAAAAGUkI0RHRxf6vMN5uuhVCWVnZ2vv3r2KjIyUw+Eo9YRsAt6uXbsUFRVVqn2pLHjPSx7vecni/S55vOclj/e8ZPF+lzze85Jj4pIJVXXr1pWfX+ErqRixKoB5w+rXr6+yxPwPw/80JYv3vOTxnpcs3u+Sx3te8njPSxbvd8njPS8ZpxqpcqN4BQAAAAB4iWAFAAAAAF4iWJVxwcHBmjJlin1EyeA9L3m85yWL97vk8Z6XPN7zksX7XfJ4z8seilcAAAAAgJcYsQIAAAAALxGsAAAAAMBLBCsAAAAA8BLBCgAAAAC8RLAqA2bOnKnGjRsrJCREPXr00NKlS095/fvvv6/WrVvb6zt06KCvvvqqxPpa3k2bNk3dunVTZGSkatasqZEjR2rDhg2nfM1rr70mh8ORbzPvPYrmwQcfPOn9M5/fU+Ez7jnzs+TE99tst9xyS4HX8/kuvh9++EHDhg1T3bp17fv1ySef5Hve1ISaPHmy6tSpo9DQUA0YMECbNm3y+d8Flcmp3vOMjAzdc8899mdFeHi4vWbs2LHau3evz382VSan+5yPGzfupPdv8ODBp22Xz7ln73dBP9fN9uSTTxbaJp/xkkewKmVz5szRhAkTbLnMFStWqFOnTho0aJBiY2MLvP6XX37RFVdcoeuvv16///67DQZmW7t2bYn3vTz6/vvv7S+YS5Ys0fz58+1fyAMHDlRycvIpX2fuaL5v377cbceOHSXW54qgXbt2+d6/n376qdBr+Yx7Z9myZfnea/M5Ny6//PJCX8Pnu3jMzwvzs9r8gliQ6dOn69///rdefPFF/frrr/aXffNzPTU1tdA2i/t3QWVzqvc8JSXFvmcPPPCAffzoo4/sP5gNHz7cpz+bKpvTfc4NE6Tyvn/vvPPOKdvkc+75+533fTbb7NmzbVC69NJLT9kun/ESZsqto/R0797decstt+QeZ2VlOevWreucNm1agdePGjXKOXTo0HznevTo4bzxxhvPeF8rotjYWHO7Aef3339f6DWvvvqqMzo6ukT7VZFMmTLF2alTpyJfz2fct26//XZns2bNnNnZ2QU+z+fbO+bnx8cff5x7bN7n2rVrO5988sncc3Fxcc7g4GDnO++847O/CyqzE9/zgixdutRet2PHDp/9bKrMCnrPr7nmGueIESOK1Q6fc999xs17369fv1New2e85DFiVYrS09O1fPlyO03Ezc/Pzx4vXry4wNeY83mvN8y/9hR2PU4tPj7ePlarVu2U1yUlJalRo0Zq0KCBRowYoT/++KOEelgxmGlQZnpD06ZNdeWVV2rnzp2FXstn3Lc/Y9566y1dd9119l82C8Pn23e2bdum/fv35/sMR0dH2ylPhX2GPfm7AKf/2W4+81WqVPHZzyacbNGiRXZafatWrXTTTTfp8OHDhV7L59x3Dhw4oC+//NLO7DgdPuMli2BVig4dOqSsrCzVqlUr33lzbP5iLog5X5zrUbjs7GzdcccdOvfcc9W+fftCrzN/YZgh908//dT+kmpe16tXL+3evbtE+1temV8ozTqeuXPn6oUXXrC/ePbp00eJiYkFXs9n3HfMHP24uDi7FqIwfL59y/05Lc5n2JO/C1A4M+XSrLkyU4rNNFdf/WzCydMA33jjDS1cuFBPPPGEnWo/ZMgQ+1kuCJ9z33n99dftWvFLLrnklNfxGS95AaXwNYEyway1Mut2TjffuGfPnnZzM790tmnTRi+99JIefvjhEuhp+Wb+onXr2LGj/UFvRkfee++9Iv1rGzz3yiuv2Pff/GtlYfh8oyIx62ZHjRplC4iYXyRPhZ9N3hkzZkzuvikcYt7DZs2a2VGs/v37l2rfKjrzj2Fm9Ol0hYb4jJc8RqxKUUxMjPz9/e2Qbl7muHbt2gW+xpwvzvUo2K233qovvvhC3333nerXr1+s1wYGBuqss87S5s2bz1j/KjIzNadly5aFvn98xn3DFKBYsGCB/va3vxXrdXy+veP+nBbnM+zJ3wUoPFSZz74p2nKq0SpPfjbh1MxUM/NZLuz943PuGz/++KMtzlLcn+0Gn/Ezj2BVioKCgtSlSxc7jO5mpuGY47z/gpyXOZ/3esP8BVLY9cjP/CumCVUff/yxvv32WzVp0qTYbZipDGvWrLGllFF8Zj3Pli1bCn3/+Iz7xquvvmrXPgwdOrRYr+Pz7R3zM8X8kpj3M5yQkGCrAxb2Gfbk7wIUHKrMehLzDwrVq1f3+c8mnJqZPmzWWBX2/vE5991MBPM+mgqCxcVnvASUQsEM5PHuu+/aalGvvfaa888//3SOHz/eWaVKFef+/fvt81dffbXz3nvvzb3+559/dgYEBDifeuop57p162zFl8DAQOeaNWtK8bsoP2666SZbAW3RokXOffv25W4pKSm515z4nk+dOtU5b94855YtW5zLly93jhkzxhkSEuL8448/Sum7KF/uvPNO+35v27bNfn4HDBjgjImJsRUZDT7jvmcqbTVs2NB5zz33nPQcn2/vJSYmOn///Xe7mb9Gn3nmGbvvrkD3+OOP25/jn376qXP16tW2eleTJk2cx44dy23DVPN67rnnivx3QWV3qvc8PT3dOXz4cGf9+vWdK1euzPezPS0trdD3/HQ/myq7U73n5rmJEyc6Fy9ebN+/BQsWOM8++2xnixYtnKmpqblt8Dn33c8VIz4+3hkWFuZ84YUXCmyDz3jpI1iVAeZ/AvNLUFBQkC1FumTJktznzj//fFvSNK/33nvP2bJlS3t9u3btnF9++WUp9Lp8Mj+sCtpMyenC3vM77rgj98+nVq1azosuusi5YsWKUvoOyp/Ro0c769SpY9+/evXq2ePNmzfnPs9n3PdMUDKf6w0bNpz0HJ9v73333XcF/hxxv6+m5PoDDzxg30/zS2T//v1P+rNo1KiR/UeDov5dUNmd6j03vzQW9rPdvK6w9/x0P5squ1O95+YfIwcOHOisUaOG/Ycv897ecMMNJwUkPue++7livPTSS87Q0FB7C4eC8BkvfQ7zn5IYGQMAAACAioo1VgAAAADgJYIVAAAAAHiJYAUAAAAAXiJYAQAAAICXCFYAAAAA4CWCFQAAAAB4iWAFAAAAAF4iWAEAAACAlwhWAAB4yeFw6JNPPintbgAAShHBCgBQro0bN84GmxO3wYMHl3bXAACVSEBpdwAAAG+ZEPXqq6/mOxccHFxq/QEAVD6MWAEAyj0TomrXrp1vq1q1qn3OjF698MILGjJkiEJDQ9W0aVN98MEH+V6/Zs0a9evXzz5fvXp1jR8/XklJSfmumT17ttq1a2e/Vp06dXTrrbfme/7QoUO6+OKLFRYWphYtWuizzz7Lfe7o0aO68sorVaNGDfs1zPMnBkEAQPlGsAIAVHgPPPCALr30Uq1atcoGnDFjxmjdunX2ueTkZA0aNMgGsWXLlun999/XggUL8gUnE8xuueUWG7hMCDOhqXnz5vm+xtSpUzVq1CitXr1aF110kf06R44cyf36f/75p77++mv7dU17MTExJfwuAADOJIfT6XSe0a8AAMAZXmP11ltvKSQkJN/5f/7zn3YzI1b/93//Z8OM2znnnKOzzz5b//nPfzRr1izdc8892rVrl8LDw+3zX331lYYNG6a9e/eqVq1aqlevnq699lo98sgjBfbBfI37779fDz/8cG5Yi4iIsEHKTFMcPny4DVJm1AsAUDGxxgoAUO717ds3X3AyqlWrlrvfs2fPfM+Z45UrV9p9M4LUqVOn3FBlnHvuucrOztaGDRtsaDIBq3///qfsQ8eOHXP3TVtRUVGKjY21xzfddJMdMVuxYoUGDhyokSNHqlevXl5+1wCAsoRgBQAo90yQOXFqnq+YNVFFERgYmO/YBDITzgyzvmvHjh12JGz+/Pk2pJmphU899dQZ6TMAoOSxxgoAUOEtWbLkpOM2bdrYffNo1l6Z6XtuP//8s/z8/NSqVStFRkaqcePGWrhwoVd9MIUrrrnmGjttccaMGXr55Ze9ag8AULYwYgUAKPfS0tK0f//+fOcCAgJyC0SYghRdu3ZV79699fbbb2vp0qV65ZVX7HOmyMSUKVNs6HnwwQd18OBB3Xbbbbr66qvt+irDnDfrtGrWrGlHnxITE234MtcVxeTJk9WlSxdbVdD09YsvvsgNdgCAioFgBQAo9+bOnWtLoOdlRpvWr1+fW7Hv3Xff1c0332yve+edd9S2bVv7nCmPPm/ePN1+++3q1q2bPTbroZ555pnctkzoSk1N1b/+9S9NnDjRBrbLLrusyP0LCgrSpEmTtH37dju1sE+fPrY/AICKg6qAAIAKzax1+vjjj23BCAAAzhTWWAEAAACAlwhWAAAAAOAl1lgBACo0ZrwDAEoCI1YAAAAA4CWCFQAAAAB4iWAFAAAAAF4iWAEAAACAlwhWAAAAAOAlghUAAAAAeIlgBQAAAABeIlgBAAAAgLzz/9Eei01cjYROAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 170
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "3. What happens if you add several Dense layers without specifying the activation function?\n",
    "\n",
    "4. How are the weights in each dense layer initialized as default? How are the bias weights initialized?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "\n",
    "3. Each layer is linear by default $a(x) = x)$; the model as a whole is a linear transformation if no activations are applied.\n",
    "4. Weights are being initialized using glorot_uniform in $[-\\sqrt{\\frac{6}{n_{in} + n_{out}}}, \\sqrt{\\frac{6}{n_{in} + n_{out}}}]$; Bias weights are initialized as vectors of zeros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Adressing class imbalance**\n",
    "\n",
    "This dataset is rather unbalanced with the majority of the samples belonging to class=1. We need to define class weights so that the training pays more attention to the class with fewer samples. We use the [`compute_class_weight`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) function from `scikit-learn`.\n",
    "\n",
    "You need to call the function something like this\n",
    "```python\n",
    "class_weights = class_weight.compute_class_weight(class_weight = , classes = , y = )\n",
    "```\n",
    "\n",
    "otherwise it will through an error."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:09.264889Z",
     "start_time": "2026-02-27T10:01:08.970724Z"
    }
   },
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Calculate class weights\n",
    "value1, value2 = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(Ytrain), y=Ytrain)\n",
    "\n",
    "# Print the class weights\n",
    "print(value1, value2)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Convert class weights into a dictionary that can be used as input to the model.fit() function\n",
    "\n",
    "class_weights = {0: value1,\n",
    "                 1: value2}\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1372876783033035 0.5947943609097803\n"
     ]
    }
   ],
   "execution_count": 171
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model using class weights. 2 hidden layers with 20 nodes each\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:29.820857Z",
     "start_time": "2026-02-27T10:01:24.145901Z"
    }
   },
   "source": [
    "# Setup some training and hyper-parameters\n",
    "batch_size = 10000\n",
    "epochs = 20\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Specify the learning rate, the input shape and the loss function\n",
    "learning_rate = 0.1\n",
    "input_shape = (Xtrain.shape[1],)\n",
    "loss = BinaryCrossentropy()\n",
    "\n",
    "# Build the model\n",
    "model2 = build_DNN(input_shape=input_shape,\n",
    "                   n_hidden_units=20,\n",
    "                   n_hidden_layers=2,\n",
    "                   loss=loss,\n",
    "                   learning_rate=learning_rate)\n",
    "\n",
    "# Train the model, provide training data and validation data\n",
    "history2 = model2.fit(Xtrain, Ytrain,\n",
    "                      validation_data=(Xval, Yval),\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      class_weight=class_weights,\n",
    "                      verbose=1)\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 1s 7ms/step - loss: 0.6443 - accuracy: 0.8358 - val_loss: 0.5739 - val_accuracy: 0.8893\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.8881 - val_loss: 0.4106 - val_accuracy: 0.8852\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8839 - val_loss: 0.3130 - val_accuracy: 0.8835\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8836 - val_loss: 0.2820 - val_accuracy: 0.8846\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.8856 - val_loss: 0.2703 - val_accuracy: 0.8870\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.8886 - val_loss: 0.2621 - val_accuracy: 0.8906\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.8911 - val_loss: 0.2567 - val_accuracy: 0.8921\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2082 - accuracy: 0.8921 - val_loss: 0.2528 - val_accuracy: 0.8930\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2042 - accuracy: 0.8940 - val_loss: 0.2494 - val_accuracy: 0.8954\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.8956 - val_loss: 0.2463 - val_accuracy: 0.8965\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.8964 - val_loss: 0.2441 - val_accuracy: 0.8973\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.8973 - val_loss: 0.2415 - val_accuracy: 0.8981\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.8981 - val_loss: 0.2400 - val_accuracy: 0.8988\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1919 - accuracy: 0.8986 - val_loss: 0.2376 - val_accuracy: 0.8993\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.8991 - val_loss: 0.2357 - val_accuracy: 0.8998\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.8999 - val_loss: 0.2349 - val_accuracy: 0.9008\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9010 - val_loss: 0.2331 - val_accuracy: 0.9023\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9025 - val_loss: 0.2320 - val_accuracy: 0.9035\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.9036 - val_loss: 0.2316 - val_accuracy: 0.9044\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.9044 - val_loss: 0.2308 - val_accuracy: 0.9050\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:33.368567Z",
     "start_time": "2026-02-27T10:01:29.827045Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Evaluate model on test data\n",
    "score = model2.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "print('Test loss: %.8f' % score[0])\n",
    "print('Test accuracy: %.8f' % score[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23228835\n",
      "Test accuracy: 0.90445995\n"
     ]
    }
   ],
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:01:33.786313Z",
     "start_time": "2026-02-27T10:01:33.398216Z"
    }
   },
   "source": [
    "plot_results(history2)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T10:02:07.851576Z",
     "start_time": "2026-02-27T10:02:07.292432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for question 10\n",
    "model_4_50 = build_DNN(input_shape=(Xtrain.shape[1],),\n",
    "                       n_hidden_layers=4,\n",
    "                       n_hidden_units=50,\n",
    "                       loss=BinaryCrossentropy)\n",
    "model_4_50.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_205 (Dense)           (None, 50)                4700      \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12401 (48.44 KB)\n",
      "Trainable params: 12401 (48.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 176
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Additional questions**\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "5. Why do we have to use a batch size? Why can't we simply use all data at once? This is more relevant for even larger datasets.\n",
    "\n",
    "6. What is the processing time for one training epoch when the batch size is 100? What is the processing time for one epoch when the batch size is 1,000? What is the processing time for one epoch when the batch size is 10,000? Explain the results. \n",
    "\n",
    "7. How many times are the weights in the DNN updated in each training epoch if the batch size is 100? How many times are the weights in the DNN updated in each training epoch if the batch size is 1,000? How many times are the weights in the DNN updated in each training epoch if the batch size is 10,000?  \n",
    "\n",
    "8. What limits how large the batch size can be?\n",
    "\n",
    "9.  Generally speaking, how is the learning rate related to the batch size? If the batch size is decreased, how should the learning rate be changed?\n",
    "10. How many trainable parameters does the network with 4 dense layers with 50 nodes each have, compared to the initial network with 2 layers and 20 nodes per layer? Hint: use model.summary()\n",
    "   \n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "5. The batch size regulates when the model should update its weights. Smaller batch sizes lead to better generalization since the weights are updated more often, higher batch sizes provide faster epoch times but model likely generalizes worse. Regulating batch sizes also regulates computational feasibility.\n",
    "6. Average batch processing time (simplified): <br>\n",
    "    6.1 $b=100$: 3s with 550us/step<br>\n",
    "    6.2 $b=1000$: 1s with 920us/step<br>\n",
    "    6.3 $b=10000$: 0s with 3ms/step<br>\n",
    "    Since the weights need to be updated less  often with a greater batch size, the epoch iteration time decreases steadily, with increasing step times\n",
    "7. rule: dataset of $N$ samples and batch_size $b$ updates weights $u = \\lceil \\frac{N}{b} \\rceil$ (rounded up) times; so in our case of $N=534895$<br>\n",
    "   7.1 if $b=100$ then $u = \\frac{534895}{100} = 5349$ <br>\n",
    "   7.2 if $b=1000$ then $u = \\frac{534895}{1000} = 535$ <br>\n",
    "   7.3 if $b=10000$ then $u = \\frac{534895}{10000} = 54$ <br>\n",
    "8. Minimum batch size: 1, maximum batch size (theoretical): dataset sample size, maximum batch size (practical): Memory size\n",
    "9. Since the learning rate controls the weight updates, when using a smaller batch size, the learning rate should be decreased since the gradients are more noisy and less accurate.\n",
    "10. 4 dense layers and 50 nodes: $50n_{in} + 7751 = 12401$ // 2 dense layers and 20 nodes: $20n_{in} +461 = 2321$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Model regularization**\n",
    "\n",
    "In the following sections you will explore methods for model normalization, namely `BatchNormalization` and `Dropout`, and also look at the impact of ofter activation functions and optimization algorithms.\n",
    "#### **2.3.1 Batch normalization**\n",
    "\n",
    "Now add batch normalization after each hidden dense layer in `build_DNN`.\n",
    "\n",
    "See the [documentation](https://keras.io/layers/normalization/) for information about how to call the function.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "11. Why is batch normalization important when training deep networks?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "11. Batch normalization normalizes the inputs to the next layer to a predictable range, making issues with exploding/vanishing gradients less likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers, 20 nodes each, class weights and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:19:33.893191Z",
     "start_time": "2026-02-27T10:19:20.740933Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "model6 = build_DNN(input_shape=(Xtrain.shape[1],),\n",
    "                   n_hidden_layers=2,\n",
    "                   n_hidden_units=20,\n",
    "                   learning_rate=0.1,\n",
    "                   loss=BinaryCrossentropy(),\n",
    "                   use_bn=True\n",
    "                   )\n",
    "\n",
    "history6 = model6.fit(Xtrain, Ytrain,\n",
    "                      validation_data=(Xval, Yval),\n",
    "                      class_weight=class_weights,\n",
    "                      epochs=20,\n",
    "                      batch_size=10000,\n",
    "                      verbose=1)\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = model6.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.8f' % score[0])\n",
    "print('Test accuracy: %.8f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history6)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.3563 - accuracy: 0.8772 - val_loss: 0.4298 - val_accuracy: 0.8929\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.8874 - val_loss: 0.3227 - val_accuracy: 0.8988\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.2238 - accuracy: 0.8943 - val_loss: 0.2634 - val_accuracy: 0.9016\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.2104 - accuracy: 0.8978 - val_loss: 0.2322 - val_accuracy: 0.9020\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.2017 - accuracy: 0.9002 - val_loss: 0.2187 - val_accuracy: 0.9032\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1957 - accuracy: 0.9028 - val_loss: 0.2138 - val_accuracy: 0.9052\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1915 - accuracy: 0.9064 - val_loss: 0.2151 - val_accuracy: 0.9063\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1884 - accuracy: 0.9077 - val_loss: 0.2184 - val_accuracy: 0.9073\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1860 - accuracy: 0.9086 - val_loss: 0.2221 - val_accuracy: 0.9082\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1842 - accuracy: 0.9092 - val_loss: 0.2221 - val_accuracy: 0.9093\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.9098 - val_loss: 0.2227 - val_accuracy: 0.9100\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.1813 - accuracy: 0.9103 - val_loss: 0.2226 - val_accuracy: 0.9103\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.1802 - accuracy: 0.9108 - val_loss: 0.2211 - val_accuracy: 0.9106\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1793 - accuracy: 0.9110 - val_loss: 0.2214 - val_accuracy: 0.9108\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1784 - accuracy: 0.9115 - val_loss: 0.2193 - val_accuracy: 0.9111\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1776 - accuracy: 0.9119 - val_loss: 0.2169 - val_accuracy: 0.9114\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1768 - accuracy: 0.9121 - val_loss: 0.2158 - val_accuracy: 0.9118\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1762 - accuracy: 0.9123 - val_loss: 0.2143 - val_accuracy: 0.9121\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1755 - accuracy: 0.9125 - val_loss: 0.2182 - val_accuracy: 0.9120\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.1748 - accuracy: 0.9126 - val_loss: 0.2163 - val_accuracy: 0.9128\n",
      "Test loss: 0.21785510\n",
      "Test accuracy: 0.91200906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAFzCAYAAAA9opjHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABY8klEQVR4nO3dB3xV9f3/8Xf2gCQQNsjeIKBMUXEhw40tP3ed1f5c1Z9a0Vq3ljpqbdW/ttatdbXVWgez7gUFUWTJHjLCTAIh+/4fn+/NvdxAEgLJzbn35vV8PI73nHPPPeebyzXJO9/v93PifD6fTwAAAACAgxZ/8C8FAAAAABiCFQAAAADUEcEKAAAAAOqIYAUAAAAAdUSwAgAAAIA6IlgBAAAAQB0RrAAAAACgjghWAAAAAFBHiXU9QSwqLy/X+vXrlZGRobi4OK+bAwAAAMAjPp9P+fn5at++veLjq++XIlhVwUJVx44dvW4GAAAAgAixdu1aHXLIIdU+T7CqgvVUBd68zMxMr5sDAAAAwCN5eXmu0yWQEapDsKpCYPifhSqCFQAAAIC4/UwRongFAAAAANQRwQoAAAAA6ohgBQAAAAB1xBwrAAAA4ADLb5eWlqqsrMzrpqAeJCQkKDExsc63WSJYAQAAALVUXFysDRs2qKCgwOumoB6lp6erXbt2Sk5OPuhzEKwAAACAWigvL9fKlStdD4fdLNZ+Ca9rLwe87320sLx582b3b9uzZ88abwJcE4IVAAAAUAv2C7iFK7unkfVwIDakpaUpKSlJq1evdv/GqampB3UeilcAAAAAB+BgezQQ2/+mfCoAAAAAoI4IVpHM55M2LZC+/rPXLQEAAABQA4JVJCvKl/58rPTBzdKWpV63BgAAAAjq0qWLHn300Vof/9FHH7liHzt27FAsIlhFstRMqesx/vXF73rdGgAAAEQhCzM1LXfddddBnXf27Nm64ooran38kUce6UrVZ2VlKRZRFTDS9TlFWj5TWvSudPT/ed0aAAAARBkLMwGvv/667rjjDi1ZsiS4r2nTppXKj9uNj+2GufvTqlWrA2pHcnKy2rZtq1hFj1U0BCvFST/+V8pb73VrAAAAEMKCSEFxaYMvdt3asjATWKy3yHqpAtuLFy9WRkaGPvjgAw0ZMkQpKSn67LPPtHz5cp1xxhlq06aNC17Dhg3TjBkzahwKGBcXp7/+9a8688wzXTl6uyfUO++8U+1QwOeff17NmjXT1KlT1bdvX3ed8ePHVwqCpaWl+uUvf+mOa9GihSZNmqSLLrpIEyZMUKShxyrSZbSVDhkmrZslLXlfGvZzr1sEAACACrtLytTvjqkNft2F94xTenL9/Sp/yy236OGHH1a3bt3UvHlzrV27VieffLLuv/9+F7ZefPFFnXbaaa6nq1OnTtWe5+6779aDDz6ohx56SI899pjOP/98d3+o7OzsKo8vKChw133ppZdcyfMLLrhAN910k1555RX3/AMPPODWn3vuORe+/vjHP+rtt9/W8ccfr0hDj1XU9FrJPxwQAAAAqGf33HOPxowZo+7du7sQNGjQIP3iF7/QoYce6nqe7r33XvdcaA9UVS6++GKde+656tGjh377299q586dmjVrVrXHl5SU6KmnntLQoUM1ePBgXXPNNZo5c2bweQtnt956q+sF69Onjx5//HHXexWJ6LGKBn1Pk2bcKa36VNq9XUpr7nWLAAAAICktKcH1Hnlx3fpkwSaUBSIravHee++5oXk2JG/37t1as2ZNjecZOHBgcL1JkybKzMxUTk5OtcfbkEELbAHt2rULHp+bm6tNmzZp+PDhwecTEhLckMXy8nJFGoJVNGjRXWrVV9q8SFo6XRp4ltctAgAAQMW8ovockucVC0GhbDje9OnT3TA9631KS0vTxIkTVVxcXON5kpKS9nl/agpBVR1/IPPHIglDAaNF31P9j4v+7XVLAAAAEOM+//xzN6zPhuANGDDAFbpYtWpVg7YhKyvLFc+wsu4BVrFw7ty5ikQEq2ibZ7VshlSy2+vWAAAAIIbZvKp//vOfmjdvnr799ludd955ngy/u/baazV58mT961//coUzrrvuOm3fvt31bEUaglW0aHeYlNVRKimQVnzkdWsAAAAQwx555BFXHdBu6mvVAMeNG+eKSzS0SZMmuWIYF154oUaOHOlKsltbUlNTFWnifNE6iDGM8vLyXNejTZizCXcR44NJ0tdPSYddIE14wuvWAAAANCqFhYVauXKlunbtGpG/2DcG5eXlruz6WWed5SoVNsS/bW2zAT1W0Tgc0O5nVVbqdWsAAACAsFq9erWefvpp/fDDD5o/f76uvPJKF4BsaGKkIVhFk05HSmnZ0u5t0tqvvG4NAAAAEFbx8fF6/vnnNWzYMB111FEuXM2YMcP1WkWa6K8N2ZgkJEq9T5LmveK/WXCXo71uEQAAABA2HTt2dBUKowE9VtE6HHDxuxLT4wAAAICIQLCKNt1PkJLSpdy10sbvvG4NAAAAAIJVFEpKk3qM9q/bcEAAAAAAniNYRaM+p+4ZDggAAADAcwSraNRrnBSfKOUslLYu97o1AAAAQKNHsIpGac33VARc/J7XrQEAAECMO+6443T99dcHt7t06aJHH320xtfExcXp7bffrvO16+s84UawilYMBwQAAEAtnHbaaRo/fnyVz3366acuuHz33YEVRZs9e7auuOIK1ae77rpLhx122D77N2zYoJNOOkmRjmAV7WXX186S8jd53RoAAABEqMsuu0zTp0/XunXr9nnuueee09ChQzVw4MADOmerVq2Unp6uhtC2bVulpKQo0hGsolVme6nDEEk+acn7XrcGAAAAEerUU091Qej555+vtH/nzp168803NWHCBJ177rnq0KGDC0sDBgzQq6++WuM59x4KuHTpUh1zzDFKTU1Vv379XJDb26RJk9SrVy93jW7duun2229XSUmJe87advfdd+vbb791PWi2BNq791DA+fPn64QTTlBaWppatGjhes7sawm4+OKL3df08MMPq127du6Yq6++OnitcEkM69kR/l6rH+f4hwMOvcTr1gAAADQ+Pp9UUtDw17X7msbF1erQxMREXXjhhS6o3HbbbS6oGAtVZWVluuCCC9y6BZ/MzEy99957+tnPfqbu3btr+PDh+z1/eXm5fvKTn6hNmzb6+uuvlZubW2k+VkBGRoZrQ/v27V04uvzyy92+m2++WWeffba+//57TZkyRTNmzHDHZ2Vl7XOOXbt2ady4cRo5cqQbjpiTk6Of//znuuaaayoFxw8//NCFKntctmyZO78NM7RrhgvBKpr1OU2aeY+04mOpMFdK3ffDBwAAgDCyUPXb9g1/3V+vl5Kb1PrwSy+9VA899JA+/vhjV4giMAzwpz/9qTp37qybbropeOy1116rqVOn6o033qhVsLIgtHjxYvcaC03mt7/97T7zon7zm99U6vGya7722msuWFnvU9OmTV0ItKF/1fnb3/6mwsJCvfjii2rSxP/1P/74424e2QMPPODCnWnevLnbn5CQoD59+uiUU07RzJkzwxqsGAoYzVr1klr2kspLpKX7drcCAAAAxsLFkUceqWeffdZtWy+OFa6w+VfWa3Xvvfe6IYDZ2dku4FhIWrNmTa3OvWjRInXs2DEYqoz1KO3t9ddf11FHHeWCk13DglZtrxF6rUGDBgVDlbFzWq/ZkiVLgvv69+/vQlWA9V5Z71Y40WMVC8MBP/vBPxxwwESvWwMAANC42JA86z3y4roHyEKU9UY98cQTrrfKhvode+yxrqfnj3/8o5szZeHKQosN5SsuLq635n755Zc6//zz3TwqG8pnw/yst+r3v/+9wiEpKanStg1/tPAVTgSrWBgO+Nkf/D1WJYVSUqrXLQIAAGg8bL7SAQzJ89JZZ52l6667zg2ns6F0V155pQscn3/+uc444ww318pYAPnhhx9cEYra6Nu3r9auXevKolvPkPnqq68qHfPFF1+4IYc2xytg9erVlY5JTk52vWf7u5bNpbK5VoFeK2t/fHy8evfuLS95PhTQErONsbQKIiNGjNCsWbNq9TpLuPZBsIofoXw+n+644w73j2pjNU888URXpSRmtT9cymgvFe+UVn7idWsAAAAQoWz4nRVxuPXWW10Isup5pmfPnq6Kn4UfG2r3i1/8Qps21f52Pvb7dq9evXTRRRe5qn42xDA0QAWuYcP+7Hf45cuX609/+pPeeuutSsdYJli5cqXmzZunLVu2qKioaJ9rWa+X5Qa7lhW7sOIU1gtnxTYC86saZbCycZY33HCD7rzzTs2dO9eNl7Suwf2Nf1y1apWb7DZq1Kh9nnvwwQfdP9RTTz3lqpJYkrVz2iS3mBQfv+eeVov/7XVrAAAAEMFsOOD27dvd78eBOVE212nw4MFunxW2sDlQe3de1MR6i9566y3t3r3bFbuwKn33339/pWNOP/10/d///Z+r3mfV+SzEWbn1UFZIw25kfPzxx7vy8FWVfLdS7Tb/a9u2bRo2bJgmTpyo0aNHu0IVXovzWRePR6yHyt6QwBth3Y428c1S5y233FLla6x70GrkW2UTS8M7duwI1rW3L8U+IDfeeGOwsomVe7T0al2G55xzTq3alZeX58Z92mut5GTEW/6h9NIEKb2ldNMPUvyeiXoAAACoH/aHeutR6dq1q+s1QeP4t82rZTbwrMfKJsPNmTPHdR0GGxMf77Ztclt17rnnHrVu3dql7b3Zm7Fx48ZK57Q3wQJcTee0bkZ7w0KXqNLlaCm1mVSwRVpbu6GUAAAAAOqPZ8HKxk1a79PeYyFt28JRVT777DM988wzevrpp6t8PvC6AzmnmTx5sgtggcV6zaJKQpLUa7x/3aoDAgAAAGhcxStqKz8/301Ks1DVsmXLej23TeCzrr3AYlVNok5gntWif/vvAA4AAACgwXhWbt3Ckd20a++KI7Zd1d2WrXqIFa2wuyoHBGrR2x2a7YZggdfZOQKlHgPbNkmuOikpKW6Jaj1GS4mp0o7V0qYFUttDvW4RAAAA0Gh41mNldeqHDBmimTNnVgpKtl3VnZrtbtHz58935RcDi1UXsaohtm7D92yymYWr0HPafCmrDljVOWOK3T+h+2j/OsMBAQAAgAbl6Q2CrdS61aAfOnSoK81od3u2m31dcskl7vkLL7xQHTp0cHOgrDrHoYdW7oVp1qyZewzdb3eJvu+++1ytfAtaVsbRKgUeSMnIqGXDAZe8Jy16Vzqu6qqKAAAAqBsPi2ojgv9NPQ1WdoOyzZs3uxv6WnEJG643ZcqUYPEJu4mYVQo8EDfffLMLZ1dccYUrxX700Ue7czaKkpi9T5LiEqRN86Xtq6TmXbxuEQAAQMxISkpyjwUFBUpLS/O6OahH9m8a+m8cdfexilRRdx+rUM+fKq36VBr3W2nk1V63BgAAIKZs2LDB/fHebv9jN6uNi4vzukmoA4tCFqpycnLcaLjQOg0Hmg087bFCGPSpCFY2HJBgBQAAUK8CxdLsF3HEjmbNmlVZQO9AEKxicZ7VlEnSmi+lnZulpq28bhEAAEDMsB4q69WwHquSkhKvm4N6YMP/rFp5XRGsYk2zjlK7w6QN86QfPpAGX+h1iwAAAGKO/SJeH7+MI3ZEzQ2CcYDDAY0NBwQAAAAQdgSrWNS3Ilit+FAqyve6NQAAAEDMI1jFolZ9pOzuUlmxtGyG160BAAAAYh7BKhZZ2U8rYmEYDggAAACEHcEqVvU9zf+4dJpUWux1awAAAICYRrCKVR2GSk3bSkV50qpPvG4NAAAAENMIVrEqPl7qc7J/neGAAAAAQFgRrGJZYJ7Vkvel8nKvWwMAAADELIJVLOtyjJSSJe3cJP34X69bAwAAAMQsglUsS0yWeo31ry/6t9etAQAAAGIWwaqxDAdc/K7k83ndGgAAACAmEaxiXY8xUkKKtG2FtHmx160BAAAAYhLBKtalNJW6H+9fpzogAAAAEBYEq0Y1HJB5VgAAAEA4EKwag94nS3Hx0oZvpR1rvG4NAAAAEHMIVo1Bk5ZSp5H+9cXve90aAAAAIOYQrBpjdUAAAAAA9Ypg1Vj0OdX/uPpzaddWr1sDAAAAxBSCVWPRvLPUdoDkK5d+mOJ1awAAAICYQrBqjL1WDAcEAAAA6hXBqjEGq+X/kYp3ed0aAAAAIGYQrBqTNv2l5l2k0kJp2UyvWwMAAADEDIJVYxIXx3BAAAAAIAwIVo1NIFhZAYuyEq9bAwAAAMQEglVj03G41KSVVJgrrfrM69YAAAAAMYFg1djEJ0i9T/avMxwQAAAAqBcEq8YoOM/qPam83OvWAAAAAFGPYNUYdTtWSs6Q8jdI67/xujUAAABA1CNYNUaJKVLPMf71xf/2ujUAAABA1CNYNVZ9TvE/LmKeFQAAAFBXBKvGqudYKSFZ2rpU2vyD160BAAAAohrBqrFKzZS6HutfZzggAAAAUCcEq8aM4YAAAABAvSBYqbEHqzhp/Vwp90evWwMAAABELYJVY9a0tdRxhH99yftetwYAAACIWgSrxi44HJB5VgAAAMDBIlg1dn1P9T+u+kwq2OZ1awAAAICoRLCKYAXFpXrq4+W66NlZKi0rD89FsrtJrftLvjJp6bTwXAMAAACIcQSrCJaUEK8nP1quj3/YrDmrt4fvQgwHBAAAAOqEYBXhwWp039ZufeqCTeEfDrhsplRcEL7rAAAAADGKYBXhxvZr6x6nLdwon88Xnou0HShldZJKd0srPgzPNQAAAIAY5nmweuKJJ9SlSxelpqZqxIgRmjVrVrXH/vOf/9TQoUPVrFkzNWnSRIcddpheeumlSsdcfPHFiouLq7SMHz9e0erYXq2UmhSvddt3a+GGvPBcJC6OmwUDAAAA0RqsXn/9dd1www268847NXfuXA0aNEjjxo1TTk5OlcdnZ2frtttu05dffqnvvvtOl1xyiVumTp1a6TgLUhs2bAgur776qqJVWnKCjunZyq1Pa4jhgD98IJWVhu86AAAAQAzyNFg98sgjuvzyy1046tevn5566imlp6fr2WefrfL44447Tmeeeab69u2r7t2767rrrtPAgQP12WefVTouJSVFbdu2DS7NmzdXNBvb3z8ccOqCjeG7SKeRUnoLafd2ac0X4bsOAAAAEIM8C1bFxcWaM2eOTjzxxD2NiY9329YjtT8232jmzJlasmSJjjnmmErPffTRR2rdurV69+6tK6+8Ulu3bq3xXEVFRcrLy6u0RJLRfVorIT5Oizfma83WMBWXiE+Qep/kX2c4IAAAABAdwWrLli0qKytTmzZtKu237Y0bq++Zyc3NVdOmTZWcnKxTTjlFjz32mMaMGVNpGOCLL77oQtcDDzygjz/+WCeddJK7VnUmT56srKys4NKxY0dFkuZNkjW8S3awiEXY9KkYDrj4PUuu4bsOAAAAEGM8L15xoDIyMjRv3jzNnj1b999/v5ujZT1UAeecc45OP/10DRgwQBMmTNC7777rjg09Zm+33nqrC2yBZe3atYo04/q3Cf9wwG7HS0lNpLx10oZ54bsOAAAAEGM8C1YtW7ZUQkKCNm2qXJDBtm1eVHVsuGCPHj1cRcAbb7xREydOdD1O1enWrZu71rJly6o9xuZkZWZmVloizZiKeVb/Xb1dW3YWheciSalSz4qhmQwHBAAAACI/WNlQviFDhrghewHl5eVue+TIkbU+j73G5khVZ926dW6OVbt27RTNOjRL04AOWW6E3oyFmxpgOCDBCgAAAKgtT4cC2jC+p59+Wi+88IIWLVrkCk3s2rXLVQk0F154oRumF2A9U9OnT9eKFSvc8b///e/dfawuuOAC9/zOnTv1q1/9Sl999ZVWrVrlQtoZZ5zherisjHu0CwwHnBbOYNVzrBSfKG1eLG2pvpcPAAAAwB6J8tDZZ5+tzZs364477nAFK2x435QpU4IFLdasWeOG/gVY6LrqqqtcL1RaWpr69Omjl19+2Z3H2NBCu7+VBbUdO3aoffv2Gjt2rO6991433C/aWdn1h6f9oM+WbtHOolI1TQnDP19aM6nrMdLy//h7rY6+vv6vAQAAAMSYOJ/VLUclVm7dqgNaIYtImm9l/1Qn/P5jrdyyS4+fd7hOHdg+PBea/VfpvRulQ4ZJP58RnmsAAAAAMZQNoq4qYGMWFxensf0qhgMuCONwwN6n+B/XzZbyNoTvOgAAAECMIFhF4XBA8+HiHBWXlofnIpnt/L1VZsn74bkGAAAAEEMIVlHm8I7N1CojRflFpfpyxdbwXahPRa8V1QEBAACA/SJYRZn4+DiN6dcANwvuc5r/ceUn0u4d4bsOAAAAEAMIVlEoMM9q+sJNKi8PU+2Rlj2kVn2k8lJp6fTwXAMAAACIEQSrKHRk95bKSEnU5vwifbN2RwMMB/x3+K4BAAAAxACCVRRKTozX8X1au/VpC8M5HPBU/+PSGVLJ7vBdBwAAAIhyBKsoNbb/nrLrYbsVWfvDpcwOUskuacXH4bkGAAAAEAMIVlHquN6tlZwQ724WvDRnZ3guEhfHcEAAAACgFghWUappSqKO6tHCrU9b0ADDAZd8IJWVhu86AAAAQBQjWEWxcRU3C566YFP4LtL5KCmtuVSwVVr7dfiuAwAAAEQxglUUG923jRutN//HXK3fEabiEgmJUq+T/OvcLBgAAACoEsEqirXKSNHQzs0bYDhgxTyrRe9K4SqUAQAAAEQxglWMDAectjCMwwG7nyAlpkm5a6SN88N3HQAAACBKEayi3Nh+/mD19cpt2r6rODwXSU6Xeoz2rzMcEAAAANgHwSrKdWqRrj5tM1RW7tPMxTnhrw5owwEBAAAAVEKwigFjA8MBwznPqtc4KS5BylkgbVsRvusAAAAAUYhgFQPG9W/jHj9Zulm7i8vCc5H0bKnL0f71xe+F5xoAAABAlCJYxYB+7TLVoVmaCkvKXbgKG4YDAgAAAFUiWMWAuLi4kJsFN0DZdbtR8M4wzucCAAAAogzBKsaGA85clKPSsvLwXCSrg9R+sCSftOT98FwDAAAAiEIEqxgxtEu2spskK3d3iWat3NYwNwsGAAAA4BCsYkRCfJxO7Ns6/DcL7nua/3Hlx1JhXviuAwAAAEQRglUM3izYyq77fL7wXKRVb6llL6msWJr1l/BcAwAAAIgyBKsYcnTPlkpPTtD63ELN/zE3fBc65mb/46ePSPlhLJYBAAAARAmCVQxJTUrQsb1aufVpC8I4HHDARKnDUKlklzTz3vBdBwAAAIgSBKsY0yBl1+PipPG/86/Pe0VaPy981wIAAACiAMEqxhzfu7US4+O0NGenVmzeGb4LdRwmDfgff+n1qb+WwjWnCwAAAIgCBKsYk5WepJHdW4S/OqA58S4pMU1a/bm06J3wXgsAAACIYASrGDS2/57qgGGVdYh05LX+9Wm3SyWF4b0eAAAAEKEIVjFoTN827nHumh3KyQtz2DnqOimjnbRjtfT1U+G9FgAAABChCFYxqG1Wqg7r2KxhhgOmNJVG3+lf/+RhaWdOeK8HAAAARCCCVYwa279NwwQrM/Bsqf3hUnG+9J/7wn89AAAAIMIQrGK87PqXy7cor7AkvBeLj5fGTfavz31R2jg/vNcDAAAAYiFYrV27VuvWrQtuz5o1S9dff73+8pe/1GfbUAfdWzVV91ZNVFLm04eLG2B4XueRUv8z/eXXp9xK+XUAAAA0KgcVrM477zx9+OGHbn3jxo0aM2aMC1e33Xab7rnnnvpuI+rYazVtQQMMBzQn3i0lpEirPpWWvN8w1wQAAACiNVh9//33Gj58uFt/4403dOihh+qLL77QK6+8oueff76+24g6BquPluSosKQs/Bds3lk68hr/+tTbpNKi8F8TAAAAiNZgVVJSopSUFLc+Y8YMnX766W69T58+2rBhQ/22EAdtQIcstc1M1a7iMn2xfEvDXPTo/5OatpG2r5RmMTQUAAAAjcNBBav+/fvrqaee0qeffqrp06dr/Pjxbv/69evVokWL+m4jDlJ8fFywOuDU7xtoOGBKhnTC7f71jx+SdjVQoAMAAACiLVg98MAD+vOf/6zjjjtO5557rgYNGuT2v/POO8EhgogMY/v5hwPOWLRJZeUNVFDisPOktgOlolzpw982zDUBAAAAD8X5fAdXvq2srEx5eXlq3rx5cN+qVauUnp6u1q1bK5rZ15WVlaXc3FxlZmYqmpWUlWvIvdOVV1iqN34xUsO7ZjfMhVd9Jj1/ihQXL/3v51Kbfg1zXQAAAMCDbHBQPVa7d+9WUVFRMFStXr1ajz76qJYsWRL1oSrWJCXEa3TfipsFL9jYcBfucrTU9zTJVy5N/TXl1wEAABDTDipYnXHGGXrxxRfd+o4dOzRixAj9/ve/14QJE/Tkk0/WdxtRR+MC86wWbtRBdlAenDH3SAnJ0ooPpaXTGu66AAAAQDQEq7lz52rUqFFu/e9//7vatGnjeq0sbP3pT3+q7zaijo7p1UopifFau223Fm/Mb7gLZ3eTjrjSv269VmUlDXdtAAAAINKDVUFBgTIyMtz6tGnT9JOf/ETx8fE64ogjXMA6EE888YS6dOmi1NRU1/NlNxquzj//+U8NHTpUzZo1U5MmTXTYYYfppZdeqnSM9cjccccdateundLS0nTiiSdq6dKlaszSkxM1qmcrtz61IYcDmlE3SU1aSVuXSbP/2rDXBgAAACI5WPXo0UNvv/221q5dq6lTp2rs2LFuf05OzgEVe3j99dd1ww036M4773S9YFZdcNy4ce48VcnOztZtt92mL7/8Ut99950uueQSt1gbAh588EHXa2bl4L/++msXwOychYWFaswCwwGnLWigsusBqZnS8bf51z+aLBVsa9jrAwAAAJFaFdCG/5133nmuMuAJJ5zg7mVlJk+erE8++UQffPBBrc5jPVTDhg3T448/7rbLy8vVsWNHXXvttbrllltqdY7BgwfrlFNO0b333ut6q9q3b68bb7xRN910k3veqnfYUMXnn39e55xzTqOrChiwbVexht43XVZx/dObj1fH7PSGu3h5mfTnY6RN30vDfyGd/GDDXRsAAACI1KqAEydO1Jo1a/Tf//63Um/R6NGj9Yc//KFW5yguLtacOXPcUL1gY+Lj3bb1SO2PhaiZM2e6SoTHHHOM27dy5Upt3Lix0jntTbAAV9M5rcKhvWGhS6zJbpIcLLXe4MMB4xOkcRX3s7LhgJuXNOz1AQAAgDA7qGBl2rZtq8MPP1zr16/XunXr3D67OXCfPn1q9fotW7a4Hi/rTQpl2xaOqmNJsWnTpkpOTnY9VY899pjGjBnjngu87kDPaT1tFsACi/WaxfLNgqctbODhgKbbsVLvUyRfmTS1YmggAAAA0JiDlQ3Zu+eee1wI6dy5s1usoIQNx7PnwsmKZsybN0+zZ8/W/fff7+ZoffTRR3U656233uoCW2CxuWOxaGzFPKv/rtqmrTuLPGjAvVJ8krRsurR0RsNfHwAAAAiTxIN5kRWQeOaZZ/S73/1ORx11lNv32Wef6a677nJFIizw7E/Lli2VkJCgTZsq957YtvWGVceGC1rxDGNVARctWuR6nI477rjg6+wcVhUw9Jx2bHVSUlLcEusOaZ6u/u0ztWB9nmYuytFZwxq4Z65Fd2nEL6QvH/eXX+92nJRwUB9BAAAAIPp7rF544QX99a9/1ZVXXqmBAwe65aqrrtLTTz/tikTUhg3lGzJkiJsnFWC9XbY9cuTIWrfFXmNzpEzXrl1duAo9p82XsuqAB3LOWDauf1tv5lkFHPMrKS1b2rJEmvOcN20AAAAAIiFYbdu2rcq5VLbPnqstG8ZnYcyCmvU8WVDbtWuXK6FuLrzwQjdML8B6pqwC4YoVK9zxv//97919rC644AL3fFxcnK6//nrdd999eueddzR//nx3DqsUOGHChIP5UmM2WH26bIt2FZU2fAPSmkknVMyx+vB+aff2hm8DAAAAUM8OahyW3W/KSqTb/aJC2T7rvaqts88+W5s3b3Y39LXiEjZcb8qUKcHiE1Z50Ib+BVjosp4xK5ZhN/+1IPfyyy+78wTcfPPN7rgrrrhCO3bs0NFHH+3OaTcghtSrTVN1bpGu1VsL9PEPm3XygD1DJhvM4IulWVYdcJH08YPS+MkN3wYAAADA6/tYffzxx64iX6dOnYJD7KycuRV9eP/99zVq1ChFs1i8j1Wo376/SH/5ZIXOOKy9/njO4d40YtlM6eWfSPGJ0lVfSy398+YAAACARnMfq2OPPVY//PCDzjzzTNcrZMtPfvITLViwwA3NQ2Qb28/fI/ifxTkqLg1vFcdq9Rgt9RwnlZdK037jTRsAAAAAL3usqvPtt99q8ODB7v5U0SzWe6zKyn0a8duZ2rKzSC9eOlzH9GrlTUM2/yA9OdIfrn72ttT9eG/aAQAAAHjRY4XolhAfpzH9Wrv1aQs9qg5oWvWShv3cv27l18s8KKYBAAAA1AOCVSM1tqI64LQFm1ReXm+dlgfu2ElSajMpZ6H0zYvetQMAAACoA4JVI3Vk9xZqmpKonPwifbtuh3cNSc+Wjv+1f/0/90mFud61BQAAAGiIcutWoKImVsQC0SElMUHH9W6ld7/boKkLNunwTs29a8zQS6XZf5W2/CB98pA09j7v2gIAAACEu8fKJm3VtHTu3NndkBfRdbNgT+dZmYQkaez9/vWvnpK2Lve2PQAAAEA4e6yee+65Az0/Ipj1WCUnxGvF5l1alpOvHq0zvGtMzzFS99HS8pnS9Dukc17xri0AAADAAWKOVSOWkZqkI3u0cOs2HNBTcXHSuPuluARp8bvSyk+8bQ8AAABwAAhWjdzYfoHqgB4PBzSt+/rnW5kpv5bKo/t+aAAAAGg8CFaN3In9WrvOom/X5WpD7m6vmyMdd6uUkiVtmi/NYzggAAAAogPBqpFrnZGqwRUVAacv9Hg4oGnSQjpukn995r1SYZ7XLQIAAAD2i2AFjevfxj1OjYThgGbY5VJ2d2lXjvTZI163BgAAANgvghWC86y+WrFNuQUlXjdHSkz2F7IwXz4hbV/ldYsAAACAGhGsoC4tm6h3mwyVlfs0c3EEDAc0vcZLXY+Vyoql6Xd63RoAAACgRgQrROZwQFd+/bdSXLy08G1p9RdetwgAAACoFsEKztj+/uGAH/+wWbuLI6TMedtDpcEX+den3CKVl3vdIgAAAKBKBCs4/dtnqkOzNBWWlOvTpZsVMY6/TUrJlDZ8K337qtetAQAAAKpEsIITFxenMf38wwGnRULZ9YCmraRjbvKvz7xHKtrpdYsAAACAfRCsEDSuYjjgzEWbVFoWQcPuRvyv1LyLtHOj9PmjXrcGAAAA2AfBCkHDujRX8/QkbS8o0exV2xUxElOksff51794TNqxxusWAQAAAJUQrBCUmBCv0X0jrDpgQJ9TpS6jpNJCacZdXrcGAAAAqIRghSqHA05fuEk+n08RI1B+XXHS9/+Q1nztdYsAAACAIIIVKhnVs6XSkhL0447dWrA+TxGl3UDp8Av861Nvpfw6AAAAIgbBCpWkJiXo2F6tInM4oDnhdim5qfTjHGn+m163BgAAAHAIVtjH2P4VZdcXRFDZ9YCMNtKoG/3rNteqeJfXLQIAAAAIVtjX6D5tlBgfpyWb8rVqSwQGlyOukpp1kvLX+6sEAgAAAB4jWGEfWelJOqJbC7c+bWEEDgdMSpXG3ONf/+xRKfdHr1sEAACARo5ghRqHA06NxOGApt8EqdNIqXS3NPNur1sDAACARo5ghSqN6ecPVnPXbFdOfqEijpVfHz/ZX379u9eldXO8bhEAAAAaMYIVqtQuK02DDsmS3cpqxsIcRaT2h0uDzvWvT7lFrrEAAACABwhWqNbYipsFR2TZ9YDRd0hJ6dK6Wf4bBwMAAAAeIFihWuMq5ll9sXyL8gtLFJEy20lH3+Bfn34n5dcBAADgCYIVqtWjdYa6tWqikjKfPlyyWRHryGukzEOkvHXSyxOl3Tu8bhEAAAAaGYIVajS2n3844LRIHg6YlCZNfFZKyZTWfCE9f6qUH6HVDAEAABCTCFao1XDAj5ZsVlFpmSJWpxHSxe9JTVpLm+ZLz46Ttq/yulUAAABoJAhWqNGgQ5qpTWaKdhaV6ovlWxXR2g2ULpsqNessbV8pPTNO2rTA61YBAACgESBYoUbx8XHBe1pF9HDAgOxu0qVTpdb9pJ0bpedOktZ87XWrAAAAEOMIVtivcRVl16cv3KSy8ii4V5RVCrzkfanjCKkwV3rxDGnpdK9bBQAAgBhGsMJ+jejaQhmpidqys1jfrNmuqJDWXPrZW1KPMVLpbunVc6T5f/e6VQAAAIhRBCvsV3JivEb3aR35NwveW3IT6dxXpQH/I5WXSv/4uTTraa9bBQAAgBhEsEKtjK0YDjht4Sb5fFEwHDAgIUk68y/S8Csk+aT3b5I++p0UTV8DAAAAIh7BCrVybK9Wrudq9dYCLdmUr6gSHy+d9KB03K3+7Y8mSx/cLJWXe90yAAAAxAiCFWqlSUqijunZ0q1PWxCFN9+Ni5OOu0U6+WHbkGb9Rfrn5VJZidctAwAAQAzwPFg98cQT6tKli1JTUzVixAjNmjWr2mOffvppjRo1Ss2bN3fLiSeeuM/xF198seLi4iot48ePb4CvJPaN7dc2+uZZ7W345dJP/yrFJ0rf/1169VypuMDrVgEAACDKeRqsXn/9dd1www268847NXfuXA0aNEjjxo1TTk5Olcd/9NFHOvfcc/Xhhx/qyy+/VMeOHTV27Fj9+OOPlY6zILVhw4bg8uqrrzbQVxTbRvdtrfg4acH6PK3bHsVhZMBE6dzXpMQ0adl06aUJ0u4oqXYIAACAiORpsHrkkUd0+eWX65JLLlG/fv301FNPKT09Xc8++2yVx7/yyiu66qqrdNhhh6lPnz7661//qvLycs2cObPScSkpKWrbtm1wsd4t1F2Lpika2iU7eocDhuo5RrrwX1JqlrT2a+m5k6W8DV63CgAAAFHKs2BVXFysOXPmuOF8wcbEx7tt642qjYKCApWUlCg72//LfmjPVuvWrdW7d29deeWV2rp1a43nKSoqUl5eXqUFNd8sOKqHAwZ0GiFd8oHUtK2Us1B6dpy0dbnXrQIAAEAU8ixYbdmyRWVlZWrTpk2l/ba9cWPtfmmfNGmS2rdvXymc2TDAF1980fViPfDAA/r444910kknuWtVZ/LkycrKygouNsQQVRvbz//vNXvVNq3YvFNRr01/6dIpUvOu0o7V0rPjpY3zvW4VAAAAooznxSsO1u9+9zu99tpreuutt1zhi4BzzjlHp59+ugYMGKAJEybo3Xff1ezZs10vVnVuvfVW5ebmBpe1a9c20FcRfTpmp2twp2Yq90lnPP653p8fA8PnsrtKl06V2gyQduVIz50irf7C61YBAAAgingWrFq2bKmEhARt2lR5ro5t27yomjz88MMuWE2bNk0DBw6s8dhu3bq5ay1btqzaY2xOVmZmZqUF1Xvi/MEa2rm58otKddUrc3X729+rsKT6HsGokNFGuvhdqdNIqShXeulMackUr1sFAACAKOFZsEpOTtaQIUMqFZ4IFKIYOXJkta978MEHde+992rKlCkaOnTofq+zbt06N8eqXbt29db2xq5dVppeveIIXXlcd7f90ler9dMnv9DKLbsU1dKaSRf8U+o1XiotlF47T/r2Na9bBQAAgCjg6VBAK7Vu96Z64YUXtGjRIldoYteuXa5KoLnwwgvdML0AmzN1++23u6qBdu8rm4tly86d/rk+9virX/1KX331lVatWuVC2hlnnKEePXq4Mu6oP0kJ8Zo0vo+eu2SYspskuxLspz32md75dr2iWnK6dPbL0sBzJF+Z9NYvpK+e9LpVAAAAiHCeBquzzz7bDeu74447XAn1efPmuZ6oQEGLNWvWuPtQBTz55JOumuDEiRNdD1RgsXMYG1r43XffuTlWvXr10mWXXeZ6xT799FM33A/17/jerfX+L0dpeJds7Swq1S9f/Ua/fmt+dA8NTEiSJjwpHXGVf3vKLdJ/7pN8Pq9bBgAAgAgV5/Px2+LerNy6VQe0QhbMt6qd0rJyPTpjqZ74aJnLH33aZri5WN1bNVXUsi/k04f9ocoMvVQ6+WEpPsHrlgEAACDCskHUVgVEZElMiNdN43rrxUuHq0WTZC3emO+GBr79zY+KWnFx0jG/kk55xDak/z4r/eMyqbTY65YBAAAgwhCsUK9G9WylD64bpSO6ZauguEzXvz5Pk/7+nXYXR/HQwGGXSROfleKTpAVvSa+eLRXFwD28AAAAUG8IVqh3rTNT9crPj9B1o3u6Tp/X/7tWE574XMty8hW1Dv2JdN7rUlK6tPw/0otnSAXbvG4VAAAAIgTBCmGREB+n/xvTS69cNkItm6ZoySYbGvi5/jFnnaJWj9HShe9Iac2lH/8rPXeSlBflVRABAABQLwhWCKsje7TU+9cdraN6tNDukjLd+Oa3uunNb1VQXKqo1HGYdMkUKaO9tHmx9Mw4aUv1N58GAABA40CwQti1zkjVi5eO0A1jeik+Tvr7nHU64/HP9cOmKB0a2LqPdNlUqUUPKXeN9Ow4af08r1sFAAAADxGs0GBDA385uqebe9U6I0VLc3bq9Mc/0xuz1yoqK/436+TvuWo3SCrYIj1/qrTyU69bBQAAAI8QrNCgRnZvofevG6VRPVuqsKRcN//jO93wxrfaVRSFQwObtpIuelfqfLRUnC+9/FNp8XtetwoAAAAeIFihwVkxixcuGa5fjevthga+9c2POu3xz7RoQ56iTmqmdME/pD6nSmVF0usXSN+87HWrAAAA0MAIVvBEfHycrj6+h167YqTaZqZqxeZdriT7375eE31DA5NSpf95QTrsAslXLv3raumLx7xuFQAAABoQwQqeGt412w0NPK53KxWVluvXb83XL1+bp/zCEkWVhETpjMelI6/1b0/7jTTjLinaQiIAAAAOCsEKnstukqxnLxqmW07q44pc/Pvb9Trtsc/0/Y+5iip2N+Sx90kn3u3f/uwP0r9/KRUXeN0yAAAAhFmcL+rGXYVfXl6esrKylJubq8zMTK+b06jMWb1N1/7tG63PLVRyYrxuP7WfLhjRSXEWWqLJnBekd6/3Dw1MyZIGnS0NuURq08/rlgEAACAM2YBgVQWClbe27yp2NxGeuTjHbZ8yoJ0m/3SAMlOTFFUWvy9NuUXasXrPvo4j/AGr/wQpKc3L1gEAAKAWCFZ1QLDynn0s//rpSj0wZbFKy33q3CJdj587WAMOyVJUKS+XVnwozXnOH7R8Zf79qc2kQedKQy7233AYAAAAEYlgVQcEq8gxd812NzTwxx27lZwQr9tO6asLR3aOvqGBJn+j9M1L0pwXpdw1e/Z3Gunvxep3hr/CIAAAACIGwaoOCFaRJbegRDf9/VtNX7jJbY/v31YPTByorLQoGxoYUF4mLf+P9N/npB+m7OnFSmsuDTrP34vVqpfXrQQAAIAIVnVCsIo89jF97vNVmvzBIpWU+dQxO80NDRzUsZmiWt56/w2FrdhF3ro9+zsfLQ29ROp7mpSY4mULAQAAGrU8gtXBI1hFrm/X7tA1r87V2m27lZQQp1tO6qtLj+oSnUMD9+7FWjbD34u1dKq/mqBJbyEdZr1Yl0gtunvdSgAAgEYnj2B18AhWkS13d4lu+cd3+uD7jW57TL82emjiQDVLT1ZMyF0nzX1JmvuilL9+z/6ux/gDVp9TpcQY+VoBAAAiHMGqDghWkc8+ti99tVr3vbtIxWXl6tAsTY+dd7gGd2qumFFWKi2d5q8ouHS6fdX+/U1aSYedLw25SMru5nUrAQAAYhrBqg4IVtFj/rpcNzRw9dYCxcdJJ/RprfNGdNKxvVorwXbEih1r/D1Y1pO1099T53Q7Thp6qdT7ZCkhSot5AAAARDCCVR0QrKJLXmGJfvPW93rn2z3D5tplpeqsoR119rCOat8sLbZ6saySoPViLZsZ0ovVWjr8An8vVvMuXrcSjYF9Fi3k522QyopCngj5g8Y+cx+re64u+6s5v81TLC+Vykr8j4Glym1bykKe23u7ptfW4rnAduD/10A7g19T6PbBPFeHcyYkS0npUnITKbmplBxYbyIlVTzuvVTa35ShyQBiXh7B6uARrKLTspx8vTZrrf4xd522F9gvMXK9WMf1bq1zh3fS8b1bKTEhXjFj+yp/L5ZVFdy5ac8vTN1P8FcU7HWSlJDocSMRlUqLpPwN/qqVbvlxr8f1/s9coMgKGrf4xD0hq04hrWKxsGfB1j5fdjuK4Hp5Fftt8YWsl++1Xr7vfvfo2+vcVV0n5HXxCVJq1l5LM/9jSibhEohxeQSrg0ewim6FJWWaumCjXp21Rl+t2Bbc3yYzRWcP7aizhnXUIc3TFTPsL+FL3vdXFFzx4Z79TdtKg38mDb5QatbJyxYikhQXVISmKsJSYH3X5tr/Qp3RTkoK6RWu9CMlZH2fHzUH89xex/lqeE18vBSf5G+jDZO1X4yr3U70P9r2gRxb7XY1r42L39PO4Nflq7wefO5Aj9PBna+sWCopkIp3VV5K9toO7rdjd/rX7bXws0AZCFwWtPYJYdWEssBCMAMiGsGqDghWsWPF5p16ffZavTlnnbbtKg6Ofjm2VyvXi2VzspJiqRdr20pp7gv+XqzgL8dxUs8x/oqCPcfSixXLCvOqD0uB9cIdtTtXYqqU2V7K7OB/tAAVWA/st0IqFmDQONkfdaoKXMUV68HAZvtD1qsKcqFhzgJbnAXSBH8YDa7HhaxXPBc8Jr7q/fucI74W+xP2XbfhnEV5UmFu5cX21YfEtCrCV+b+g1latpTWzN9WAGFDsKoDglXsKSot0/SFm1wv1ufLtgb3t85ICc7F6pgdQ71YpcXSkvf8vVgrP96zP6O9fy5WhyH++2I168xfSqOBDWfava2ip2lD9cGpOL9257PhV1mBkLRXWAo8pjWvYo4UgEpsmOA+gauKAFbdUpRbP+0IhqzmUnr2XuvN/dvpzfes26O9hv/HgVohWNUBwSq2rdqyS6/NXqu/z1mrLTv39GKN6tlK5w7rqBP7tYmtXqyty6U5z0vzXpEK9oRKx/4Sm9XRH7Kyu1d+tOGDVBoMf2Aq2CLlb/TPWbLglF/xGLptRSLsL+a1YX/JDgalaoKTDVXiFyogQoJZ/gEEMQttO/zru3fUrcfMeuNc0KoqjDWrCGMhwSzwnA175PtH9P68sXtl2h/kcu2PcusqHn/0/8xJSJFSMqSUphWPmf75km49sD/Tv15pf8WSmBqznw2CVR0QrBqH4tJyzVjk78X6dOmW4P6WTVP0P0MP0TnDOqpziyaKqYIEi/4tLX5X2rpM2rrCP/Smph+6zTvvFbi6+e+dlWWhiyGFNf6ytGuLPxDlhyx7b+/KqX1gMukta+5lymznn/wPoPEMx7SAtXu7v1e7YNuedXt024H1kP02HPNg2S/flcJYsz0BzP6wY3Mu7RdsW5IqHhNT/MMd7dE9b9uplReGFR88+1Xe/l0DoSkYnEIClI1qCPe8yHgrZBMSvoIBLaOG/aHhrOKYCKw2SrCqA4JV47Nma4Fe/+8avfHfddqcv6d09NE9Wrq5WGP6tVFyYox907f/9e0vVNajtW15yOMKadsKqXR39a+1yfiVQle3PeEr65DYHe/vAtPm6nuWAts7c/wVxWolzj9XKaONfx5T04rH4HZb/7qV1I+wHzQAolRJYdVhrFIw27FXMNvmvxVBuFg1yNCg5ULZ3gEsNJiFBLRggNv79YF1q1CZvqdqpTtHWvSEOTd/topepmCQWl/LsBwnZbT1/yHODQc/ZM+wcPt54+ZN7vT3olpvaFFgPb9if17F9t77bRh6PceJQO+Z3a9z4jPyGsGqDghWjVdJWblmLspxvVifLN0cLKDVokmyJrperE7q2rIR9AjYF24hoVLoWrHnsdJ9i6r44di8657AFRq67Ju5Fz/ILBCV7JZKC/0/fGw9+Bi6VOyzUGmT6C0ghQYn62GqbYlxG2bpAlPbinBUsewdnOwYhlwCiIafC/ZLdLAnLDSMWa/ZNv8QRfc9tMj/fdQ92vfdQv9j6H47rtZ/gAoTC1qhoSsYvGw9bc+6e74ikAXWK72min0W+mozLM4Ku+zTyxQ6XO/H2g/5tFENlQKTBahD9gQp+5kTjp83NszQRsAUhQauisdgEKsIZcHgttcS2L93QOw1XjrvdXmNYFUHBCuYtdsK9MZ/17qqgjkhvVhHdm/herHG9m+jlMQY7ZnZ3zdQ+0ZfVeDavrLmoQb2l8PQ0BUIXNb7ZYHFfviGBh77AVwpBBXse4ytVwpMVRxXUxA8UBaYLByFBqTQ4BQIUi4wMVwSAGq80bgLXIXVBLCK9RrDWmEVx4Wes+Lngqs8WfFzpSHYz4rqwpiFG/tjnfU+WUCtDRtmGRqS3BDwkABli/XSxcJnojgkfFlAtd8VPEawqgOCFUKVlpXrwyWbXS/Wh0tygr1Y2daLNcQ/F6tbq6ZeNzMyWM+Q/aVtn9C13H9D4wOZTxQublhI2p6/SAbWA8NFQp+raohek5axO9QRAGKd610p2FP2P/DHuOBtA6rYFwxm1e2z7YrXHcw8JptTFAxMe/UyWXhyRYf4PcNLBKs6IFihOj/u2K03Zvt7sTbmFQb3j+iarfNGdNK4/m2VmsQv3dX+FSp3TcUcrr1C1461/kmv+wSetNqHoKqOT9x7mwnSAIAwsnlKwbBVUDl4FYeMorB5s4EgRen7iEewqgOCFWrTi/XxD/5erP8szlF5xf9FzdKT9NPBh+jc4R3Vo3WG180EAABAHRGs6oBghQOxIdd6sda5+VjWoxUwvEu2u/Hwsb1buRLuAAAAiD4EqzogWOFglJX7XCXBV79eo5mLc9x2QO82GRrZvYVbjujaQlnpVIEDAACIBgSrOiBYoa425RW6uVjvzd+gxRvt/g572DDqfu0yXXVBC1rDumQrI5WgBQAAEIkIVnVAsEJ92rarWF+t2Kovl2/Vlyu2alnOzkrPJ8THaUCHLH+PVrcWGtqludKTKdMNAAAQCQhWdUCwQjjl5BW6gGVh64vlW7V6a+Wb4SUlxOmwjs1cyDqiewsN7tScSoMAAAAeIVjVAcEKDWn9jt2uN8tCloWt0AIYJjkxXkM6NXc9WjZ8cOAhzdw+AAAAhB/Bqg4IVvCK/e+4dttufbF8i+vVssCVk19U6Zi0pAQ3XPDI7i1d2Dq0faYSEwhaAAAA4UCwqgOCFSKF/e+5fPMu/9DBijlaNmcrVEZKooZ1zXa9WUd0a+EKY8THc6NBAACA+kCwqgOCFSJVeblPP+TkB4cOfr1iq/IKSysdk5WWpCO6Zbs5WiO7t1SvNk0Vxx3dAQAAwpoNPB8/9MQTT6hLly5KTU3ViBEjNGvWrGqPffrppzVq1Cg1b97cLSeeeOI+x1tOvOOOO9SuXTulpaW5Y5YuXdoAXwkQftYT1adtpi45qquevnCovrljrN699mj9+uQ+Or53KzVJTlDu7hJNXbBJd/17ocY9+omG3T9DV/9trl7+arWWb97p/h8BAABA/fK0x+r111/XhRdeqKeeesqFqkcffVRvvvmmlixZotatW+9z/Pnnn6+jjjpKRx55pAtiDzzwgN566y0tWLBAHTp0cMfYvsmTJ+uFF15Q165ddfvtt2v+/PlauHChe01t0GOFaFVSVq75P+a6Hi0rhDF71TYVlpRXOqZ1RooO7ZCl3m0z1Kdthvq2y1TXlk2UxDwtAACA6BwKaGFq2LBhevzxx912eXm5OnbsqGuvvVa33HLLfl9fVlbmeq7s9RbQ7Etp3769brzxRt10003uGHsD2rRpo+eff17nnHNOrdpFsEKsKCot07dr/UHLCmJ8s2aHissqBy2TnBCv7q2buqBlS++KwGUhjGGEAACgMcurZTbw7C6kxcXFmjNnjm699dbgvvj4eDd078svv6zVOQoKClRSUqLs7Gy3vXLlSm3cuNGdI8DeBAtwds7qglVRUZFbQt88IBakJCZoeNdst1x3Yk8VlpTpu3W5WrIxT4s25mtJxbKzqFSLNuS5JVSz9KSKsJXpf2yX6eZscQNjAACAyjz77WjLli2ux8l6k0LZ9uLFi2t1jkmTJrkeqkCQslAVOMfe5ww8VxUbOnj33XcfxFcBRBe70XAgaAVYT++67bu1eGO+Fm/I0+JN/seVW3ZpR0GJvlqxzS0B1oHVOTu9YijhnsDVKTtdCVQjBAAAjVTU/tn5d7/7nV577TV99NFHtZ47VR3rNbvhhhsq9VjZkESgMbChfh2z090ypt+eP0pY79aynJ3BwLVkU74WbcjXlp1FWrW1wC1WJCMgNSlevdv4w5YLXe3869lNkj36ygAAABpBsGrZsqUSEhK0adOeX8yMbbdt27bG1z788MMuWM2YMUMDBw4M7g+8zs5hVQFDz3nYYYdVe76UlBS3AKjcu2VFLmwJZcHKhg+GBi7btiIZ367LdUsom6cVmLPlgle7DPVo3dQNUwQAAIgVngWr5ORkDRkyRDNnztSECROCxSts+5prrqn2dQ8++KDuv/9+TZ06VUOHDq30nFUBtHBl5wgEKet9+vrrr3XllVeG+SsCGoeWTVPUskeKjurRMrivrNynVVt3+QOXDSesCF5rthUoJ7/ILZ8u3RI83oYMdmvZxA0hdMUy2mSoc4t0HdI8XWnJBC4AABB9PB0KaMPvLrroIheQhg8f7sqt79q1S5dccol73ir9WRl1mwMVKKVu96j629/+5u59FZg31bRpU7fYkKbrr79e9913n3r27Bkst27zsALhDUD9s6DUvVVTt5w8YE9v8a6i0mCPVmjgsnttLc3Z6ZZ/f1v5XC2bJruAdUjzNPfYMTstuN2hWZrrSQMAAIg0ngars88+W5s3b3ZhyUKS9TJNmTIlWHxizZo1rlJgwJNPPumqCU6cOLHSee68807dddddbv3mm2924eyKK67Qjh07dPTRR7tz1nUeFoAD1yQlUYM7NXdLaLGMTXlFWrQxLxi4fti0U2u3FSi/qFRbdha7Zd7aHVWe04YWWsiyOWHB8FURvNo3S1NyIvfjAgAADc/T+1hFKu5jBXjDerIsYFmVwnXbKz/a/l3FZTW+3ioWts1MDQlcFb1d2WkufLXNSuVGyAAAIPZuEBypCFZA5LFvVVb+3YUsF7YKtHZbSPDaXuAKaNTEqsG3y0qrcpih9YBZKKNkPAAACEWwqgOCFRB97FvZ1l3Fwd6tQG/X2pBer+LSmoNXYnyc2jVLDQ4tbJ2RqlYZKa5gh/8xWS0zUpSRkujmdAIAgNiXV8tsELX3sQKAUBZ0XMXCpik6rGOzfZ4vL/e5UvGhQSu01+vHHbtVUuZz27bUJCUxPiRs+R9bVYSuVtaGkMcmyQmEMAAAGgGCFYBGIT4+Tq0zU90ypPOeYhqhwWtTfuGeeV3bdmvzziJtzi9ygcwKatj6zqJSFZWWuyBmy/6kJSWoZUayP4DtFbrssVXguYwUpSfzLRkAgGjFT3EAqAheNv/KlmFdsqs9bndxmQtaoaErGL7yi93+wL6C4jLtLimrVS+YSU9OCPaC2bDDysMQ/Ut2k2Q1S0tSZloS88EAAIggBCsAOAB2A2MrdGHL/th9vLaEBK3NVkrePRbteax4zgpvWBBbvbXALbWRmZqoZunJapaepKw0/2LrzdL27LPn9+xPUlZ6klISuRcYAAD1jWAFAGG8j5ctnVs02W/hDSslv0/oqnjcHOgJyy9yJeltOKLJKyx1y5ptB9YuG564J3hVPAbCWEgwC/SMufX0ZOaLAQBQA4IVAHjMwkrTlES3dGlZcwgzJWXlLmBZ+fnc3cUVj/7tHbtLlFtQ7B4D23luvdgdU+6TG564O7dMG3ILD6idVjVxn56wivDVJCVBTVOS1DQ10VVNdF9Pqv8xI3XPNr1lAIBYRbACgChjNzkOzLk6EFagI7+oVLkucBXvG8YC627bf4zbV1Ci4rJylbrKisVukXYdZNsrQqQLW0n+EBYSvDIqevlCtysHNH94S09KcPPiAACIFAQrAGgkLIgE5mJ10v7niIUOVbQ5YJXCWEhvmQ1NzC8sdY87Kx4twO0sLAnus6GOxkraby8ocYu0/4Ie1bERiU2Sq+kZqwhnVgwk+Jic6ObHWc+aVV+07XS3HthOUGJC/EG3BwAAghUAYL9DFS2UpCX7qyYeDOst21W8J3z5g1flbSv2UTmkVQ5tuyrWrefMbm3vjrH5Znn183UmJ8a7gGVBywUuC2iB4LVXCAt9rqpj0wJhjp41AGg0CFYAgLCzcJGRmuQWZR38eaz3zO4jVql3LBDEiiyIlSm/sEQFRWUuyFl5fOstK7BgVlzqKi9aQAvst3ULaqa4tNwt/t60+hMIZPZoQSvVPca7dRdYk6w3rWI7+Lw/yKVW7PMft++jPW83rKaoCAB4j2AFAIgaFiAsTNhyoHPMqmNhqqC4NBjAXPiyEFYRzvYOY+7YoopHu1fZXtvuHCVlrlfN2OttCRfrEAuErdAgZuuBMBca2KoKZpUek+L33VfxmJwQTw8cAFSDYAUAaNRsCGByopWYr79zBualBQKa9ahZNcZCq8hYcePo3aHrxRXPVaxbMCvc67jA8wUV6zZfzViHm+t9C2N4C2Xhyh++LJj5Q9ie9X0f7di9Q5pbqgp1FedKToxTckJCxb9NxZIQ74qf0DsHIFIRrAAACNu8tASpaXiuYWX3A2GrsLhcBSX+XrU9Aa68IpT5Q11guzA0vJWUuaGVgceikMfCkMeyiuGSxipE2pIv//3UGpoFrNCwFVi3apn2mFLF88HnDuB1SSHHVfW6wDZDMQEEEKwAAIhCFghscfPWwqzUQlxI8NonkFW1r6qQVmLH7v8cgfluFh4Dc+D2DnYqUsSoLuyFrqdU85y/h67mY4LP77XtQmHF58B68ywMJsX71xPi6d0DGhrBCgAA1MhK0Te1JaXhf22w3jILWMHAVVaukopH2w7dHwhjgWBWFLIefK6K14Wer/Lr/EMuA8dZOHTHVwzDjOSwZ5kqELwSLXQFQ5h/3f5NkyvW3eJCWcW2C21xVbzWv9i+4LkqAl7gvKHrifEWAKtYDxwTv+dats78PUQ7ghUAAIhY1vOSEO8vtBEp7PYBgTAVGtyqC3v+9TIVleznmL3P4dbLqj2+pCLkVdWzZ8VTAsdF0791YnxFaEu0MBZXfWgLCXxVrQeOdSHOzlvxnJ3TQl7gObumWw/29FWcIz7keBcM/ecNHl9xXtfmwLXsNfFxBMRGjGAFAABwAOwX59QIC3tWMCUQsgI9c7Ztwzj9vXh7ngs9zn+sz/XalZbvWQ99LnAO13tX0cNnQS6wHvqc/9jK1yoNnKe84nh7bRWBz3onbbEQGUm9fwfKclUgjAUCmT+k7Qlre4e/yqGwci+fP/TtGyr37n10x4X0PAZ6FoM9hHv1OAbPE2gXPYd1RrACAACIcjafylVTTIxXNLAgaCEqENBKK8KYBS7bt28wqxwU9w5vrtcuGO72en35nte6oaV23Yrnysr3XM9eZ+t2fOAc/qGo/n3BdXttRQgMLewSUB7oLVR0B8OkvXvjgoEvdH/lY5KqPLaa19dwnsCxrTNSNLRLtqIFwQoAAAANHgT9vSSKqJ6/gxkWGgxjLrCFBC8LZ3uFtD0hb9/wVzlUBsLevr2GgRDotssr9zZWf5z1FlZ9nZqDYcPcxqE6o3q21EuXjVC0IFgBAAAAB8GGzSXboujoKayq5zA0ZFkwq9yDF+jZ2zOXb+/nKq+XB3sES0OCZej+QJD0h77KPYR7n79P2wxFE4IVAAAA0Eh7DgPzr1B3vIsAAAAAUEcEKwAAAACoI4IVAAAAANQRwQoAAAAA6ohgBQAAAAB1RLACAAAAgDoiWAEAAABAHRGsAAAAAKCOCFYAAAAAUEcEKwAAAACoI4IVAAAAANRRYl1PEIt8Pp97zMvL87opAAAAADwUyASBjFAdglUV8vPz3WPHjh29bgoAAACACMkIWVlZ1T4f59tf9GqEysvLtX79emVkZCguLs7zhGwBb+3atcrMzPS0LY0F73nD4z1vWLzfDY/3vOHxnjcs3u+Gx3vecCwuWahq37694uOrn0lFj1UV7A075JBDFEnsfxj+p2lYvOcNj/e8YfF+Nzze84bHe96weL8bHu95w6ippyqA4hUAAAAAUEcEKwAAAACoI4JVhEtJSdGdd97pHtEweM8bHu95w+L9bni85w2P97xh8X43PN7zyEPxCgAAAACoI3qsAAAAAKCOCFYAAAAAUEcEKwAAAACoI4IVAAAAANQRwSoCPPHEE+rSpYtSU1M1YsQIzZo1q8bj33zzTfXp08cdP2DAAL3//vsN1tZoN3nyZA0bNkwZGRlq3bq1JkyYoCVLltT4mueff15xcXGVFnvvUTt33XXXPu+ffX5rwmf84Nn3kr3fb1uuvvrqKo/n833gPvnkE5122mlq3769e7/efvvtSs9bTag77rhD7dq1U1pamk488UQtXbq03n8WNCY1veclJSWaNGmS+17RpEkTd8yFF16o9evX1/v3psZkf5/ziy++eJ/3b/z48fs9L5/zg3u/q/q+bstDDz1U7Tn5jDc8gpXHXn/9dd1www2uXObcuXM1aNAgjRs3Tjk5OVUe/8UXX+jcc8/VZZddpm+++cYFA1u+//77Bm97NPr444/dL5hfffWVpk+f7n4gjx07Vrt27arxdXZH8w0bNgSX1atXN1ibY0H//v0rvX+fffZZtcfyGa+b2bNnV3qv7XNu/ud//qfa1/D5PjD2/cK+V9sviFV58MEH9ac//UlPPfWUvv76a/fLvn1fLywsrLefBY1NTe95QUGBe89uv/129/jPf/7T/cHs9NNPr9fvTY3N/j7nxoJU6Pv36quv1nhOPucH/36Hvs+2PPvssy4o/fSnP63xvHzGG5iVW4d3hg8f7rv66quD22VlZb727dv7Jk+eXOXxZ511lu+UU06ptG/EiBG+X/ziF2FvayzKycmx2w34Pv7442qPee6553xZWVkN2q5Ycuedd/oGDRpU6+P5jNev6667zte9e3dfeXl5lc/z+a4b+/7x1ltvBbftfW7btq3voYceCu7bsWOHLyUlxffqq6/W28+Cxmzv97wqs2bNcsetXr263r43NWZVvecXXXSR74wzzjig8/A5r7/PuL33J5xwQo3H8BlvePRYeai4uFhz5sxxw0QC4uPj3faXX35Z5Wtsf+jxxv7aU93xqFlubq57zM7OrvG4nTt3qnPnzurYsaPOOOMMLViwoIFaGBtsGJQNb+jWrZvOP/98rVmzptpj+YzX7/eYl19+WZdeeqn7y2Z1+HzXn5UrV2rjxo2VPsNZWVluyFN1n+GD+VmA/X9vt898s2bN6u17E/b10UcfuWH1vXv31pVXXqmtW7dWeyyf8/qzadMmvffee25kx/7wGW9YBCsPbdmyRWVlZWrTpk2l/bZtP5irYvsP5HhUr7y8XNdff72OOuooHXroodUeZz8wrMv9X//6l/sl1V535JFHat26dQ3a3mhlv1DaPJ4pU6boySefdL94jho1Svn5+VUez2e8/tgY/R07dri5ENXh812/Ap/TA/kMH8zPAlTPhlzanCsbUmzDXOvrexP2HQb44osvaubMmXrggQfcUPuTTjrJfZarwue8/rzwwgturvhPfvKTGo/jM97wEj24JhARbK6VzdvZ33jjkSNHuiXAfuns27ev/vznP+vee+9tgJZGN/tBGzBw4ED3jd56R954441a/bUNB++ZZ55x77/9tbI6fL4RS2ze7FlnneUKiNgvkjXhe1PdnHPOOcF1Kxxi72H37t1dL9bo0aM9bVussz+GWe/T/goN8RlvePRYeahly5ZKSEhwXbqhbLtt27ZVvsb2H8jxqNo111yjd999Vx9++KEOOeSQA3ptUlKSDj/8cC1btixs7YtlNjSnV69e1b5/fMbrhxWgmDFjhn7+858f0Ov4fNdN4HN6IJ/hg/lZgOpDlX32rWhLTb1VB/O9CTWzoWb2Wa7u/eNzXj8+/fRTV5zlQL+3Gz7j4Uew8lBycrKGDBniutEDbBiObYf+BTmU7Q893tgPkOqOR2X2V0wLVW+99Zb+85//qGvXrgd8DhvKMH/+fFdKGQfO5vMsX7682vePz3j9eO6559zch1NOOeWAXsfnu27se4r9khj6Gc7Ly3PVAav7DB/MzwJUHapsPon9QaFFixb1/r0JNbPhwzbHqrr3j895/Y1EsPfRKggeKD7jDcCDghkI8dprr7lqUc8//7xv4cKFviuuuMLXrFkz38aNG93zP/vZz3y33HJL8PjPP//cl5iY6Hv44Yd9ixYtchVfkpKSfPPnz/fwq4geV155pauA9tFHH/k2bNgQXAoKCoLH7P2e33333b6pU6f6li9f7pszZ47vnHPO8aWmpvoWLFjg0VcRXW688Ub3fq9cudJ9fk888URfy5YtXUVGw2e8/lmlrU6dOvkmTZq0z3N8vusuPz/f980337jFfow+8sgjbj1Qge53v/ud+z7+r3/9y/fdd9+56l1du3b17d69O3gOq+b12GOP1fpnQWNX03teXFzsO/30032HHHKIb968eZW+txcVFVX7nu/ve1NjV9N7bs/ddNNNvi+//NK9fzNmzPANHjzY17NnT19hYWHwHHzO6+/7isnNzfWlp6f7nnzyySrPwWfcewSrCGD/E9gvQcnJya4U6VdffRV87thjj3UlTUO98cYbvl69ernj+/fv73vvvfc8aHV0sm9WVS1Wcrq69/z6668P/vu0adPGd/LJJ/vmzp3r0VcQfc4++2xfu3bt3PvXoUMHt71s2bLg83zG658FJftcL1myZJ/n+HzX3Ycffljl95HA+2ol12+//Xb3ftovkaNHj97n36Jz587ujwa1/VnQ2NX0ntsvjdV9b7fXVfee7+97U2NX03tuf4wcO3asr1WrVu4PX/beXn755fsEJD7n9fd9xfz5z3/2paWluVs4VIXPuPfi7D8N0TMGAAAAALGKOVYAAAAAUEcEKwAAAACoI4IVAAAAANQRwQoAAAAA6ohgBQAAAAB1RLACAAAAgDoiWAEAAABAHRGsAACoo7i4OL399tteNwMA4CGCFQAgql188cUu2Oy9jB8/3uumAQAakUSvGwAAQF1ZiHruuecq7UtJSfGsPQCAxoceKwBA1LMQ1bZt20pL8+bN3XPWe/Xkk0/qpJNOUlpamrp166a///3vlV4/f/58nXDCCe75Fi1a6IorrtDOnTsrHfPss8+qf//+7lrt2rXTNddcU+n5LVu26Mwzz1R6erp69uypd955J/jc9u3bdf7556tVq1buGvb83kEQABDdCFYAgJh3++2366c//am+/fZbF3DOOeccLVq0yD23a9cujRs3zgWx2bNn680339SMGTMqBScLZldffbULXBbCLDT16NGj0jXuvvtunXXWWfruu+908sknu+ts27YteP2FCxfqgw8+cNe187Vs2bKB3wUAQDjF+Xw+X1ivAABAmOdYvfzyy0pNTa20/9e//rVbrMfqf//3f12YCTjiiCM0ePBg/b//9//09NNPa9KkSVq7dq2aNGninn///fd12mmnaf369WrTpo06dOigSy65RPfdd1+VbbBr/OY3v9G9994bDGtNmzZ1QcqGKZ5++ukuSFmvFwAgNjHHCgAQ9Y4//vhKwclkZ2cH10eOHFnpOdueN2+eW7cepEGDBgVDlTnqqKNUXl6uJUuWuNBkAWv06NE1tmHgwIHBdTtXZmamcnJy3PaVV17peszmzp2rsWPHasKECTryyCPr+FUDACIJwQoAEPUsyOw9NK++2Jyo2khKSqq0bYHMwpmx+V2rV692PWHTp093Ic2GFj788MNhaTMAoOExxwoAEPO++uqrfbb79u3r1u3R5l7Z8L2Azz//XPHx8erdu7cyMjLUpUsXzZw5s05tsMIVF110kRu2+Oijj+ovf/lLnc4HAIgs9FgBAKJeUVGRNm7cWGlfYmJisECEFaQYOnSojj76aL3yyiuaNWuWnnnmGfecFZm48847Xei56667tHnzZl177bX62c9+5uZXGdtv87Rat27tep/y8/Nd+LLjauOOO+7QkCFDXFVBa+u7774bDHYAgNhAsAIARL0pU6a4EuihrLdp8eLFwYp9r732mq666ip33Kuvvqp+/fq556w8+tSpU3Xddddp2LBhbtvmQz3yyCPBc1noKiws1B/+8AfddNNNLrBNnDix1u1LTk7WrbfeqlWrVrmhhaNGjXLtAQDEDqoCAgBims11euutt1zBCAAAwoU5VgAAAABQRwQrAAAAAKgj5lgBAGIaI94BAA2BHisAAAAAqCOCFQAAAADUEcEKAAAAAOqIYAUAAAAAdUSwAgAAAIA6IlgBAAAAQB0RrAAAAACgjghWAAAAAFBHBCsAAAAAUN38fxF78ZfjxxOeAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 178
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3.2 Activation function**\n",
    "\n",
    "Try changing the activation function in each layer from sigmoid to [ReLU](https://keras.io/api/layers/activations/).\n",
    "\n",
    "**Note**: the last layer should still have a sigmoid activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers, 20 nodes each, class weights, ReLU and no batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:20:22.138832Z",
     "start_time": "2026-02-27T10:20:13.244025Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "model7 = build_DNN(input_shape=(Xtrain.shape[1],),\n",
    "                   n_hidden_layers=2,\n",
    "                   n_hidden_units=20,\n",
    "                   learning_rate=0.1,\n",
    "                   loss=BinaryCrossentropy(),\n",
    "                   act_fun=\"relu\")\n",
    "\n",
    "history7 = model7.fit(Xtrain, Ytrain,\n",
    "                      validation_data=(Xval, Yval),\n",
    "                      class_weight=class_weights,\n",
    "                      epochs=20,\n",
    "                      batch_size=10000,\n",
    "                      verbose=1)\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = model7.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.8f' % score[0])\n",
    "print('Test accuracy: %.8f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history7)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.3416 - accuracy: 0.8479 - val_loss: 0.2693 - val_accuracy: 0.8912\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2066 - accuracy: 0.8943 - val_loss: 0.2471 - val_accuracy: 0.8975\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9006 - val_loss: 0.2376 - val_accuracy: 0.9035\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 0.9049 - val_loss: 0.2335 - val_accuracy: 0.9065\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9068 - val_loss: 0.2285 - val_accuracy: 0.9081\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9081 - val_loss: 0.2258 - val_accuracy: 0.9098\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9098 - val_loss: 0.2223 - val_accuracy: 0.9108\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9104 - val_loss: 0.2194 - val_accuracy: 0.9111\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9106 - val_loss: 0.2196 - val_accuracy: 0.9112\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9108 - val_loss: 0.2157 - val_accuracy: 0.9115\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9117 - val_loss: 0.2157 - val_accuracy: 0.9127\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1701 - accuracy: 0.9124 - val_loss: 0.2162 - val_accuracy: 0.9131\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9127 - val_loss: 0.2177 - val_accuracy: 0.9130\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9128 - val_loss: 0.2151 - val_accuracy: 0.9133\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1679 - accuracy: 0.9130 - val_loss: 0.2151 - val_accuracy: 0.9133\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9131 - val_loss: 0.2105 - val_accuracy: 0.9138\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1666 - accuracy: 0.9133 - val_loss: 0.2107 - val_accuracy: 0.9139\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.9134 - val_loss: 0.2038 - val_accuracy: 0.9143\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.9137 - val_loss: 0.2142 - val_accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9140 - val_loss: 0.2093 - val_accuracy: 0.9147\n",
      "Test loss: 0.21101059\n",
      "Test accuracy: 0.91384119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 179
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3.3 Optimizer**\n",
    "\n",
    "Try changing the optimizer from SGD to Adam (with learning rate 0.1 as before). Remember to import the Adam optimizer from [keras.optimizers](https://keras.io/optimizers/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers, 20 nodes each, class weights, Adam optimizer, no batch normalization, sigmoid activations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:20:35.421452Z",
     "start_time": "2026-02-27T10:20:26.871520Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "model8 = build_DNN(input_shape=(Xtrain.shape[1],),\n",
    "                   n_hidden_layers=2,\n",
    "                   n_hidden_units=20,\n",
    "                   learning_rate=0.1,\n",
    "                   loss=BinaryCrossentropy(),\n",
    "                   optimizer=\"adam\")\n",
    "\n",
    "history8 = model8.fit(Xtrain, Ytrain,\n",
    "                      validation_data=(Xval, Yval),\n",
    "                      class_weight=class_weights,\n",
    "                      epochs=20,\n",
    "                      batch_size=10000,\n",
    "                      verbose=1)\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = model8.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.8f' % score[0])\n",
    "print('Test accuracy: %.8f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history8)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 1s 7ms/step - loss: 0.2337 - accuracy: 0.8853 - val_loss: 0.2189 - val_accuracy: 0.9142\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9154 - val_loss: 0.2125 - val_accuracy: 0.9165\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9165 - val_loss: 0.2087 - val_accuracy: 0.9181\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9178 - val_loss: 0.2043 - val_accuracy: 0.9189\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.9187 - val_loss: 0.2074 - val_accuracy: 0.9191\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9197 - val_loss: 0.2026 - val_accuracy: 0.9209\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.9196 - val_loss: 0.1916 - val_accuracy: 0.9204\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9203 - val_loss: 0.1935 - val_accuracy: 0.9198\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.9200 - val_loss: 0.1970 - val_accuracy: 0.9204\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9214 - val_loss: 0.1926 - val_accuracy: 0.9199\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9239 - val_loss: 0.1708 - val_accuracy: 0.9274\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9260 - val_loss: 0.1800 - val_accuracy: 0.9273\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.9266 - val_loss: 0.1639 - val_accuracy: 0.9318\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9287 - val_loss: 0.1747 - val_accuracy: 0.9315\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1337 - accuracy: 0.9322 - val_loss: 0.1658 - val_accuracy: 0.9337\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1333 - accuracy: 0.9319 - val_loss: 0.1654 - val_accuracy: 0.9334\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.9325 - val_loss: 0.1673 - val_accuracy: 0.9332\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9322 - val_loss: 0.1633 - val_accuracy: 0.9337\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.9332 - val_loss: 0.1635 - val_accuracy: 0.9342\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9331 - val_loss: 0.1650 - val_accuracy: 0.9339\n",
      "Test loss: 0.16660747\n",
      "Test accuracy: 0.93313843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 180
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 **Dropout regularization**\n",
    "\n",
    "Dropout is a type of regularization that can improve accuracy for validation and test data. It randomly removes connections to force the neural network to not rely too much on a small number of weights.\n",
    "\n",
    "Add a Dropout layer after each Dense layer (but not after the final dense layer) in `build_DNN`, with a dropout probability of 50%. Look at the [documentation](https://keras.io/api/layers/regularization_layers/dropout/) for more information on how to call set this layer.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "12. How does the validation accuracy change when adding dropout?\n",
    "13. How does the test accuracy change when adding dropout?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "12. Decreases, but more stable over epochs\n",
    "13. Decreases, but more stable over epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hidden layers with 20 nodes each, class weights, dropout, SGD optimizer, no batch normalization and sigmoid activations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:21:21.497274Z",
     "start_time": "2026-02-27T10:21:10.841611Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "model9 = build_DNN(input_shape=(Xtrain.shape[1],),\n",
    "                   n_hidden_layers=2,\n",
    "                   n_hidden_units=20,\n",
    "                   learning_rate=0.1,\n",
    "                   loss=BinaryCrossentropy(),\n",
    "                   use_dropout=True)\n",
    "\n",
    "history9 = model9.fit(Xtrain, Ytrain,\n",
    "                      validation_data=(Xval, Yval),\n",
    "                      class_weight=class_weights,\n",
    "                      epochs=20,\n",
    "                      batch_size=10000,\n",
    "                      verbose=1)\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = model9.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.8f' % score[0])\n",
    "print('Test accuracy: %.8f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history9)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 0.6916 - accuracy: 0.5513 - val_loss: 0.5600 - val_accuracy: 0.8844\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5763 - accuracy: 0.6960 - val_loss: 0.4579 - val_accuracy: 0.8811\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7718 - val_loss: 0.3689 - val_accuracy: 0.8806\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4204 - accuracy: 0.8132 - val_loss: 0.3179 - val_accuracy: 0.8804\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8365 - val_loss: 0.2966 - val_accuracy: 0.8803\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.8487 - val_loss: 0.2849 - val_accuracy: 0.8803\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8561 - val_loss: 0.2801 - val_accuracy: 0.8803\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.8620 - val_loss: 0.2788 - val_accuracy: 0.8803\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.8648 - val_loss: 0.2775 - val_accuracy: 0.8804\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2974 - accuracy: 0.8684 - val_loss: 0.2756 - val_accuracy: 0.8805\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2921 - accuracy: 0.8702 - val_loss: 0.2755 - val_accuracy: 0.8806\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2860 - accuracy: 0.8717 - val_loss: 0.2743 - val_accuracy: 0.8811\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.2817 - accuracy: 0.8729 - val_loss: 0.2730 - val_accuracy: 0.8822\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.2776 - accuracy: 0.8740 - val_loss: 0.2724 - val_accuracy: 0.8829\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2741 - accuracy: 0.8746 - val_loss: 0.2706 - val_accuracy: 0.8835\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2700 - accuracy: 0.8757 - val_loss: 0.2699 - val_accuracy: 0.8840\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2672 - accuracy: 0.8766 - val_loss: 0.2685 - val_accuracy: 0.8844\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2633 - accuracy: 0.8772 - val_loss: 0.2670 - val_accuracy: 0.8849\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2612 - accuracy: 0.8780 - val_loss: 0.2665 - val_accuracy: 0.8854\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.8782 - val_loss: 0.2655 - val_accuracy: 0.8860\n",
      "Test loss: 0.26672104\n",
      "Test accuracy: 0.88517767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAF2CAYAAACCrWJKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABUs0lEQVR4nO3dB3xUVdrH8Se9QAglCaH3LkVpImIFERTEsqKrUkRxXbChr4pKV1kbYmFldRUsq6Kuuq4FBRQVaS6ooEDovSWUBBJSZ97Pc5IZZpJJZZKbmfl993N37r1z587JMCbzn3POc4PsdrtdAAAAAABnJPjMHg4AAAAAUIQrAAAAAPACwhUAAAAAeAHhCgAAAAC8gHAFAAAAAF5AuAIAAAAALyBcAQAAAIAXEK4AAAAAwAsIVwAAAADgBYQrAAAAAPCHcDVnzhxp3ry5REZGSu/evWX16tXFHpuTkyPTp0+XVq1ameO7du0qCxcuPKNzAgAAAIA3hIqFFixYIBMmTJC5c+eaEDR79mwZOHCgJCUlSUJCQpHjH3vsMXnnnXfktddek/bt28vXX38tV199tSxfvlzOPvvsCp3TE5vNJvv375eYmBgJCgry+s8NAAAAwDfY7XY5ceKENGzYUIKDS+mbsluoV69e9nHjxjm38/Ly7A0bNrTPnDnT4/ENGjSwv/zyy277rrnmGvtNN91U4XN6smfPHru+NCwsLCwsLCwsLCwsLCJiMkJpLOu5ys7OljVr1sjEiROd+zQJ9u/fX1asWOHxMVlZWWaon6uoqChZtmxZhc/pOK8urulU7dmzR2rVqnUGPyUAAAAAX5aWliZNmjQxo9pKY1m4SklJkby8PKlfv77bft3etGmTx8fo8L5Zs2bJBRdcYOZdLVmyRD7++GNznoqeU82cOVOmTZtWZL8GK8IVAAAAgKAyTBeyvKBFebzwwgvSpk0bM98qPDxcxo8fL6NHjy597GMptKcrNTXVuWiPFQAAAACUh2XhKi4uTkJCQuTQoUNu+3U7MTHR42Pi4+Pl008/lfT0dNm1a5fpjapZs6a0bNmywudUERERzl4qeqsAAAAA+FS40p6n7t27m6F9rlX6dLtPnz4lPlbnXTVq1Ehyc3Pl3//+t1x11VVnfE4AAAAA8NlS7FoyfeTIkdKjRw/p1auXKZuuvVI61E+NGDHChCidE6VWrVol+/btk27dupnbqVOnmvD04IMPlvmcAAAAAOB34Wr48OGSnJwskydPloMHD5rQpBcFdhSk2L17t9t8qszMTHOtq+3bt5vhgIMHD5a3335bateuXeZzAgAAAEBlCNJ67JVyZh8vtxgbG2uKWzD/CgAAAAhcaeXIBj5VLRAAAAAAqivCFQAAAAB4AeEKAAAAAHy9oAUAAAAAH2WzidjzRGy65Lqsu27nnt7nul3ssbbT22HRIq0vFV9CuKruMtNEwqJEQsKsbgkAAIBv0Hptjg/wdluhdVsx+wtuy7U/r4TnKma/ubW7rOd5fg7nvjz3EOPcV7h9rucrOFeR5/D0vI62uoaeQiHH43aevtCV++8Y11Zk/M/iSwhX1d17N4js+kkkIlYkuo5IdD2RqLr5t9F6W9d923U9NMLq1gMAAE+cH5Yd3+rrh9aCD6/F9QIU3uf24dglNHgKBsV+yPfGh/MSgkeR8xQKCyWGjsKPKyb0eGo/rBcUIhIcKhJccBsU7LLuuC+45O3aTcXXEK6qu1PH8m+zUvOXYzvL/tjwmgVhy0MIMyGtIKy53hceXWk/CgAAhuNb8rzs/CW34NYsOR6GExUEi8JBwxk4HKHE9ThPjy0cUAqdx/HNfOHHFB7aVNq3+YWHP3k6T2V/44/S6Qd4xwd+vTUf6INd1suw3zzedT2k9P1BQae33W4LnqPIfYWfu5KOdws5rvcXDkgF28UGpJDTP2cAIlxVd39ZJnLquEjGEZFTR/NvM466rxfe1kCmv8CzT+YvqbvL/nyhkS69Y8WFsroikbGF/sMr9B9vafvdjqGuCgAUy3yTbytbT4Wn4UglDjvSgJNTEHCyTq8XXpzhx3F/oWPLfX824aIkJX7ILfgwW+RvbIjnD+2uH/KL/A0u4e9ykX3l/DBf5HkLrxfz3EV+BtdwU1ybCwckD+fyFHyASkC4qu70F0GNevlLWekfW+3lcgteBeHLYygr2GfLEcnNFEnbl79UJU9/JDz+8SjtD4F+SxLk8o1JkPut7jfPV/i+ko537JMS7ivlXOaxzh/W5Vzl2K7IY4rdrmbKdC1ze9Weq9Tz2Cv42FLOW5HHenyMvRznLuuxno4r+D9zfMH9jvVy3Vb0ccU93qW9HrfP9L5Cr4nrscU9f5nnSRQaEqW3gSAkIn84uzNAOJaQYm4dAcQ1dLiEEU/nKPwtfGmPKXJ84ZBThm/33drpqe0ehkkB8FmEK3+kv5h1yJ8u9VqV7TH6x197uYoLXoV7zTJTi47j9rhdxg8GelweY6QBoEIqOlxIP8yHhLssYfkBR2/Ntut6uEioy3El3u84JsL9+OLuN+2rpl/+AEA5EK6QT/+oRcTkL3WaV82QlpKq1hQ31KW0ajmOb41NoCvmG25H2Ctyn62E44v5lrzY53E5l/O5pIRt54tV+vFl+la+lG2vfojx0rkq1KagSn6OoAqcp7yP8dLxFXqOYk9U/vO79dZ62lfcraee5IrcejiPW5sLHVP4vjIfV+g1KtdzuQ53KmG4lMchUSXdR08H4Evsdrvk5Nklz2aXXJtNcvP01n09T9d1n+O+PNdtm3ls4XOYfW732VyOyT+H2336PC7PbTMfMez5H2/Env+RS/+no4wLRik4j9GBUiUcb3fsK3S83mFzO77QOVyO131N6kbLW7f2El9CuELlM0PoCj4MAAAAuNAP047goOHABIi8/A//5rYgUJj7C0KGuS3Yb+53Wz/9WEewMLcFocKx7Xafreh9Hu/P0wBQ+JynA0+e/XRgcX+8zYQJR4hB2fhihzbhCgAAwE8Di4aQ7FybZBfcavjIv7VJVsGtY/v0vtPHuD/W5das281tTsExjnPkh6SC3pZiApPbftKGERYSJKHBwRIaHCQhLuuhZl1vC+5zWXfcHxIcLGEF94WFBBcck3+/uS/E/b78Y4NdjgmS4CBdNNAE5X8vrrc628SxXbBuOuEL7jM1QwodH1To/iLn8Xju/Od2P3eQRIX53hfzhCsAABCQoSOnIBw4AoJr4NCA4RomnL0SLr0ajh4Mm0svhe7Ls4np5TC3Zjt/3Rxf0PPhPL7gvDZHL4fLus3Dc7q2wzXoOH4W/TmyCkJOmer7VFP6QVsDhIYAc+sIGyH5ASHUbb/7Ma7HFgklGiIKbk24cNmvgSYkyHW70P1u68WdM/+5HeHGPMZxTpdtZzgqaKvuh38gXAEAgEoJMKbXw6XnI8tlOysnz7nfua9g3dEDogHHGXYK9ZgU7kU5ve3eW+M4j+u2L4eOitLegfCQ4PwlVAOI4zZIwkNDJNzcuu7Pv3U8Jiw0yMO+07cRBccUDjdFg1DBbcF+c78e5whDBesaVgBfRLgCAMCPaI9GZk6eCSV6676uAeb0bZbeugYcE0DyigQeZygqFJYKByc9p2OfLwWY04Ej/8O+LhEFAcMRGAr3TujQJcc+0zNR0OvhaZ+jx8PT4zRM6L6QYDG9ISFBepvfM6L7gt2OKXhswboj6DhCTpFtl59Lj9dhVgAqF+EKAIBKDDoZ2blySoNNtk0yCwKN3prQk1N4n0v4KUNAcjzWNTBpL011Y4KA48N/wQd/DS9u22EFwcC1d8QRcApCjukdKQgPp487HYic4aJQWHINHaanxuXcGlYIHQC8hXAFAAhYOkRMg8+p7DzJyM6/PZWTK6eybc5Q5LyvYF1v84/Nda5r6Dn9+NPHay+OlRwhJiIsRCLD8tcjzXpI/n5nwMnfLhJ8XAORMwSFeAxHnoJThA43C2U+CYDAQbgCAPgcneiflpkjR9OzncuxjGw5orfp2XIi83TwcQ08+SEo17leVb082jESGZofcNzCja57uHXcn39sfkgxt277PR+jzxNRsE2oAYCqRbgCAFhOg44jGBUXmBy3uu9YRo4ZcuctGkKiNaSEh0h0eIgp/xtVcGu2w0MlKixYosNDTZhxPabo8aESFR5sHhNdsF9DEEPPAMD/Ea4AAF6loee4CUDZcuSke0A6mq69TVlyNCPHLUhpz1JFxESESt2a4VInOlzq1ji91IoMLQhE+eHHGYjcAlOIRIeFSmR4/lA2wg8A4EwRrgAAxfYmpZ3KkdRTOWYIXtqpXJf1gv2nck14MiFJA1V6thw/lVOhSnFaaECDkQaleh4Ck9mvtzXyb2tHh5v5PAAAVBeEKwDwU7l5NjP3SMOQIwgVCUfmvlyz7Xqcrp9pMYbYqDBnGHINRnVrhEndGhHmNn9/hNSpESY1I0LpPQIA+DTCFQD4wAVZk09myZ6jGWZYXX4AKr5HKT8o5crJrNwzfm6th1ArKkxqRYaZsFQrKtRlXfeHmh6kwj1MdaLDzEVCAQAIJIQrAKgmQ/D2HsuQ3UczZPcRvT0lu4+mm+09R09VeE6SqhEeUjQgFWzrrdkXGeoSmMIkNjp/X43wUHOxUwAAUDrCFQBUce9TfoA6JbuOpju3D6Vllfh4zTcNYqMkPibC2WPkCEP54Sg/NDnWHffFRIaaC6UCAIDKR7gCgErqfdplep0Kto9mSGZOyXOYdM5R07rR+Uu9gtuCpWHtKIo3AABQzRGuAKACvU+7zNC9/KW8vU8alprVi5YmLuFJl9rRYRR0AADAhxGuAMCFzWaXfcdPydbDJ2XnEcecp7L3Pul1l1x7nVwDFL1PAAD4N8IVgIAOUVsOn5DNh07K5kMnTKDSJSM7r8TeJw1JnsITvU8AAAQ2whWAgAhRGp40RGmY2nIoP0QVV4EvPCRYWsbXkBZxNYoEqEZ1oigQAQAAqme4mjNnjjzzzDNy8OBB6dq1q7z00kvSq1evYo+fPXu2vPLKK7J7926Ji4uT6667TmbOnCmRkZHm/qlTp8q0adPcHtOuXTvZtGlTpf8sAKwNUXuPne6J2nLohGw5XLYQ1aZ+jLRNqClt6usSI83qRnONJgAA4FvhasGCBTJhwgSZO3eu9O7d2wSngQMHSlJSkiQkJBQ5/t1335WHH35Y3njjDTnvvPNk8+bNMmrUKDMEZ9asWc7jOnXqJIsXL3Zuh4ZaniEBeDlEbS4ITxqiNh/OH9JX3HwoR4hqWz9G2pgQFWOCFCEKAAB4k6WpQwPR7bffLqNHjzbbGrK++OILE540RBW2fPly6du3r/z5z382282bN5cbb7xRVq1a5XachqnExMQq+ikAVFaI2nMswwzhM+HJcVvGENW2fk1pnZB/q8P5CFEAAMBvw1V2drasWbNGJk6c6NwXHBws/fv3lxUrVnh8jPZWvfPOO7J69WozdHD79u3y5Zdfyi233OJ23JYtW6Rhw4ZmqGCfPn3MsMGmTZsW25asrCyzOKSlpXnlZwRQtvLm2hO16eAJ53wo7ZXallxCiAoNllbxNU0vFCEKAABIoIerlJQUycvLk/r167vt1+3i5kdpj5U+7vzzzzcfyHJzc+Uvf/mLPPLII85jdHjh/PnzzTyrAwcOmPlX/fr1k99//11iYmI8nlfDV+F5WgAqT1pmjizfekR+2JIsP25Jlj1HT5UYojQ4OYfzJRCiAABA9eRTk5GWLl0qTz75pPz97383IWrr1q1yzz33yIwZM2TSpEnmmEGDBjmP79KlizmuWbNm8sEHH8iYMWM8nld7z3Tul2vPVZMmTargJwICQ57NLuv2Hpcft6TID5uT5Zc9x80+h7CQIGfvkw7pa216pGJMiArR2ucAAAA+wLJwpZX+QkJC5NChQ277dbu4+VIaoHQI4G233Wa2O3fuLOnp6TJ27Fh59NFHzbDCwmrXri1t27Y1Qaw4ERERZgHgPfuPnzK9Uj9sTpFlW1Mk9VSO2/0t42rIBW3jpV+bODm3ZT2pEeFT3/UAAAAUYdmnmfDwcOnevbssWbJEhg0bZvbZbDazPX78eI+PycjIKBKgNKApHSboycmTJ2Xbtm1F5mUB8K5T2XmycscR0zOlPVRaeMJVTGSonN86Tvq1yQ9Ueu0oAAAAf2LpV8U6FG/kyJHSo0cPU6BCS7FrT5SjeuCIESOkUaNGZk6UGjJkiKkwePbZZzuHBWpvlu53hKwHHnjAbOtQwP3798uUKVPMfVpVEID36BcaGw+cyO+d2pIsP+84Jtl5pwtQ6Gi+bk1qmzClPVRdG8cyTwoAAPg1S8PV8OHDJTk5WSZPnmwuItytWzdZuHChs8iFXijYtafqscceM9e00tt9+/ZJfHy8CVJPPPGE85i9e/eaIHXkyBFzvxa/WLlypVkHcGZSTmbJMp03ZQpRpEjyidNVNlWj2lFyQdv83qm+reIkNjrMsrYCAABUtSB7cePpApgWtIiNjZXU1FSpVauW1c0BLJOda5P/7TrqLETxx373yxREhYVIn1b1zDA/7Z3SeVT6BQgAAEAgZgNmkANw0u9adqSkO+dNrdh+RDKy89yO6dSwVsFQvzjp3qyORITmD8kFAAAIdIQrIMBpFb/lW3WoX37v1L7j7teciqsZIRe0iZN+bePk/NbxEh9DZU0AAABPCFdAgNHrS/2297izd+rXQtecCg8Jlh7N65hhfhe0iZf2iTESzLWmAAAASkW4AgLEyaxc+eeP22X+8p1yPMP9mlOt4ms4w1TvlnUlOpxfDQAAAOXFJyjAz2Xm5Mk7K3fJ35duk6Pp2WZfbFRYwTWndLhfvKnyBwAAgDNDuAL8VG6eTf69dq+8sHiL7E/NNPu0mt+Ey9rKoLMaSAhD/QAAALyKcAX4GZvNLl/+fkBmfbNZtqekm30NYiPl3v5t5NpzGnMhXwAAgEpCuAL8qIz695uT5Zmvk5zXo6pbI1z+elErufncZhIZRsl0AACAykS4AvzAml1H5amFSbJ6x1GzXTMiVG7r10Ju69fSrAMAAKDy8akL8GEb9qfJc98kyZJNh812eGiwjDi3mfz14tam1woAAABVh3AF+KCdKekya9Fm+e+6/WK3iylOcX2PxnL3pW2kQSyV/wAAAKxAuAJ8yMHUTHnx2y3ywc97JLfgwr9XdmkgEwa0lZbxNa1uHgAAQEAjXAE+4Fh6tsz9fpu5AHBWrs3su6hdvDxwWTs5q1Gs1c0DAAAA4Qqo3tKzcuX1ZTvktR+2y4msXLOvR7M68uDl7aVXi7pWNw8AAAAuCFdANZSVmyf/Wrlb5ny3VY6kZ5t9HRrUkgcHtjM9VkFBXAAYAACguiFcAdVIbp5NPv5ln7yweIvsO37K7GteL1omXNZOruzcQIKDCVUAAADVFeEKqCYXAP7q94OmrPq25HSzL7FWpKn+96cejSUsJNjqJgIAAKAUhCvA4lD145YUeebrJFm/L9Xsqx0dJn+9qJWM6NNcIsNCrG4iAAAAyohwBVhk7e5j8vTCTbJy+1GzHR0eIred30Juu6Cl1IoMs7p5AAAAKCfCFVDFNh1Mk2e/3iyLNx4y2+EhwXLzuc3krxe3kriaEVY3DwAAABVEuAKqyO4jGTJrUZL857f9YreLaG2K67o3lnv6t5VGtaOsbh4AAADOEOEKqGSH0zLlxW+3yPur90iuzW72De6cKBMGtJPWCTWtbh4AAAC8hHAFVOIFgF/6dqvMX75DMnNsZt8FbePl/y5rJ50bx1rdPAAAAHgZ4QqoBEfTs2XUvNWybm9+BcBzmtaWBy9vL+e2rGd10wAAAFBJCFeAlx1MzZSbX18lWw+flDrRYfL0dV2lf4cECQriAsAAAAD+jHAFeNHOlHQTrPYeOyUNYiPl7TG9pHVCjNXNAgAAQBUgXAFesvFAmtzy+mpJOZklzetFyzu39ZbGdaKtbhYAAACqCOEK8II1u47J6HmrJS0zVzo0qCVv3dpL4mO4ZhUAAEAgIVwBZ+jHLcky9q01cionT7o3qyNvjOopsVFhVjcLAAAAVYxwBZyBr9YfkLvf/0Vy8uymzPrcm8+R6HD+swIAAAhEfAoEKuiD/+2Rh/+9TvS6wFd0biDPD+8m4aHBVjcLAAAAFrH8k+CcOXOkefPmEhkZKb1795bVq1eXePzs2bOlXbt2EhUVJU2aNJH77rtPMjMzz+icQHn988ft8uBH+cFqeI8m8uKNZxOsAAAAApylnwYXLFggEyZMkClTpsjatWula9euMnDgQDl8+LDH49999115+OGHzfEbN26U119/3ZzjkUceqfA5gfKw2+0y65skefyLjWZ77AUt5W/XdpaQYK5hBQAAEOiC7Ppp0SLaq9SzZ095+eWXzbbNZjO9UXfddZcJUYWNHz/ehKolS5Y4991///2yatUqWbZsWYXO6UlaWprExsZKamqq1KpVy0s/LXydzWaX6Z9vkPnLd5rt/xvYTv56USsuDgwAAODH0sqRDSzrucrOzpY1a9ZI//79TzcmONhsr1ixwuNjzjvvPPMYxzC/7du3y5dffimDBw+u8DlVVlaWedFcF8BVTp5N7v/wNxOsNEvNuKqTjLu4NcEKAAAA1he0SElJkby8PKlfv77bft3etGmTx8f8+c9/No87//zzzfCs3Nxc+ctf/uIcFliRc6qZM2fKtGnTvPJzwf9k5uTJ+Hd/kcUbD5nhf7Ou7ypXdWtkdbMAAABQzfjUDPylS5fKk08+KX//+9/NfKqPP/5YvvjiC5kxY8YZnXfixImmm8+x7Nmzx2tthm87mZUro+f9bIJVRGiwvHpLd4IVAAAAqlfPVVxcnISEhMihQ4fc9ut2YmKix8dMmjRJbrnlFrntttvMdufOnSU9PV3Gjh0rjz76aIXOqSIiIswCuDqWni2j5q2W3/amSs2IUPnnyB5ybst6VjcLAAAA1ZRlPVfh4eHSvXt3t+IUWnxCt/v06ePxMRkZGWYOlSsNU0qHCVbknIAnB1Mz5fp/rDDBqk50mLx7e2+CFQAAAKrvRYS1ZPrIkSOlR48e0qtXL3MNK+2JGj16tLl/xIgR0qhRIzMnSg0ZMkRmzZolZ599tqkKuHXrVtObpfsdIau0cwKl2XUkXW765yrZe+yUJNaKlHdu6yWtE2KsbhYAAACqOUvD1fDhwyU5OVkmT54sBw8elG7dusnChQudBSl2797t1lP12GOPmepsertv3z6Jj483weqJJ54o8zmBkmw6mCa3vL5akk9kSfN60fL2mN7SpG601c0CAACAD7D0OlfVFde5Ckxrdx8zxStST+VI+8QYeWtML0mIibS6WQAAAPCRbGBpzxVQXSzbkiJj3/6fZGTnyTlNa8u8Ub0kNjrM6mYBAADAhxCuEPAW/n5A7n7vV8nOs0m/NnHyj1u6S3Q4/2kAAACgfPgEiYD24f/2yEP/Xic2u8jgzony/PBuEhGaXxwFAAAAKA/CFQLW68t2yIzPN5j14T2ayJPXdJaQ4CCrmwUAAAAfRbhCwNEaLs8v3iIvLtlitm/v10IeGdzBVKIEAAAAKopwhYBis9ll+ucbZP7ynWb7gcvayriLWxOsAAAAcMYIVwgYuXk2efDf6+TjtfvM9vSrOsmIPs2tbhYAAAD8BOEKASEzJ0/ueu8XWbThkJlX9dyfusqwsxtZ3SwAAAD4EcIV/N7JrFwZ+9b/ZPm2IxIeGix///M50r9jfaubBQAAAD9DuIJfO5aeLaPm/yy/7TkuNcJD5J8je0qfVvWsbhYAAAD8EOEKfutQWqbc8voq2XzopNSJDpM3b+0lXRrXtrpZAAAA8FOEK/ilXUfS5ebXV8meo6cksVakvD2ml7SpH2N1swAAAODHCFfwO0kHT5hglXwiS5rVi5Z3xvSWJnWjrW4WAAAA/BzhCn7ll93HZNS8nyX1VI60T4yRt8b0koSYSKubBQAAgABAuILf+Glritz+1v8kIztPzmlaW+aN6iWx0WFWNwsAAAABgnAFv/DD5mS57c3/SXaeTfq1iZN/3NJdosN5ewMAAKDq8OkTPi8jO1ce+vc6E6wu75QoL9zYTSJCQ6xuFgAAAAJMsNUNAM7U3KXb5EBqpjSuEyWzbyBYAQAAwBqEK/i0PUczZO4P2836Y1d0kMgwghUAAACsQbiCT3v8iw2SnWuTvq3rycBOiVY3BwAAAAGMcAWftWxLinz9xyEJCQ6SKUM6SVBQkNVNAgAAQAAjXMEn5eTZZNp//zDrt5zbTNrWj7G6SQAAAAhwhCv4pLdX7JIth09K3Rrhcl//tlY3BwAAACBcwfccOZklzy/ebNb/b2A7LhQMAACAaoFwBZ/z7DdJciIzVzo1rCXX92hidXMAAAAAg3AFn7J+b6q8//Mesz5taCdTzAIAAACoDghX8Bl2u12m/vcPsdtFhnVrKD2a17W6SQAAAIAT4Qo+4z+/7pc1u45JdHiIPDyog9XNAQAAANwQruATTmblypNfbjTr4y5uLYmxkVY3CQAAAHBDuIJPmPPdVjl8Ikua1YuWMee3sLo5AAAAQPUMV3PmzJHmzZtLZGSk9O7dW1avXl3ssRdddJEEBQUVWa644grnMaNGjSpy/+WXX15FPw28bWdKurz+4w6zPumKjhIZFmJ1kwAAAIAiQsViCxYskAkTJsjcuXNNsJo9e7YMHDhQkpKSJCEhocjxH3/8sWRnZzu3jxw5Il27dpU//elPbsdpmJo3b55zOyIiopJ/ElSWx7/YINl5Nrmgbbxc2qHoewIAAADwyZ4r7WGaPn267N692ysNmDVrltx+++0yevRo6dixowlZ0dHR8sYbb3g8vm7dupKYmOhcFi1aZI4vHK40TLkeV6dOHa+0F1VradJhWbzxsIQGB8nkKzuaXkgAAADAL8LVvffea3qPWrZsKQMGDJD3339fsrKyKvTk2gO1Zs0a6d+//+kGBQeb7RUrVpTpHK+//rrccMMNUqNGDbf9S5cuNT1f7dq1kzvvvNP0cBVH25+Wlua2wHrZuTaZ/vkGsz66b3NpnVDT6iYBAAAA3g1Xv/76q5kX1aFDB7nrrrukQYMGMn78eFm7dm25zpWSkiJ5eXlSv359t/26ffDgwVIfr234/fff5bbbbisyJPCtt96SJUuWyFNPPSXff/+9DBo0yDyXJzNnzpTY2Fjn0qRJk3L9HKgcby7fKduT0yWuZrjcdWkbq5sDAAAAVE5Bi3POOUdefPFF2b9/v0yZMkX++c9/Ss+ePaVbt25mSJ9e8LWyaa9V586dpVevXm77tSdr6NCh5r5hw4bJ559/Lj///LPpzfJk4sSJkpqa6lz27NlT6W1HyQ6fyJQXlmwx6w9e3l5qRYZZ3SQAAACgcsJVTk6OfPDBBybE3H///dKjRw8TsK699lp55JFH5Kabbir1HHFxcRISEiKHDh1y26/bOk+qJOnp6WZI4pgxY0p9Hh3CqM+1detWj/fr/KxatWq5LbDWMwuTzLWtujaOlevOaWx1cwAAAADvVwvUoX9ahe+9994z86NGjBghzz//vLRv3955zNVXX216sUoTHh4u3bt3N8P3tIdJ2Ww2s63DDEvy4YcfmrlSN998c6nPs3fvXjPnSocvovr7dc9x+XDNXrM+dWgnCQ6miAUAAAD8MFxpaNJCFq+88ooJRGFhRYdrtWjRwgzNKwstwz5y5EjT86XD+7QUu/ZKafVApeGtUaNGZl5U4SGB+vz16tVz23/y5EmZNm2a6UHT3q9t27bJgw8+KK1btzYl3lG92Wx2mfLZH2b92nMay9lNqfIIAAAAPw1X27dvl2bNmpV4jFbuc73GVEmGDx8uycnJMnnyZFPEQudsLVy40FnkQku+aw+ZK70G1rJly+Sbb74pcj4dZrhu3Tp588035fjx49KwYUO57LLLZMaMGVzrygf8e+1e+W3PcakZESoPXd7O6uYAAAAAZRZkL2flCS0MoUP39IK/rlatWmWCjfZA+Totxa5VA7W4BfOvqs6JzBy5+NnvJeVklkwc1F7uuLCV1U0CAABAgEsrRzYod0GLcePGeaymt2/fPnMfUFEvfbvVBKuWcTVkdN8WVjcHAAAAKJdyh6sNGzaYMuyFnX322eY+oCK2JZ+UN5btMOuThnSU8NAKF7IEAAAALFHuT7A6b6lw6XR14MABCQ0t9xQuwFwTbfp/N0iuzS6XtE+Qi9slWN0kAAAAoPLDlRaHcFx010ELR+i1rbSKIFBe3246LN9vTpawkCCZdGVHq5sDAAAAVEi5u5qeffZZueCCC0zFQB0KqH799VdT3e/tt9+uWCsQsLJy82T65/nDScec31JaxNWwukkAAABA1YQrveaUljr/17/+Jb/99ptERUWZa1LdeOONHq95BZTkjWU7ZdeRDEmIiZDxl7S2ujkAAABAhVVokpRex2rs2LEVf1ZARA6lZcpL324x6w8Pam+ubQUAAAD4qgp/mtXKgHqB3+zsbLf9Q4cO9Ua7EAD+9tUmycjOk3Oa1pZh3RpZ3RwAAACgasPV9u3b5eqrr5b169dLUFCQqfSmdF3l5eWdWYsQENbsOiqf/LJP9G0zdWgnCQ7Of/8AAAAAAVMt8J577pEWLVrI4cOHJTo6Wv744w/54YcfpEePHrJ06dLKaSX8Sp7NLlM/yy9icX33JtKlcW2rmwQAAABUfc/VihUr5Ntvv5W4uDgJDg42y/nnny8zZ86Uu+++W3755ZczbxX82of/2yPr96VKTESo/N/l7axuDgAAAGBNz5UO+4uJiTHrGrD2799v1rU0e1JSkndaBb+VeipHnv46/31y74C2ElczwuomAQAAANb0XJ111lmmBLsODezdu7c8/fTTEh4eLq+++qq0bNnSO62C33ph8RY5mp4trRNqyog+zaxuDgAAAGBduHrsscckPT3drE+fPl2uvPJK6devn9SrV08WLFjgvZbB72w5dELeXLHTrE8Z0lHCQsrdcQoAAAD4T7gaOHCgc71169ayadMmOXr0qNSpU8dZMRAoTKtKTvvvBlPM4rKO9aVfm3irmwQAAAB4Vbm6DnJyciQ0NFR+//13t/1169YlWKFE32w4JMu2pkh4aLA8dkVHq5sDAAAAWBuuwsLCpGnTplzLCuWSmZMnMz7PL70+tl9LaVov2uomAQAAAF5X7kkvjz76qDzyyCNmKCBQFq/9sF32HjslibUi5a8Xt7K6OQAAAED1mHP18ssvy9atW6Vhw4am/HqNGjXc7l+7dq032wcft//4KZmzdKtZnzi4vUSHl/stBwAAAPiEcn/SHTZsWOW0BH5p5lebJDPHJj2b15GhXRta3RwAAACg+oSrKVOmVE5L4HdWbT8i//1tvwQHiUwd2omiJwAAAPBrXGgIlUJLrk/9b34Rixt6NZVODWOtbhIAAABQvXqugoODS+yBoJIg1Hurd8vGA2lSKzJUHrisndXNAQAAAKpfuPrkk0+KXPvql19+kTfffFOmTZvmzbbBRx3PyJZnv0ky6/df1k7q1gi3ukkAAABA9QtXV111VZF91113nXTq1EkWLFggY8aM8Vbb4KNmLdosxzNypF39GLmpd1OrmwMAAAD41pyrc889V5YsWeKt08FHbTqYJu+s3GXWpwztKKEhTOsDAABAYPDKJ99Tp07Jiy++KI0aNfLG6eCj7Ha7TP3sD7HZRQZ3TpTzWsVZ3SQAAACg+g4LrFOnjltBC/1AfeLECYmOjpZ33nnH2+2DD/ly/UFZuf2oRIQGyyODO1jdHAAAAKB6h6vnn3/eLVxp9cD4+Hjp3bu3CV4ITKey8+SJL/JLr//lwlbSuE601U0CAAAAqne4GjVqVOW0BD5t7vfbZH9qpjSqHWXCFQAAABBoyj3nat68efLhhx8W2a/7tBw7As+eoxkmXKlHr+ggUeEhVjcJAAAAqP7haubMmRIXV7RQQUJCgjz55JMVasScOXOkefPmEhkZaYYXrl69uthjL7roIjMssfByxRVXuM0Dmzx5sjRo0ECioqKkf//+smXLlgq1DaV78suNkpVrk3Nb1pVBZyVa3RwAAADAN8LV7t27pUWLFkX2N2vWzNxXXnptrAkTJsiUKVNk7dq10rVrVxk4cKAcPnzY4/Eff/yxHDhwwLn8/vvvEhISIn/605+cxzz99NOmeuHcuXNl1apVUqNGDXPOzMzMcrcPJVu+NUW++v2gBAeJTB3ayW0+HgAAABBIyh2utIdq3bp1Rfb/9ttvUq9evXI3YNasWXL77bfL6NGjpWPHjiYQaeXBN954w+PxdevWlcTEROeyaNEic7wjXGmv1ezZs+Wxxx4zFzzu0qWLvPXWW7J//3759NNPy90+FC83zyZT//uHWb/l3GbSPrGW1U0CAAAAfCdc3XjjjXL33XfLd999J3l5eWb59ttv5Z577pEbbrihXOfKzs6WNWvWmGF7zgYFB5vtFStWlOkcr7/+unle7Z1SO3bskIMHD7qdMzY21gw3LO6cWVlZkpaW5ragdHqx4M2HTkqd6DC5b0Bbq5sDAAAA+Fa1wBkzZsjOnTvl0ksvldDQ/IfbbDYZMWJEuedcpaSkmHBWv359t/26vWnTplIfr3OzdFigBiwHDVaOcxQ+p+M+T/PIpk2bVq62B7qj6dkya9Fms37/Ze2kdnS41U0CAAAAfCtchYeHm3lSjz/+uPz666+mYETnzp3NnKuqpqFKn7tXr15ndJ6JEyeaeV8O2nPVpEkTL7TQfz37TZKkZeZKhwa15MZeTa1uDgAAAOB74cqhTZs2ZjkTWnVQi1EcOnTIbb9u63yqkqSnp8v7778v06dPd9vveJyeQ6sFup6zW7duHs8VERFhFpTN7/tS5b3V+cVLpg3tJCFazQIAAAAIcOWec3XttdfKU089VWS/VuhzrdhX1l6w7t27y5IlS5z7dIihbvfp06fEx+p1tXSu1M033+y2XysZasByPaf2RGnVwNLOibJ5YckWsdtFhnRtKL1a1LW6OQAAAIBvhqsffvhBBg8eXGT/oEGDzH3lpcPxXnvtNXMB4o0bN8qdd95peqW0eqDSuVw6bM/TkMBhw4YVqVCopcDvvfdeM2zxs88+k/Xr15tzNGzY0ByPM5ORnSs/bE4263+9qJXVzQEAAAB8d1jgyZMnTY9TYWFhYRWqsjd8+HBJTk42F/3VghM6dG/hwoXOghR67SytIOgqKSlJli1bJt98843Hcz744IMmoI0dO1aOHz8u559/vjmnXqQYZ+bHLSnmgsGN60RJ+8QYq5sDAAAAVBtBdr0wVDlo8Ygrr7zShCFXU6dOlf/+97+mtLqv05Co5dtTU1OlVi2u3eTq/z78TT5cs1dG920uU4Z0sro5AAAAQLXJBuXuuZo0aZJcc801sm3bNrnkkkvMPp3f9O6778pHH31U8Vaj2suz2eXbTYfN+oAO7qXuAQAAgEBX7nA1ZMgQ+fTTT801rTRMaSn2rl27mgsJ161LcQN/9svuY3IkPVtqRYZKTwpZAAAAAGdeiv2KK64wi6Ob7L333pMHHnjADAnUiwLDPy3amF8y/+L2CRIWUu5aKAAAAIBfq/AnZK0MOHLkSFOF77nnnjNDBFeuXOnd1qFaWbQhP1wN6MiQQAAAAOCMeq60mt/8+fNNGXTtsbr++uvNtaZ0mGDHjh3Lcyr4mG3JJ2V7crqEhQTJBW3jrW4OAAAA4Ls9VzrXql27drJu3TqZPXu27N+/X1566aXKbR2qjcUFvVbntqwntSLDrG4OAAAA4Ls9V1999ZXcfffd5iK/bdq0qdxWodpZXDDfiiGBAAAAwBn2XOlFe0+cOCHdu3eX3r17y8svvywpKSllfTh82JGTWbJm1zGzfikl2AEAAIAzC1fnnnuuvPbaa3LgwAG544475P333zfFLGw2myxatMgEL/gnvbaVzS7SqWEtaVQ7yurmAAAAAP5RLbBGjRpy6623mp6s9evXy/333y9/+9vfJCEhQYYOHVo5rUS1qBLYn14rAAAAoFhndLEiLXDx9NNPy969e821ruB/MnPy5Mct+cM/mW8FAAAAFM8rV4INCQmRYcOGyWeffeaN06EaWb4tRU7l5EmD2EgzLBAAAABAJYYrBMaQwKCgIKubAwAAAFRbhCsUy2azy+KNh806QwIBAACAkhGuUKzf9h6X5BNZUjMiVHq3rGt1cwAAAIBqjXCFUi8cfGG7eIkIDbG6OQAAAEC1RrhCqfOtBlCCHQAAACgV4Qoe7TqSLpsPnZSQ4CC5uF2C1c0BAAAAqj3CFTxyFLLo1byuxEaHWd0cAAAAoNojXMGjRRsOmtv+VAkEAAAAyoRwhSKOZ2TLzzuPmXXmWwEAAABlQ7hCEd8lHZY8m13a1Y+RpvWirW4OAAAA4BMIVyhi8QYuHAwAAACUF+EKbrJy82RpUn64Yr4VAAAAUHaEK7hZuf2opGfnSUJMhHRpFGt1cwAAAACfQbiCm8UFFw6+tEN9CQ4Osro5AAAAgM8gXMHJbrfL4o354WpARy4cDAAAAJQH4QpOf+xPkwOpmRIVFiLntYqzujkAAACATyFcwembgiGBF7SNk8iwEKubAwAAAPgUwhWKzLca0DHR6qYAAAAAPodwBWPvsQzZcCBNtIbFJe2ZbwUAAAD4XLiaM2eONG/eXCIjI6V3796yevXqEo8/fvy4jBs3Tho0aCARERHStm1b+fLLL533T506VYKCgtyW9u3bV8FP4tuWbMy/tlWPZnWlbo1wq5sDAAAA+JxQK598wYIFMmHCBJk7d64JVrNnz5aBAwdKUlKSJCQU7T3Jzs6WAQMGmPs++ugjadSokezatUtq167tdlynTp1k8eLFzu3QUEt/TJ/gqBLYnyqBAAAAQIVYmjpmzZolt99+u4wePdpsa8j64osv5I033pCHH364yPG6/+jRo7J8+XIJCwsz+7TXqzANU4mJzBsqq7TMHFm5/YhZ79+hvtXNAQAAAHySZcMCtRdqzZo10r9//9ONCQ422ytWrPD4mM8++0z69OljhgXWr19fzjrrLHnyySclLy/P7bgtW7ZIw4YNpWXLlnLTTTfJ7t27S2xLVlaWpKWluS2B5PukZMnJs0ur+BrSMr6m1c0BAAAAfJJl4SolJcWEIg1JrnT74MGDHh+zfft2MxxQH6fzrCZNmiTPPfecPP74485jdHjh/PnzZeHChfLKK6/Ijh07pF+/fnLixIli2zJz5kyJjY11Lk2aNJFAsqigSmD/jvRaAQAAABXlU5ORbDabmW/16quvSkhIiHTv3l327dsnzzzzjEyZMsUcM2jQIOfxXbp0MWGrWbNm8sEHH8iYMWM8nnfixIlm7peD9lwFSsDKybPJd0n5xSwuI1wBAAAAvheu4uLiTEA6dCi/18RBt4ubL6UVAnWulT7OoUOHDqanS4cZhocXrXKnxS60ouDWrVuLbYtWHdQlEK3ecVROZOZKvRrh0q1JHaubAwAAAPgsy4YFahDSnqclS5a49Uzpts6r8qRv374mJOlxDps3bzahy1OwUidPnpRt27aZY1D8kMBLOyRIiF7kCgAAAIDvXedKh+K99tpr8uabb8rGjRvlzjvvlPT0dGf1wBEjRpghew56v1YLvOeee0yo0sqCWtBCC1w4PPDAA/L999/Lzp07TVXBq6++2vR03XjjjZb8jNWZ3W4/XYKdKoEAAACA7865Gj58uCQnJ8vkyZPN0L5u3bqZQhSOIhda5U8rCDroPKivv/5a7rvvPjOfSq9zpUHroYcech6zd+9eE6SOHDki8fHxcv7558vKlSvNOtxtOnhC9h47JRGhwdKvDa8PAAAAcCaC7Np9ATda0EKrBqampkqtWrXEX720ZIs8t2iz9O+QIP8c2dPq5gAAAAA+nQ0sHRYIay1iSCAAAADgNYSrAHUwNVPW7U2VoCAtZkG4AgAAAM4U4SpAOQpZdGtSW+JjArMMPQAAAOBNhKsAD1cDuHAwAAAA4BWEqwCUnpUry7ceMesDGBIIAAAAeAXhKgD9sDlZsvNs0rxetLROqGl1cwAAAAC/QLgK8CqBQVrRAgAAAMAZI1wFmNw8m3y76bBZ7898KwAAAMBrCFcBZs2uY3I8I0dqR4dJj2Z1rG4OAAAA4DcIVwFm0Yb8IYGXtEuQ0BD++QEAAABv4dN1ALHb7c75VpRgBwAAALyLcBVAtiWflF1HMiQ8JFj6tY23ujkAAACAXyFcBZBvCoYEnte6ntSMCLW6OQAAAIBfIVwFkMUbTpdgBwAAAOBdhKsAkXwiS37Zc9ysE64AAAAA7yNcBYhvNx0Su12kS+NYSYyNtLo5AAAAgN8hXAVYCXZ6rQAAAIDKQbgKAKey8+THLSlmnRLsAAAAQOUgXAWAZVtTJCvXJo1qR0n7xBirmwMAAAD4JcJVAFi04aCz1yooKMjq5gAAAAB+iXDl5/Jsdlmy8bBZZ0ggAAAAUHkIV37u1z3H5Eh6tsREhkqvFnWtbg4AAADgtwhXfm7Rhvxeq4vbJUhYCP/cAAAAQGXh03aAzLfqz5BAAAAAoFIRrvzY9uSTsi05XUKDg+SidvFWNwcAAADwa4QrP+YoZHFuy3pSKzLM6uYAAAAAfo1w5ccWbThkbqkSCAAAAFQ+wpWfOpqeLf/bddSsX9ohwermAAAAAH6PcOWnvt10WGx2kQ4NaknjOtFWNwcAAADwe4QrP7WYIYEAAABAlSJc+aHMnDz5YUuyWR/QgXAFAAAABES4mjNnjjRv3lwiIyOld+/esnr16hKPP378uIwbN04aNGggERER0rZtW/nyyy/P6Jz+ZsW2I5KRnSeJtSLlrEa1rG4OAAAAEBAsDVcLFiyQCRMmyJQpU2Tt2rXStWtXGThwoBw+nF9CvLDs7GwZMGCA7Ny5Uz766CNJSkqS1157TRo1alThc/qjbwqGBPbvmCBBQUFWNwcAAAAICEF2u91u1ZNrr1LPnj3l5ZdfNts2m02aNGkid911lzz88MNFjp87d64888wzsmnTJgkLC/PKOT1JS0uT2NhYSU1NlVq1fKvnx2azy7kzl8jhE1ny5q295MK2XDwYAAAAqKjyZAPLeq60F2rNmjXSv3//040JDjbbK1as8PiYzz77TPr06WOGBdavX1/OOussefLJJyUvL6/C51RZWVnmRXNdfNX6fakmWNWMCJVzW9a1ujkAAABAwLAsXKWkpJhQpCHJlW4fPHjQ42O2b99uhgPq43Se1aRJk+S5556Txx9/vMLnVDNnzjRp1LFoT5evXzhYe6wiQkOsbg4AAAAQMELFh+gQv4SEBHn11VclJCREunfvLvv27TNDBXWOVUVNnDjRzNNy0J4rXw1Yizeenm8FAACAyqFf6Ofk5FjdDHiBTjfSbOHT4SouLs78EIcO5YcBB91OTEz0+BitEFj4h+/QoYPpldIhgRU5p9Kqg7r4uj1HM2TTwRMSEhwkF7cjXAEAAHiblivQz55awRr+o3bt2iYvnGkxOMvCVXh4uOl5WrJkiQwbNszZM6Xb48eP9/iYvn37yrvvvmuO07lUavPmzSZ06flUec/pTxxDAns2ryO1o/NfDwAAAHiPI1jpaKro6GgqM/tBWM7IyHBWFtdc4bPDAnUo3siRI6VHjx7Sq1cvmT17tqSnp8vo0aPN/SNGjDBl1nVOlLrzzjtNFcB77rnHVP/bsmWLKWhx9913l/mcgRCu+nPhYAAAgEoZCugIVvXq1bO6OfCSqKgoc6sBS/9tz2SIoKXhavjw4ZKcnCyTJ0823wJ069ZNFi5c6CxIsXv3bmcPldJ5UF9//bXcd9990qVLFxO8NGg99NBDZT6nv0rNyJHVO4+a9QEd/ftnBQAAsIJjjpX2WMG/RBf8m+q/8ZmEK0uvc1Vd+eJ1rv7z6z655/1fpW39mvLNfRda3RwAAAC/k5mZKTt27JAWLVpIZGSk1c1BFf3b+sR1ruBd3xQMCaTXCgAAALAG4coPZOfa5PukZLPOfCsAAABUhebNm5v6BmW1dOlSUwDEnystEq78wMrtR+RkVq7Ex0RI18a1rW4OAAAAqhENNCUtU6dOrdB5f/75Zxk7dmyZjz/vvPPkwIEDZoidv/KpiwijlAsHd0iQ4GDKgQIAAOA0DTQOCxYsMIXfkpKSnPtq1qzpXNdyDFoVMTS09JgQHx9frnaEh4eXeO1Zf0DPlY/T/wAWU4IdAADAuuskZedaspS1Lp0GGseivUbaW+XY3rRpk8TExMhXX31lrhcbEREhy5Ytk23btslVV11lKm5r+OrZs6csXry4xGGBQUFB8s9//lOuvvpqU32vTZs28tlnnxU7LHD+/Pnm4r1aDbxDhw7meS6//HK3MJibm2suu6THafl7rRKul11yXNO2uqHnysf9sT9N9qdmSlRYiPRtHWd1cwAAAALKqZw86Tj5a0uee8P0gRId7p2P8w8//LA8++yz0rJlS6lTp47s2bNHBg8eLE888YQJXG+99ZYMGTLE9Hg1bdq02PNMmzZNnn76aXnmmWfkpZdekptuukl27doldevW9Xi8XsBXn/ftt982l2C6+eab5YEHHpB//etf5v6nnnrKrM+bN88EsBdeeEE+/fRTufjii6U6oufKT4YE9msTJ5FhFa/JDwAAgMA1ffp0GTBggLRq1coEoa5du8odd9whZ511lumBmjFjhrnPtSfKk1GjRsmNN94orVu3lieffFJOnjwpq1evLvZ4va7U3LlzpUePHnLOOefI+PHjZcmSJc77NaBNnDjR9Ia1b99eXn75ZdOLVV3Rc+XjFlGCHQAAwDI6ekh7kKx6bm/RcONKQ5EWuvjiiy/MMD0dnnfq1CnZvXt3iefp0qWLc71GjRrmulCHDx8u9ngdPqihzaFBgwbO4/W6UocOHZJevXo579cL/OrwRZvNJtUR4cqH7T9+ygwLDAoSuaR9gtXNAQAACDg6h8hbQ/OspEHIlQ7NW7RokRmyp71QUVFRct1110l2dnaJ5wkLCyvy+pQUhDwdX9a5ZNURwwL9YEhg96Z1pF7NCKubAwAAAD/x008/mSF+Ohyvc+fOpvjFzp07q7QNsbGxpqCGlnx30EqGa9eulerK92N2AGNIIAAAACqDzrP6+OOPTREL7U2aNGmSJUPx7rrrLpk5c6bpPdM5VzoH69ixY6ZN1RE9Vz4qLTPHXDxY9SdcAQAAwItmzZplqgbqhX81YA0cONAUnKhqDz30kCmQMWLECOnTp48p165tiYyMlOooyO7LgxorSVpamumG1El0OgmvOvp83X4Z/+4v0jK+hnx7/0VWNwcAAMDvZWZmyo4dO6RFixbV9sO9v7PZbKYk+/XXX28qGFbFv215sgHDAn2U48LBA7hwMAAAAPzUrl275JtvvpELL7xQsrKyTCl2DUF//vOfpTpiWKAPysmzybeb8ktUMt8KAAAA/io4OFjmz58vPXv2lL59+8r69etl8eLFpveqOqLnygf9vPOopGXmSt0a4XJ20zpWNwcAAACoFE2aNDGVC30FPVc+XCVQr20VElw9K6UAAAAAgYZw5WO0/ojj+lYMCQQAAACqD8KVj0k6dEL2HD0lEaHB0q9NnNXNAQAAAFCAcOWjVQLPbx0n0eFMmQMAAACqC8KVj1m0Mb9KIBcOBgAAAKoXwpUPOZSWKb/tOW7WL+2QYHVzAAAAALggXPmQJQW9Vt2a1JaEGK4KDgAAgKpx0UUXyb333uvcbt68ucyePbvExwQFBcmnn356xs/trfNUBcKVD1m04aC5pUogAAAAymrIkCFy+eWXe7zvxx9/NOFl3bp15Trnzz//LGPHjhVvmjp1qnTr1q3I/gMHDsigQYPEFxCufER6Vq78tO2IWSdcAQAAoKzGjBkjixYtkr179xa5b968edKjRw/p0qVLuc4ZHx8v0dHRUhUSExMlIiJCfAHhykf8uCVZsnNt0rRutLRJqGl1cwAAAKDsdpHsdGsWfe4yuPLKK00Ymj9/vtv+kydPyocffijDhg2TG2+8URo1amQCU+fOneW9994r8ZyFhwVu2bJFLrjgAomMjJSOHTuaMFfYQw89JG3btjXP0bJlS5k0aZLk5OSY+7Rt06ZNk99++830pOniaG/hYYHr16+XSy65RKKioqRevXqmB01/FodRo0aZn+nZZ5+VBg0amGPGjRvnfK7KRC1vH7Fow2Fnr5W+wQAAAFAN5GSIPNnQmud+ZL9IeI1SDwsNDZURI0aYsPLoo486P0tqsMrLy5Obb77ZrGv4qVWrlnzxxRdyyy23SKtWraRXr16lnt9ms8k111wj9evXl1WrVklqaqrb/CyHmJgY04aGDRuagHT77bebfQ8++KAMHz5cfv/9d1m4cKEsXrzYHB8bG1vkHOnp6TJw4EDp06ePGZp4+PBhue2222T8+PFu4fG7774zwUpvt27das6vQw71OSsTPVc+IM9ml2835V/fqn8HhgQCAACgfG699VbZtm2bfP/9925DAq+99lpp1qyZPPDAAyZ8aI/SXXfdZeZoffDBB2U6t4ahTZs2yVtvvSVdu3Y1PVhPPvlkkeMee+wxOe+880yvl84D0+d0PIf2QtWsWdMEQR0GqIvuK+zdd9+VzMxM81xnnXWW6cF6+eWX5e2335ZDh/I/L6s6deqY/e3btzc9d1dccYUsWbJEKhs9Vz5gza5jciwjR2KjwqRn8zpWNwcAAAAOYdH5PUhWPXcZacjQYPPGG2+Yyn/am6PFLKZPn256rzQMadDZt2+fZGdnS1ZWVpnnVG3cuFGaNGlieqQctGepsAULFsiLL75oQp4O48vNzTU9ZeWhz6UBrkaN0z12ffv2Nb1nSUlJpvdMderUSUJCQpzHaC+W9pZVNnqufMDijfkp/JL2CRIawj8ZAABAtaFD7HRonhVLOaeKaGGLf//733LixAnTa6XD/i688EJ55pln5IUXXjDDAnUY3a+//mqG3mnI8pYVK1bITTfdJIMHD5bPP/9cfvnlFzNE0ZvP4SosLMxtW4dCagCrbHxSr+bsdrss2pAfrqgSCAAAgIq6/vrrJTg42Ayt02F1OlRQQ8dPP/0kV111lZl7pb1COjRw8+bNZT5vhw4dZM+ePaZkusPKlSvdjlm+fLkZfqiBSqsTtmnTRnbt2uV2THh4uOlFK+25tOiFzr1y0Pbrz9WuXTuxWrUIV3PmzDFjL7W6SO/evWX16tXFHqsT1RwVRByLPs6VVggpfExxtf2ru23J6bIjJV3CQ4LlgrbxVjcHAAAAPkrnNGlhh4kTJ5ogpJ+ZlQYdre6nAUiH3d1xxx1u85dK079/f1MFcOTIkSb46HBDDVGu9Dl2794t77//vhkWqMMDP/nkE7djNA/s2LHD9JylpKSYoYmFae+XfvbX59ICGNrTpnPEtACHY0hgQIcrHXs5YcIEmTJliqxdu9akZe2G1MofxdGxmfqGcCyFU6/SMOV6TGnlJKsrR6/Vua3qSc0IpsgBAACg4nRo4LFjx8znbcccKS00cc4555h9Oh9Li0loKfOy0l4jDUqnTp0y1QW1et8TTzzhdszQoUPlvvvuM1X9tHCGBjktxe5Ki2voZ/iLL77YlI739Pld54F9/fXXcvToUenZs6dcd911cumll5riFdVBkF3HnVlIe6r0hXG8IDoWUifEaQJ9+OGHPfZcaWnH48ePF3tOTeF6v2s9/PJIS0szpR+1jGR5J9l527WvLDcFLWYMO0tuObeZpW0BAAAIZFqlTntWWrRoUWTkFHxbSf+25ckGlvZc6QS2NWvWmK5EZ4OCg822TnorjlYX0TGbGsJ0fOgff/xR5JilS5dKQkKCGXt55513ypEjR4o9n3Y56ovmulQHNptdOjeKlYaxkdK/Q4LVzQEAAABQXcOVjqXUSWuFx0fq9sGDBz0+RsOSlpD8z3/+I++8847p6dKyknv37nUeo92JOklPa9k/9dRTpp7/oEGDip0gN3PmTJNGHYuGtuogODhIpg7tJD89fIk0iC1a5x8AAABA9eFzk3i0Zr5r3XwNVlo15B//+IfMmDHD7Lvhhhuc93fu3Fm6dOliSk1qb5aOySxMJ/XpvC8H7bmqLgFLOa6iDQAAAKD6srTnKi4uzlzcq3A1Et3WiXRlrWF/9tlnmwuhFUfLSepzFXdMRESEGT/pugAAAACAz4QrrWXfvXt3M3zPQYf56banqzp7okP99GrLetXl4uiQQZ1zVdIxAAAAQFlYXA8O1fjf1PJS7Doc77XXXpM333zT1NXX4hN6UbDRo0eb+0eMGGGG7TlMnz5dvvnmG9m+fbsp3a4XO9NS7Fry0VHs4v/+7//Mhct27txpgpoWvWjdurUpLwkAAABUhI6YUhkZGVY3BV7m+Dd1/Bv77JwrvZBZcnKyTJ482RSx0Lr3CxcudBa50IuNaQVBB63Lf/vtt5tj69SpY3q+tE5+x44dzf06zHDdunUmrGk5dq3ff9lll5n5WDr8DwAAAKgI/ZxZu3Zt5/VY9ZpLzI33/R6rjIwM82+q/7b6b+zT17mqjqrTda4AAABQfehHZ/2Sv6RrrsL3aLDSmg+ewnJ5soHlPVcAAACAr9AP3zqPX6+nmpOTY3Vz4AU6FPBMe6wcCFcAAABAOemHcW99IIf/sLygBQAAAAD4A8IVAAAAAHgB4QoAAAAAvIA5Vx44CihqZRAAAAAAgSutIBOUpcg64cqDEydOmNsmTZpY3RQAAAAA1SQjaEn2knCdKw9sNpvs379fYmJiLL8wnCZlDXl79uzhmltVhNe86vGaVy1e76rHa171eM2rFq931eM1rzoalzRYNWzYUIKDS55VRc+VB/qiNW7cWKoT/Y+G/3CqFq951eM1r1q83lWP17zq8ZpXLV7vqsdrXjVK67FyoKAFAAAAAHgB4QoAAAAAvIBwVc1FRETIlClTzC2qBq951eM1r1q83lWP17zq8ZpXLV7vqsdrXj1R0AIAAAAAvICeKwAAAADwAsIVAAAAAHgB4QoAAAAAvIBwBQAAAABeQLiqBubMmSPNmzeXyMhI6d27t6xevbrE4z/88ENp3769Ob5z587y5ZdfVllbfd3MmTOlZ8+eEhMTIwkJCTJs2DBJSkoq8THz58+XoKAgt0Vfe5TN1KlTi7x++v4tCe/xM6O/Twq/5rqMGzfO4/G8x8vnhx9+kCFDhkjDhg3Na/Xpp5+63a91oiZPniwNGjSQqKgo6d+/v2zZssXrfwsCSUmveU5Ojjz00EPmd0WNGjXMMSNGjJD9+/d7/XdTICntfT5q1Kgir9/ll19e6nl5n1fs9fb0O12XZ555pthz8h63BuHKYgsWLJAJEyaYUppr166Vrl27ysCBA+Xw4cMej1++fLnceOONMmbMGPnll19MONDl999/r/K2+6Lvv//efMBcuXKlLFq0yPxRvuyyyyQ9Pb3Ex+mVzw8cOOBcdu3aVWVt9gedOnVye/2WLVtW7LG8x8/czz//7PZ663td/elPfyr2MbzHy05/X+jvav2Q6MnTTz8tL774osydO1dWrVplPvDr7/XMzEyv/S0INCW95hkZGeY1mzRpkrn9+OOPzZdmQ4cO9ervpkBT2vtcaZhyff3ee++9Es/J+7zir7fr66zLG2+8YcLStddeW+J5eY9bQEuxwzq9evWyjxs3zrmdl5dnb9iwoX3mzJkej7/++uvtV1xxhdu+3r172++4445Kb6s/Onz4sF6KwP79998Xe8y8efPssbGxVdoufzJlyhR7165dy3w873Hvu+eee+ytWrWy22w2j/fzHq84/f3xySefOLf1NU5MTLQ/88wzzn3Hjx+3R0RE2N977z2v/S0IZIVfc09Wr15tjtu1a5fXfjcFMk+v+ciRI+1XXXVVuc7D+9x773F97S+55JISj+E9bg16riyUnZ0ta9asMUNGHIKDg832ihUrPD5G97ser/Rbn+KOR8lSU1PNbd26dUs87uTJk9KsWTNp0qSJXHXVVfLHH39UUQv9gw6J0qEOLVu2lJtuukl2795d7LG8x73/e+add96RW2+91XzLWRze496xY8cOOXjwoNt7ODY21gx/Ku49XJG/BSj9d7u+32vXru21300oaunSpWaIfbt27eTOO++UI0eOFHss73PvOXTokHzxxRdmhEdpeI9XPcKVhVJSUiQvL0/q16/vtl+39Y+zJ7q/PMejeDabTe69917p27evnHXWWcUep380tPv9P//5j/mQqo8777zzZO/evVXaXl+lHyp1Ts/ChQvllVdeMR8++/XrJydOnPB4PO9x79Jx+8ePHzfzI4rDe9x7HO/T8ryHK/K3AMXT4Zc6B0uHF+twV2/9bkLRIYFvvfWWLFmyRJ566ikz7H7QoEHmvewJ73PvefPNN83c8WuuuabE43iPWyPUoucFLKdzr3QeT2njj/v06WMWB/3Q2aFDB/nHP/4hM2bMqIKW+jb9Y+vQpUsX88tee0g++OCDMn3rhjPz+uuvm38D/eayOLzH4S90Hu31119vioroh8mS8LvpzNxwww3OdS0moq9hq1atTG/WpZdeamnb/J1+Gaa9UKUVHuI9bg16riwUFxcnISEhpnvXlW4nJiZ6fIzuL8/x8Gz8+PHy+eefy3fffSeNGzcu12PDwsLk7LPPlq1bt1Za+/yZDtNp27Ztsa8f73Hv0aIUixcvlttuu61cj+M9XnGO92l53sMV+VuA4oOVvu+1iEtJvVYV+d2EkumwM30vF/f68T73jh9//NEUbCnv73XFe7xqEK4sFB4eLt27dzdd6g46HEe3Xb9FdqX7XY9X+kekuOPhTr/N1GD1ySefyLfffistWrQo9zl0WMP69etNmWWUn87t2bZtW7GvH+9x75k3b56ZD3HFFVeU63G8xytOf6foB0XX93BaWpqpGljce7gifwvgOVjp/BL9QqFevXpe/92EkukwYp1zVdzrx/vce6MR9HXUyoLlxXu8ilhUSAMF3n//fVNFav78+fYNGzbYx44da69du7b94MGD5v5bbrnF/vDDDzuP/+mnn+yhoaH2Z5991r5x40ZTCSYsLMy+fv16C38K33HnnXeaqmhLly61HzhwwLlkZGQ4jyn8mk+bNs3+9ddf27dt22Zfs2aN/YYbbrBHRkba//jjD4t+Ct9y//33m9d7x44d5v3bv39/e1xcnKnUqHiPVw6twtW0aVP7Qw89VOQ+3uNn5sSJE/ZffvnFLPpndNasWWbdUZnub3/7m/k9/p///Me+bt06U9WrRYsW9lOnTjnPoVW+XnrppTL/LQh0Jb3m2dnZ9qFDh9obN25s//XXX91+t2dlZRX7mpf2uynQlfSa630PPPCAfcWKFeb1W7x4sf2cc86xt2nTxp6Zmek8B+9z7/1eUampqfbo6Gj7K6+84vEcvMerB8JVNaD/IeiHoPDwcFOmdOXKlc77LrzwQlPu1NUHH3xgb9u2rTm+U6dO9i+++MKCVvsm/YXladFS1MW95vfee6/z36d+/fr2wYMH29euXWvRT+B7hg8fbm/QoIF5/Ro1amS2t27d6ryf93jl0LCk7+2kpKQi9/EePzPfffedx98jjtdUy7FPmjTJvJb6QfLSSy8t8u/QrFkz88VBWf8WBLqSXnP94Fjc73Z9XHGveWm/mwJdSa+5fiF52WWX2ePj482XX/ra3n777UVCEu9z7/1eUf/4xz/sUVFR5vIOnvAerx6C9P+qqpcMAAAAAPwVc64AAAAAwAsIVwAAAADgBYQrAAAAAPACwhUAAAAAeAHhCgAAAAC8gHAFAAAAAF5AuAIAAAAALyBcAQAAAIAXEK4AADhDQUFB8umnn1rdDACAxQhXAACfNmrUKBNuCi+XX3651U0DAASYUKsbAADAmdIgNW/ePLd9ERERlrUHABCY6LkCAPg8DVKJiYluS506dcx92ov1yiuvyKBBgyQqKkpatmwpH330kdvj169fL5dccom5v169ejJ27Fg5efKk2zFvvPGGdOrUyTxXgwYNZPz48W73p6SkyNVXXy3R0dHSpk0b+eyzz5z3HTt2TG666SaJj483z6H3Fw6DAADfR7gCAPi9SZMmybXXXiu//fabCTk33HCDbNy40dyXnp4uAwcONGHs559/lg8//FAWL17sFp40nI0bN86ELg1iGpxat27t9hzTpk2T66+/XtatWyeDBw82z3P06FHn82/YsEG++uor87x6vri4uCp+FQAAlS3IbrfbK/1ZAACoxDlX77zzjkRGRrrtf+SRR8yiPVd/+ctfTKBxOPfcc+Wcc86Rv//97/Laa6/JQw89JHv27JEaNWqY+7/88ksZMmSI7N+/X+rXry+NGjWS0aNHy+OPP+6xDfocjz32mMyYMcMZ2GrWrGnClA5ZHDp0qAlT2vsFAPBfzLkCAPi8iy++2C08qbp16zrX+/Tp43afbv/6669mXXuSunbt6gxWqm/fvmKz2SQpKckEJw1Zl156aYlt6NKli3Ndz1WrVi05fPiw2b7zzjtNz9natWvlsssuk2HDhsl55513hj81AKC6IVwBAHyehpnCw/S8RedIlUVYWJjbtoYyDWhK53vt2rXL9IgtWrTIBDUdZvjss89WSpsBANZgzhUAwO+tXLmyyHaHDh3Mut7qXCwdyufw008/SXBwsLRr105iYmKkefPmsmTJkjNqgxazGDlypBnCOHv2bHn11VfP6HwAgOqHnisAgM/LysqSgwcPuu0LDQ11Fo3QIhU9evSQ888/X/71r3/J6tWr5fXXXzf3aeGJKVOmmOAzdepUSU5OlrvuuktuueUWM99K6X6dt5WQkGB6oU6cOGECmB5XFpMnT5bu3bubaoPa1s8//9wZ7gAA/oNwBQDweQsXLjTl0V1pr9OmTZuclfzef/99+etf/2qOe++996Rjx47mPi2d/vXXX8s999wjPXv2NNs6P2rWrFnOc2nwyszMlOeff14eeOABE9quu+66MrcvPDxcJk6cKDt37jTDDPv162faAwDwL1QLBAD4NZ379Mknn5giEgAAVCbmXAEAAACAFxCuAAAAAMALmHMFAPBrjH4HAFQVeq4AAAAAwAsIVwAAAADgBYQrAAAAAPACwhUAAAAAeAHhCgAAAAC8gHAFAAAAAF5AuAIAAAAALyBcAQAAAICcuf8HeO5reQsUeJ8AAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 181
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3:  Hyper parameter tuning\n",
    "\n",
    "### **3.1 Manual hyper parameter tuning**\n",
    "Spend some time (20 to 30 minutes) tuning the network architecture (number of layers, number of nodes per layer, activation function) and other hyper parameters (optimizer, learning rate, batch size, number of epochs, degree of regularization). For example, try a much deeper network. How much does the training time increase for a network with 10 layers?\n",
    "\n",
    "#### **<span style=\"color:red\">Question</span>**\n",
    "14. How high classification accuracy can you achieve for the test data? What is your best configuration?\n",
    "   \n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "14. The best accuracy we could achieve was 0.93542671 with the configuration as shown below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T10:24:31.742528Z",
     "start_time": "2026-02-27T10:22:12.942491Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "best_model = build_DNN(input_shape=(Xtrain.shape[1],),\n",
    "                       n_hidden_layers=4,\n",
    "                       n_hidden_units=30,\n",
    "                       learning_rate=0.001,\n",
    "                       loss=BinaryCrossentropy(),\n",
    "                       use_bn=True,\n",
    "                       optimizer=\"adam\",\n",
    "                       act_fun=\"relu\")\n",
    "\n",
    "best_history = best_model.fit(Xtrain, Ytrain,\n",
    "                              validation_data=(Xval, Yval),\n",
    "                              class_weight=class_weights,\n",
    "                              epochs=20,\n",
    "                              batch_size=100,\n",
    "                              verbose=1)\n",
    "# Evaluate model on test data\n",
    "best_score = best_model.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.8f' % best_score[0])\n",
    "print('Test accuracy: %.8f' % best_score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(best_history)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1715 - accuracy: 0.9131 - val_loss: 0.1975 - val_accuracy: 0.9172\n",
      "Epoch 2/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1504 - accuracy: 0.9208 - val_loss: 0.1882 - val_accuracy: 0.9294\n",
      "Epoch 3/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1393 - accuracy: 0.9282 - val_loss: 0.2283 - val_accuracy: 0.9223\n",
      "Epoch 4/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1346 - accuracy: 0.9305 - val_loss: 0.1673 - val_accuracy: 0.9335\n",
      "Epoch 5/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1322 - accuracy: 0.9316 - val_loss: 0.2064 - val_accuracy: 0.9326\n",
      "Epoch 6/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1302 - accuracy: 0.9325 - val_loss: 0.1718 - val_accuracy: 0.9342\n",
      "Epoch 7/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1295 - accuracy: 0.9328 - val_loss: 0.1651 - val_accuracy: 0.9325\n",
      "Epoch 8/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1285 - accuracy: 0.9332 - val_loss: 0.1657 - val_accuracy: 0.9348\n",
      "Epoch 9/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1271 - accuracy: 0.9338 - val_loss: 0.1688 - val_accuracy: 0.9357\n",
      "Epoch 10/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1261 - accuracy: 0.9342 - val_loss: 0.1547 - val_accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1263 - accuracy: 0.9343 - val_loss: 0.1712 - val_accuracy: 0.9350\n",
      "Epoch 12/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1255 - accuracy: 0.9344 - val_loss: 0.3711 - val_accuracy: 0.9171\n",
      "Epoch 13/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1250 - accuracy: 0.9347 - val_loss: 0.1716 - val_accuracy: 0.9336\n",
      "Epoch 14/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1240 - accuracy: 0.9347 - val_loss: 0.1813 - val_accuracy: 0.9341\n",
      "Epoch 15/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1236 - accuracy: 0.9351 - val_loss: 0.4054 - val_accuracy: 0.9079\n",
      "Epoch 16/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1235 - accuracy: 0.9350 - val_loss: 0.4219 - val_accuracy: 0.9077\n",
      "Epoch 17/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1227 - accuracy: 0.9352 - val_loss: 0.1610 - val_accuracy: 0.9360\n",
      "Epoch 18/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1221 - accuracy: 0.9354 - val_loss: 0.1482 - val_accuracy: 0.9359\n",
      "Epoch 19/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1219 - accuracy: 0.9355 - val_loss: 0.1643 - val_accuracy: 0.9361\n",
      "Epoch 20/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1214 - accuracy: 0.9357 - val_loss: 0.1473 - val_accuracy: 0.9362\n",
      "Test loss: 0.15012409\n",
      "Test accuracy: 0.93542671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 182
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Automatic hyper parameter search**\n",
    "The number of hyper parameters that can be tried manually is limited and the process of trying out the different combinations and keeping track of them is time consuming and tedious. Today, there are several libraries available for automatic hyper parameter tuning (see an extensive list [here](https://github.com/balavenkatesh3322/hyperparameter_tuning)). The library that we will use in this lab is `Ray Tune` which can be integrated with many of the deep learning APIs available today (for the full description of the library capabilities see the [documentation](https://docs.ray.io/en/latest/tune/index.html)).\n",
    "\n",
    "\n",
    "To use the `Ray Tune` functionality we need a function that defines the model training. This will then be used in a wrapper function that defines the hyper parameter search space, the resources available for running the search and the search algorithm. \n",
    "\n",
    "Start by implementing the `train_DNN` function in the `utilities.py` file (more detailed instructions are available in `utilities.py`). In the cell below, you can set up the search space and a `tune` ray object that takes the `train_DNN`. The tuner will set `train_DNN`, will select a set of hyper parameters and train several models for us (more information [here](https://docs.ray.io/en/latest/tune/key-concepts.html?_gl=1*j3ryje*_up*MQ..*_ga*NzQyMjIzNzg4LjE3MzY0MTk5MzY.*_ga_0LCWHW1N3S*MTczNjQxOTkzNS4xLjAuMTczNjQxOTkzNS4wLjAuMA..#tune-60-seconds)). \n",
    "\n",
    "\n",
    "`Ray Tune` library provides several types of hyper parameter search algorithms, including random and grid search, and Bayesian optimization. In this lab we will be using the default Ray Tune opitmization algorithm which is random serach. More infromation about the available search arlgorithms can be found [here](https://docs.ray.io/en/latest/tune/api/suggestion.html).\n",
    "\n",
    "#### **<span style=\"color:red\">Question</span>**\n",
    "15. Run the automatic hyper parameter search with range of possible hyper parameter values as in your manual search. Does the automatic search set of parameters match those that you have found?\n",
    "16. What are the benefits and drawbacks of automatic hyper parameter search?\n",
    "   \n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "15. The automatic hyperparameter search found the following configuration (using 25 samples) as best with 0.94435\t:\n",
    "    - act_fun: 'relu', optimizer: 'adam', use_bn: True, n_hidden_layers: 3, n_hidden_units: 40\n",
    "    - this is better than my manual search, i havent tested this configuration manually\n",
    "    - interestingly, by chance this configuration has been sampled twice and produces 2 different accuracy scores, likely due to seed and randomness\n",
    "16. hyper parameter search makes it easy to explore difference parameters without manual interaction, but searching for hyperparameter can be manually improved using domain knowledge and isolating effects of parameters differences"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T11:02:45.345493Z",
     "start_time": "2026-02-27T10:24:52.591499Z"
    }
   },
   "source": [
    "# import train_DNN\n",
    "from utilities import train_DNN\n",
    "\n",
    "# imports for hyperparameter tuning\n",
    "from ray import tune, train\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "# --------------------------------------------  \n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Define the hyper parameter, both those that should be searched and those that are fixed.\n",
    "#  Hyperparameters to search are: act_fun, optimizer, use_bn, n_hidden_layers and n_hidden_units.\n",
    "# The remaining parameters can be set to fixed values (This is to reduce the search space and time).\n",
    "# Add the batch size and epochs so that the train_DNN can access them.\n",
    "hyperparameter_space = {\n",
    "    \"act_fun\": tune.choice([\"relu\", \"sigmoid\"]),\n",
    "    \"optimizer\": tune.choice([\"sgd\", \"adam\"]),\n",
    "    \"use_bn\": tune.choice([True, False]),\n",
    "    \"n_hidden_layers\": tune.randint(2, 5),\n",
    "    \"n_hidden_units\": tune.choice([15, 20, 30, 40]),\n",
    "    # here define the fixed parameters\n",
    "    \"loss\": BinaryCrossentropy(),\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"use_dropout\": False,\n",
    "    \"use_custom_dropout\": False,\n",
    "    \"use_variational_layer\": False,\n",
    "    \"input_shape\": (Xtrain.shape[1],),\n",
    "}\n",
    "\n",
    "# specify batch and number of epochs\n",
    "training_config = {\n",
    "    \"data\": (Xtrain, Ytrain, Xval, Yval),\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 100\n",
    "}\n",
    "\n",
    "# specify the number of samples to take from the hyper parameter space and run. The larger the number, the longer the search time.\n",
    "# Start small (e.g. 2) to test your implementation, then increase.\n",
    "num_samples = 25\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Definition of the Scheduler. This allows for several models to be trained/stopped/re-started simultaneously \n",
    "sched = AsyncHyperBandScheduler(\n",
    "    metric=\"mean_accuracy\", mode=\"max\",\n",
    "    time_attr=\"training_iteration\", max_t=400, grace_period=20\n",
    ")\n",
    "\n",
    "# Setting up the tuner.\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(tune.with_parameters(train_DNN, training_config=training_config),\n",
    "                        resources={\"cpu\": 8, \"gpu\": 0}),\n",
    "    # definition of which training function to use and the available resources. Consider adding \"gpu\":0 to resources if available.\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=sched,\n",
    "        num_samples=num_samples,\n",
    "    ),\n",
    "    run_config=train.RunConfig(\n",
    "        name=\"DNN_hp_tuning\",\n",
    "        stop={\"mean_accuracy\": 1},\n",
    "        storage_path='/Users/finnbeckmann/uni/DLLabs/ray'\n",
    "        # where to save the summary of the hyper parameter tuning.\n",
    "    ),\n",
    "    param_space=hyperparameter_space,\n",
    ")\n",
    "\n",
    "# Run the hyper parameter search.\n",
    "results = tuner.fit()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2026-02-27 12:02:45</td></tr>\n",
       "<tr><td>Running for: </td><td>00:37:47.89        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.7/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=15<br>Bracket: Iter 320.000: None | Iter 80.000: None | Iter 20.000: 0.9390333741903305<br>Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 3<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_DNN_906fd_00009</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2026-02-27_11-24-54_848116_79203/artifacts/2026-02-27_11-24-57/DNN_hp_tuning/driver_artifacts/train_DNN_906fd_00009_9_act_fun=sigmoid,n_hidden_layers=3,n_hidden_units=20,optimizer=adam,use_bn=True_2026-02-27_11-24-57/error.txt  </td></tr>\n",
       "<tr><td>train_DNN_906fd_00014</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2026-02-27_11-24-54_848116_79203/artifacts/2026-02-27_11-24-57/DNN_hp_tuning/driver_artifacts/train_DNN_906fd_00014_14_act_fun=sigmoid,n_hidden_layers=3,n_hidden_units=40,optimizer=adam,use_bn=False_2026-02-27_11-24-57/error.txt</td></tr>\n",
       "<tr><td>train_DNN_906fd_00021</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2026-02-27_11-24-54_848116_79203/artifacts/2026-02-27_11-24-57/DNN_hp_tuning/driver_artifacts/train_DNN_906fd_00021_21_act_fun=relu,n_hidden_layers=4,n_hidden_units=15,optimizer=adam,use_bn=True_2026-02-27_11-24-57/error.txt    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc           </th><th>act_fun  </th><th style=\"text-align: right;\">  n_hidden_layers</th><th style=\"text-align: right;\">  n_hidden_units</th><th>optimizer  </th><th>use_bn  </th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_DNN_906fd_00000</td><td>TERMINATED</td><td>127.0.0.1:5354</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              30</td><td>adam       </td><td>True    </td><td style=\"text-align: right;\">0.94435 </td><td style=\"text-align: right;\">0.10607 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        126.059 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00001</td><td>TERMINATED</td><td>127.0.0.1:5381</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.920139</td><td style=\"text-align: right;\">0.147799</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         71.2563</td></tr>\n",
       "<tr><td>train_DNN_906fd_00002</td><td>TERMINATED</td><td>127.0.0.1:5426</td><td>sigmoid  </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              20</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.840627</td><td style=\"text-align: right;\">0.433625</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         67.468 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00003</td><td>TERMINATED</td><td>127.0.0.1:5445</td><td>sigmoid  </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              20</td><td>adam       </td><td>False   </td><td style=\"text-align: right;\">0.939177</td><td style=\"text-align: right;\">0.113244</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         88.3461</td></tr>\n",
       "<tr><td>train_DNN_906fd_00004</td><td>TERMINATED</td><td>127.0.0.1:5480</td><td>relu     </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              20</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.919033</td><td style=\"text-align: right;\">0.148996</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         64.9396</td></tr>\n",
       "<tr><td>train_DNN_906fd_00005</td><td>TERMINATED</td><td>127.0.0.1:5487</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>True    </td><td style=\"text-align: right;\">0.916918</td><td style=\"text-align: right;\">0.152097</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         88.9457</td></tr>\n",
       "<tr><td>train_DNN_906fd_00006</td><td>TERMINATED</td><td>127.0.0.1:5508</td><td>sigmoid  </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              20</td><td>adam       </td><td>False   </td><td style=\"text-align: right;\">0.938603</td><td style=\"text-align: right;\">0.114153</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         96.107 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00007</td><td>TERMINATED</td><td>127.0.0.1:5533</td><td>sigmoid  </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              40</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.840627</td><td style=\"text-align: right;\">0.425481</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         75.9178</td></tr>\n",
       "<tr><td>train_DNN_906fd_00008</td><td>TERMINATED</td><td>127.0.0.1:5557</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              15</td><td>sgd        </td><td>True    </td><td style=\"text-align: right;\">0.916587</td><td style=\"text-align: right;\">0.155163</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         84.6968</td></tr>\n",
       "<tr><td>train_DNN_906fd_00010</td><td>TERMINATED</td><td>127.0.0.1:5627</td><td>sigmoid  </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              40</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.840627</td><td style=\"text-align: right;\">0.428601</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         75.6393</td></tr>\n",
       "<tr><td>train_DNN_906fd_00011</td><td>TERMINATED</td><td>127.0.0.1:5641</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              20</td><td>adam       </td><td>True    </td><td style=\"text-align: right;\">0.941203</td><td style=\"text-align: right;\">0.110122</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        118.005 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00012</td><td>TERMINATED</td><td>127.0.0.1:5662</td><td>sigmoid  </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              20</td><td>adam       </td><td>False   </td><td style=\"text-align: right;\">0.939895</td><td style=\"text-align: right;\">0.113701</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         88.8766</td></tr>\n",
       "<tr><td>train_DNN_906fd_00013</td><td>TERMINATED</td><td>127.0.0.1:5684</td><td>sigmoid  </td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">              30</td><td>adam       </td><td>False   </td><td style=\"text-align: right;\">0.940788</td><td style=\"text-align: right;\">0.10982 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         83.5416</td></tr>\n",
       "<tr><td>train_DNN_906fd_00015</td><td>TERMINATED</td><td>127.0.0.1:5750</td><td>sigmoid  </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.903953</td><td style=\"text-align: right;\">0.183174</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         68.3282</td></tr>\n",
       "<tr><td>train_DNN_906fd_00016</td><td>TERMINATED</td><td>127.0.0.1:5786</td><td>sigmoid  </td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">              20</td><td>adam       </td><td>True    </td><td style=\"text-align: right;\">0.937661</td><td style=\"text-align: right;\">0.113247</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        102.782 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00017</td><td>TERMINATED</td><td>127.0.0.1:5853</td><td>sigmoid  </td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">              15</td><td>adam       </td><td>True    </td><td style=\"text-align: right;\">0.937887</td><td style=\"text-align: right;\">0.114444</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        101.339 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00018</td><td>TERMINATED</td><td>127.0.0.1:5973</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              15</td><td>sgd        </td><td>True    </td><td style=\"text-align: right;\">0.91746 </td><td style=\"text-align: right;\">0.153376</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         90.3399</td></tr>\n",
       "<tr><td>train_DNN_906fd_00019</td><td>TERMINATED</td><td>127.0.0.1:6021</td><td>sigmoid  </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              30</td><td>adam       </td><td>False   </td><td style=\"text-align: right;\">0.939822</td><td style=\"text-align: right;\">0.110727</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        110.137 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00020</td><td>TERMINATED</td><td>127.0.0.1:6078</td><td>sigmoid  </td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>True    </td><td style=\"text-align: right;\">0.908522</td><td style=\"text-align: right;\">0.166087</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         89.7045</td></tr>\n",
       "<tr><td>train_DNN_906fd_00022</td><td>TERMINATED</td><td>127.0.0.1:6167</td><td>sigmoid  </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.840627</td><td style=\"text-align: right;\">0.417028</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         99.3952</td></tr>\n",
       "<tr><td>train_DNN_906fd_00023</td><td>TERMINATED</td><td>127.0.0.1:6261</td><td>relu     </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>False   </td><td style=\"text-align: right;\">0.919111</td><td style=\"text-align: right;\">0.14881 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        102.472 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00024</td><td>TERMINATED</td><td>127.0.0.1:6312</td><td>relu     </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              30</td><td>sgd        </td><td>True    </td><td style=\"text-align: right;\">0.916019</td><td style=\"text-align: right;\">0.152742</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">        123.519 </td></tr>\n",
       "<tr><td>train_DNN_906fd_00009</td><td>ERROR     </td><td>127.0.0.1:5615</td><td>sigmoid  </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              20</td><td>adam       </td><td>True    </td><td style=\"text-align: right;\">0.935756</td><td style=\"text-align: right;\">0.118198</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         41.5022</td></tr>\n",
       "<tr><td>train_DNN_906fd_00014</td><td>ERROR     </td><td>127.0.0.1:5745</td><td>sigmoid  </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">              40</td><td>adam       </td><td>False   </td><td style=\"text-align: right;\">0.923538</td><td style=\"text-align: right;\">0.140992</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         10.7297</td></tr>\n",
       "<tr><td>train_DNN_906fd_00021</td><td>ERROR     </td><td>127.0.0.1:6156</td><td>relu     </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">              15</td><td>adam       </td><td>True    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "fa358feddf0f393139f23a29003f9ff1"
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 30:41 - loss: 0.9146 - accuracy: 0.2000\n",
      " 104/5349 [..............................] - ETA: 5s - loss: 0.4408 - accuracy: 0.8619\n",
      " 218/5349 [>.............................] - ETA: 4s - loss: 0.3321 - accuracy: 0.8852\n",
      " 320/5349 [>.............................] - ETA: 4s - loss: 0.2880 - accuracy: 0.8926\n",
      " 430/5349 [=>............................] - ETA: 4s - loss: 0.2577 - accuracy: 0.8992\n",
      " 520/5349 [=>............................] - ETA: 4s - loss: 0.2429 - accuracy: 0.9013\n",
      " 628/5349 [==>...........................] - ETA: 4s - loss: 0.2297 - accuracy: 0.9029\n",
      " 718/5349 [===>..........................] - ETA: 4s - loss: 0.2220 - accuracy: 0.9042\n",
      " 811/5349 [===>..........................] - ETA: 4s - loss: 0.2152 - accuracy: 0.9051\n",
      " 908/5349 [====>.........................] - ETA: 4s - loss: 0.2089 - accuracy: 0.9069\n",
      "1012/5349 [====>.........................] - ETA: 4s - loss: 0.2039 - accuracy: 0.9074\n",
      "1110/5349 [=====>........................] - ETA: 4s - loss: 0.2002 - accuracy: 0.9077\n",
      "1218/5349 [=====>........................] - ETA: 4s - loss: 0.1963 - accuracy: 0.9084\n",
      "1316/5349 [======>.......................] - ETA: 4s - loss: 0.1935 - accuracy: 0.9086\n",
      "1426/5349 [======>.......................] - ETA: 3s - loss: 0.1906 - accuracy: 0.9091\n",
      "1525/5349 [=======>......................] - ETA: 3s - loss: 0.1885 - accuracy: 0.9092\n",
      "1633/5349 [========>.....................] - ETA: 3s - loss: 0.1862 - accuracy: 0.9098\n",
      "1735/5349 [========>.....................] - ETA: 3s - loss: 0.1841 - accuracy: 0.9103\n",
      "1833/5349 [=========>....................] - ETA: 3s - loss: 0.1826 - accuracy: 0.9107\n",
      "1939/5349 [=========>....................] - ETA: 3s - loss: 0.1806 - accuracy: 0.9113\n",
      "2107/5349 [==========>...................] - ETA: 3s - loss: 0.1783 - accuracy: 0.9117\n",
      "2215/5349 [===========>..................] - ETA: 3s - loss: 0.1769 - accuracy: 0.9120\n",
      "2322/5349 [============>.................] - ETA: 2s - loss: 0.1754 - accuracy: 0.9125\n",
      "2431/5349 [============>.................] - ETA: 2s - loss: 0.1740 - accuracy: 0.9129\n",
      "2542/5349 [=============>................] - ETA: 2s - loss: 0.1730 - accuracy: 0.9130\n",
      "2640/5349 [=============>................] - ETA: 2s - loss: 0.1722 - accuracy: 0.9129\n",
      "2733/5349 [==============>...............] - ETA: 2s - loss: 0.1713 - accuracy: 0.9133\n",
      "2794/5349 [==============>...............] - ETA: 2s - loss: 0.1707 - accuracy: 0.9135\n",
      "2869/5349 [===============>..............] - ETA: 2s - loss: 0.1701 - accuracy: 0.9137\n",
      "2953/5349 [===============>..............] - ETA: 2s - loss: 0.1696 - accuracy: 0.9139\n",
      "3036/5349 [================>.............] - ETA: 2s - loss: 0.1689 - accuracy: 0.9141\n",
      "3112/5349 [================>.............] - ETA: 2s - loss: 0.1685 - accuracy: 0.9142\n",
      "3203/5349 [================>.............] - ETA: 2s - loss: 0.1679 - accuracy: 0.9143\n",
      "3271/5349 [=================>............] - ETA: 2s - loss: 0.1675 - accuracy: 0.9144\n",
      "3363/5349 [=================>............] - ETA: 2s - loss: 0.1670 - accuracy: 0.9145\n",
      "3437/5349 [==================>...........] - ETA: 1s - loss: 0.1665 - accuracy: 0.9146\n",
      "3480/5349 [==================>...........] - ETA: 1s - loss: 0.1662 - accuracy: 0.9147\n",
      "3550/5349 [==================>...........] - ETA: 1s - loss: 0.1658 - accuracy: 0.9148\n",
      "3622/5349 [===================>..........] - ETA: 1s - loss: 0.1654 - accuracy: 0.9149\n",
      "3700/5349 [===================>..........] - ETA: 1s - loss: 0.1650 - accuracy: 0.9150\n",
      "3777/5349 [====================>.........] - ETA: 1s - loss: 0.1645 - accuracy: 0.9151\n",
      "3878/5349 [====================>.........] - ETA: 1s - loss: 0.1641 - accuracy: 0.9152\n",
      "3976/5349 [=====================>........] - ETA: 1s - loss: 0.1637 - accuracy: 0.9153\n",
      "4079/5349 [=====================>........] - ETA: 1s - loss: 0.1633 - accuracy: 0.9154\n",
      "4172/5349 [======================>.......] - ETA: 1s - loss: 0.1628 - accuracy: 0.9156\n",
      "4278/5349 [======================>.......] - ETA: 1s - loss: 0.1623 - accuracy: 0.9157\n",
      "4375/5349 [=======================>......] - ETA: 1s - loss: 0.1619 - accuracy: 0.9158\n",
      "4472/5349 [========================>.....] - ETA: 0s - loss: 0.1616 - accuracy: 0.9158\n",
      "4572/5349 [========================>.....] - ETA: 0s - loss: 0.1613 - accuracy: 0.9158\n",
      "4663/5349 [=========================>....] - ETA: 0s - loss: 0.1609 - accuracy: 0.9160\n",
      "4762/5349 [=========================>....] - ETA: 0s - loss: 0.1606 - accuracy: 0.9161\n",
      "4858/5349 [==========================>...] - ETA: 0s - loss: 0.1603 - accuracy: 0.9162\n",
      "4948/5349 [==========================>...] - ETA: 0s - loss: 0.1601 - accuracy: 0.9162\n",
      "5052/5349 [===========================>..] - ETA: 0s - loss: 0.1597 - accuracy: 0.9164\n",
      "5107/5349 [===========================>..] - ETA: 0s - loss: 0.1596 - accuracy: 0.9164\n",
      "5211/5349 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 0.9166\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9166\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1588 - accuracy: 0.9167 - val_loss: 0.1400 - val_accuracy: 0.9239\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 8s - loss: 0.1094 - accuracy: 0.9300\n",
      " 107/5349 [..............................] - ETA: 4s - loss: 0.1395 - accuracy: 0.9263\n",
      " 215/5349 [>.............................] - ETA: 4s - loss: 0.1408 - accuracy: 0.9244\n",
      " 317/5349 [>.............................] - ETA: 4s - loss: 0.1404 - accuracy: 0.9237\n",
      " 403/5349 [=>............................] - ETA: 4s - loss: 0.1411 - accuracy: 0.9239\n",
      " 504/5349 [=>............................] - ETA: 4s - loss: 0.1417 - accuracy: 0.9234\n",
      " 596/5349 [==>...........................] - ETA: 4s - loss: 0.1409 - accuracy: 0.9241\n",
      " 704/5349 [==>...........................] - ETA: 4s - loss: 0.1410 - accuracy: 0.9239\n",
      " 805/5349 [===>..........................] - ETA: 4s - loss: 0.1407 - accuracy: 0.9241\n",
      " 907/5349 [====>.........................] - ETA: 4s - loss: 0.1404 - accuracy: 0.9243\n",
      "1006/5349 [====>.........................] - ETA: 4s - loss: 0.1401 - accuracy: 0.9245\n",
      "1100/5349 [=====>........................] - ETA: 4s - loss: 0.1397 - accuracy: 0.9249\n",
      "1248/5349 [=====>........................] - ETA: 4s - loss: 0.1395 - accuracy: 0.9248\n",
      "1347/5349 [======>.......................] - ETA: 4s - loss: 0.1394 - accuracy: 0.9249\n",
      "1456/5349 [=======>......................] - ETA: 3s - loss: 0.1397 - accuracy: 0.9246\n",
      "1556/5349 [=======>......................] - ETA: 3s - loss: 0.1396 - accuracy: 0.9245\n",
      "1660/5349 [========>.....................] - ETA: 3s - loss: 0.1394 - accuracy: 0.9245\n",
      "1763/5349 [========>.....................] - ETA: 3s - loss: 0.1391 - accuracy: 0.9249\n",
      "1866/5349 [=========>....................] - ETA: 3s - loss: 0.1388 - accuracy: 0.9251\n",
      "1954/5349 [=========>....................] - ETA: 3s - loss: 0.1387 - accuracy: 0.9252\n",
      "2061/5349 [==========>...................] - ETA: 3s - loss: 0.1382 - accuracy: 0.9256\n",
      "2159/5349 [===========>..................] - ETA: 3s - loss: 0.1380 - accuracy: 0.9257\n",
      "2260/5349 [===========>..................] - ETA: 3s - loss: 0.1378 - accuracy: 0.9259\n",
      "2412/5349 [============>.................] - ETA: 2s - loss: 0.1375 - accuracy: 0.9262\n",
      "2518/5349 [=============>................] - ETA: 2s - loss: 0.1370 - accuracy: 0.9264\n",
      "2610/5349 [=============>................] - ETA: 2s - loss: 0.1368 - accuracy: 0.9265\n",
      "2719/5349 [==============>...............] - ETA: 2s - loss: 0.1365 - accuracy: 0.9266\n",
      "2821/5349 [==============>...............] - ETA: 2s - loss: 0.1363 - accuracy: 0.9268\n",
      "2928/5349 [===============>..............] - ETA: 2s - loss: 0.1360 - accuracy: 0.9270\n",
      "3032/5349 [================>.............] - ETA: 2s - loss: 0.1355 - accuracy: 0.9272\n",
      "3127/5349 [================>.............] - ETA: 2s - loss: 0.1353 - accuracy: 0.9273\n",
      "3230/5349 [=================>............] - ETA: 2s - loss: 0.1353 - accuracy: 0.9274\n",
      "3337/5349 [=================>............] - ETA: 2s - loss: 0.1352 - accuracy: 0.9274\n",
      "3447/5349 [==================>...........] - ETA: 1s - loss: 0.1350 - accuracy: 0.9275\n",
      "3555/5349 [==================>...........] - ETA: 1s - loss: 0.1347 - accuracy: 0.9277\n",
      "3661/5349 [===================>..........] - ETA: 1s - loss: 0.1345 - accuracy: 0.9278\n",
      "3759/5349 [====================>.........] - ETA: 1s - loss: 0.1345 - accuracy: 0.9278\n",
      "3870/5349 [====================>.........] - ETA: 1s - loss: 0.1344 - accuracy: 0.9279\n",
      "3980/5349 [=====================>........] - ETA: 1s - loss: 0.1344 - accuracy: 0.9279\n",
      "4149/5349 [======================>.......] - ETA: 1s - loss: 0.1342 - accuracy: 0.9281\n",
      "4257/5349 [======================>.......] - ETA: 1s - loss: 0.1342 - accuracy: 0.9281\n",
      "4367/5349 [=======================>......] - ETA: 0s - loss: 0.1341 - accuracy: 0.9283\n",
      "4477/5349 [========================>.....] - ETA: 0s - loss: 0.1341 - accuracy: 0.9282\n",
      "4577/5349 [========================>.....] - ETA: 0s - loss: 0.1339 - accuracy: 0.9282\n",
      "4684/5349 [=========================>....] - ETA: 0s - loss: 0.1338 - accuracy: 0.9283\n",
      "4791/5349 [=========================>....] - ETA: 0s - loss: 0.1337 - accuracy: 0.9284\n",
      "4898/5349 [==========================>...] - ETA: 0s - loss: 0.1337 - accuracy: 0.9284\n",
      "5000/5349 [===========================>..] - ETA: 0s - loss: 0.1337 - accuracy: 0.9284\n",
      "5111/5349 [===========================>..] - ETA: 0s - loss: 0.1334 - accuracy: 0.9285\n",
      "5215/5349 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9286\n",
      "5322/5349 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9287\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1332 - accuracy: 0.9287 - val_loss: 0.1271 - val_accuracy: 0.9329\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 3/20\n",
      "  55/5349 [..............................] - ETA: 4s - loss: 0.1236 - accuracy: 0.9309\n",
      " 168/5349 [..............................] - ETA: 4s - loss: 0.1223 - accuracy: 0.9325\n",
      " 281/5349 [>.............................] - ETA: 4s - loss: 0.1234 - accuracy: 0.9331\n",
      " 386/5349 [=>............................] - ETA: 4s - loss: 0.1257 - accuracy: 0.9317\n",
      " 554/5349 [==>...........................] - ETA: 4s - loss: 0.1270 - accuracy: 0.9308\n",
      " 626/5349 [==>...........................] - ETA: 4s - loss: 0.1273 - accuracy: 0.9305\n",
      " 708/5349 [==>...........................] - ETA: 4s - loss: 0.1270 - accuracy: 0.9309\n",
      " 794/5349 [===>..........................] - ETA: 4s - loss: 0.1267 - accuracy: 0.9317\n",
      " 880/5349 [===>..........................] - ETA: 4s - loss: 0.1268 - accuracy: 0.9316\n",
      " 971/5349 [====>.........................] - ETA: 4s - loss: 0.1267 - accuracy: 0.9319\n",
      "1064/5349 [====>.........................] - ETA: 4s - loss: 0.1262 - accuracy: 0.9321\n",
      "1145/5349 [=====>........................] - ETA: 4s - loss: 0.1260 - accuracy: 0.9319\n",
      "1239/5349 [=====>........................] - ETA: 4s - loss: 0.1261 - accuracy: 0.9320\n",
      "1312/5349 [======>.......................] - ETA: 4s - loss: 0.1260 - accuracy: 0.9319\n",
      "1357/5349 [======>.......................] - ETA: 4s - loss: 0.1259 - accuracy: 0.9318\n",
      "1430/5349 [=======>......................] - ETA: 4s - loss: 0.1257 - accuracy: 0.9319\n",
      "1496/5349 [=======>......................] - ETA: 4s - loss: 0.1257 - accuracy: 0.9320\n",
      "1595/5349 [=======>......................] - ETA: 4s - loss: 0.1257 - accuracy: 0.9321\n",
      "1684/5349 [========>.....................] - ETA: 4s - loss: 0.1255 - accuracy: 0.9323\n",
      "1787/5349 [=========>....................] - ETA: 3s - loss: 0.1256 - accuracy: 0.9321\n",
      "1897/5349 [=========>....................] - ETA: 3s - loss: 0.1252 - accuracy: 0.9324\n",
      "2009/5349 [==========>...................] - ETA: 3s - loss: 0.1252 - accuracy: 0.9322\n",
      "2119/5349 [==========>...................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9324\n",
      "2209/5349 [===========>..................] - ETA: 3s - loss: 0.1250 - accuracy: 0.9325\n",
      "2310/5349 [===========>..................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9324\n",
      "2424/5349 [============>.................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9324\n",
      "2532/5349 [=============>................] - ETA: 2s - loss: 0.1248 - accuracy: 0.9325\n",
      "2642/5349 [=============>................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9325\n",
      "2735/5349 [==============>...............] - ETA: 2s - loss: 0.1247 - accuracy: 0.9325\n",
      "2843/5349 [==============>...............] - ETA: 2s - loss: 0.1249 - accuracy: 0.9324\n",
      "2947/5349 [===============>..............] - ETA: 2s - loss: 0.1247 - accuracy: 0.9325\n",
      "3059/5349 [================>.............] - ETA: 2s - loss: 0.1248 - accuracy: 0.9325\n",
      "3164/5349 [================>.............] - ETA: 2s - loss: 0.1248 - accuracy: 0.9326\n",
      "3261/5349 [=================>............] - ETA: 2s - loss: 0.1247 - accuracy: 0.9326\n",
      "3362/5349 [=================>............] - ETA: 2s - loss: 0.1247 - accuracy: 0.9326\n",
      "3473/5349 [==================>...........] - ETA: 1s - loss: 0.1248 - accuracy: 0.9325\n",
      "3529/5349 [==================>...........] - ETA: 1s - loss: 0.1248 - accuracy: 0.9325\n",
      "3632/5349 [===================>..........] - ETA: 1s - loss: 0.1248 - accuracy: 0.9325\n",
      "3746/5349 [====================>.........] - ETA: 1s - loss: 0.1247 - accuracy: 0.9325\n",
      "3852/5349 [====================>.........] - ETA: 1s - loss: 0.1245 - accuracy: 0.9326\n",
      "3965/5349 [=====================>........] - ETA: 1s - loss: 0.1246 - accuracy: 0.9326\n",
      "4071/5349 [=====================>........] - ETA: 1s - loss: 0.1245 - accuracy: 0.9327\n",
      "4167/5349 [======================>.......] - ETA: 1s - loss: 0.1244 - accuracy: 0.9328\n",
      "4276/5349 [======================>.......] - ETA: 1s - loss: 0.1244 - accuracy: 0.9327\n",
      "4384/5349 [=======================>......] - ETA: 0s - loss: 0.1243 - accuracy: 0.9328\n",
      "4491/5349 [========================>.....] - ETA: 0s - loss: 0.1244 - accuracy: 0.9328\n",
      "4596/5349 [========================>.....] - ETA: 0s - loss: 0.1243 - accuracy: 0.9328\n",
      "4660/5349 [=========================>....] - ETA: 0s - loss: 0.1243 - accuracy: 0.9329\n",
      "4771/5349 [=========================>....] - ETA: 0s - loss: 0.1242 - accuracy: 0.9329\n",
      "4872/5349 [==========================>...] - ETA: 0s - loss: 0.1241 - accuracy: 0.9330\n",
      "4960/5349 [==========================>...] - ETA: 0s - loss: 0.1240 - accuracy: 0.9331\n",
      "5067/5349 [===========================>..] - ETA: 0s - loss: 0.1240 - accuracy: 0.9332\n",
      "5173/5349 [============================>.] - ETA: 0s - loss: 0.1239 - accuracy: 0.9332\n",
      "5276/5349 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.9332\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9332\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1238 - accuracy: 0.9332 - val_loss: 0.1201 - val_accuracy: 0.9360\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 4/20\n",
      "  57/5349 [..............................] - ETA: 4s - loss: 0.1246 - accuracy: 0.9363\n",
      " 170/5349 [..............................] - ETA: 4s - loss: 0.1226 - accuracy: 0.9352\n",
      " 283/5349 [>.............................] - ETA: 4s - loss: 0.1219 - accuracy: 0.9348\n",
      " 375/5349 [=>............................] - ETA: 4s - loss: 0.1207 - accuracy: 0.9354\n",
      " 485/5349 [=>............................] - ETA: 4s - loss: 0.1214 - accuracy: 0.9355\n",
      " 593/5349 [==>...........................] - ETA: 4s - loss: 0.1216 - accuracy: 0.9353\n",
      " 707/5349 [==>...........................] - ETA: 4s - loss: 0.1219 - accuracy: 0.9350\n",
      " 813/5349 [===>..........................] - ETA: 4s - loss: 0.1221 - accuracy: 0.9351\n",
      " 927/5349 [====>.........................] - ETA: 4s - loss: 0.1217 - accuracy: 0.9352\n",
      "1031/5349 [====>.........................] - ETA: 4s - loss: 0.1219 - accuracy: 0.9350\n",
      "1145/5349 [=====>........................] - ETA: 3s - loss: 0.1220 - accuracy: 0.9346\n",
      "1254/5349 [======>.......................] - ETA: 3s - loss: 0.1223 - accuracy: 0.9343\n",
      "1366/5349 [======>.......................] - ETA: 3s - loss: 0.1222 - accuracy: 0.9343\n",
      "1469/5349 [=======>......................] - ETA: 3s - loss: 0.1225 - accuracy: 0.9340\n",
      "1579/5349 [=======>......................] - ETA: 3s - loss: 0.1223 - accuracy: 0.9342\n",
      "1685/5349 [========>.....................] - ETA: 3s - loss: 0.1221 - accuracy: 0.9345\n",
      "1786/5349 [=========>....................] - ETA: 3s - loss: 0.1220 - accuracy: 0.9346\n",
      "1893/5349 [=========>....................] - ETA: 3s - loss: 0.1218 - accuracy: 0.9348\n",
      "2007/5349 [==========>...................] - ETA: 3s - loss: 0.1216 - accuracy: 0.9348\n",
      "2104/5349 [==========>...................] - ETA: 3s - loss: 0.1217 - accuracy: 0.9348\n",
      "2159/5349 [===========>..................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9347\n",
      "2272/5349 [===========>..................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9346\n",
      "2382/5349 [============>.................] - ETA: 2s - loss: 0.1216 - accuracy: 0.9347\n",
      "2495/5349 [============>.................] - ETA: 2s - loss: 0.1214 - accuracy: 0.9347\n",
      "2605/5349 [=============>................] - ETA: 2s - loss: 0.1214 - accuracy: 0.9347\n",
      "2716/5349 [==============>...............] - ETA: 2s - loss: 0.1213 - accuracy: 0.9347\n",
      "2819/5349 [==============>...............] - ETA: 2s - loss: 0.1210 - accuracy: 0.9348\n",
      "2932/5349 [===============>..............] - ETA: 2s - loss: 0.1211 - accuracy: 0.9346\n",
      "3034/5349 [================>.............] - ETA: 2s - loss: 0.1210 - accuracy: 0.9346\n",
      "3148/5349 [================>.............] - ETA: 2s - loss: 0.1209 - accuracy: 0.9346\n",
      "3253/5349 [=================>............] - ETA: 1s - loss: 0.1208 - accuracy: 0.9347\n",
      "3355/5349 [=================>............] - ETA: 1s - loss: 0.1209 - accuracy: 0.9347\n",
      "3465/5349 [==================>...........] - ETA: 1s - loss: 0.1208 - accuracy: 0.9348\n",
      "3574/5349 [===================>..........] - ETA: 1s - loss: 0.1209 - accuracy: 0.9348\n",
      "3684/5349 [===================>..........] - ETA: 1s - loss: 0.1207 - accuracy: 0.9348\n",
      "3793/5349 [====================>.........] - ETA: 1s - loss: 0.1206 - accuracy: 0.9349\n",
      "3904/5349 [====================>.........] - ETA: 1s - loss: 0.1206 - accuracy: 0.9349\n",
      "4012/5349 [=====================>........] - ETA: 1s - loss: 0.1206 - accuracy: 0.9348\n",
      "4066/5349 [=====================>........] - ETA: 1s - loss: 0.1206 - accuracy: 0.9348\n",
      "4172/5349 [======================>.......] - ETA: 1s - loss: 0.1204 - accuracy: 0.9349\n",
      "4272/5349 [======================>.......] - ETA: 1s - loss: 0.1204 - accuracy: 0.9349\n",
      "4381/5349 [=======================>......] - ETA: 0s - loss: 0.1204 - accuracy: 0.9349\n",
      "4491/5349 [========================>.....] - ETA: 0s - loss: 0.1203 - accuracy: 0.9349\n",
      "4602/5349 [========================>.....] - ETA: 0s - loss: 0.1203 - accuracy: 0.9350\n",
      "4712/5349 [=========================>....] - ETA: 0s - loss: 0.1202 - accuracy: 0.9350\n",
      "4818/5349 [==========================>...] - ETA: 0s - loss: 0.1202 - accuracy: 0.9350\n",
      "4929/5349 [==========================>...] - ETA: 0s - loss: 0.1202 - accuracy: 0.9351\n",
      "5030/5349 [===========================>..] - ETA: 0s - loss: 0.1202 - accuracy: 0.9351\n",
      "5140/5349 [===========================>..] - ETA: 0s - loss: 0.1202 - accuracy: 0.9351\n",
      "5242/5349 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9351\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9351\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1203 - accuracy: 0.9351 - val_loss: 0.1455 - val_accuracy: 0.9277\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 5/20\n",
      "  53/5349 [..............................] - ETA: 5s - loss: 0.1193 - accuracy: 0.9338\n",
      " 161/5349 [..............................] - ETA: 4s - loss: 0.1182 - accuracy: 0.9352\n",
      " 274/5349 [>.............................] - ETA: 4s - loss: 0.1180 - accuracy: 0.9366\n",
      " 381/5349 [=>............................] - ETA: 4s - loss: 0.1178 - accuracy: 0.9366\n",
      " 491/5349 [=>............................] - ETA: 4s - loss: 0.1173 - accuracy: 0.9369\n",
      " 597/5349 [==>...........................] - ETA: 4s - loss: 0.1178 - accuracy: 0.9366\n",
      " 709/5349 [==>...........................] - ETA: 4s - loss: 0.1179 - accuracy: 0.9364\n",
      " 798/5349 [===>..........................] - ETA: 4s - loss: 0.1179 - accuracy: 0.9369\n",
      " 910/5349 [====>.........................] - ETA: 4s - loss: 0.1178 - accuracy: 0.9367\n",
      "1019/5349 [====>.........................] - ETA: 4s - loss: 0.1175 - accuracy: 0.9368\n",
      "1132/5349 [=====>........................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9367\n",
      "1234/5349 [=====>........................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9365\n",
      "1343/5349 [======>.......................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9367\n",
      "1448/5349 [=======>......................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9367\n",
      "1553/5349 [=======>......................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9365\n",
      "1657/5349 [========>.....................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9366\n",
      "1814/5349 [=========>....................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9363\n",
      "1913/5349 [=========>....................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9362\n",
      "2023/5349 [==========>...................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9364\n",
      "2126/5349 [==========>...................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9363\n",
      "2235/5349 [===========>..................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9362\n",
      "2325/5349 [============>.................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9365\n",
      "2423/5349 [============>.................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9364\n",
      "2527/5349 [=============>................] - ETA: 2s - loss: 0.1180 - accuracy: 0.9364\n",
      "2597/5349 [=============>................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9364\n",
      "2704/5349 [==============>...............] - ETA: 2s - loss: 0.1178 - accuracy: 0.9365\n",
      "2811/5349 [==============>...............] - ETA: 2s - loss: 0.1179 - accuracy: 0.9364\n",
      "2914/5349 [===============>..............] - ETA: 2s - loss: 0.1180 - accuracy: 0.9362\n",
      "3021/5349 [===============>..............] - ETA: 2s - loss: 0.1179 - accuracy: 0.9363\n",
      "3126/5349 [================>.............] - ETA: 2s - loss: 0.1178 - accuracy: 0.9362\n",
      "3233/5349 [=================>............] - ETA: 2s - loss: 0.1177 - accuracy: 0.9364\n",
      "3339/5349 [=================>............] - ETA: 1s - loss: 0.1177 - accuracy: 0.9364\n",
      "3510/5349 [==================>...........] - ETA: 1s - loss: 0.1177 - accuracy: 0.9363\n",
      "3601/5349 [===================>..........] - ETA: 1s - loss: 0.1177 - accuracy: 0.9363\n",
      "3695/5349 [===================>..........] - ETA: 1s - loss: 0.1177 - accuracy: 0.9363\n",
      "3797/5349 [====================>.........] - ETA: 1s - loss: 0.1176 - accuracy: 0.9363\n",
      "3911/5349 [====================>.........] - ETA: 1s - loss: 0.1175 - accuracy: 0.9364\n",
      "4011/5349 [=====================>........] - ETA: 1s - loss: 0.1174 - accuracy: 0.9364\n",
      "4125/5349 [======================>.......] - ETA: 1s - loss: 0.1174 - accuracy: 0.9364\n",
      "4231/5349 [======================>.......] - ETA: 1s - loss: 0.1174 - accuracy: 0.9364\n",
      "4342/5349 [=======================>......] - ETA: 0s - loss: 0.1175 - accuracy: 0.9364\n",
      "4450/5349 [=======================>......] - ETA: 0s - loss: 0.1175 - accuracy: 0.9364\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.1177 - accuracy: 0.9362\n",
      "4671/5349 [=========================>....] - ETA: 0s - loss: 0.1177 - accuracy: 0.9362\n",
      "4784/5349 [=========================>....] - ETA: 0s - loss: 0.1178 - accuracy: 0.9362\n",
      "4891/5349 [==========================>...] - ETA: 0s - loss: 0.1179 - accuracy: 0.9361\n",
      "5001/5349 [===========================>..] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "5108/5349 [===========================>..] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "5217/5349 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9360\n",
      "5322/5349 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1179 - accuracy: 0.9360 - val_loss: 0.1204 - val_accuracy: 0.9385\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.0979 - accuracy: 0.9500\n",
      " 110/5349 [..............................] - ETA: 4s - loss: 0.1198 - accuracy: 0.9352\n",
      " 224/5349 [>.............................] - ETA: 4s - loss: 0.1169 - accuracy: 0.9372\n",
      " 326/5349 [>.............................] - ETA: 4s - loss: 0.1174 - accuracy: 0.9369\n",
      " 434/5349 [=>............................] - ETA: 4s - loss: 0.1178 - accuracy: 0.9362\n",
      " 543/5349 [==>...........................] - ETA: 4s - loss: 0.1175 - accuracy: 0.9368\n",
      " 652/5349 [==>...........................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9364\n",
      " 754/5349 [===>..........................] - ETA: 4s - loss: 0.1183 - accuracy: 0.9365\n",
      " 853/5349 [===>..........................] - ETA: 4s - loss: 0.1185 - accuracy: 0.9361\n",
      " 949/5349 [====>.........................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9364\n",
      "1061/5349 [====>.........................] - ETA: 4s - loss: 0.1179 - accuracy: 0.9366\n",
      "1169/5349 [=====>........................] - ETA: 3s - loss: 0.1186 - accuracy: 0.9359\n",
      "1278/5349 [======>.......................] - ETA: 3s - loss: 0.1182 - accuracy: 0.9362\n",
      "1389/5349 [======>.......................] - ETA: 3s - loss: 0.1186 - accuracy: 0.9358\n",
      "1444/5349 [=======>......................] - ETA: 3s - loss: 0.1184 - accuracy: 0.9361\n",
      "1550/5349 [=======>......................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9360\n",
      "1654/5349 [========>.....................] - ETA: 3s - loss: 0.1179 - accuracy: 0.9360\n",
      "1756/5349 [========>.....................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9362\n",
      "1855/5349 [=========>....................] - ETA: 3s - loss: 0.1176 - accuracy: 0.9363\n",
      "1965/5349 [==========>...................] - ETA: 3s - loss: 0.1176 - accuracy: 0.9362\n",
      "2076/5349 [==========>...................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9362\n",
      "2183/5349 [===========>..................] - ETA: 3s - loss: 0.1176 - accuracy: 0.9364\n",
      "2291/5349 [===========>..................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9365\n",
      "2397/5349 [============>.................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9367\n",
      "2503/5349 [=============>................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9366\n",
      "2612/5349 [=============>................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9365\n",
      "2706/5349 [==============>...............] - ETA: 2s - loss: 0.1175 - accuracy: 0.9365\n",
      "2871/5349 [===============>..............] - ETA: 2s - loss: 0.1173 - accuracy: 0.9365\n",
      "2984/5349 [===============>..............] - ETA: 2s - loss: 0.1173 - accuracy: 0.9364\n",
      "3095/5349 [================>.............] - ETA: 2s - loss: 0.1173 - accuracy: 0.9364\n",
      "3177/5349 [================>.............] - ETA: 2s - loss: 0.1172 - accuracy: 0.9364\n",
      "3252/5349 [=================>............] - ETA: 2s - loss: 0.1173 - accuracy: 0.9364\n",
      "3341/5349 [=================>............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9364\n",
      "3425/5349 [==================>...........] - ETA: 1s - loss: 0.1172 - accuracy: 0.9363\n",
      "3496/5349 [==================>...........] - ETA: 1s - loss: 0.1173 - accuracy: 0.9362\n",
      "3570/5349 [===================>..........] - ETA: 1s - loss: 0.1173 - accuracy: 0.9362\n",
      "3658/5349 [===================>..........] - ETA: 1s - loss: 0.1174 - accuracy: 0.9362\n",
      "3751/5349 [====================>.........] - ETA: 1s - loss: 0.1174 - accuracy: 0.9362\n",
      "3839/5349 [====================>.........] - ETA: 1s - loss: 0.1175 - accuracy: 0.9362\n",
      "3930/5349 [=====================>........] - ETA: 1s - loss: 0.1175 - accuracy: 0.9362\n",
      "3988/5349 [=====================>........] - ETA: 1s - loss: 0.1175 - accuracy: 0.9362\n",
      "4069/5349 [=====================>........] - ETA: 1s - loss: 0.1173 - accuracy: 0.9363\n",
      "4161/5349 [======================>.......] - ETA: 1s - loss: 0.1172 - accuracy: 0.9364\n",
      "4255/5349 [======================>.......] - ETA: 1s - loss: 0.1171 - accuracy: 0.9365\n",
      "4419/5349 [=======================>......] - ETA: 0s - loss: 0.1171 - accuracy: 0.9365\n",
      "4525/5349 [========================>.....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9365\n",
      "4633/5349 [========================>.....] - ETA: 0s - loss: 0.1170 - accuracy: 0.9366\n",
      "4742/5349 [=========================>....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9365\n",
      "4851/5349 [==========================>...] - ETA: 0s - loss: 0.1169 - accuracy: 0.9366\n",
      "4961/5349 [==========================>...] - ETA: 0s - loss: 0.1168 - accuracy: 0.9367\n",
      "5060/5349 [===========================>..] - ETA: 0s - loss: 0.1168 - accuracy: 0.9366\n",
      "5168/5349 [===========================>..] - ETA: 0s - loss: 0.1167 - accuracy: 0.9366\n",
      "5278/5349 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9366\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9367\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1167 - accuracy: 0.9367 - val_loss: 0.1186 - val_accuracy: 0.9361\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 7/20\n",
      "  56/5349 [..............................] - ETA: 4s - loss: 0.1137 - accuracy: 0.9371\n",
      " 170/5349 [..............................] - ETA: 4s - loss: 0.1153 - accuracy: 0.9358\n",
      " 283/5349 [>.............................] - ETA: 4s - loss: 0.1195 - accuracy: 0.9336\n",
      " 386/5349 [=>............................] - ETA: 4s - loss: 0.1164 - accuracy: 0.9359\n",
      " 497/5349 [=>............................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9371\n",
      " 573/5349 [==>...........................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9369\n",
      " 684/5349 [==>...........................] - ETA: 4s - loss: 0.1139 - accuracy: 0.9377\n",
      " 787/5349 [===>..........................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9372\n",
      " 900/5349 [====>.........................] - ETA: 4s - loss: 0.1144 - accuracy: 0.9373\n",
      "1011/5349 [====>.........................] - ETA: 4s - loss: 0.1151 - accuracy: 0.9368\n",
      "1126/5349 [=====>........................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9368\n",
      "1237/5349 [=====>........................] - ETA: 3s - loss: 0.1146 - accuracy: 0.9369\n",
      "1348/5349 [======>.......................] - ETA: 3s - loss: 0.1149 - accuracy: 0.9367\n",
      "1456/5349 [=======>......................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9367\n",
      "1570/5349 [=======>......................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9370\n",
      "1679/5349 [========>.....................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9371\n",
      "1792/5349 [=========>....................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9370\n",
      "1845/5349 [=========>....................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9370\n",
      "1952/5349 [=========>....................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9370\n",
      "2065/5349 [==========>...................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9370\n",
      "2174/5349 [===========>..................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9371\n",
      "2289/5349 [===========>..................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9370\n",
      "2389/5349 [============>.................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9372\n",
      "2502/5349 [=============>................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9372\n",
      "2612/5349 [=============>................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9373\n",
      "2725/5349 [==============>...............] - ETA: 2s - loss: 0.1149 - accuracy: 0.9371\n",
      "2833/5349 [==============>...............] - ETA: 2s - loss: 0.1148 - accuracy: 0.9373\n",
      "2945/5349 [===============>..............] - ETA: 2s - loss: 0.1148 - accuracy: 0.9374\n",
      "3055/5349 [================>.............] - ETA: 2s - loss: 0.1149 - accuracy: 0.9373\n",
      "3168/5349 [================>.............] - ETA: 2s - loss: 0.1150 - accuracy: 0.9372\n",
      "3279/5349 [=================>............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9373\n",
      "3392/5349 [==================>...........] - ETA: 1s - loss: 0.1149 - accuracy: 0.9373\n",
      "3498/5349 [==================>...........] - ETA: 1s - loss: 0.1150 - accuracy: 0.9373\n",
      "3611/5349 [===================>..........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9371\n",
      "3720/5349 [===================>..........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9372\n",
      "3833/5349 [====================>.........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9372\n",
      "3941/5349 [=====================>........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9371\n",
      "4053/5349 [=====================>........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9372\n",
      "4106/5349 [======================>.......] - ETA: 1s - loss: 0.1151 - accuracy: 0.9372\n",
      "4206/5349 [======================>.......] - ETA: 1s - loss: 0.1151 - accuracy: 0.9372\n",
      "4319/5349 [=======================>......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9373\n",
      "4425/5349 [=======================>......] - ETA: 0s - loss: 0.1152 - accuracy: 0.9371\n",
      "4538/5349 [========================>.....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9371\n",
      "4645/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9371\n",
      "4758/5349 [=========================>....] - ETA: 0s - loss: 0.1152 - accuracy: 0.9371\n",
      "4869/5349 [==========================>...] - ETA: 0s - loss: 0.1152 - accuracy: 0.9371\n",
      "4982/5349 [==========================>...] - ETA: 0s - loss: 0.1152 - accuracy: 0.9371\n",
      "5090/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "5201/5349 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.9370\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 0.9370\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1152 - accuracy: 0.9371 - val_loss: 0.1160 - val_accuracy: 0.9382\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.0892 - accuracy: 0.9400\n",
      " 113/5349 [..............................] - ETA: 4s - loss: 0.1233 - accuracy: 0.9342\n",
      " 227/5349 [>.............................] - ETA: 4s - loss: 0.1180 - accuracy: 0.9359\n",
      " 323/5349 [>.............................] - ETA: 4s - loss: 0.1159 - accuracy: 0.9360\n",
      " 433/5349 [=>............................] - ETA: 4s - loss: 0.1146 - accuracy: 0.9370\n",
      " 544/5349 [==>...........................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9370\n",
      " 655/5349 [==>...........................] - ETA: 4s - loss: 0.1148 - accuracy: 0.9371\n",
      " 767/5349 [===>..........................] - ETA: 4s - loss: 0.1149 - accuracy: 0.9369\n",
      " 878/5349 [===>..........................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9370\n",
      " 986/5349 [====>.........................] - ETA: 4s - loss: 0.1143 - accuracy: 0.9371\n",
      "1100/5349 [=====>........................] - ETA: 3s - loss: 0.1149 - accuracy: 0.9368\n",
      "1190/5349 [=====>........................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9364\n",
      "1289/5349 [======>.......................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9363\n",
      "1377/5349 [======>.......................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9362\n",
      "1469/5349 [=======>......................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9362\n",
      "1609/5349 [========>.....................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9362\n",
      "1705/5349 [========>.....................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9362\n",
      "1787/5349 [=========>....................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9360\n",
      "1877/5349 [=========>....................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9361\n",
      "1952/5349 [=========>....................] - ETA: 3s - loss: 0.1160 - accuracy: 0.9361\n",
      "2041/5349 [==========>...................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9362\n",
      "2128/5349 [==========>...................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9363\n",
      "2230/5349 [===========>..................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9363\n",
      "2336/5349 [============>.................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9363\n",
      "2448/5349 [============>.................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9364\n",
      "2558/5349 [=============>................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9365\n",
      "2671/5349 [=============>................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9366\n",
      "2781/5349 [==============>...............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9366\n",
      "2891/5349 [===============>..............] - ETA: 2s - loss: 0.1157 - accuracy: 0.9366\n",
      "3001/5349 [===============>..............] - ETA: 2s - loss: 0.1157 - accuracy: 0.9366\n",
      "3101/5349 [================>.............] - ETA: 2s - loss: 0.1157 - accuracy: 0.9367\n",
      "3211/5349 [=================>............] - ETA: 2s - loss: 0.1156 - accuracy: 0.9368\n",
      "3323/5349 [=================>............] - ETA: 2s - loss: 0.1154 - accuracy: 0.9370\n",
      "3427/5349 [==================>...........] - ETA: 1s - loss: 0.1154 - accuracy: 0.9370\n",
      "3483/5349 [==================>...........] - ETA: 1s - loss: 0.1154 - accuracy: 0.9370\n",
      "3596/5349 [===================>..........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9371\n",
      "3707/5349 [===================>..........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9370\n",
      "3821/5349 [====================>.........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9370\n",
      "3928/5349 [=====================>........] - ETA: 1s - loss: 0.1150 - accuracy: 0.9372\n",
      "4041/5349 [=====================>........] - ETA: 1s - loss: 0.1149 - accuracy: 0.9373\n",
      "4150/5349 [======================>.......] - ETA: 1s - loss: 0.1151 - accuracy: 0.9373\n",
      "4265/5349 [======================>.......] - ETA: 1s - loss: 0.1150 - accuracy: 0.9372\n",
      "4373/5349 [=======================>......] - ETA: 0s - loss: 0.1150 - accuracy: 0.9373\n",
      "4484/5349 [========================>.....] - ETA: 0s - loss: 0.1150 - accuracy: 0.9373\n",
      "4588/5349 [========================>.....] - ETA: 0s - loss: 0.1150 - accuracy: 0.9374\n",
      "4701/5349 [=========================>....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9373\n",
      "4808/5349 [=========================>....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9372\n",
      "4907/5349 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9372\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.9372\n",
      "5115/5349 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.9371\n",
      "5223/5349 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9372\n",
      "5336/5349 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9372\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1149 - accuracy: 0.9372 - val_loss: 0.1115 - val_accuracy: 0.9393\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 16s - loss: 0.0935 - accuracy: 0.9400\n",
      " 111/5349 [..............................] - ETA: 4s - loss: 0.1142 - accuracy: 0.9357\n",
      " 222/5349 [>.............................] - ETA: 4s - loss: 0.1138 - accuracy: 0.9357\n",
      " 333/5349 [>.............................] - ETA: 4s - loss: 0.1137 - accuracy: 0.9359\n",
      " 447/5349 [=>............................] - ETA: 4s - loss: 0.1139 - accuracy: 0.9357\n",
      " 558/5349 [==>...........................] - ETA: 4s - loss: 0.1130 - accuracy: 0.9366\n",
      " 725/5349 [===>..........................] - ETA: 4s - loss: 0.1133 - accuracy: 0.9368\n",
      " 834/5349 [===>..........................] - ETA: 4s - loss: 0.1132 - accuracy: 0.9372\n",
      " 947/5349 [====>.........................] - ETA: 3s - loss: 0.1131 - accuracy: 0.9372\n",
      "1055/5349 [====>.........................] - ETA: 3s - loss: 0.1134 - accuracy: 0.9371\n",
      "1163/5349 [=====>........................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9370\n",
      "1254/5349 [======>.......................] - ETA: 3s - loss: 0.1133 - accuracy: 0.9374\n",
      "1366/5349 [======>.......................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9374\n",
      "1474/5349 [=======>......................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9377\n",
      "1587/5349 [=======>......................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9376\n",
      "1698/5349 [========>.....................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9377\n",
      "1808/5349 [=========>....................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9375\n",
      "1912/5349 [=========>....................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9375\n",
      "2024/5349 [==========>...................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9376\n",
      "2130/5349 [==========>...................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9377\n",
      "2241/5349 [===========>..................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9377\n",
      "2348/5349 [============>.................] - ETA: 2s - loss: 0.1134 - accuracy: 0.9379\n",
      "2448/5349 [============>.................] - ETA: 2s - loss: 0.1134 - accuracy: 0.9380\n",
      "2557/5349 [=============>................] - ETA: 2s - loss: 0.1134 - accuracy: 0.9379\n",
      "2666/5349 [=============>................] - ETA: 2s - loss: 0.1136 - accuracy: 0.9377\n",
      "2775/5349 [==============>...............] - ETA: 2s - loss: 0.1137 - accuracy: 0.9377\n",
      "2883/5349 [===============>..............] - ETA: 2s - loss: 0.1137 - accuracy: 0.9376\n",
      "2992/5349 [===============>..............] - ETA: 2s - loss: 0.1137 - accuracy: 0.9376\n",
      "3094/5349 [================>.............] - ETA: 2s - loss: 0.1136 - accuracy: 0.9377\n",
      "3189/5349 [================>.............] - ETA: 2s - loss: 0.1137 - accuracy: 0.9376\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1135 - accuracy: 0.9377\n",
      "3392/5349 [==================>...........] - ETA: 1s - loss: 0.1136 - accuracy: 0.9377\n",
      "3560/5349 [==================>...........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9376\n",
      "3671/5349 [===================>..........] - ETA: 1s - loss: 0.1136 - accuracy: 0.9377\n",
      "3782/5349 [====================>.........] - ETA: 1s - loss: 0.1136 - accuracy: 0.9377\n",
      "3889/5349 [====================>.........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9377\n",
      "3996/5349 [=====================>........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9378\n",
      "4095/5349 [=====================>........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9377\n",
      "4195/5349 [======================>.......] - ETA: 1s - loss: 0.1136 - accuracy: 0.9378\n",
      "4304/5349 [=======================>......] - ETA: 0s - loss: 0.1137 - accuracy: 0.9377\n",
      "4412/5349 [=======================>......] - ETA: 0s - loss: 0.1137 - accuracy: 0.9377\n",
      "4521/5349 [========================>.....] - ETA: 0s - loss: 0.1137 - accuracy: 0.9377\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.1138 - accuracy: 0.9377\n",
      "4739/5349 [=========================>....] - ETA: 0s - loss: 0.1137 - accuracy: 0.9378\n",
      "4831/5349 [==========================>...] - ETA: 0s - loss: 0.1137 - accuracy: 0.9378\n",
      "4937/5349 [==========================>...] - ETA: 0s - loss: 0.1136 - accuracy: 0.9378\n",
      "4988/5349 [==========================>...] - ETA: 0s - loss: 0.1136 - accuracy: 0.9378\n",
      "5090/5349 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9379\n",
      "5198/5349 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.9378\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9379\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1136 - accuracy: 0.9379 - val_loss: 0.1135 - val_accuracy: 0.9379\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 10/20\n",
      "  46/5349 [..............................] - ETA: 6s - loss: 0.1160 - accuracy: 0.9339 \n",
      " 143/5349 [..............................] - ETA: 5s - loss: 0.1150 - accuracy: 0.9364\n",
      " 238/5349 [>.............................] - ETA: 5s - loss: 0.1149 - accuracy: 0.9362\n",
      " 333/5349 [>.............................] - ETA: 5s - loss: 0.1133 - accuracy: 0.9376\n",
      " 440/5349 [=>............................] - ETA: 5s - loss: 0.1134 - accuracy: 0.9371\n",
      " 542/5349 [==>...........................] - ETA: 4s - loss: 0.1139 - accuracy: 0.9369\n",
      " 709/5349 [==>...........................] - ETA: 4s - loss: 0.1141 - accuracy: 0.9368\n",
      " 802/5349 [===>..........................] - ETA: 4s - loss: 0.1140 - accuracy: 0.9370\n",
      " 913/5349 [====>.........................] - ETA: 4s - loss: 0.1138 - accuracy: 0.9370\n",
      "1022/5349 [====>.........................] - ETA: 4s - loss: 0.1141 - accuracy: 0.9370\n",
      "1129/5349 [=====>........................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9369\n",
      "1241/5349 [=====>........................] - ETA: 4s - loss: 0.1142 - accuracy: 0.9371\n",
      "1351/5349 [======>.......................] - ETA: 3s - loss: 0.1139 - accuracy: 0.9372\n",
      "1456/5349 [=======>......................] - ETA: 3s - loss: 0.1136 - accuracy: 0.9372\n",
      "1556/5349 [=======>......................] - ETA: 3s - loss: 0.1136 - accuracy: 0.9373\n",
      "1664/5349 [========>.....................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9372\n",
      "1769/5349 [========>.....................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9374\n",
      "1877/5349 [=========>....................] - ETA: 3s - loss: 0.1140 - accuracy: 0.9372\n",
      "1979/5349 [==========>...................] - ETA: 3s - loss: 0.1139 - accuracy: 0.9373\n",
      "2088/5349 [==========>...................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9374\n",
      "2196/5349 [===========>..................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9374\n",
      "2251/5349 [===========>..................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9374\n",
      "2357/5349 [============>.................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9373\n",
      "2457/5349 [============>.................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9373\n",
      "2560/5349 [=============>................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9375\n",
      "2666/5349 [=============>................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9376\n",
      "2774/5349 [==============>...............] - ETA: 2s - loss: 0.1136 - accuracy: 0.9377\n",
      "2882/5349 [===============>..............] - ETA: 2s - loss: 0.1135 - accuracy: 0.9378\n",
      "2988/5349 [===============>..............] - ETA: 2s - loss: 0.1132 - accuracy: 0.9380\n",
      "3073/5349 [================>.............] - ETA: 2s - loss: 0.1132 - accuracy: 0.9380\n",
      "3171/5349 [================>.............] - ETA: 2s - loss: 0.1133 - accuracy: 0.9380\n",
      "3273/5349 [=================>............] - ETA: 2s - loss: 0.1133 - accuracy: 0.9379\n",
      "3377/5349 [=================>............] - ETA: 1s - loss: 0.1134 - accuracy: 0.9379\n",
      "3483/5349 [==================>...........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9381\n",
      "3586/5349 [===================>..........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9381\n",
      "3697/5349 [===================>..........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9381\n",
      "3804/5349 [====================>.........] - ETA: 1s - loss: 0.1134 - accuracy: 0.9381\n",
      "3915/5349 [====================>.........] - ETA: 1s - loss: 0.1135 - accuracy: 0.9381\n",
      "4015/5349 [=====================>........] - ETA: 1s - loss: 0.1135 - accuracy: 0.9381\n",
      "4121/5349 [======================>.......] - ETA: 1s - loss: 0.1135 - accuracy: 0.9381\n",
      "4221/5349 [======================>.......] - ETA: 1s - loss: 0.1135 - accuracy: 0.9381\n",
      "4385/5349 [=======================>......] - ETA: 0s - loss: 0.1134 - accuracy: 0.9381\n",
      "4498/5349 [========================>.....] - ETA: 0s - loss: 0.1134 - accuracy: 0.9380\n",
      "4605/5349 [========================>.....] - ETA: 0s - loss: 0.1135 - accuracy: 0.9380\n",
      "4714/5349 [=========================>....] - ETA: 0s - loss: 0.1134 - accuracy: 0.9380\n",
      "4825/5349 [==========================>...] - ETA: 0s - loss: 0.1133 - accuracy: 0.9380\n",
      "4925/5349 [==========================>...] - ETA: 0s - loss: 0.1133 - accuracy: 0.9380\n",
      "5032/5349 [===========================>..] - ETA: 0s - loss: 0.1132 - accuracy: 0.9381\n",
      "5141/5349 [===========================>..] - ETA: 0s - loss: 0.1133 - accuracy: 0.9380\n",
      "5250/5349 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9380\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9380\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1133 - accuracy: 0.9380 - val_loss: 0.1193 - val_accuracy: 0.9358\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1185 - accuracy: 0.9100\n",
      " 103/5349 [..............................] - ETA: 5s - loss: 0.1152 - accuracy: 0.9367\n",
      " 215/5349 [>.............................] - ETA: 4s - loss: 0.1165 - accuracy: 0.9354\n",
      " 304/5349 [>.............................] - ETA: 5s - loss: 0.1152 - accuracy: 0.9364\n",
      " 418/5349 [=>............................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9360\n",
      " 528/5349 [=>............................] - ETA: 4s - loss: 0.1149 - accuracy: 0.9364\n",
      " 641/5349 [==>...........................] - ETA: 4s - loss: 0.1144 - accuracy: 0.9363\n",
      " 751/5349 [===>..........................] - ETA: 4s - loss: 0.1141 - accuracy: 0.9369\n",
      " 863/5349 [===>..........................] - ETA: 4s - loss: 0.1133 - accuracy: 0.9374\n",
      " 970/5349 [====>.........................] - ETA: 4s - loss: 0.1134 - accuracy: 0.9373\n",
      "1084/5349 [=====>........................] - ETA: 3s - loss: 0.1132 - accuracy: 0.9373\n",
      "1194/5349 [=====>........................] - ETA: 3s - loss: 0.1130 - accuracy: 0.9373\n",
      "1307/5349 [======>.......................] - ETA: 3s - loss: 0.1133 - accuracy: 0.9370\n",
      "1411/5349 [======>.......................] - ETA: 3s - loss: 0.1133 - accuracy: 0.9372\n",
      "1522/5349 [=======>......................] - ETA: 3s - loss: 0.1132 - accuracy: 0.9373\n",
      "1632/5349 [========>.....................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9371\n",
      "1801/5349 [=========>....................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9369\n",
      "1905/5349 [=========>....................] - ETA: 3s - loss: 0.1136 - accuracy: 0.9369\n",
      "2017/5349 [==========>...................] - ETA: 3s - loss: 0.1132 - accuracy: 0.9370\n",
      "2113/5349 [==========>...................] - ETA: 3s - loss: 0.1131 - accuracy: 0.9371\n",
      "2224/5349 [===========>..................] - ETA: 2s - loss: 0.1132 - accuracy: 0.9371\n",
      "2331/5349 [============>.................] - ETA: 2s - loss: 0.1132 - accuracy: 0.9371\n",
      "2442/5349 [============>.................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9371\n",
      "2552/5349 [=============>................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9371\n",
      "2665/5349 [=============>................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9372\n",
      "2775/5349 [==============>...............] - ETA: 2s - loss: 0.1131 - accuracy: 0.9374\n",
      "2887/5349 [===============>..............] - ETA: 2s - loss: 0.1132 - accuracy: 0.9374\n",
      "2997/5349 [===============>..............] - ETA: 2s - loss: 0.1131 - accuracy: 0.9375\n",
      "3110/5349 [================>.............] - ETA: 2s - loss: 0.1130 - accuracy: 0.9375\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1132 - accuracy: 0.9375\n",
      "3331/5349 [=================>............] - ETA: 1s - loss: 0.1131 - accuracy: 0.9376\n",
      "3435/5349 [==================>...........] - ETA: 1s - loss: 0.1131 - accuracy: 0.9376\n",
      "3522/5349 [==================>...........] - ETA: 1s - loss: 0.1131 - accuracy: 0.9377\n",
      "3607/5349 [===================>..........] - ETA: 1s - loss: 0.1131 - accuracy: 0.9377\n",
      "3706/5349 [===================>..........] - ETA: 1s - loss: 0.1129 - accuracy: 0.9378\n",
      "3834/5349 [====================>.........] - ETA: 1s - loss: 0.1130 - accuracy: 0.9377\n",
      "3928/5349 [=====================>........] - ETA: 1s - loss: 0.1130 - accuracy: 0.9377\n",
      "4013/5349 [=====================>........] - ETA: 1s - loss: 0.1130 - accuracy: 0.9377\n",
      "4106/5349 [======================>.......] - ETA: 1s - loss: 0.1129 - accuracy: 0.9378\n",
      "4200/5349 [======================>.......] - ETA: 1s - loss: 0.1129 - accuracy: 0.9379\n",
      "4271/5349 [======================>.......] - ETA: 1s - loss: 0.1128 - accuracy: 0.9379\n",
      "4357/5349 [=======================>......] - ETA: 0s - loss: 0.1127 - accuracy: 0.9379\n",
      "4451/5349 [=======================>......] - ETA: 0s - loss: 0.1126 - accuracy: 0.9380\n",
      "4544/5349 [========================>.....] - ETA: 0s - loss: 0.1127 - accuracy: 0.9379\n",
      "4657/5349 [=========================>....] - ETA: 0s - loss: 0.1127 - accuracy: 0.9380\n",
      "4749/5349 [=========================>....] - ETA: 0s - loss: 0.1127 - accuracy: 0.9380\n",
      "4859/5349 [==========================>...] - ETA: 0s - loss: 0.1127 - accuracy: 0.9380\n",
      "4940/5349 [==========================>...] - ETA: 0s - loss: 0.1128 - accuracy: 0.9379\n",
      "4968/5349 [==========================>...] - ETA: 0s - loss: 0.1128 - accuracy: 0.9380\n",
      "5067/5349 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9380\n",
      "5176/5349 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9381\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9381\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9381\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1127 - accuracy: 0.9381 - val_loss: 0.1112 - val_accuracy: 0.9391\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1574 - accuracy: 0.9100\n",
      " 112/5349 [..............................] - ETA: 4s - loss: 0.1109 - accuracy: 0.9404\n",
      " 224/5349 [>.............................] - ETA: 4s - loss: 0.1104 - accuracy: 0.9403\n",
      " 320/5349 [>.............................] - ETA: 4s - loss: 0.1106 - accuracy: 0.9398\n",
      " 430/5349 [=>............................] - ETA: 4s - loss: 0.1107 - accuracy: 0.9398\n",
      " 534/5349 [=>............................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9400\n",
      " 645/5349 [==>...........................] - ETA: 4s - loss: 0.1109 - accuracy: 0.9396\n",
      " 734/5349 [===>..........................] - ETA: 4s - loss: 0.1108 - accuracy: 0.9397\n",
      " 843/5349 [===>..........................] - ETA: 4s - loss: 0.1120 - accuracy: 0.9390\n",
      " 951/5349 [====>.........................] - ETA: 4s - loss: 0.1123 - accuracy: 0.9390\n",
      "1059/5349 [====>.........................] - ETA: 4s - loss: 0.1126 - accuracy: 0.9386\n",
      "1169/5349 [=====>........................] - ETA: 3s - loss: 0.1124 - accuracy: 0.9385\n",
      "1281/5349 [======>.......................] - ETA: 3s - loss: 0.1124 - accuracy: 0.9387\n",
      "1445/5349 [=======>......................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9388\n",
      "1555/5349 [=======>......................] - ETA: 3s - loss: 0.1120 - accuracy: 0.9389\n",
      "1662/5349 [========>.....................] - ETA: 3s - loss: 0.1120 - accuracy: 0.9390\n",
      "1774/5349 [========>.....................] - ETA: 3s - loss: 0.1124 - accuracy: 0.9389\n",
      "1885/5349 [=========>....................] - ETA: 3s - loss: 0.1123 - accuracy: 0.9386\n",
      "1999/5349 [==========>...................] - ETA: 3s - loss: 0.1124 - accuracy: 0.9385\n",
      "2097/5349 [==========>...................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9387\n",
      "2205/5349 [===========>..................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9387\n",
      "2313/5349 [===========>..................] - ETA: 2s - loss: 0.1121 - accuracy: 0.9387\n",
      "2420/5349 [============>.................] - ETA: 2s - loss: 0.1121 - accuracy: 0.9388\n",
      "2522/5349 [=============>................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9389\n",
      "2635/5349 [=============>................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9388\n",
      "2736/5349 [==============>...............] - ETA: 2s - loss: 0.1124 - accuracy: 0.9387\n",
      "2839/5349 [==============>...............] - ETA: 2s - loss: 0.1124 - accuracy: 0.9386\n",
      "2949/5349 [===============>..............] - ETA: 2s - loss: 0.1126 - accuracy: 0.9384\n",
      "3063/5349 [================>.............] - ETA: 2s - loss: 0.1125 - accuracy: 0.9385\n",
      "3173/5349 [================>.............] - ETA: 2s - loss: 0.1125 - accuracy: 0.9385\n",
      "3285/5349 [=================>............] - ETA: 1s - loss: 0.1125 - accuracy: 0.9384\n",
      "3391/5349 [==================>...........] - ETA: 1s - loss: 0.1124 - accuracy: 0.9385\n",
      "3504/5349 [==================>...........] - ETA: 1s - loss: 0.1125 - accuracy: 0.9384\n",
      "3600/5349 [===================>..........] - ETA: 1s - loss: 0.1125 - accuracy: 0.9384\n",
      "3710/5349 [===================>..........] - ETA: 1s - loss: 0.1125 - accuracy: 0.9384\n",
      "3819/5349 [====================>.........] - ETA: 1s - loss: 0.1125 - accuracy: 0.9385\n",
      "3932/5349 [=====================>........] - ETA: 1s - loss: 0.1125 - accuracy: 0.9385\n",
      "3990/5349 [=====================>........] - ETA: 1s - loss: 0.1125 - accuracy: 0.9385\n",
      "4099/5349 [=====================>........] - ETA: 1s - loss: 0.1124 - accuracy: 0.9385\n",
      "4212/5349 [======================>.......] - ETA: 1s - loss: 0.1124 - accuracy: 0.9384\n",
      "4318/5349 [=======================>......] - ETA: 0s - loss: 0.1123 - accuracy: 0.9385\n",
      "4422/5349 [=======================>......] - ETA: 0s - loss: 0.1124 - accuracy: 0.9385\n",
      "4530/5349 [========================>.....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9384\n",
      "4643/5349 [=========================>....] - ETA: 0s - loss: 0.1124 - accuracy: 0.9384\n",
      "4752/5349 [=========================>....] - ETA: 0s - loss: 0.1124 - accuracy: 0.9383\n",
      "4861/5349 [==========================>...] - ETA: 0s - loss: 0.1124 - accuracy: 0.9384\n",
      "4971/5349 [==========================>...] - ETA: 0s - loss: 0.1125 - accuracy: 0.9383\n",
      "5084/5349 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.9384\n",
      "5186/5349 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9384\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9384\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1123 - accuracy: 0.9384 - val_loss: 0.1163 - val_accuracy: 0.9363\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.0847 - accuracy: 0.9800\n",
      " 112/5349 [..............................] - ETA: 4s - loss: 0.1103 - accuracy: 0.9376\n",
      " 224/5349 [>.............................] - ETA: 4s - loss: 0.1091 - accuracy: 0.9398\n",
      " 331/5349 [>.............................] - ETA: 4s - loss: 0.1110 - accuracy: 0.9393\n",
      " 444/5349 [=>............................] - ETA: 4s - loss: 0.1109 - accuracy: 0.9399\n",
      " 543/5349 [==>...........................] - ETA: 4s - loss: 0.1102 - accuracy: 0.9405\n",
      " 651/5349 [==>...........................] - ETA: 4s - loss: 0.1103 - accuracy: 0.9406\n",
      " 761/5349 [===>..........................] - ETA: 4s - loss: 0.1107 - accuracy: 0.9403\n",
      " 867/5349 [===>..........................] - ETA: 4s - loss: 0.1111 - accuracy: 0.9400\n",
      " 974/5349 [====>.........................] - ETA: 4s - loss: 0.1111 - accuracy: 0.9399\n",
      "1084/5349 [=====>........................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9395\n",
      "1189/5349 [=====>........................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9393\n",
      "1301/5349 [======>.......................] - ETA: 3s - loss: 0.1114 - accuracy: 0.9392\n",
      "1408/5349 [======>.......................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9391\n",
      "1495/5349 [=======>......................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9390\n",
      "1580/5349 [=======>......................] - ETA: 3s - loss: 0.1111 - accuracy: 0.9392\n",
      "1721/5349 [========>.....................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9394\n",
      "1813/5349 [=========>....................] - ETA: 3s - loss: 0.1107 - accuracy: 0.9395\n",
      "1911/5349 [=========>....................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9397\n",
      "1997/5349 [==========>...................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9396\n",
      "2077/5349 [==========>...................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9397\n",
      "2164/5349 [===========>..................] - ETA: 3s - loss: 0.1107 - accuracy: 0.9395\n",
      "2248/5349 [===========>..................] - ETA: 3s - loss: 0.1107 - accuracy: 0.9396\n",
      "2307/5349 [===========>..................] - ETA: 3s - loss: 0.1105 - accuracy: 0.9397\n",
      "2372/5349 [============>.................] - ETA: 3s - loss: 0.1105 - accuracy: 0.9397\n",
      "2449/5349 [============>.................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9396\n",
      "2536/5349 [=============>................] - ETA: 2s - loss: 0.1105 - accuracy: 0.9397\n",
      "2639/5349 [=============>................] - ETA: 2s - loss: 0.1106 - accuracy: 0.9397\n",
      "2747/5349 [==============>...............] - ETA: 2s - loss: 0.1105 - accuracy: 0.9398\n",
      "2857/5349 [===============>..............] - ETA: 2s - loss: 0.1104 - accuracy: 0.9398\n",
      "2966/5349 [===============>..............] - ETA: 2s - loss: 0.1104 - accuracy: 0.9398\n",
      "3073/5349 [================>.............] - ETA: 2s - loss: 0.1105 - accuracy: 0.9397\n",
      "3177/5349 [================>.............] - ETA: 2s - loss: 0.1104 - accuracy: 0.9397\n",
      "3323/5349 [=================>............] - ETA: 2s - loss: 0.1105 - accuracy: 0.9397\n",
      "3429/5349 [==================>...........] - ETA: 1s - loss: 0.1105 - accuracy: 0.9398\n",
      "3537/5349 [==================>...........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9397\n",
      "3645/5349 [===================>..........] - ETA: 1s - loss: 0.1107 - accuracy: 0.9396\n",
      "3748/5349 [====================>.........] - ETA: 1s - loss: 0.1108 - accuracy: 0.9395\n",
      "3854/5349 [====================>.........] - ETA: 1s - loss: 0.1108 - accuracy: 0.9395\n",
      "3948/5349 [=====================>........] - ETA: 1s - loss: 0.1109 - accuracy: 0.9396\n",
      "4045/5349 [=====================>........] - ETA: 1s - loss: 0.1109 - accuracy: 0.9396\n",
      "4141/5349 [======================>.......] - ETA: 1s - loss: 0.1109 - accuracy: 0.9396\n",
      "4246/5349 [======================>.......] - ETA: 1s - loss: 0.1110 - accuracy: 0.9396\n",
      "4347/5349 [=======================>......] - ETA: 1s - loss: 0.1110 - accuracy: 0.9395\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.1109 - accuracy: 0.9395\n",
      "4550/5349 [========================>.....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9394\n",
      "4602/5349 [========================>.....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9394\n",
      "4706/5349 [=========================>....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9394\n",
      "4812/5349 [=========================>....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9393\n",
      "4910/5349 [==========================>...] - ETA: 0s - loss: 0.1112 - accuracy: 0.9393\n",
      "5015/5349 [===========================>..] - ETA: 0s - loss: 0.1112 - accuracy: 0.9393\n",
      "5125/5349 [===========================>..] - ETA: 0s - loss: 0.1112 - accuracy: 0.9393\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9393\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9392\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1112 - accuracy: 0.9392 - val_loss: 0.1120 - val_accuracy: 0.9313\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1295 - accuracy: 0.9500\n",
      " 114/5349 [..............................] - ETA: 4s - loss: 0.1104 - accuracy: 0.9392\n",
      " 225/5349 [>.............................] - ETA: 4s - loss: 0.1095 - accuracy: 0.9390\n",
      " 333/5349 [>.............................] - ETA: 4s - loss: 0.1100 - accuracy: 0.9394\n",
      " 448/5349 [=>............................] - ETA: 4s - loss: 0.1096 - accuracy: 0.9392\n",
      " 601/5349 [==>...........................] - ETA: 4s - loss: 0.1102 - accuracy: 0.9390\n",
      " 710/5349 [==>...........................] - ETA: 4s - loss: 0.1096 - accuracy: 0.9392\n",
      " 818/5349 [===>..........................] - ETA: 4s - loss: 0.1093 - accuracy: 0.9396\n",
      " 923/5349 [====>.........................] - ETA: 4s - loss: 0.1090 - accuracy: 0.9398\n",
      "1034/5349 [====>.........................] - ETA: 4s - loss: 0.1091 - accuracy: 0.9398\n",
      "1142/5349 [=====>........................] - ETA: 3s - loss: 0.1096 - accuracy: 0.9397\n",
      "1253/5349 [======>.......................] - ETA: 3s - loss: 0.1097 - accuracy: 0.9396\n",
      "1366/5349 [======>.......................] - ETA: 3s - loss: 0.1097 - accuracy: 0.9398\n",
      "1475/5349 [=======>......................] - ETA: 3s - loss: 0.1096 - accuracy: 0.9399\n",
      "1583/5349 [=======>......................] - ETA: 3s - loss: 0.1101 - accuracy: 0.9397\n",
      "1687/5349 [========>.....................] - ETA: 3s - loss: 0.1101 - accuracy: 0.9396\n",
      "1798/5349 [=========>....................] - ETA: 3s - loss: 0.1100 - accuracy: 0.9397\n",
      "1907/5349 [=========>....................] - ETA: 3s - loss: 0.1102 - accuracy: 0.9396\n",
      "2021/5349 [==========>...................] - ETA: 3s - loss: 0.1101 - accuracy: 0.9397\n",
      "2120/5349 [==========>...................] - ETA: 2s - loss: 0.1103 - accuracy: 0.9397\n",
      "2230/5349 [===========>..................] - ETA: 2s - loss: 0.1103 - accuracy: 0.9396\n",
      "2339/5349 [============>.................] - ETA: 2s - loss: 0.1104 - accuracy: 0.9394\n",
      "2453/5349 [============>.................] - ETA: 2s - loss: 0.1103 - accuracy: 0.9396\n",
      "2553/5349 [=============>................] - ETA: 2s - loss: 0.1104 - accuracy: 0.9395\n",
      "2665/5349 [=============>................] - ETA: 2s - loss: 0.1105 - accuracy: 0.9394\n",
      "2770/5349 [==============>...............] - ETA: 2s - loss: 0.1105 - accuracy: 0.9394\n",
      "2883/5349 [===============>..............] - ETA: 2s - loss: 0.1107 - accuracy: 0.9392\n",
      "2990/5349 [===============>..............] - ETA: 2s - loss: 0.1107 - accuracy: 0.9392\n",
      "3103/5349 [================>.............] - ETA: 2s - loss: 0.1106 - accuracy: 0.9393\n",
      "3214/5349 [=================>............] - ETA: 1s - loss: 0.1107 - accuracy: 0.9393\n",
      "3325/5349 [=================>............] - ETA: 1s - loss: 0.1105 - accuracy: 0.9394\n",
      "3490/5349 [==================>...........] - ETA: 1s - loss: 0.1105 - accuracy: 0.9394\n",
      "3604/5349 [===================>..........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9394\n",
      "3711/5349 [===================>..........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9394\n",
      "3824/5349 [====================>.........] - ETA: 1s - loss: 0.1107 - accuracy: 0.9394\n",
      "3920/5349 [====================>.........] - ETA: 1s - loss: 0.1108 - accuracy: 0.9394\n",
      "4032/5349 [=====================>........] - ETA: 1s - loss: 0.1107 - accuracy: 0.9394\n",
      "4139/5349 [======================>.......] - ETA: 1s - loss: 0.1108 - accuracy: 0.9393\n",
      "4252/5349 [======================>.......] - ETA: 1s - loss: 0.1108 - accuracy: 0.9393\n",
      "4359/5349 [=======================>......] - ETA: 0s - loss: 0.1109 - accuracy: 0.9393\n",
      "4469/5349 [========================>.....] - ETA: 0s - loss: 0.1108 - accuracy: 0.9393\n",
      "4574/5349 [========================>.....] - ETA: 0s - loss: 0.1108 - accuracy: 0.9393\n",
      "4686/5349 [=========================>....] - ETA: 0s - loss: 0.1109 - accuracy: 0.9393\n",
      "4795/5349 [=========================>....] - ETA: 0s - loss: 0.1109 - accuracy: 0.9393\n",
      "4906/5349 [==========================>...] - ETA: 0s - loss: 0.1109 - accuracy: 0.9393\n",
      "5015/5349 [===========================>..] - ETA: 0s - loss: 0.1109 - accuracy: 0.9392\n",
      "5127/5349 [===========================>..] - ETA: 0s - loss: 0.1108 - accuracy: 0.9392\n",
      "5234/5349 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9392\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9392\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1108 - accuracy: 0.9392 - val_loss: 0.1092 - val_accuracy: 0.9448\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 8s - loss: 0.1614 - accuracy: 0.9000\n",
      "  88/5349 [..............................] - ETA: 6s - loss: 0.1092 - accuracy: 0.9427\n",
      " 230/5349 [>.............................] - ETA: 5s - loss: 0.1107 - accuracy: 0.9420\n",
      " 324/5349 [>.............................] - ETA: 5s - loss: 0.1110 - accuracy: 0.9410\n",
      " 423/5349 [=>............................] - ETA: 5s - loss: 0.1108 - accuracy: 0.9409\n",
      " 492/5349 [=>............................] - ETA: 5s - loss: 0.1112 - accuracy: 0.9410\n",
      " 566/5349 [==>...........................] - ETA: 5s - loss: 0.1114 - accuracy: 0.9405\n",
      " 655/5349 [==>...........................] - ETA: 5s - loss: 0.1108 - accuracy: 0.9410\n",
      " 745/5349 [===>..........................] - ETA: 5s - loss: 0.1113 - accuracy: 0.9404\n",
      " 844/5349 [===>..........................] - ETA: 5s - loss: 0.1109 - accuracy: 0.9403\n",
      " 949/5349 [====>.........................] - ETA: 4s - loss: 0.1111 - accuracy: 0.9401\n",
      "1053/5349 [====>.........................] - ETA: 4s - loss: 0.1118 - accuracy: 0.9394\n",
      "1162/5349 [=====>........................] - ETA: 4s - loss: 0.1116 - accuracy: 0.9394\n",
      "1267/5349 [======>.......................] - ETA: 4s - loss: 0.1113 - accuracy: 0.9396\n",
      "1364/5349 [======>.......................] - ETA: 4s - loss: 0.1111 - accuracy: 0.9397\n",
      "1424/5349 [======>.......................] - ETA: 4s - loss: 0.1108 - accuracy: 0.9399\n",
      "1583/5349 [=======>......................] - ETA: 4s - loss: 0.1112 - accuracy: 0.9394\n",
      "1689/5349 [========>.....................] - ETA: 3s - loss: 0.1111 - accuracy: 0.9394\n",
      "1803/5349 [=========>....................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9399\n",
      "1910/5349 [=========>....................] - ETA: 3s - loss: 0.1105 - accuracy: 0.9399\n",
      "2015/5349 [==========>...................] - ETA: 3s - loss: 0.1105 - accuracy: 0.9400\n",
      "2119/5349 [==========>...................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9400\n",
      "2230/5349 [===========>..................] - ETA: 3s - loss: 0.1103 - accuracy: 0.9401\n",
      "2336/5349 [============>.................] - ETA: 3s - loss: 0.1105 - accuracy: 0.9399\n",
      "2447/5349 [============>.................] - ETA: 2s - loss: 0.1106 - accuracy: 0.9399\n",
      "2548/5349 [=============>................] - ETA: 2s - loss: 0.1105 - accuracy: 0.9401\n",
      "2660/5349 [=============>................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9399\n",
      "2767/5349 [==============>...............] - ETA: 2s - loss: 0.1106 - accuracy: 0.9400\n",
      "2880/5349 [===============>..............] - ETA: 2s - loss: 0.1107 - accuracy: 0.9398\n",
      "2976/5349 [===============>..............] - ETA: 2s - loss: 0.1109 - accuracy: 0.9398\n",
      "3029/5349 [===============>..............] - ETA: 2s - loss: 0.1108 - accuracy: 0.9399\n",
      "3133/5349 [================>.............] - ETA: 2s - loss: 0.1108 - accuracy: 0.9399\n",
      "3237/5349 [=================>............] - ETA: 2s - loss: 0.1108 - accuracy: 0.9398\n",
      "3351/5349 [=================>............] - ETA: 2s - loss: 0.1108 - accuracy: 0.9399\n",
      "3456/5349 [==================>...........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9400\n",
      "3557/5349 [==================>...........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9400\n",
      "3615/5349 [===================>..........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9399\n",
      "3715/5349 [===================>..........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9399\n",
      "3813/5349 [====================>.........] - ETA: 1s - loss: 0.1107 - accuracy: 0.9399\n",
      "3915/5349 [====================>.........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9400\n",
      "4015/5349 [=====================>........] - ETA: 1s - loss: 0.1106 - accuracy: 0.9400\n",
      "4117/5349 [======================>.......] - ETA: 1s - loss: 0.1106 - accuracy: 0.9399\n",
      "4220/5349 [======================>.......] - ETA: 1s - loss: 0.1107 - accuracy: 0.9399\n",
      "4329/5349 [=======================>......] - ETA: 1s - loss: 0.1106 - accuracy: 0.9399\n",
      "4425/5349 [=======================>......] - ETA: 0s - loss: 0.1106 - accuracy: 0.9399\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.1106 - accuracy: 0.9399\n",
      "4627/5349 [========================>.....] - ETA: 0s - loss: 0.1107 - accuracy: 0.9399\n",
      "4739/5349 [=========================>....] - ETA: 0s - loss: 0.1107 - accuracy: 0.9399\n",
      "4833/5349 [==========================>...] - ETA: 0s - loss: 0.1107 - accuracy: 0.9400\n",
      "4942/5349 [==========================>...] - ETA: 0s - loss: 0.1107 - accuracy: 0.9400\n",
      "5051/5349 [===========================>..] - ETA: 0s - loss: 0.1107 - accuracy: 0.9399\n",
      "5160/5349 [===========================>..] - ETA: 0s - loss: 0.1108 - accuracy: 0.9399\n",
      "5266/5349 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9400\n",
      "5323/5349 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 0.9400\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1106 - accuracy: 0.9400 - val_loss: 0.1122 - val_accuracy: 0.9303\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1334 - accuracy: 0.9100\n",
      " 113/5349 [..............................] - ETA: 4s - loss: 0.1085 - accuracy: 0.9412\n",
      " 225/5349 [>.............................] - ETA: 4s - loss: 0.1121 - accuracy: 0.9401\n",
      " 333/5349 [>.............................] - ETA: 4s - loss: 0.1117 - accuracy: 0.9405\n",
      " 389/5349 [=>............................] - ETA: 4s - loss: 0.1106 - accuracy: 0.9411\n",
      " 501/5349 [=>............................] - ETA: 4s - loss: 0.1111 - accuracy: 0.9403\n",
      " 598/5349 [==>...........................] - ETA: 4s - loss: 0.1113 - accuracy: 0.9399\n",
      " 702/5349 [==>...........................] - ETA: 4s - loss: 0.1109 - accuracy: 0.9399\n",
      " 799/5349 [===>..........................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9400\n",
      " 913/5349 [====>.........................] - ETA: 4s - loss: 0.1098 - accuracy: 0.9405\n",
      "1019/5349 [====>.........................] - ETA: 4s - loss: 0.1095 - accuracy: 0.9407\n",
      "1132/5349 [=====>........................] - ETA: 3s - loss: 0.1092 - accuracy: 0.9410\n",
      "1240/5349 [=====>........................] - ETA: 3s - loss: 0.1091 - accuracy: 0.9412\n",
      "1353/5349 [======>.......................] - ETA: 3s - loss: 0.1090 - accuracy: 0.9412\n",
      "1462/5349 [=======>......................] - ETA: 3s - loss: 0.1089 - accuracy: 0.9414\n",
      "1576/5349 [=======>......................] - ETA: 3s - loss: 0.1088 - accuracy: 0.9414\n",
      "1687/5349 [========>.....................] - ETA: 3s - loss: 0.1091 - accuracy: 0.9413\n",
      "1798/5349 [=========>....................] - ETA: 3s - loss: 0.1088 - accuracy: 0.9415\n",
      "1908/5349 [=========>....................] - ETA: 3s - loss: 0.1089 - accuracy: 0.9414\n",
      "2022/5349 [==========>...................] - ETA: 3s - loss: 0.1091 - accuracy: 0.9415\n",
      "2133/5349 [==========>...................] - ETA: 2s - loss: 0.1092 - accuracy: 0.9414\n",
      "2246/5349 [===========>..................] - ETA: 2s - loss: 0.1090 - accuracy: 0.9416\n",
      "2353/5349 [============>.................] - ETA: 2s - loss: 0.1089 - accuracy: 0.9417\n",
      "2516/5349 [=============>................] - ETA: 2s - loss: 0.1087 - accuracy: 0.9418\n",
      "2616/5349 [=============>................] - ETA: 2s - loss: 0.1087 - accuracy: 0.9419\n",
      "2730/5349 [==============>...............] - ETA: 2s - loss: 0.1088 - accuracy: 0.9417\n",
      "2839/5349 [==============>...............] - ETA: 2s - loss: 0.1089 - accuracy: 0.9418\n",
      "2950/5349 [===============>..............] - ETA: 2s - loss: 0.1089 - accuracy: 0.9418\n",
      "3059/5349 [================>.............] - ETA: 2s - loss: 0.1088 - accuracy: 0.9418\n",
      "3171/5349 [================>.............] - ETA: 2s - loss: 0.1088 - accuracy: 0.9418\n",
      "3274/5349 [=================>............] - ETA: 1s - loss: 0.1090 - accuracy: 0.9416\n",
      "3387/5349 [=================>............] - ETA: 1s - loss: 0.1090 - accuracy: 0.9416\n",
      "3495/5349 [==================>...........] - ETA: 1s - loss: 0.1090 - accuracy: 0.9417\n",
      "3610/5349 [===================>..........] - ETA: 1s - loss: 0.1090 - accuracy: 0.9417\n",
      "3721/5349 [===================>..........] - ETA: 1s - loss: 0.1090 - accuracy: 0.9417\n",
      "3830/5349 [====================>.........] - ETA: 1s - loss: 0.1091 - accuracy: 0.9416\n",
      "3934/5349 [=====================>........] - ETA: 1s - loss: 0.1091 - accuracy: 0.9416\n",
      "4046/5349 [=====================>........] - ETA: 1s - loss: 0.1091 - accuracy: 0.9416\n",
      "4118/5349 [======================>.......] - ETA: 1s - loss: 0.1090 - accuracy: 0.9416\n",
      "4208/5349 [======================>.......] - ETA: 1s - loss: 0.1090 - accuracy: 0.9416\n",
      "4300/5349 [=======================>......] - ETA: 0s - loss: 0.1090 - accuracy: 0.9417\n",
      "4349/5349 [=======================>......] - ETA: 0s - loss: 0.1091 - accuracy: 0.9416\n",
      "4440/5349 [=======================>......] - ETA: 0s - loss: 0.1091 - accuracy: 0.9416\n",
      "4522/5349 [========================>.....] - ETA: 0s - loss: 0.1090 - accuracy: 0.9416\n",
      "4612/5349 [========================>.....] - ETA: 0s - loss: 0.1090 - accuracy: 0.9416\n",
      "4702/5349 [=========================>....] - ETA: 0s - loss: 0.1089 - accuracy: 0.9416\n",
      "4795/5349 [=========================>....] - ETA: 0s - loss: 0.1090 - accuracy: 0.9416\n",
      "4869/5349 [==========================>...] - ETA: 0s - loss: 0.1090 - accuracy: 0.9415\n",
      "4929/5349 [==========================>...] - ETA: 0s - loss: 0.1091 - accuracy: 0.9415\n",
      "5023/5349 [===========================>..] - ETA: 0s - loss: 0.1091 - accuracy: 0.9414\n",
      "5123/5349 [===========================>..] - ETA: 0s - loss: 0.1092 - accuracy: 0.9414\n",
      "5216/5349 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9414\n",
      "5321/5349 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9414\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1092 - accuracy: 0.9414 - val_loss: 0.1251 - val_accuracy: 0.9357\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.0984 - accuracy: 0.9300\n",
      " 111/5349 [..............................] - ETA: 4s - loss: 0.1047 - accuracy: 0.9447\n",
      " 223/5349 [>.............................] - ETA: 4s - loss: 0.1077 - accuracy: 0.9421\n",
      " 331/5349 [>.............................] - ETA: 4s - loss: 0.1088 - accuracy: 0.9419\n",
      " 442/5349 [=>............................] - ETA: 4s - loss: 0.1081 - accuracy: 0.9420\n",
      " 544/5349 [==>...........................] - ETA: 4s - loss: 0.1079 - accuracy: 0.9418\n",
      " 656/5349 [==>...........................] - ETA: 4s - loss: 0.1087 - accuracy: 0.9417\n",
      " 761/5349 [===>..........................] - ETA: 4s - loss: 0.1087 - accuracy: 0.9422\n",
      " 861/5349 [===>..........................] - ETA: 4s - loss: 0.1085 - accuracy: 0.9424\n",
      " 964/5349 [====>.........................] - ETA: 4s - loss: 0.1084 - accuracy: 0.9424\n",
      "1077/5349 [=====>........................] - ETA: 4s - loss: 0.1082 - accuracy: 0.9425\n",
      "1179/5349 [=====>........................] - ETA: 3s - loss: 0.1080 - accuracy: 0.9427\n",
      "1291/5349 [======>.......................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9424\n",
      "1376/5349 [======>.......................] - ETA: 3s - loss: 0.1085 - accuracy: 0.9423\n",
      "1489/5349 [=======>......................] - ETA: 3s - loss: 0.1085 - accuracy: 0.9423\n",
      "1593/5349 [=======>......................] - ETA: 3s - loss: 0.1087 - accuracy: 0.9422\n",
      "1705/5349 [========>.....................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9422\n",
      "1814/5349 [=========>....................] - ETA: 3s - loss: 0.1085 - accuracy: 0.9421\n",
      "1984/5349 [==========>...................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9422\n",
      "2093/5349 [==========>...................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9421\n",
      "2207/5349 [===========>..................] - ETA: 2s - loss: 0.1082 - accuracy: 0.9422\n",
      "2314/5349 [===========>..................] - ETA: 2s - loss: 0.1082 - accuracy: 0.9422\n",
      "2426/5349 [============>.................] - ETA: 2s - loss: 0.1082 - accuracy: 0.9423\n",
      "2535/5349 [=============>................] - ETA: 2s - loss: 0.1082 - accuracy: 0.9423\n",
      "2646/5349 [=============>................] - ETA: 2s - loss: 0.1083 - accuracy: 0.9423\n",
      "2756/5349 [==============>...............] - ETA: 2s - loss: 0.1083 - accuracy: 0.9422\n",
      "2869/5349 [===============>..............] - ETA: 2s - loss: 0.1083 - accuracy: 0.9422\n",
      "2979/5349 [===============>..............] - ETA: 2s - loss: 0.1083 - accuracy: 0.9423\n",
      "3092/5349 [================>.............] - ETA: 2s - loss: 0.1083 - accuracy: 0.9424\n",
      "3191/5349 [================>.............] - ETA: 2s - loss: 0.1081 - accuracy: 0.9425\n",
      "3304/5349 [=================>............] - ETA: 1s - loss: 0.1081 - accuracy: 0.9426\n",
      "3414/5349 [==================>...........] - ETA: 1s - loss: 0.1081 - accuracy: 0.9426\n",
      "3528/5349 [==================>...........] - ETA: 1s - loss: 0.1082 - accuracy: 0.9425\n",
      "3628/5349 [===================>..........] - ETA: 1s - loss: 0.1081 - accuracy: 0.9426\n",
      "3735/5349 [===================>..........] - ETA: 1s - loss: 0.1081 - accuracy: 0.9426\n",
      "3792/5349 [====================>.........] - ETA: 1s - loss: 0.1080 - accuracy: 0.9426\n",
      "3902/5349 [====================>.........] - ETA: 1s - loss: 0.1082 - accuracy: 0.9425\n",
      "4014/5349 [=====================>........] - ETA: 1s - loss: 0.1082 - accuracy: 0.9425\n",
      "4123/5349 [======================>.......] - ETA: 1s - loss: 0.1083 - accuracy: 0.9425\n",
      "4233/5349 [======================>.......] - ETA: 1s - loss: 0.1083 - accuracy: 0.9424\n",
      "4340/5349 [=======================>......] - ETA: 0s - loss: 0.1084 - accuracy: 0.9424\n",
      "4453/5349 [=======================>......] - ETA: 0s - loss: 0.1084 - accuracy: 0.9424\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.1085 - accuracy: 0.9424\n",
      "4676/5349 [=========================>....] - ETA: 0s - loss: 0.1085 - accuracy: 0.9425\n",
      "4781/5349 [=========================>....] - ETA: 0s - loss: 0.1084 - accuracy: 0.9425\n",
      "4886/5349 [==========================>...] - ETA: 0s - loss: 0.1084 - accuracy: 0.9425\n",
      "4985/5349 [==========================>...] - ETA: 0s - loss: 0.1084 - accuracy: 0.9426\n",
      "5098/5349 [===========================>..] - ETA: 0s - loss: 0.1084 - accuracy: 0.9425\n",
      "5205/5349 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9426\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9426\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1084 - accuracy: 0.9426 - val_loss: 0.1083 - val_accuracy: 0.9415\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 18/20\n",
      "  56/5349 [..............................] - ETA: 4s - loss: 0.1071 - accuracy: 0.9455\n",
      " 170/5349 [..............................] - ETA: 4s - loss: 0.1060 - accuracy: 0.9439\n",
      " 284/5349 [>.............................] - ETA: 4s - loss: 0.1071 - accuracy: 0.9437\n",
      " 448/5349 [=>............................] - ETA: 4s - loss: 0.1077 - accuracy: 0.9436\n",
      " 560/5349 [==>...........................] - ETA: 4s - loss: 0.1079 - accuracy: 0.9437\n",
      " 668/5349 [==>...........................] - ETA: 4s - loss: 0.1071 - accuracy: 0.9440\n",
      " 781/5349 [===>..........................] - ETA: 4s - loss: 0.1073 - accuracy: 0.9437\n",
      " 891/5349 [===>..........................] - ETA: 4s - loss: 0.1075 - accuracy: 0.9434\n",
      "1003/5349 [====>.........................] - ETA: 3s - loss: 0.1074 - accuracy: 0.9438\n",
      "1107/5349 [=====>........................] - ETA: 3s - loss: 0.1073 - accuracy: 0.9437\n",
      "1217/5349 [=====>........................] - ETA: 3s - loss: 0.1083 - accuracy: 0.9433\n",
      "1315/5349 [======>.......................] - ETA: 3s - loss: 0.1079 - accuracy: 0.9436\n",
      "1430/5349 [=======>......................] - ETA: 3s - loss: 0.1080 - accuracy: 0.9436\n",
      "1537/5349 [=======>......................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9434\n",
      "1646/5349 [========>.....................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9432\n",
      "1756/5349 [========>.....................] - ETA: 3s - loss: 0.1082 - accuracy: 0.9434\n",
      "1867/5349 [=========>....................] - ETA: 3s - loss: 0.1081 - accuracy: 0.9436\n",
      "1947/5349 [=========>....................] - ETA: 3s - loss: 0.1081 - accuracy: 0.9435\n",
      "2036/5349 [==========>...................] - ETA: 3s - loss: 0.1082 - accuracy: 0.9435\n",
      "2122/5349 [==========>...................] - ETA: 3s - loss: 0.1083 - accuracy: 0.9434\n",
      "2260/5349 [===========>..................] - ETA: 2s - loss: 0.1084 - accuracy: 0.9433\n",
      "2340/5349 [============>.................] - ETA: 2s - loss: 0.1083 - accuracy: 0.9433\n",
      "2435/5349 [============>.................] - ETA: 2s - loss: 0.1083 - accuracy: 0.9433\n",
      "2518/5349 [=============>................] - ETA: 2s - loss: 0.1084 - accuracy: 0.9433\n",
      "2615/5349 [=============>................] - ETA: 2s - loss: 0.1081 - accuracy: 0.9434\n",
      "2704/5349 [==============>...............] - ETA: 2s - loss: 0.1083 - accuracy: 0.9434\n",
      "2756/5349 [==============>...............] - ETA: 2s - loss: 0.1083 - accuracy: 0.9434\n",
      "2837/5349 [==============>...............] - ETA: 2s - loss: 0.1082 - accuracy: 0.9434\n",
      "2932/5349 [===============>..............] - ETA: 2s - loss: 0.1081 - accuracy: 0.9435\n",
      "3023/5349 [===============>..............] - ETA: 2s - loss: 0.1079 - accuracy: 0.9436\n",
      "3132/5349 [================>.............] - ETA: 2s - loss: 0.1078 - accuracy: 0.9436\n",
      "3241/5349 [=================>............] - ETA: 2s - loss: 0.1079 - accuracy: 0.9435\n",
      "3355/5349 [=================>............] - ETA: 2s - loss: 0.1079 - accuracy: 0.9435\n",
      "3458/5349 [==================>...........] - ETA: 1s - loss: 0.1079 - accuracy: 0.9435\n",
      "3563/5349 [==================>...........] - ETA: 1s - loss: 0.1079 - accuracy: 0.9435\n",
      "3652/5349 [===================>..........] - ETA: 1s - loss: 0.1080 - accuracy: 0.9435\n",
      "3762/5349 [====================>.........] - ETA: 1s - loss: 0.1079 - accuracy: 0.9435\n",
      "3925/5349 [=====================>........] - ETA: 1s - loss: 0.1078 - accuracy: 0.9436\n",
      "4038/5349 [=====================>........] - ETA: 1s - loss: 0.1078 - accuracy: 0.9436\n",
      "4137/5349 [======================>.......] - ETA: 1s - loss: 0.1079 - accuracy: 0.9435\n",
      "4249/5349 [======================>.......] - ETA: 1s - loss: 0.1079 - accuracy: 0.9434\n",
      "4356/5349 [=======================>......] - ETA: 0s - loss: 0.1077 - accuracy: 0.9436\n",
      "4465/5349 [========================>.....] - ETA: 0s - loss: 0.1077 - accuracy: 0.9436\n",
      "4572/5349 [========================>.....] - ETA: 0s - loss: 0.1077 - accuracy: 0.9436\n",
      "4682/5349 [=========================>....] - ETA: 0s - loss: 0.1076 - accuracy: 0.9436\n",
      "4789/5349 [=========================>....] - ETA: 0s - loss: 0.1077 - accuracy: 0.9435\n",
      "4902/5349 [==========================>...] - ETA: 0s - loss: 0.1078 - accuracy: 0.9435\n",
      "5004/5349 [===========================>..] - ETA: 0s - loss: 0.1078 - accuracy: 0.9434\n",
      "5115/5349 [===========================>..] - ETA: 0s - loss: 0.1078 - accuracy: 0.9434\n",
      "5218/5349 [============================>.] - ETA: 0s - loss: 0.1078 - accuracy: 0.9434\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9435\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1077 - accuracy: 0.9434 - val_loss: 0.1101 - val_accuracy: 0.9408\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 19/20\n",
      "  43/5349 [..............................] - ETA: 6s - loss: 0.1125 - accuracy: 0.9405\n",
      " 149/5349 [..............................] - ETA: 5s - loss: 0.1113 - accuracy: 0.9403\n",
      " 261/5349 [>.............................] - ETA: 4s - loss: 0.1110 - accuracy: 0.9407\n",
      " 368/5349 [=>............................] - ETA: 4s - loss: 0.1086 - accuracy: 0.9419\n",
      " 481/5349 [=>............................] - ETA: 4s - loss: 0.1081 - accuracy: 0.9424\n",
      " 588/5349 [==>...........................] - ETA: 4s - loss: 0.1082 - accuracy: 0.9424\n",
      " 700/5349 [==>...........................] - ETA: 4s - loss: 0.1085 - accuracy: 0.9421\n",
      " 807/5349 [===>..........................] - ETA: 4s - loss: 0.1083 - accuracy: 0.9425\n",
      " 919/5349 [====>.........................] - ETA: 4s - loss: 0.1082 - accuracy: 0.9427\n",
      "1028/5349 [====>.........................] - ETA: 4s - loss: 0.1087 - accuracy: 0.9422\n",
      "1140/5349 [=====>........................] - ETA: 3s - loss: 0.1083 - accuracy: 0.9426\n",
      "1242/5349 [=====>........................] - ETA: 3s - loss: 0.1080 - accuracy: 0.9426\n",
      "1357/5349 [======>.......................] - ETA: 3s - loss: 0.1084 - accuracy: 0.9423\n",
      "1454/5349 [=======>......................] - ETA: 3s - loss: 0.1079 - accuracy: 0.9427\n",
      "1561/5349 [=======>......................] - ETA: 3s - loss: 0.1077 - accuracy: 0.9430\n",
      "1618/5349 [========>.....................] - ETA: 3s - loss: 0.1077 - accuracy: 0.9430\n",
      "1727/5349 [========>.....................] - ETA: 3s - loss: 0.1077 - accuracy: 0.9430\n",
      "1837/5349 [=========>....................] - ETA: 3s - loss: 0.1076 - accuracy: 0.9429\n",
      "1937/5349 [=========>....................] - ETA: 3s - loss: 0.1075 - accuracy: 0.9430\n",
      "2051/5349 [==========>...................] - ETA: 3s - loss: 0.1071 - accuracy: 0.9433\n",
      "2160/5349 [===========>..................] - ETA: 2s - loss: 0.1072 - accuracy: 0.9433\n",
      "2271/5349 [===========>..................] - ETA: 2s - loss: 0.1070 - accuracy: 0.9435\n",
      "2379/5349 [============>.................] - ETA: 2s - loss: 0.1071 - accuracy: 0.9433\n",
      "2492/5349 [============>.................] - ETA: 2s - loss: 0.1070 - accuracy: 0.9433\n",
      "2601/5349 [=============>................] - ETA: 2s - loss: 0.1070 - accuracy: 0.9433\n",
      "2715/5349 [==============>...............] - ETA: 2s - loss: 0.1070 - accuracy: 0.9434\n",
      "2822/5349 [==============>...............] - ETA: 2s - loss: 0.1071 - accuracy: 0.9434\n",
      "2926/5349 [===============>..............] - ETA: 2s - loss: 0.1071 - accuracy: 0.9433\n",
      "3034/5349 [================>.............] - ETA: 2s - loss: 0.1072 - accuracy: 0.9433\n",
      "3147/5349 [================>.............] - ETA: 2s - loss: 0.1070 - accuracy: 0.9434\n",
      "3256/5349 [=================>............] - ETA: 1s - loss: 0.1068 - accuracy: 0.9436\n",
      "3312/5349 [=================>............] - ETA: 1s - loss: 0.1068 - accuracy: 0.9436\n",
      "3424/5349 [==================>...........] - ETA: 1s - loss: 0.1068 - accuracy: 0.9438\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1066 - accuracy: 0.9438\n",
      "3647/5349 [===================>..........] - ETA: 1s - loss: 0.1065 - accuracy: 0.9439\n",
      "3746/5349 [====================>.........] - ETA: 1s - loss: 0.1066 - accuracy: 0.9438\n",
      "3857/5349 [====================>.........] - ETA: 1s - loss: 0.1066 - accuracy: 0.9439\n",
      "3962/5349 [=====================>........] - ETA: 1s - loss: 0.1067 - accuracy: 0.9439\n",
      "4074/5349 [=====================>........] - ETA: 1s - loss: 0.1067 - accuracy: 0.9439\n",
      "4183/5349 [======================>.......] - ETA: 1s - loss: 0.1067 - accuracy: 0.9439\n",
      "4296/5349 [=======================>......] - ETA: 0s - loss: 0.1068 - accuracy: 0.9439\n",
      "4405/5349 [=======================>......] - ETA: 0s - loss: 0.1067 - accuracy: 0.9440\n",
      "4516/5349 [========================>.....] - ETA: 0s - loss: 0.1067 - accuracy: 0.9440\n",
      "4624/5349 [========================>.....] - ETA: 0s - loss: 0.1066 - accuracy: 0.9441\n",
      "4737/5349 [=========================>....] - ETA: 0s - loss: 0.1066 - accuracy: 0.9441\n",
      "4848/5349 [==========================>...] - ETA: 0s - loss: 0.1067 - accuracy: 0.9440\n",
      "4961/5349 [==========================>...] - ETA: 0s - loss: 0.1068 - accuracy: 0.9439\n",
      "5066/5349 [===========================>..] - ETA: 0s - loss: 0.1068 - accuracy: 0.9439\n",
      "5179/5349 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9440\n",
      "5286/5349 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9440\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9440\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1068 - accuracy: 0.9440 - val_loss: 0.1057 - val_accuracy: 0.9458\n",
      "\u001B[36m(train_DNN pid=5354)\u001B[0m Epoch 20/20\n",
      "  46/5349 [..............................] - ETA: 5s - loss: 0.1065 - accuracy: 0.9493\n",
      " 132/5349 [..............................] - ETA: 6s - loss: 0.1059 - accuracy: 0.9461\n",
      " 223/5349 [>.............................] - ETA: 5s - loss: 0.1079 - accuracy: 0.9448\n",
      " 298/5349 [>.............................] - ETA: 6s - loss: 0.1059 - accuracy: 0.9454\n",
      " 391/5349 [=>............................] - ETA: 5s - loss: 0.1063 - accuracy: 0.9454\n",
      " 483/5349 [=>............................] - ETA: 5s - loss: 0.1064 - accuracy: 0.9445\n",
      " 575/5349 [==>...........................] - ETA: 5s - loss: 0.1058 - accuracy: 0.9447\n",
      " 661/5349 [==>...........................] - ETA: 5s - loss: 0.1061 - accuracy: 0.9446\n",
      " 756/5349 [===>..........................] - ETA: 5s - loss: 0.1067 - accuracy: 0.9441\n",
      " 830/5349 [===>..........................] - ETA: 5s - loss: 0.1064 - accuracy: 0.9443\n",
      " 903/5349 [====>.........................] - ETA: 5s - loss: 0.1068 - accuracy: 0.9443\n",
      " 950/5349 [====>.........................] - ETA: 5s - loss: 0.1069 - accuracy: 0.9442\n",
      "1028/5349 [====>.........................] - ETA: 5s - loss: 0.1068 - accuracy: 0.9443\n",
      "1119/5349 [=====>........................] - ETA: 4s - loss: 0.1068 - accuracy: 0.9443\n",
      "1225/5349 [=====>........................] - ETA: 4s - loss: 0.1067 - accuracy: 0.9444\n",
      "1339/5349 [======>.......................] - ETA: 4s - loss: 0.1067 - accuracy: 0.9443\n",
      "1450/5349 [=======>......................] - ETA: 4s - loss: 0.1065 - accuracy: 0.9444\n",
      "1558/5349 [=======>......................] - ETA: 4s - loss: 0.1066 - accuracy: 0.9444\n",
      "1666/5349 [========>.....................] - ETA: 4s - loss: 0.1063 - accuracy: 0.9447\n",
      "1779/5349 [========>.....................] - ETA: 3s - loss: 0.1062 - accuracy: 0.9449\n",
      "1886/5349 [=========>....................] - ETA: 3s - loss: 0.1062 - accuracy: 0.9447\n",
      "1997/5349 [==========>...................] - ETA: 3s - loss: 0.1061 - accuracy: 0.9448\n",
      "2100/5349 [==========>...................] - ETA: 3s - loss: 0.1060 - accuracy: 0.9447\n",
      "2211/5349 [===========>..................] - ETA: 3s - loss: 0.1059 - accuracy: 0.9448\n",
      "2318/5349 [============>.................] - ETA: 3s - loss: 0.1058 - accuracy: 0.9449\n",
      "2430/5349 [============>.................] - ETA: 3s - loss: 0.1055 - accuracy: 0.9450\n",
      "2537/5349 [=============>................] - ETA: 2s - loss: 0.1056 - accuracy: 0.9449\n",
      "2645/5349 [=============>................] - ETA: 2s - loss: 0.1058 - accuracy: 0.9448\n",
      "2749/5349 [==============>...............] - ETA: 2s - loss: 0.1057 - accuracy: 0.9448\n",
      "2860/5349 [===============>..............] - ETA: 2s - loss: 0.1055 - accuracy: 0.9449\n",
      "2969/5349 [===============>..............] - ETA: 2s - loss: 0.1056 - accuracy: 0.9449\n",
      "3081/5349 [================>.............] - ETA: 2s - loss: 0.1055 - accuracy: 0.9448\n",
      "3246/5349 [=================>............] - ETA: 2s - loss: 0.1056 - accuracy: 0.9449\n",
      "3358/5349 [=================>............] - ETA: 2s - loss: 0.1055 - accuracy: 0.9449\n",
      "3467/5349 [==================>...........] - ETA: 1s - loss: 0.1055 - accuracy: 0.9449\n",
      "3576/5349 [===================>..........] - ETA: 1s - loss: 0.1055 - accuracy: 0.9449\n",
      "3675/5349 [===================>..........] - ETA: 1s - loss: 0.1056 - accuracy: 0.9449\n",
      "3785/5349 [====================>.........] - ETA: 1s - loss: 0.1056 - accuracy: 0.9449\n",
      "3886/5349 [====================>.........] - ETA: 1s - loss: 0.1055 - accuracy: 0.9449\n",
      "3963/5349 [=====================>........] - ETA: 1s - loss: 0.1057 - accuracy: 0.9448\n",
      "4070/5349 [=====================>........] - ETA: 1s - loss: 0.1057 - accuracy: 0.9447\n",
      "4178/5349 [======================>.......] - ETA: 1s - loss: 0.1056 - accuracy: 0.9447\n",
      "4270/5349 [======================>.......] - ETA: 1s - loss: 0.1057 - accuracy: 0.9447\n",
      "4376/5349 [=======================>......] - ETA: 0s - loss: 0.1057 - accuracy: 0.9447\n",
      "4480/5349 [========================>.....] - ETA: 0s - loss: 0.1057 - accuracy: 0.9446\n",
      "4592/5349 [========================>.....] - ETA: 0s - loss: 0.1057 - accuracy: 0.9446\n",
      "4697/5349 [=========================>....] - ETA: 0s - loss: 0.1058 - accuracy: 0.9445\n",
      "4808/5349 [=========================>....] - ETA: 0s - loss: 0.1059 - accuracy: 0.9445\n",
      "4913/5349 [==========================>...] - ETA: 0s - loss: 0.1060 - accuracy: 0.9444\n",
      "5026/5349 [===========================>..] - ETA: 0s - loss: 0.1061 - accuracy: 0.9444\n",
      "5137/5349 [===========================>..] - ETA: 0s - loss: 0.1062 - accuracy: 0.9443\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9444\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1061 - accuracy: 0.9443 - val_loss: 0.1575 - val_accuracy: 0.9375\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 1/20\n",
      "  92/5349 [..............................] - ETA: 2s - loss: 0.6987 - accuracy: 0.4315   \n",
      " 308/5349 [>.............................] - ETA: 2s - loss: 0.6621 - accuracy: 0.7176\n",
      " 628/5349 [==>...........................] - ETA: 2s - loss: 0.6155 - accuracy: 0.7840\n",
      " 804/5349 [===>..........................] - ETA: 2s - loss: 0.5924 - accuracy: 0.7966\n",
      "1029/5349 [====>.........................] - ETA: 2s - loss: 0.5641 - accuracy: 0.8066\n",
      "1237/5349 [=====>........................] - ETA: 2s - loss: 0.5390 - accuracy: 0.8129\n",
      "1462/5349 [=======>......................] - ETA: 1s - loss: 0.5131 - accuracy: 0.8178\n",
      "1676/5349 [========>.....................] - ETA: 1s - loss: 0.4901 - accuracy: 0.8216\n",
      "1898/5349 [=========>....................] - ETA: 1s - loss: 0.4682 - accuracy: 0.8251\n",
      "2113/5349 [==========>...................] - ETA: 1s - loss: 0.4488 - accuracy: 0.8278\n",
      "2331/5349 [============>.................] - ETA: 1s - loss: 0.4313 - accuracy: 0.8303\n",
      "2550/5349 [=============>................] - ETA: 1s - loss: 0.4154 - accuracy: 0.8324\n",
      "2741/5349 [==============>...............] - ETA: 1s - loss: 0.4033 - accuracy: 0.8343\n",
      "2953/5349 [===============>..............] - ETA: 1s - loss: 0.3910 - accuracy: 0.8363\n",
      "3174/5349 [================>.............] - ETA: 1s - loss: 0.3793 - accuracy: 0.8383\n",
      "3506/5349 [==================>...........] - ETA: 0s - loss: 0.3643 - accuracy: 0.8413\n",
      "3711/5349 [===================>..........] - ETA: 0s - loss: 0.3562 - accuracy: 0.8431\n",
      "3924/5349 [=====================>........] - ETA: 0s - loss: 0.3484 - accuracy: 0.8451\n",
      "4148/5349 [======================>.......] - ETA: 0s - loss: 0.3409 - accuracy: 0.8473\n",
      "4369/5349 [=======================>......] - ETA: 0s - loss: 0.3337 - accuracy: 0.8497\n",
      "4565/5349 [========================>.....] - ETA: 0s - loss: 0.3284 - accuracy: 0.8514\n",
      "4778/5349 [=========================>....] - ETA: 0s - loss: 0.3228 - accuracy: 0.8533\n",
      "5000/5349 [===========================>..] - ETA: 0s - loss: 0.3175 - accuracy: 0.8551\n",
      "5213/5349 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.8568\n",
      "5325/5349 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.8576\n",
      "5349/5349 [==============================] - 4s 675us/step - loss: 0.3097 - accuracy: 0.8577 - val_loss: 0.1966 - val_accuracy: 0.8969\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2794 - accuracy: 0.8300\n",
      " 213/5349 [>.............................] - ETA: 2s - loss: 0.1974 - accuracy: 0.8966\n",
      " 433/5349 [=>............................] - ETA: 2s - loss: 0.1950 - accuracy: 0.8975\n",
      " 647/5349 [==>...........................] - ETA: 2s - loss: 0.1944 - accuracy: 0.8980\n",
      " 874/5349 [===>..........................] - ETA: 2s - loss: 0.1944 - accuracy: 0.8981\n",
      "1053/5349 [====>.........................] - ETA: 2s - loss: 0.1938 - accuracy: 0.8985\n",
      "1285/5349 [======>.......................] - ETA: 1s - loss: 0.1936 - accuracy: 0.8982\n",
      "1505/5349 [=======>......................] - ETA: 1s - loss: 0.1930 - accuracy: 0.8985\n",
      "1736/5349 [========>.....................] - ETA: 1s - loss: 0.1925 - accuracy: 0.8983\n",
      "1954/5349 [=========>....................] - ETA: 1s - loss: 0.1920 - accuracy: 0.8984\n",
      "2180/5349 [===========>..................] - ETA: 1s - loss: 0.1920 - accuracy: 0.8984\n",
      "2395/5349 [============>.................] - ETA: 1s - loss: 0.1917 - accuracy: 0.8984\n",
      "2742/5349 [==============>...............] - ETA: 1s - loss: 0.1913 - accuracy: 0.8983\n",
      "2964/5349 [===============>..............] - ETA: 1s - loss: 0.1904 - accuracy: 0.8988\n",
      "3194/5349 [================>.............] - ETA: 0s - loss: 0.1902 - accuracy: 0.8989\n",
      "3417/5349 [==================>...........] - ETA: 0s - loss: 0.1897 - accuracy: 0.8991\n",
      "3644/5349 [===================>..........] - ETA: 0s - loss: 0.1891 - accuracy: 0.8994\n",
      "3852/5349 [====================>.........] - ETA: 0s - loss: 0.1886 - accuracy: 0.8996\n",
      "4079/5349 [=====================>........] - ETA: 0s - loss: 0.1882 - accuracy: 0.8998\n",
      "4300/5349 [=======================>......] - ETA: 0s - loss: 0.1878 - accuracy: 0.9001\n",
      "4528/5349 [========================>.....] - ETA: 0s - loss: 0.1876 - accuracy: 0.9002\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.1872 - accuracy: 0.9004\n",
      "4963/5349 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.9006\n",
      "5185/5349 [============================>.] - ETA: 0s - loss: 0.1866 - accuracy: 0.9007\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1863 - accuracy: 0.9009\n",
      "5349/5349 [==============================] - 3s 623us/step - loss: 0.1863 - accuracy: 0.9010 - val_loss: 0.1788 - val_accuracy: 0.9050\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 3/20\n",
      " 113/5349 [..............................] - ETA: 2s - loss: 0.1753 - accuracy: 0.9075\n",
      " 341/5349 [>.............................] - ETA: 2s - loss: 0.1764 - accuracy: 0.9070\n",
      " 554/5349 [==>...........................] - ETA: 2s - loss: 0.1780 - accuracy: 0.9058\n",
      " 687/5349 [==>...........................] - ETA: 2s - loss: 0.1775 - accuracy: 0.9059\n",
      " 830/5349 [===>..........................] - ETA: 2s - loss: 0.1778 - accuracy: 0.9053\n",
      " 975/5349 [====>.........................] - ETA: 2s - loss: 0.1778 - accuracy: 0.9053\n",
      "1130/5349 [=====>........................] - ETA: 2s - loss: 0.1776 - accuracy: 0.9052\n",
      "1308/5349 [======>.......................] - ETA: 2s - loss: 0.1774 - accuracy: 0.9056\n",
      "1506/5349 [=======>......................] - ETA: 2s - loss: 0.1776 - accuracy: 0.9053\n",
      "1779/5349 [========>.....................] - ETA: 2s - loss: 0.1773 - accuracy: 0.9055\n",
      "1977/5349 [==========>...................] - ETA: 1s - loss: 0.1772 - accuracy: 0.9054\n",
      "2154/5349 [===========>..................] - ETA: 1s - loss: 0.1773 - accuracy: 0.9053\n",
      "2322/5349 [============>.................] - ETA: 1s - loss: 0.1772 - accuracy: 0.9054\n",
      "2442/5349 [============>.................] - ETA: 1s - loss: 0.1772 - accuracy: 0.9054\n",
      "2611/5349 [=============>................] - ETA: 1s - loss: 0.1773 - accuracy: 0.9054\n",
      "2827/5349 [==============>...............] - ETA: 1s - loss: 0.1770 - accuracy: 0.9055\n",
      "3040/5349 [================>.............] - ETA: 1s - loss: 0.1768 - accuracy: 0.9058\n",
      "3259/5349 [=================>............] - ETA: 1s - loss: 0.1765 - accuracy: 0.9060\n",
      "3484/5349 [==================>...........] - ETA: 1s - loss: 0.1763 - accuracy: 0.9061\n",
      "3705/5349 [===================>..........] - ETA: 0s - loss: 0.1761 - accuracy: 0.9063\n",
      "3930/5349 [=====================>........] - ETA: 0s - loss: 0.1759 - accuracy: 0.9065\n",
      "4260/5349 [======================>.......] - ETA: 0s - loss: 0.1757 - accuracy: 0.9068\n",
      "4485/5349 [========================>.....] - ETA: 0s - loss: 0.1756 - accuracy: 0.9068\n",
      "4688/5349 [=========================>....] - ETA: 0s - loss: 0.1754 - accuracy: 0.9070\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.1753 - accuracy: 0.9069\n",
      "5118/5349 [===========================>..] - ETA: 0s - loss: 0.1751 - accuracy: 0.9072\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9072\n",
      "5349/5349 [==============================] - 4s 693us/step - loss: 0.1750 - accuracy: 0.9072 - val_loss: 0.1709 - val_accuracy: 0.9100\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 4/20\n",
      " 106/5349 [..............................] - ETA: 2s - loss: 0.1686 - accuracy: 0.9114\n",
      " 331/5349 [>.............................] - ETA: 2s - loss: 0.1731 - accuracy: 0.9088\n",
      " 554/5349 [==>...........................] - ETA: 2s - loss: 0.1694 - accuracy: 0.9102\n",
      " 768/5349 [===>..........................] - ETA: 2s - loss: 0.1703 - accuracy: 0.9099\n",
      " 981/5349 [====>.........................] - ETA: 2s - loss: 0.1695 - accuracy: 0.9104\n",
      "1082/5349 [=====>........................] - ETA: 1s - loss: 0.1698 - accuracy: 0.9103\n",
      "1291/5349 [======>.......................] - ETA: 1s - loss: 0.1697 - accuracy: 0.9101\n",
      "1365/5349 [======>.......................] - ETA: 2s - loss: 0.1701 - accuracy: 0.9101\n",
      "1544/5349 [=======>......................] - ETA: 1s - loss: 0.1697 - accuracy: 0.9104\n",
      "1747/5349 [========>.....................] - ETA: 1s - loss: 0.1696 - accuracy: 0.9107\n",
      "1946/5349 [=========>....................] - ETA: 1s - loss: 0.1694 - accuracy: 0.9108\n",
      "2169/5349 [===========>..................] - ETA: 1s - loss: 0.1692 - accuracy: 0.9110\n",
      "2350/5349 [============>.................] - ETA: 1s - loss: 0.1692 - accuracy: 0.9109\n",
      "2565/5349 [=============>................] - ETA: 1s - loss: 0.1691 - accuracy: 0.9108\n",
      "2779/5349 [==============>...............] - ETA: 1s - loss: 0.1693 - accuracy: 0.9106\n",
      "2982/5349 [===============>..............] - ETA: 1s - loss: 0.1693 - accuracy: 0.9106\n",
      "3187/5349 [================>.............] - ETA: 1s - loss: 0.1692 - accuracy: 0.9105\n",
      "3414/5349 [==================>...........] - ETA: 0s - loss: 0.1692 - accuracy: 0.9105\n",
      "3623/5349 [===================>..........] - ETA: 0s - loss: 0.1692 - accuracy: 0.9104\n",
      "3844/5349 [====================>.........] - ETA: 0s - loss: 0.1694 - accuracy: 0.9104\n",
      "4056/5349 [=====================>........] - ETA: 0s - loss: 0.1694 - accuracy: 0.9106\n",
      "4287/5349 [=======================>......] - ETA: 0s - loss: 0.1692 - accuracy: 0.9107\n",
      "4624/5349 [========================>.....] - ETA: 0s - loss: 0.1691 - accuracy: 0.9107\n",
      "4858/5349 [==========================>...] - ETA: 0s - loss: 0.1690 - accuracy: 0.9108\n",
      "5079/5349 [===========================>..] - ETA: 0s - loss: 0.1688 - accuracy: 0.9109\n",
      "5302/5349 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9110\n",
      "5349/5349 [==============================] - 3s 653us/step - loss: 0.1687 - accuracy: 0.9110 - val_loss: 0.1659 - val_accuracy: 0.9129\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1395 - accuracy: 0.9400\n",
      " 214/5349 [>.............................] - ETA: 2s - loss: 0.1626 - accuracy: 0.9149\n",
      " 352/5349 [>.............................] - ETA: 2s - loss: 0.1629 - accuracy: 0.9147\n",
      " 475/5349 [=>............................] - ETA: 3s - loss: 0.1644 - accuracy: 0.9132\n",
      " 668/5349 [==>...........................] - ETA: 2s - loss: 0.1640 - accuracy: 0.9132\n",
      " 872/5349 [===>..........................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9127\n",
      "1042/5349 [====>.........................] - ETA: 2s - loss: 0.1645 - accuracy: 0.9128\n",
      "1196/5349 [=====>........................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9127\n",
      "1387/5349 [======>.......................] - ETA: 2s - loss: 0.1650 - accuracy: 0.9130\n",
      "1566/5349 [=======>......................] - ETA: 2s - loss: 0.1654 - accuracy: 0.9128\n",
      "1766/5349 [========>.....................] - ETA: 2s - loss: 0.1656 - accuracy: 0.9128\n",
      "1949/5349 [=========>....................] - ETA: 1s - loss: 0.1652 - accuracy: 0.9131\n",
      "2254/5349 [===========>..................] - ETA: 1s - loss: 0.1650 - accuracy: 0.9133\n",
      "2447/5349 [============>.................] - ETA: 1s - loss: 0.1650 - accuracy: 0.9133\n",
      "2635/5349 [=============>................] - ETA: 1s - loss: 0.1647 - accuracy: 0.9136\n",
      "2738/5349 [==============>...............] - ETA: 1s - loss: 0.1650 - accuracy: 0.9136\n",
      "2930/5349 [===============>..............] - ETA: 1s - loss: 0.1650 - accuracy: 0.9136\n",
      "3119/5349 [================>.............] - ETA: 1s - loss: 0.1648 - accuracy: 0.9137\n",
      "3332/5349 [=================>............] - ETA: 1s - loss: 0.1645 - accuracy: 0.9138\n",
      "3557/5349 [==================>...........] - ETA: 0s - loss: 0.1644 - accuracy: 0.9138\n",
      "3777/5349 [====================>.........] - ETA: 0s - loss: 0.1645 - accuracy: 0.9137\n",
      "3997/5349 [=====================>........] - ETA: 0s - loss: 0.1646 - accuracy: 0.9135\n",
      "4204/5349 [======================>.......] - ETA: 0s - loss: 0.1647 - accuracy: 0.9135\n",
      "4423/5349 [=======================>......] - ETA: 0s - loss: 0.1646 - accuracy: 0.9134\n",
      "4755/5349 [=========================>....] - ETA: 0s - loss: 0.1648 - accuracy: 0.9134\n",
      "4958/5349 [==========================>...] - ETA: 0s - loss: 0.1647 - accuracy: 0.9133\n",
      "5180/5349 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9136\n",
      "5288/5349 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9135\n",
      "5349/5349 [==============================] - 4s 697us/step - loss: 0.1646 - accuracy: 0.9135 - val_loss: 0.1626 - val_accuracy: 0.9149\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1241 - accuracy: 0.9200\n",
      " 220/5349 [>.............................] - ETA: 2s - loss: 0.1631 - accuracy: 0.9175\n",
      " 447/5349 [=>............................] - ETA: 2s - loss: 0.1642 - accuracy: 0.9150\n",
      " 653/5349 [==>...........................] - ETA: 2s - loss: 0.1651 - accuracy: 0.9141\n",
      " 869/5349 [===>..........................] - ETA: 2s - loss: 0.1649 - accuracy: 0.9140\n",
      "1079/5349 [=====>........................] - ETA: 1s - loss: 0.1646 - accuracy: 0.9139\n",
      "1278/5349 [======>.......................] - ETA: 1s - loss: 0.1643 - accuracy: 0.9141\n",
      "1487/5349 [=======>......................] - ETA: 1s - loss: 0.1642 - accuracy: 0.9142\n",
      "1712/5349 [========>.....................] - ETA: 1s - loss: 0.1634 - accuracy: 0.9148\n",
      "1905/5349 [=========>....................] - ETA: 1s - loss: 0.1633 - accuracy: 0.9150\n",
      "2132/5349 [==========>...................] - ETA: 1s - loss: 0.1632 - accuracy: 0.9147\n",
      "2461/5349 [============>.................] - ETA: 1s - loss: 0.1629 - accuracy: 0.9147\n",
      "2688/5349 [==============>...............] - ETA: 1s - loss: 0.1626 - accuracy: 0.9147\n",
      "2896/5349 [===============>..............] - ETA: 1s - loss: 0.1623 - accuracy: 0.9147\n",
      "3120/5349 [================>.............] - ETA: 1s - loss: 0.1622 - accuracy: 0.9148\n",
      "3329/5349 [=================>............] - ETA: 0s - loss: 0.1622 - accuracy: 0.9147\n",
      "3557/5349 [==================>...........] - ETA: 0s - loss: 0.1620 - accuracy: 0.9147\n",
      "3771/5349 [====================>.........] - ETA: 0s - loss: 0.1621 - accuracy: 0.9147\n",
      "3996/5349 [=====================>........] - ETA: 0s - loss: 0.1621 - accuracy: 0.9146\n",
      "4214/5349 [======================>.......] - ETA: 0s - loss: 0.1618 - accuracy: 0.9148\n",
      "4447/5349 [=======================>......] - ETA: 0s - loss: 0.1619 - accuracy: 0.9148\n",
      "4667/5349 [=========================>....] - ETA: 0s - loss: 0.1619 - accuracy: 0.9148\n",
      "4892/5349 [==========================>...] - ETA: 0s - loss: 0.1617 - accuracy: 0.9150\n",
      "5205/5349 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9150\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9149\n",
      "5349/5349 [==============================] - 3s 634us/step - loss: 0.1617 - accuracy: 0.9150 - val_loss: 0.1601 - val_accuracy: 0.9158\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1889 - accuracy: 0.9000\n",
      " 112/5349 [..............................] - ETA: 2s - loss: 0.1587 - accuracy: 0.9170\n",
      " 329/5349 [>.............................] - ETA: 2s - loss: 0.1633 - accuracy: 0.9122\n",
      " 550/5349 [==>...........................] - ETA: 2s - loss: 0.1608 - accuracy: 0.9145\n",
      " 774/5349 [===>..........................] - ETA: 2s - loss: 0.1615 - accuracy: 0.9144\n",
      " 999/5349 [====>.........................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9143\n",
      "1170/5349 [=====>........................] - ETA: 1s - loss: 0.1614 - accuracy: 0.9148\n",
      "1340/5349 [======>.......................] - ETA: 1s - loss: 0.1610 - accuracy: 0.9151\n",
      "1528/5349 [=======>......................] - ETA: 1s - loss: 0.1609 - accuracy: 0.9149\n",
      "1717/5349 [========>.....................] - ETA: 1s - loss: 0.1607 - accuracy: 0.9151\n",
      "1899/5349 [=========>....................] - ETA: 1s - loss: 0.1607 - accuracy: 0.9149\n",
      "2066/5349 [==========>...................] - ETA: 1s - loss: 0.1608 - accuracy: 0.9148\n",
      "2262/5349 [===========>..................] - ETA: 1s - loss: 0.1610 - accuracy: 0.9148\n",
      "2450/5349 [============>.................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9147\n",
      "2643/5349 [=============>................] - ETA: 1s - loss: 0.1608 - accuracy: 0.9151\n",
      "2741/5349 [==============>...............] - ETA: 1s - loss: 0.1606 - accuracy: 0.9152\n",
      "2848/5349 [==============>...............] - ETA: 1s - loss: 0.1604 - accuracy: 0.9155\n",
      "3018/5349 [===============>..............] - ETA: 1s - loss: 0.1602 - accuracy: 0.9156\n",
      "3197/5349 [================>.............] - ETA: 1s - loss: 0.1602 - accuracy: 0.9157\n",
      "3390/5349 [==================>...........] - ETA: 1s - loss: 0.1599 - accuracy: 0.9158\n",
      "3606/5349 [===================>..........] - ETA: 0s - loss: 0.1600 - accuracy: 0.9157\n",
      "3821/5349 [====================>.........] - ETA: 0s - loss: 0.1600 - accuracy: 0.9157\n",
      "4036/5349 [=====================>........] - ETA: 0s - loss: 0.1600 - accuracy: 0.9156\n",
      "4238/5349 [======================>.......] - ETA: 0s - loss: 0.1599 - accuracy: 0.9156\n",
      "4457/5349 [=======================>......] - ETA: 0s - loss: 0.1597 - accuracy: 0.9158\n",
      "4676/5349 [=========================>....] - ETA: 0s - loss: 0.1596 - accuracy: 0.9158\n",
      "5008/5349 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9159\n",
      "5229/5349 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9157\n",
      "5337/5349 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9158\n",
      "5349/5349 [==============================] - 4s 683us/step - loss: 0.1596 - accuracy: 0.9158 - val_loss: 0.1582 - val_accuracy: 0.9163\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1554 - accuracy: 0.9100\n",
      " 331/5349 [>.............................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9147\n",
      " 556/5349 [==>...........................] - ETA: 2s - loss: 0.1582 - accuracy: 0.9155\n",
      " 748/5349 [===>..........................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9153\n",
      " 968/5349 [====>.........................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9152\n",
      "1189/5349 [=====>........................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9153\n",
      "1375/5349 [======>.......................] - ETA: 1s - loss: 0.1583 - accuracy: 0.9154\n",
      "1570/5349 [=======>......................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9156\n",
      "1795/5349 [=========>....................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9156\n",
      "2007/5349 [==========>...................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9157\n",
      "2232/5349 [===========>..................] - ETA: 1s - loss: 0.1592 - accuracy: 0.9156\n",
      "2453/5349 [============>.................] - ETA: 1s - loss: 0.1593 - accuracy: 0.9154\n",
      "2677/5349 [==============>...............] - ETA: 1s - loss: 0.1589 - accuracy: 0.9157\n",
      "2893/5349 [===============>..............] - ETA: 1s - loss: 0.1590 - accuracy: 0.9154\n",
      "3113/5349 [================>.............] - ETA: 1s - loss: 0.1590 - accuracy: 0.9155\n",
      "3315/5349 [=================>............] - ETA: 0s - loss: 0.1587 - accuracy: 0.9157\n",
      "3523/5349 [==================>...........] - ETA: 0s - loss: 0.1588 - accuracy: 0.9157\n",
      "3852/5349 [====================>.........] - ETA: 0s - loss: 0.1585 - accuracy: 0.9160\n",
      "4062/5349 [=====================>........] - ETA: 0s - loss: 0.1583 - accuracy: 0.9159\n",
      "4284/5349 [=======================>......] - ETA: 0s - loss: 0.1584 - accuracy: 0.9158\n",
      "4508/5349 [========================>.....] - ETA: 0s - loss: 0.1582 - accuracy: 0.9159\n",
      "4730/5349 [=========================>....] - ETA: 0s - loss: 0.1581 - accuracy: 0.9159\n",
      "4948/5349 [==========================>...] - ETA: 0s - loss: 0.1580 - accuracy: 0.9160\n",
      "5159/5349 [===========================>..] - ETA: 0s - loss: 0.1579 - accuracy: 0.9161\n",
      "5252/5349 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9161\n",
      "5349/5349 [==============================] - 3s 637us/step - loss: 0.1578 - accuracy: 0.9162 - val_loss: 0.1565 - val_accuracy: 0.9167\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 9/20\n",
      " 112/5349 [..............................] - ETA: 2s - loss: 0.1530 - accuracy: 0.9180\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9164\n",
      " 564/5349 [==>...........................] - ETA: 2s - loss: 0.1582 - accuracy: 0.9150\n",
      " 783/5349 [===>..........................] - ETA: 2s - loss: 0.1571 - accuracy: 0.9161\n",
      "1011/5349 [====>.........................] - ETA: 1s - loss: 0.1565 - accuracy: 0.9167\n",
      "1223/5349 [=====>........................] - ETA: 1s - loss: 0.1567 - accuracy: 0.9171\n",
      "1409/5349 [======>.......................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9170\n",
      "1579/5349 [=======>......................] - ETA: 1s - loss: 0.1574 - accuracy: 0.9169\n",
      "1771/5349 [========>.....................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9170\n",
      "1957/5349 [=========>....................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9172\n",
      "2249/5349 [===========>..................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9170\n",
      "2446/5349 [============>.................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9169\n",
      "2645/5349 [=============>................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9169\n",
      "2805/5349 [==============>...............] - ETA: 1s - loss: 0.1572 - accuracy: 0.9167\n",
      "2946/5349 [===============>..............] - ETA: 1s - loss: 0.1573 - accuracy: 0.9166\n",
      "3088/5349 [================>.............] - ETA: 1s - loss: 0.1572 - accuracy: 0.9167\n",
      "3288/5349 [=================>............] - ETA: 1s - loss: 0.1570 - accuracy: 0.9167\n",
      "3478/5349 [==================>...........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9167\n",
      "3700/5349 [===================>..........] - ETA: 0s - loss: 0.1566 - accuracy: 0.9169\n",
      "3923/5349 [=====================>........] - ETA: 0s - loss: 0.1567 - accuracy: 0.9168\n",
      "4143/5349 [======================>.......] - ETA: 0s - loss: 0.1566 - accuracy: 0.9168\n",
      "4362/5349 [=======================>......] - ETA: 0s - loss: 0.1564 - accuracy: 0.9168\n",
      "4591/5349 [========================>.....] - ETA: 0s - loss: 0.1563 - accuracy: 0.9167\n",
      "4808/5349 [=========================>....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9167\n",
      "5033/5349 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.9168\n",
      "5247/5349 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9166\n",
      "5349/5349 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9166\n",
      "5349/5349 [==============================] - 4s 681us/step - loss: 0.1563 - accuracy: 0.9166 - val_loss: 0.1552 - val_accuracy: 0.9171\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1386 - accuracy: 0.9400\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1583 - accuracy: 0.9142\n",
      " 563/5349 [==>...........................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9150\n",
      " 771/5349 [===>..........................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9162\n",
      " 992/5349 [====>.........................] - ETA: 1s - loss: 0.1565 - accuracy: 0.9156\n",
      "1197/5349 [=====>........................] - ETA: 1s - loss: 0.1561 - accuracy: 0.9161\n",
      "1423/5349 [======>.......................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9164\n",
      "1580/5349 [=======>......................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9166\n",
      "1801/5349 [=========>....................] - ETA: 1s - loss: 0.1555 - accuracy: 0.9164\n",
      "2018/5349 [==========>...................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9165\n",
      "2240/5349 [===========>..................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9168\n",
      "2448/5349 [============>.................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9166\n",
      "2673/5349 [=============>................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9166\n",
      "2880/5349 [===============>..............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9165\n",
      "3103/5349 [================>.............] - ETA: 1s - loss: 0.1555 - accuracy: 0.9164\n",
      "3310/5349 [=================>............] - ETA: 0s - loss: 0.1552 - accuracy: 0.9166\n",
      "3530/5349 [==================>...........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9167\n",
      "3870/5349 [====================>.........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9166\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9167\n",
      "4310/5349 [=======================>......] - ETA: 0s - loss: 0.1553 - accuracy: 0.9167\n",
      "4538/5349 [========================>.....] - ETA: 0s - loss: 0.1552 - accuracy: 0.9169\n",
      "4752/5349 [=========================>....] - ETA: 0s - loss: 0.1552 - accuracy: 0.9169\n",
      "4979/5349 [==========================>...] - ETA: 0s - loss: 0.1553 - accuracy: 0.9167\n",
      "5202/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9168\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9168\n",
      "5349/5349 [==============================] - 3s 631us/step - loss: 0.1550 - accuracy: 0.9168 - val_loss: 0.1539 - val_accuracy: 0.9174\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 11/20\n",
      " 115/5349 [..............................] - ETA: 2s - loss: 0.1496 - accuracy: 0.9237\n",
      " 336/5349 [>.............................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9196\n",
      " 567/5349 [==>...........................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9178\n",
      " 682/5349 [==>...........................] - ETA: 2s - loss: 0.1548 - accuracy: 0.9169\n",
      " 883/5349 [===>..........................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9165\n",
      "1114/5349 [=====>........................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9164\n",
      "1325/5349 [======>.......................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9162\n",
      "1529/5349 [=======>......................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9162\n",
      "1743/5349 [========>.....................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9163\n",
      "1972/5349 [==========>...................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9166\n",
      "2185/5349 [===========>..................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9165\n",
      "2411/5349 [============>.................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9168\n",
      "2628/5349 [=============>................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9170\n",
      "2835/5349 [==============>...............] - ETA: 1s - loss: 0.1541 - accuracy: 0.9169\n",
      "3053/5349 [================>.............] - ETA: 1s - loss: 0.1542 - accuracy: 0.9170\n",
      "3261/5349 [=================>............] - ETA: 0s - loss: 0.1539 - accuracy: 0.9171\n",
      "3478/5349 [==================>...........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9171\n",
      "3702/5349 [===================>..........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9173\n",
      "3923/5349 [=====================>........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9173\n",
      "4257/5349 [======================>.......] - ETA: 0s - loss: 0.1538 - accuracy: 0.9173\n",
      "4479/5349 [========================>.....] - ETA: 0s - loss: 0.1538 - accuracy: 0.9173\n",
      "4690/5349 [=========================>....] - ETA: 0s - loss: 0.1539 - accuracy: 0.9174\n",
      "4910/5349 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.9174\n",
      "5112/5349 [===========================>..] - ETA: 0s - loss: 0.1538 - accuracy: 0.9174\n",
      "5333/5349 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9173\n",
      "5349/5349 [==============================] - 3s 635us/step - loss: 0.1539 - accuracy: 0.9173 - val_loss: 0.1528 - val_accuracy: 0.9178\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1614 - accuracy: 0.9000\n",
      " 230/5349 [>.............................] - ETA: 2s - loss: 0.1552 - accuracy: 0.9159\n",
      " 452/5349 [=>............................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9160\n",
      " 655/5349 [==>...........................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9155\n",
      " 875/5349 [===>..........................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9160\n",
      "1085/5349 [=====>........................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9165\n",
      "1253/5349 [======>.......................] - ETA: 1s - loss: 0.1553 - accuracy: 0.9164\n",
      "1427/5349 [=======>......................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9164\n",
      "1609/5349 [========>.....................] - ETA: 1s - loss: 0.1546 - accuracy: 0.9168\n",
      "1789/5349 [=========>....................] - ETA: 1s - loss: 0.1544 - accuracy: 0.9169\n",
      "1970/5349 [==========>...................] - ETA: 1s - loss: 0.1543 - accuracy: 0.9169\n",
      "2212/5349 [===========>..................] - ETA: 1s - loss: 0.1540 - accuracy: 0.9172\n",
      "2375/5349 [============>.................] - ETA: 1s - loss: 0.1540 - accuracy: 0.9171\n",
      "2526/5349 [=============>................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9169\n",
      "2698/5349 [==============>...............] - ETA: 1s - loss: 0.1540 - accuracy: 0.9171\n",
      "2790/5349 [==============>...............] - ETA: 1s - loss: 0.1537 - accuracy: 0.9173\n",
      "2951/5349 [===============>..............] - ETA: 1s - loss: 0.1536 - accuracy: 0.9173\n",
      "3107/5349 [================>.............] - ETA: 1s - loss: 0.1535 - accuracy: 0.9174\n",
      "3293/5349 [=================>............] - ETA: 1s - loss: 0.1535 - accuracy: 0.9174\n",
      "3502/5349 [==================>...........] - ETA: 1s - loss: 0.1535 - accuracy: 0.9173\n",
      "3719/5349 [===================>..........] - ETA: 0s - loss: 0.1534 - accuracy: 0.9174\n",
      "3917/5349 [====================>.........] - ETA: 0s - loss: 0.1533 - accuracy: 0.9174\n",
      "4119/5349 [======================>.......] - ETA: 0s - loss: 0.1532 - accuracy: 0.9174\n",
      "4324/5349 [=======================>......] - ETA: 0s - loss: 0.1533 - accuracy: 0.9173\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1529 - accuracy: 0.9175\n",
      "4855/5349 [==========================>...] - ETA: 0s - loss: 0.1527 - accuracy: 0.9177\n",
      "5083/5349 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.9177\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1529 - accuracy: 0.9176\n",
      "5349/5349 [==============================] - 4s 706us/step - loss: 0.1528 - accuracy: 0.9176 - val_loss: 0.1518 - val_accuracy: 0.9183\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 13/20\n",
      " 110/5349 [..............................] - ETA: 2s - loss: 0.1512 - accuracy: 0.9177\n",
      " 333/5349 [>.............................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9169\n",
      " 565/5349 [==>...........................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9171\n",
      " 766/5349 [===>..........................] - ETA: 2s - loss: 0.1530 - accuracy: 0.9169\n",
      " 992/5349 [====>.........................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9178\n",
      "1200/5349 [=====>........................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9182\n",
      "1487/5349 [=======>......................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9182\n",
      "1703/5349 [========>.....................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9182\n",
      "1931/5349 [=========>....................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9183\n",
      "2147/5349 [===========>..................] - ETA: 1s - loss: 0.1519 - accuracy: 0.9184\n",
      "2373/5349 [============>.................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9183\n",
      "2565/5349 [=============>................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9184\n",
      "2786/5349 [==============>...............] - ETA: 1s - loss: 0.1522 - accuracy: 0.9181\n",
      "3008/5349 [===============>..............] - ETA: 1s - loss: 0.1522 - accuracy: 0.9180\n",
      "3227/5349 [=================>............] - ETA: 0s - loss: 0.1519 - accuracy: 0.9181\n",
      "3437/5349 [==================>...........] - ETA: 0s - loss: 0.1518 - accuracy: 0.9182\n",
      "3667/5349 [===================>..........] - ETA: 0s - loss: 0.1519 - accuracy: 0.9181\n",
      "3884/5349 [====================>.........] - ETA: 0s - loss: 0.1518 - accuracy: 0.9181\n",
      "4098/5349 [=====================>........] - ETA: 0s - loss: 0.1517 - accuracy: 0.9181\n",
      "4306/5349 [=======================>......] - ETA: 0s - loss: 0.1517 - accuracy: 0.9181\n",
      "4651/5349 [=========================>....] - ETA: 0s - loss: 0.1520 - accuracy: 0.9178\n",
      "4862/5349 [==========================>...] - ETA: 0s - loss: 0.1520 - accuracy: 0.9178\n",
      "5089/5349 [===========================>..] - ETA: 0s - loss: 0.1519 - accuracy: 0.9179\n",
      "5313/5349 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9179\n",
      "5349/5349 [==============================] - 3s 634us/step - loss: 0.1519 - accuracy: 0.9179 - val_loss: 0.1510 - val_accuracy: 0.9185\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1553 - accuracy: 0.9100\n",
      " 222/5349 [>.............................] - ETA: 2s - loss: 0.1515 - accuracy: 0.9198\n",
      " 447/5349 [=>............................] - ETA: 2s - loss: 0.1518 - accuracy: 0.9191\n",
      " 642/5349 [==>...........................] - ETA: 2s - loss: 0.1528 - accuracy: 0.9179\n",
      " 866/5349 [===>..........................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9179\n",
      "1077/5349 [=====>........................] - ETA: 1s - loss: 0.1524 - accuracy: 0.9180\n",
      "1260/5349 [======>.......................] - ETA: 1s - loss: 0.1519 - accuracy: 0.9182\n",
      "1415/5349 [======>.......................] - ETA: 1s - loss: 0.1515 - accuracy: 0.9184\n",
      "1581/5349 [=======>......................] - ETA: 1s - loss: 0.1516 - accuracy: 0.9183\n",
      "1764/5349 [========>.....................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9184\n",
      "1949/5349 [=========>....................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9184\n",
      "2100/5349 [==========>...................] - ETA: 1s - loss: 0.1509 - accuracy: 0.9186\n",
      "2283/5349 [===========>..................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9188\n",
      "2467/5349 [============>.................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9188\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.1507 - accuracy: 0.9188\n",
      "2943/5349 [===============>..............] - ETA: 1s - loss: 0.1509 - accuracy: 0.9186\n",
      "3054/5349 [================>.............] - ETA: 1s - loss: 0.1509 - accuracy: 0.9186\n",
      "3174/5349 [================>.............] - ETA: 1s - loss: 0.1509 - accuracy: 0.9186\n",
      "3350/5349 [=================>............] - ETA: 1s - loss: 0.1510 - accuracy: 0.9185\n",
      "3526/5349 [==================>...........] - ETA: 1s - loss: 0.1511 - accuracy: 0.9183\n",
      "3741/5349 [===================>..........] - ETA: 0s - loss: 0.1510 - accuracy: 0.9184\n",
      "3957/5349 [=====================>........] - ETA: 0s - loss: 0.1513 - accuracy: 0.9182\n",
      "4065/5349 [=====================>........] - ETA: 0s - loss: 0.1513 - accuracy: 0.9182\n",
      "4277/5349 [======================>.......] - ETA: 0s - loss: 0.1513 - accuracy: 0.9182\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.1515 - accuracy: 0.9181\n",
      "4708/5349 [=========================>....] - ETA: 0s - loss: 0.1516 - accuracy: 0.9181\n",
      "4929/5349 [==========================>...] - ETA: 0s - loss: 0.1514 - accuracy: 0.9181\n",
      "5147/5349 [===========================>..] - ETA: 0s - loss: 0.1512 - accuracy: 0.9183\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9183\n",
      "5349/5349 [==============================] - 4s 703us/step - loss: 0.1512 - accuracy: 0.9183 - val_loss: 0.1502 - val_accuracy: 0.9187\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1280 - accuracy: 0.9400\n",
      " 218/5349 [>.............................] - ETA: 2s - loss: 0.1476 - accuracy: 0.9185\n",
      " 430/5349 [=>............................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9183\n",
      " 635/5349 [==>...........................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9185\n",
      " 856/5349 [===>..........................] - ETA: 2s - loss: 0.1515 - accuracy: 0.9175\n",
      "1065/5349 [====>.........................] - ETA: 2s - loss: 0.1509 - accuracy: 0.9180\n",
      "1292/5349 [======>.......................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9181\n",
      "1509/5349 [=======>......................] - ETA: 1s - loss: 0.1506 - accuracy: 0.9182\n",
      "1737/5349 [========>.....................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9186\n",
      "1911/5349 [=========>....................] - ETA: 1s - loss: 0.1503 - accuracy: 0.9184\n",
      "2092/5349 [==========>...................] - ETA: 1s - loss: 0.1501 - accuracy: 0.9188\n",
      "2405/5349 [============>.................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9185\n",
      "2626/5349 [=============>................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9184\n",
      "2810/5349 [==============>...............] - ETA: 1s - loss: 0.1505 - accuracy: 0.9183\n",
      "3022/5349 [===============>..............] - ETA: 1s - loss: 0.1507 - accuracy: 0.9182\n",
      "3222/5349 [=================>............] - ETA: 1s - loss: 0.1506 - accuracy: 0.9184\n",
      "3444/5349 [==================>...........] - ETA: 0s - loss: 0.1505 - accuracy: 0.9184\n",
      "3668/5349 [===================>..........] - ETA: 0s - loss: 0.1506 - accuracy: 0.9184\n",
      "3898/5349 [====================>.........] - ETA: 0s - loss: 0.1507 - accuracy: 0.9183\n",
      "4107/5349 [======================>.......] - ETA: 0s - loss: 0.1508 - accuracy: 0.9183\n",
      "4323/5349 [=======================>......] - ETA: 0s - loss: 0.1508 - accuracy: 0.9182\n",
      "4535/5349 [========================>.....] - ETA: 0s - loss: 0.1507 - accuracy: 0.9184\n",
      "4762/5349 [=========================>....] - ETA: 0s - loss: 0.1507 - accuracy: 0.9184\n",
      "4978/5349 [==========================>...] - ETA: 0s - loss: 0.1506 - accuracy: 0.9185\n",
      "5205/5349 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9185\n",
      "5312/5349 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9186\n",
      "5349/5349 [==============================] - 3s 643us/step - loss: 0.1505 - accuracy: 0.9186 - val_loss: 0.1496 - val_accuracy: 0.9197\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 16/20\n",
      " 109/5349 [..............................] - ETA: 2s - loss: 0.1506 - accuracy: 0.9166\n",
      " 335/5349 [>.............................] - ETA: 2s - loss: 0.1499 - accuracy: 0.9187\n",
      " 561/5349 [==>...........................] - ETA: 2s - loss: 0.1480 - accuracy: 0.9205\n",
      " 779/5349 [===>..........................] - ETA: 2s - loss: 0.1489 - accuracy: 0.9199\n",
      "1009/5349 [====>.........................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9196\n",
      "1228/5349 [=====>........................] - ETA: 1s - loss: 0.1492 - accuracy: 0.9193\n",
      "1342/5349 [======>.......................] - ETA: 1s - loss: 0.1495 - accuracy: 0.9191\n",
      "1572/5349 [=======>......................] - ETA: 1s - loss: 0.1491 - accuracy: 0.9194\n",
      "1781/5349 [========>.....................] - ETA: 1s - loss: 0.1501 - accuracy: 0.9190\n",
      "2013/5349 [==========>...................] - ETA: 1s - loss: 0.1503 - accuracy: 0.9188\n",
      "2230/5349 [===========>..................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9187\n",
      "2449/5349 [============>.................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9188\n",
      "2670/5349 [=============>................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9187\n",
      "2901/5349 [===============>..............] - ETA: 1s - loss: 0.1501 - accuracy: 0.9187\n",
      "3127/5349 [================>.............] - ETA: 1s - loss: 0.1501 - accuracy: 0.9187\n",
      "3360/5349 [=================>............] - ETA: 0s - loss: 0.1502 - accuracy: 0.9186\n",
      "3556/5349 [==================>...........] - ETA: 0s - loss: 0.1501 - accuracy: 0.9188\n",
      "3783/5349 [====================>.........] - ETA: 0s - loss: 0.1503 - accuracy: 0.9187\n",
      "4002/5349 [=====================>........] - ETA: 0s - loss: 0.1502 - accuracy: 0.9188\n",
      "4115/5349 [======================>.......] - ETA: 0s - loss: 0.1502 - accuracy: 0.9188\n",
      "4339/5349 [=======================>......] - ETA: 0s - loss: 0.1502 - accuracy: 0.9188\n",
      "4558/5349 [========================>.....] - ETA: 0s - loss: 0.1500 - accuracy: 0.9188\n",
      "4786/5349 [=========================>....] - ETA: 0s - loss: 0.1498 - accuracy: 0.9190\n",
      "5011/5349 [===========================>..] - ETA: 0s - loss: 0.1498 - accuracy: 0.9190\n",
      "5240/5349 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9189\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9189\n",
      "5349/5349 [==============================] - 3s 632us/step - loss: 0.1498 - accuracy: 0.9189 - val_loss: 0.1490 - val_accuracy: 0.9196\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0990 - accuracy: 0.9400\n",
      " 216/5349 [>.............................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9176\n",
      " 440/5349 [=>............................] - ETA: 2s - loss: 0.1500 - accuracy: 0.9177\n",
      " 649/5349 [==>...........................] - ETA: 2s - loss: 0.1500 - accuracy: 0.9175\n",
      " 841/5349 [===>..........................] - ETA: 2s - loss: 0.1496 - accuracy: 0.9182\n",
      "1042/5349 [====>.........................] - ETA: 2s - loss: 0.1497 - accuracy: 0.9179\n",
      "1238/5349 [=====>........................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9182\n",
      "1440/5349 [=======>......................] - ETA: 1s - loss: 0.1497 - accuracy: 0.9182\n",
      "1657/5349 [========>.....................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9184\n",
      "1857/5349 [=========>....................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9183\n",
      "1946/5349 [=========>....................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9184\n",
      "2119/5349 [==========>...................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9185\n",
      "2301/5349 [===========>..................] - ETA: 1s - loss: 0.1501 - accuracy: 0.9184\n",
      "2458/5349 [============>.................] - ETA: 1s - loss: 0.1498 - accuracy: 0.9186\n",
      "2645/5349 [=============>................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9187\n",
      "2831/5349 [==============>...............] - ETA: 1s - loss: 0.1496 - accuracy: 0.9190\n",
      "3008/5349 [===============>..............] - ETA: 1s - loss: 0.1496 - accuracy: 0.9190\n",
      "3192/5349 [================>.............] - ETA: 1s - loss: 0.1496 - accuracy: 0.9191\n",
      "3377/5349 [=================>............] - ETA: 1s - loss: 0.1497 - accuracy: 0.9189\n",
      "3549/5349 [==================>...........] - ETA: 0s - loss: 0.1497 - accuracy: 0.9190\n",
      "3691/5349 [===================>..........] - ETA: 0s - loss: 0.1497 - accuracy: 0.9191\n",
      "3918/5349 [====================>.........] - ETA: 0s - loss: 0.1495 - accuracy: 0.9193\n",
      "4085/5349 [=====================>........] - ETA: 0s - loss: 0.1493 - accuracy: 0.9194\n",
      "4264/5349 [======================>.......] - ETA: 0s - loss: 0.1492 - accuracy: 0.9195\n",
      "4461/5349 [========================>.....] - ETA: 0s - loss: 0.1493 - accuracy: 0.9194\n",
      "4669/5349 [=========================>....] - ETA: 0s - loss: 0.1491 - accuracy: 0.9195\n",
      "4887/5349 [==========================>...] - ETA: 0s - loss: 0.1492 - accuracy: 0.9195\n",
      "5103/5349 [===========================>..] - ETA: 0s - loss: 0.1492 - accuracy: 0.9194\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9194\n",
      "5349/5349 [==============================] - 4s 710us/step - loss: 0.1493 - accuracy: 0.9193 - val_loss: 0.1484 - val_accuracy: 0.9199\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 18/20\n",
      " 110/5349 [..............................] - ETA: 2s - loss: 0.1499 - accuracy: 0.9195\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1493 - accuracy: 0.9194\n",
      " 562/5349 [==>...........................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9195\n",
      " 771/5349 [===>..........................] - ETA: 2s - loss: 0.1492 - accuracy: 0.9193\n",
      " 985/5349 [====>.........................] - ETA: 2s - loss: 0.1491 - accuracy: 0.9194\n",
      "1317/5349 [======>.......................] - ETA: 1s - loss: 0.1488 - accuracy: 0.9196\n",
      "1537/5349 [=======>......................] - ETA: 1s - loss: 0.1490 - accuracy: 0.9196\n",
      "1756/5349 [========>.....................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9199\n",
      "1983/5349 [==========>...................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9197\n",
      "2189/5349 [===========>..................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9196\n",
      "2415/5349 [============>.................] - ETA: 1s - loss: 0.1484 - accuracy: 0.9199\n",
      "2636/5349 [=============>................] - ETA: 1s - loss: 0.1483 - accuracy: 0.9201\n",
      "2799/5349 [==============>...............] - ETA: 1s - loss: 0.1483 - accuracy: 0.9200\n",
      "2977/5349 [===============>..............] - ETA: 1s - loss: 0.1484 - accuracy: 0.9199\n",
      "3186/5349 [================>.............] - ETA: 1s - loss: 0.1485 - accuracy: 0.9199\n",
      "3397/5349 [==================>...........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9199\n",
      "3617/5349 [===================>..........] - ETA: 0s - loss: 0.1487 - accuracy: 0.9197\n",
      "3833/5349 [====================>.........] - ETA: 0s - loss: 0.1486 - accuracy: 0.9198\n",
      "4053/5349 [=====================>........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9199\n",
      "4359/5349 [=======================>......] - ETA: 0s - loss: 0.1485 - accuracy: 0.9198\n",
      "4579/5349 [========================>.....] - ETA: 0s - loss: 0.1486 - accuracy: 0.9198\n",
      "4789/5349 [=========================>....] - ETA: 0s - loss: 0.1487 - accuracy: 0.9197\n",
      "5005/5349 [===========================>..] - ETA: 0s - loss: 0.1488 - accuracy: 0.9195\n",
      "5204/5349 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9196\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9196\n",
      "5349/5349 [==============================] - 4s 662us/step - loss: 0.1488 - accuracy: 0.9196 - val_loss: 0.1479 - val_accuracy: 0.9202\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 19/20\n",
      " 108/5349 [..............................] - ETA: 2s - loss: 0.1515 - accuracy: 0.9190\n",
      " 324/5349 [>.............................] - ETA: 2s - loss: 0.1488 - accuracy: 0.9191\n",
      " 549/5349 [==>...........................] - ETA: 2s - loss: 0.1485 - accuracy: 0.9199\n",
      " 735/5349 [===>..........................] - ETA: 2s - loss: 0.1477 - accuracy: 0.9202\n",
      " 923/5349 [====>.........................] - ETA: 2s - loss: 0.1483 - accuracy: 0.9198\n",
      "1035/5349 [====>.........................] - ETA: 2s - loss: 0.1483 - accuracy: 0.9199\n",
      "1253/5349 [======>.......................] - ETA: 1s - loss: 0.1479 - accuracy: 0.9201\n",
      "1470/5349 [=======>......................] - ETA: 1s - loss: 0.1480 - accuracy: 0.9200\n",
      "1692/5349 [========>.....................] - ETA: 1s - loss: 0.1481 - accuracy: 0.9199\n",
      "1912/5349 [=========>....................] - ETA: 1s - loss: 0.1483 - accuracy: 0.9196\n",
      "2126/5349 [==========>...................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9194\n",
      "2352/5349 [============>.................] - ETA: 1s - loss: 0.1482 - accuracy: 0.9197\n",
      "2567/5349 [=============>................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9195\n",
      "2783/5349 [==============>...............] - ETA: 1s - loss: 0.1485 - accuracy: 0.9194\n",
      "2995/5349 [===============>..............] - ETA: 1s - loss: 0.1486 - accuracy: 0.9193\n",
      "3217/5349 [=================>............] - ETA: 0s - loss: 0.1486 - accuracy: 0.9193\n",
      "3391/5349 [==================>...........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9194\n",
      "3618/5349 [===================>..........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9194\n",
      "3817/5349 [====================>.........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9196\n",
      "4044/5349 [=====================>........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9196\n",
      "4257/5349 [======================>.......] - ETA: 0s - loss: 0.1484 - accuracy: 0.9197\n",
      "4487/5349 [========================>.....] - ETA: 0s - loss: 0.1483 - accuracy: 0.9198\n",
      "4821/5349 [==========================>...] - ETA: 0s - loss: 0.1482 - accuracy: 0.9198\n",
      "5048/5349 [===========================>..] - ETA: 0s - loss: 0.1482 - accuracy: 0.9199\n",
      "5263/5349 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.9198\n",
      "5349/5349 [==============================] - 3s 636us/step - loss: 0.1483 - accuracy: 0.9198 - val_loss: 0.1474 - val_accuracy: 0.9206\n",
      "\u001B[36m(train_DNN pid=5381)\u001B[0m Epoch 20/20\n",
      " 106/5349 [..............................] - ETA: 2s - loss: 0.1507 - accuracy: 0.9181\n",
      " 333/5349 [>.............................] - ETA: 2s - loss: 0.1490 - accuracy: 0.9196\n",
      " 564/5349 [==>...........................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9191\n",
      " 900/5349 [====>.........................] - ETA: 1s - loss: 0.1484 - accuracy: 0.9204\n",
      "1130/5349 [=====>........................] - ETA: 1s - loss: 0.1475 - accuracy: 0.9207\n",
      "1348/5349 [======>.......................] - ETA: 1s - loss: 0.1473 - accuracy: 0.9206\n",
      "1580/5349 [=======>......................] - ETA: 1s - loss: 0.1472 - accuracy: 0.9209\n",
      "1788/5349 [=========>....................] - ETA: 1s - loss: 0.1474 - accuracy: 0.9209\n",
      "2015/5349 [==========>...................] - ETA: 1s - loss: 0.1475 - accuracy: 0.9209\n",
      "2237/5349 [===========>..................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9205\n",
      "2458/5349 [============>.................] - ETA: 1s - loss: 0.1477 - accuracy: 0.9204\n",
      "2679/5349 [==============>...............] - ETA: 1s - loss: 0.1474 - accuracy: 0.9207\n",
      "2909/5349 [===============>..............] - ETA: 1s - loss: 0.1475 - accuracy: 0.9206\n",
      "3110/5349 [================>.............] - ETA: 1s - loss: 0.1472 - accuracy: 0.9208\n",
      "3284/5349 [=================>............] - ETA: 0s - loss: 0.1475 - accuracy: 0.9207\n",
      "3457/5349 [==================>...........] - ETA: 0s - loss: 0.1475 - accuracy: 0.9207\n",
      "3646/5349 [===================>..........] - ETA: 0s - loss: 0.1475 - accuracy: 0.9206\n",
      "3742/5349 [===================>..........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9207\n",
      "3927/5349 [=====================>........] - ETA: 0s - loss: 0.1475 - accuracy: 0.9206\n",
      "4123/5349 [======================>.......] - ETA: 0s - loss: 0.1477 - accuracy: 0.9204\n",
      "4293/5349 [=======================>......] - ETA: 0s - loss: 0.1479 - accuracy: 0.9203\n",
      "4495/5349 [========================>.....] - ETA: 0s - loss: 0.1479 - accuracy: 0.9203\n",
      "4669/5349 [=========================>....] - ETA: 0s - loss: 0.1480 - accuracy: 0.9202\n",
      "4807/5349 [=========================>....] - ETA: 0s - loss: 0.1480 - accuracy: 0.9202\n",
      "4955/5349 [==========================>...] - ETA: 0s - loss: 0.1479 - accuracy: 0.9202\n",
      "5140/5349 [===========================>..] - ETA: 0s - loss: 0.1478 - accuracy: 0.9202\n",
      "5327/5349 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9202\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 1/20\n",
      " 101/5349 [..............................] - ETA: 2s - loss: 0.9474 - accuracy: 0.1632   \n",
      " 344/5349 [>.............................] - ETA: 2s - loss: 0.7883 - accuracy: 0.3588\n",
      " 572/5349 [==>...........................] - ETA: 2s - loss: 0.7000 - accuracy: 0.5505\n",
      " 759/5349 [===>..........................] - ETA: 2s - loss: 0.6518 - accuracy: 0.6223\n",
      "1072/5349 [=====>........................] - ETA: 2s - loss: 0.5991 - accuracy: 0.6863\n",
      "1224/5349 [=====>........................] - ETA: 2s - loss: 0.5811 - accuracy: 0.7056\n",
      "1420/5349 [======>.......................] - ETA: 1s - loss: 0.5635 - accuracy: 0.7239\n",
      "1611/5349 [========>.....................] - ETA: 1s - loss: 0.5496 - accuracy: 0.7377\n",
      "1802/5349 [=========>....................] - ETA: 1s - loss: 0.5380 - accuracy: 0.7488\n",
      "2003/5349 [==========>...................] - ETA: 1s - loss: 0.5280 - accuracy: 0.7583\n",
      "2213/5349 [===========>..................] - ETA: 1s - loss: 0.5196 - accuracy: 0.7661\n",
      "2376/5349 [============>.................] - ETA: 1s - loss: 0.5147 - accuracy: 0.7708\n",
      "2515/5349 [=============>................] - ETA: 1s - loss: 0.5106 - accuracy: 0.7747\n",
      "2797/5349 [==============>...............] - ETA: 1s - loss: 0.5028 - accuracy: 0.7817\n",
      "3004/5349 [===============>..............] - ETA: 1s - loss: 0.4984 - accuracy: 0.7858\n",
      "3235/5349 [=================>............] - ETA: 1s - loss: 0.4940 - accuracy: 0.7898\n",
      "3473/5349 [==================>...........] - ETA: 0s - loss: 0.4903 - accuracy: 0.7932\n",
      "3703/5349 [===================>..........] - ETA: 0s - loss: 0.4872 - accuracy: 0.7961\n",
      "3940/5349 [=====================>........] - ETA: 0s - loss: 0.4845 - accuracy: 0.7986\n",
      "4170/5349 [======================>.......] - ETA: 0s - loss: 0.4821 - accuracy: 0.8009\n",
      "4409/5349 [=======================>......] - ETA: 0s - loss: 0.4797 - accuracy: 0.8030\n",
      "4624/5349 [========================>.....] - ETA: 0s - loss: 0.4780 - accuracy: 0.8047\n",
      "4856/5349 [==========================>...] - ETA: 0s - loss: 0.4757 - accuracy: 0.8066\n",
      "5081/5349 [===========================>..] - ETA: 0s - loss: 0.4741 - accuracy: 0.8081\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.4724 - accuracy: 0.8097\n",
      "5349/5349 [==============================] - 4s 684us/step - loss: 0.4722 - accuracy: 0.8098 - val_loss: 0.4387 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 2/20\n",
      " 115/5349 [..............................] - ETA: 2s - loss: 0.4429 - accuracy: 0.8380\n",
      " 353/5349 [>.............................] - ETA: 2s - loss: 0.4426 - accuracy: 0.8382\n",
      " 588/5349 [==>...........................] - ETA: 2s - loss: 0.4429 - accuracy: 0.8380\n",
      " 813/5349 [===>..........................] - ETA: 1s - loss: 0.4424 - accuracy: 0.8383\n",
      "1040/5349 [====>.........................] - ETA: 1s - loss: 0.4416 - accuracy: 0.8388\n",
      "1221/5349 [=====>........................] - ETA: 1s - loss: 0.4396 - accuracy: 0.8400\n",
      "1570/5349 [=======>......................] - ETA: 1s - loss: 0.4398 - accuracy: 0.8398\n",
      "1791/5349 [=========>....................] - ETA: 1s - loss: 0.4405 - accuracy: 0.8395\n",
      "2022/5349 [==========>...................] - ETA: 1s - loss: 0.4402 - accuracy: 0.8396\n",
      "2226/5349 [===========>..................] - ETA: 1s - loss: 0.4396 - accuracy: 0.8400\n",
      "2470/5349 [============>.................] - ETA: 1s - loss: 0.4397 - accuracy: 0.8399\n",
      "2691/5349 [==============>...............] - ETA: 1s - loss: 0.4399 - accuracy: 0.8398\n",
      "2929/5349 [===============>..............] - ETA: 1s - loss: 0.4391 - accuracy: 0.8403\n",
      "3164/5349 [================>.............] - ETA: 0s - loss: 0.4388 - accuracy: 0.8405\n",
      "3403/5349 [==================>...........] - ETA: 0s - loss: 0.4388 - accuracy: 0.8404\n",
      "3631/5349 [===================>..........] - ETA: 0s - loss: 0.4391 - accuracy: 0.8403\n",
      "3868/5349 [====================>.........] - ETA: 0s - loss: 0.4390 - accuracy: 0.8403\n",
      "4104/5349 [======================>.......] - ETA: 0s - loss: 0.4386 - accuracy: 0.8406\n",
      "4343/5349 [=======================>......] - ETA: 0s - loss: 0.4389 - accuracy: 0.8404\n",
      "4577/5349 [========================>.....] - ETA: 0s - loss: 0.4389 - accuracy: 0.8404\n",
      "4945/5349 [==========================>...] - ETA: 0s - loss: 0.4387 - accuracy: 0.8405\n",
      "5173/5349 [============================>.] - ETA: 0s - loss: 0.4387 - accuracy: 0.8405\n",
      "5294/5349 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 602us/step - loss: 0.4385 - accuracy: 0.8406 - val_loss: 0.4386 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 3/20\n",
      " 122/5349 [..............................] - ETA: 2s - loss: 0.4423 - accuracy: 0.8383\n",
      " 363/5349 [=>............................] - ETA: 2s - loss: 0.4394 - accuracy: 0.8401\n",
      " 606/5349 [==>...........................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8419\n",
      " 836/5349 [===>..........................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8415\n",
      "1078/5349 [=====>........................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8417\n",
      "1303/5349 [======>.......................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8417\n",
      "1534/5349 [=======>......................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8419\n",
      "1762/5349 [========>.....................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8417\n",
      "2009/5349 [==========>...................] - ETA: 1s - loss: 0.4378 - accuracy: 0.8410\n",
      "2235/5349 [===========>..................] - ETA: 1s - loss: 0.4386 - accuracy: 0.8405\n",
      "2569/5349 [=============>................] - ETA: 1s - loss: 0.4386 - accuracy: 0.8405\n",
      "2798/5349 [==============>...............] - ETA: 1s - loss: 0.4385 - accuracy: 0.8406\n",
      "3042/5349 [================>.............] - ETA: 0s - loss: 0.4391 - accuracy: 0.8402\n",
      "3278/5349 [=================>............] - ETA: 0s - loss: 0.4389 - accuracy: 0.8403\n",
      "3513/5349 [==================>...........] - ETA: 0s - loss: 0.4391 - accuracy: 0.8402\n",
      "3729/5349 [===================>..........] - ETA: 0s - loss: 0.4390 - accuracy: 0.8402\n",
      "3972/5349 [=====================>........] - ETA: 0s - loss: 0.4390 - accuracy: 0.8403\n",
      "4202/5349 [======================>.......] - ETA: 0s - loss: 0.4387 - accuracy: 0.8404\n",
      "4444/5349 [=======================>......] - ETA: 0s - loss: 0.4384 - accuracy: 0.8406\n",
      "4669/5349 [=========================>....] - ETA: 0s - loss: 0.4384 - accuracy: 0.8406\n",
      "4908/5349 [==========================>...] - ETA: 0s - loss: 0.4380 - accuracy: 0.8409\n",
      "5144/5349 [===========================>..] - ETA: 0s - loss: 0.4382 - accuracy: 0.8407\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 3s 599us/step - loss: 0.4384 - accuracy: 0.8406 - val_loss: 0.4385 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 4/20\n",
      " 117/5349 [..............................] - ETA: 2s - loss: 0.4395 - accuracy: 0.8399\n",
      " 357/5349 [=>............................] - ETA: 2s - loss: 0.4398 - accuracy: 0.8397\n",
      " 599/5349 [==>...........................] - ETA: 1s - loss: 0.4381 - accuracy: 0.8407\n",
      " 834/5349 [===>..........................] - ETA: 1s - loss: 0.4380 - accuracy: 0.8408\n",
      "1077/5349 [=====>........................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8416\n",
      "1198/5349 [=====>........................] - ETA: 1s - loss: 0.4357 - accuracy: 0.8422\n",
      "1428/5349 [=======>......................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8423\n",
      "1630/5349 [========>.....................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8418\n",
      "1796/5349 [=========>....................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8417\n",
      "1999/5349 [==========>...................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8415\n",
      "2184/5349 [===========>..................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8413\n",
      "2372/5349 [============>.................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8412\n",
      "2552/5349 [=============>................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8410\n",
      "2752/5349 [==============>...............] - ETA: 1s - loss: 0.4381 - accuracy: 0.8407\n",
      "2946/5349 [===============>..............] - ETA: 1s - loss: 0.4381 - accuracy: 0.8407\n",
      "3151/5349 [================>.............] - ETA: 1s - loss: 0.4382 - accuracy: 0.8407\n",
      "3347/5349 [=================>............] - ETA: 0s - loss: 0.4380 - accuracy: 0.8408\n",
      "3566/5349 [===================>..........] - ETA: 0s - loss: 0.4381 - accuracy: 0.8407\n",
      "3724/5349 [===================>..........] - ETA: 0s - loss: 0.4383 - accuracy: 0.8406\n",
      "3925/5349 [=====================>........] - ETA: 0s - loss: 0.4384 - accuracy: 0.8405\n",
      "4133/5349 [======================>.......] - ETA: 0s - loss: 0.4382 - accuracy: 0.8407\n",
      "4372/5349 [=======================>......] - ETA: 0s - loss: 0.4381 - accuracy: 0.8407\n",
      "4604/5349 [========================>.....] - ETA: 0s - loss: 0.4385 - accuracy: 0.8404\n",
      "4842/5349 [==========================>...] - ETA: 0s - loss: 0.4386 - accuracy: 0.8404\n",
      "5078/5349 [===========================>..] - ETA: 0s - loss: 0.4383 - accuracy: 0.8406\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.4383 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 652us/step - loss: 0.4382 - accuracy: 0.8406 - val_loss: 0.4383 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4890 - accuracy: 0.8100\n",
      " 238/5349 [>.............................] - ETA: 2s - loss: 0.4394 - accuracy: 0.8399\n",
      " 477/5349 [=>............................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8428\n",
      " 699/5349 [==>...........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8423\n",
      " 931/5349 [====>.........................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8419\n",
      "1268/5349 [======>.......................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8416\n",
      "1487/5349 [=======>......................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8413\n",
      "1715/5349 [========>.....................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8412\n",
      "1955/5349 [=========>....................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8420\n",
      "2172/5349 [===========>..................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8419\n",
      "2408/5349 [============>.................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8417\n",
      "2588/5349 [=============>................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8415\n",
      "2820/5349 [==============>...............] - ETA: 1s - loss: 0.4367 - accuracy: 0.8415\n",
      "3040/5349 [================>.............] - ETA: 1s - loss: 0.4373 - accuracy: 0.8411\n",
      "3272/5349 [=================>............] - ETA: 0s - loss: 0.4375 - accuracy: 0.8410\n",
      "3503/5349 [==================>...........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8410\n",
      "3724/5349 [===================>..........] - ETA: 0s - loss: 0.4377 - accuracy: 0.8409\n",
      "3942/5349 [=====================>........] - ETA: 0s - loss: 0.4378 - accuracy: 0.8408\n",
      "4167/5349 [======================>.......] - ETA: 0s - loss: 0.4376 - accuracy: 0.8409\n",
      "4373/5349 [=======================>......] - ETA: 0s - loss: 0.4377 - accuracy: 0.8408\n",
      "4607/5349 [========================>.....] - ETA: 0s - loss: 0.4379 - accuracy: 0.8408\n",
      "4730/5349 [=========================>....] - ETA: 0s - loss: 0.4379 - accuracy: 0.8408\n",
      "4965/5349 [==========================>...] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "5207/5349 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.8407\n",
      "5312/5349 [============================>.] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 615us/step - loss: 0.4381 - accuracy: 0.8406 - val_loss: 0.4382 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 6/20\n",
      " 118/5349 [..............................] - ETA: 2s - loss: 0.4343 - accuracy: 0.8429\n",
      " 348/5349 [>.............................] - ETA: 2s - loss: 0.4319 - accuracy: 0.8443\n",
      " 592/5349 [==>...........................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8428\n",
      " 822/5349 [===>..........................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8413\n",
      "1066/5349 [====>.........................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8403\n",
      "1301/5349 [======>.......................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8403\n",
      "1536/5349 [=======>......................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8410\n",
      "1766/5349 [========>.....................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8404\n",
      "2133/5349 [==========>...................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8404\n",
      "2350/5349 [============>.................] - ETA: 1s - loss: 0.4386 - accuracy: 0.8402\n",
      "2585/5349 [=============>................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8405\n",
      "2803/5349 [==============>...............] - ETA: 1s - loss: 0.4380 - accuracy: 0.8406\n",
      "3026/5349 [===============>..............] - ETA: 1s - loss: 0.4379 - accuracy: 0.8407\n",
      "3260/5349 [=================>............] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "3503/5349 [==================>...........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8409\n",
      "3734/5349 [===================>..........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8409\n",
      "3980/5349 [=====================>........] - ETA: 0s - loss: 0.4377 - accuracy: 0.8408\n",
      "4215/5349 [======================>.......] - ETA: 0s - loss: 0.4377 - accuracy: 0.8408\n",
      "4461/5349 [========================>.....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8409\n",
      "4694/5349 [=========================>....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8409\n",
      "4935/5349 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8407\n",
      "5172/5349 [============================>.] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "5296/5349 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 597us/step - loss: 0.4379 - accuracy: 0.8406 - val_loss: 0.4380 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 7/20\n",
      " 109/5349 [..............................] - ETA: 2s - loss: 0.4289 - accuracy: 0.8461\n",
      " 338/5349 [>.............................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8427\n",
      " 569/5349 [==>...........................] - ETA: 2s - loss: 0.4325 - accuracy: 0.8438\n",
      " 773/5349 [===>..........................] - ETA: 2s - loss: 0.4346 - accuracy: 0.8426\n",
      " 874/5349 [===>..........................] - ETA: 2s - loss: 0.4360 - accuracy: 0.8417\n",
      "1113/5349 [=====>........................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8414\n",
      "1349/5349 [======>.......................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8410\n",
      "1588/5349 [=======>......................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8413\n",
      "1824/5349 [=========>....................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8417\n",
      "2064/5349 [==========>...................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8416\n",
      "2292/5349 [===========>..................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8414\n",
      "2529/5349 [=============>................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8412\n",
      "2765/5349 [==============>...............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8412\n",
      "3004/5349 [===============>..............] - ETA: 1s - loss: 0.4371 - accuracy: 0.8410\n",
      "3234/5349 [=================>............] - ETA: 0s - loss: 0.4371 - accuracy: 0.8411\n",
      "3425/5349 [==================>...........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8411\n",
      "3591/5349 [===================>..........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8410\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.4369 - accuracy: 0.8412\n",
      "4081/5349 [=====================>........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8410\n",
      "4268/5349 [======================>.......] - ETA: 0s - loss: 0.4375 - accuracy: 0.8408\n",
      "4471/5349 [========================>.....] - ETA: 0s - loss: 0.4373 - accuracy: 0.8409\n",
      "4676/5349 [=========================>....] - ETA: 0s - loss: 0.4372 - accuracy: 0.8410\n",
      "4871/5349 [==========================>...] - ETA: 0s - loss: 0.4374 - accuracy: 0.8409\n",
      "5070/5349 [===========================>..] - ETA: 0s - loss: 0.4376 - accuracy: 0.8408\n",
      "5217/5349 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8407\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 658us/step - loss: 0.4378 - accuracy: 0.8406 - val_loss: 0.4379 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 8/20\n",
      " 104/5349 [..............................] - ETA: 2s - loss: 0.4356 - accuracy: 0.8419\n",
      " 341/5349 [>.............................] - ETA: 2s - loss: 0.4294 - accuracy: 0.8456\n",
      " 580/5349 [==>...........................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8426\n",
      " 809/5349 [===>..........................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8412\n",
      "1167/5349 [=====>........................] - ETA: 1s - loss: 0.4377 - accuracy: 0.8406\n",
      "1372/5349 [======>.......................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8411\n",
      "1597/5349 [=======>......................] - ETA: 1s - loss: 0.4373 - accuracy: 0.8409\n",
      "1807/5349 [=========>....................] - ETA: 1s - loss: 0.4377 - accuracy: 0.8406\n",
      "2047/5349 [==========>...................] - ETA: 1s - loss: 0.4379 - accuracy: 0.8405\n",
      "2269/5349 [===========>..................] - ETA: 1s - loss: 0.4377 - accuracy: 0.8406\n",
      "2499/5349 [=============>................] - ETA: 1s - loss: 0.4377 - accuracy: 0.8406\n",
      "2735/5349 [==============>...............] - ETA: 1s - loss: 0.4380 - accuracy: 0.8404\n",
      "2944/5349 [===============>..............] - ETA: 1s - loss: 0.4381 - accuracy: 0.8404\n",
      "3178/5349 [================>.............] - ETA: 0s - loss: 0.4381 - accuracy: 0.8404\n",
      "3514/5349 [==================>...........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8407\n",
      "3742/5349 [===================>..........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8408\n",
      "3976/5349 [=====================>........] - ETA: 0s - loss: 0.4374 - accuracy: 0.8408\n",
      "4208/5349 [======================>.......] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "4431/5349 [=======================>......] - ETA: 0s - loss: 0.4379 - accuracy: 0.8405\n",
      "4576/5349 [========================>.....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "4768/5349 [=========================>....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "4996/5349 [===========================>..] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "5218/5349 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "5333/5349 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 622us/step - loss: 0.4376 - accuracy: 0.8406 - val_loss: 0.4377 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 9/20\n",
      " 116/5349 [..............................] - ETA: 2s - loss: 0.4306 - accuracy: 0.8448\n",
      " 449/5349 [=>............................] - ETA: 2s - loss: 0.4395 - accuracy: 0.8395\n",
      " 693/5349 [==>...........................] - ETA: 2s - loss: 0.4369 - accuracy: 0.8410\n",
      " 917/5349 [====>.........................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8409\n",
      "1159/5349 [=====>........................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8412\n",
      "1374/5349 [======>.......................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8413\n",
      "1617/5349 [========>.....................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8417\n",
      "1839/5349 [=========>....................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8412\n",
      "2082/5349 [==========>...................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8406\n",
      "2320/5349 [============>.................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8408\n",
      "2557/5349 [=============>................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8408\n",
      "2774/5349 [==============>...............] - ETA: 1s - loss: 0.4371 - accuracy: 0.8409\n",
      "3009/5349 [===============>..............] - ETA: 1s - loss: 0.4371 - accuracy: 0.8409\n",
      "3247/5349 [=================>............] - ETA: 0s - loss: 0.4374 - accuracy: 0.8407\n",
      "3612/5349 [===================>..........] - ETA: 0s - loss: 0.4379 - accuracy: 0.8404\n",
      "3840/5349 [====================>.........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8406\n",
      "4076/5349 [=====================>........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8406\n",
      "4313/5349 [=======================>......] - ETA: 0s - loss: 0.4379 - accuracy: 0.8404\n",
      "4541/5349 [========================>.....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8405\n",
      "4773/5349 [=========================>....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8406\n",
      "5012/5349 [===========================>..] - ETA: 0s - loss: 0.4374 - accuracy: 0.8407\n",
      "5223/5349 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8406\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 599us/step - loss: 0.4375 - accuracy: 0.8406 - val_loss: 0.4375 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 10/20\n",
      " 116/5349 [..............................] - ETA: 2s - loss: 0.4316 - accuracy: 0.8441\n",
      " 357/5349 [=>............................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8420\n",
      " 717/5349 [===>..........................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8415\n",
      " 952/5349 [====>.........................] - ETA: 1s - loss: 0.4380 - accuracy: 0.8402\n",
      "1195/5349 [=====>........................] - ETA: 1s - loss: 0.4380 - accuracy: 0.8403\n",
      "1421/5349 [======>.......................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8405\n",
      "1663/5349 [========>.....................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8405\n",
      "1890/5349 [=========>....................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8405\n",
      "2130/5349 [==========>...................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8400\n",
      "2347/5349 [============>.................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8400\n",
      "2585/5349 [=============>................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8401\n",
      "2819/5349 [==============>...............] - ETA: 1s - loss: 0.4385 - accuracy: 0.8399\n",
      "3064/5349 [================>.............] - ETA: 0s - loss: 0.4383 - accuracy: 0.8401\n",
      "3300/5349 [=================>............] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "3660/5349 [===================>..........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8407\n",
      "3899/5349 [====================>.........] - ETA: 0s - loss: 0.4372 - accuracy: 0.8407\n",
      "4139/5349 [======================>.......] - ETA: 0s - loss: 0.4370 - accuracy: 0.8408\n",
      "4373/5349 [=======================>......] - ETA: 0s - loss: 0.4370 - accuracy: 0.8408\n",
      "4616/5349 [========================>.....] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "4798/5349 [=========================>....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8405\n",
      "4986/5349 [==========================>...] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "5179/5349 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 641us/step - loss: 0.4373 - accuracy: 0.8406 - val_loss: 0.4374 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 11/20\n",
      " 108/5349 [..............................] - ETA: 2s - loss: 0.4286 - accuracy: 0.8458\n",
      " 327/5349 [>.............................] - ETA: 2s - loss: 0.4299 - accuracy: 0.8450\n",
      " 570/5349 [==>...........................] - ETA: 2s - loss: 0.4332 - accuracy: 0.8430\n",
      " 789/5349 [===>..........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8418\n",
      "1148/5349 [=====>........................] - ETA: 1s - loss: 0.4345 - accuracy: 0.8422\n",
      "1378/5349 [======>.......................] - ETA: 1s - loss: 0.4351 - accuracy: 0.8419\n",
      "1604/5349 [=======>......................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8416\n",
      "1829/5349 [=========>....................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8415\n",
      "2043/5349 [==========>...................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8413\n",
      "2274/5349 [===========>..................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8413\n",
      "2484/5349 [============>.................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8415\n",
      "2712/5349 [==============>...............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8412\n",
      "2942/5349 [===============>..............] - ETA: 1s - loss: 0.4363 - accuracy: 0.8412\n",
      "3291/5349 [=================>............] - ETA: 0s - loss: 0.4365 - accuracy: 0.8410\n",
      "3524/5349 [==================>...........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8407\n",
      "3747/5349 [====================>.........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8405\n",
      "3976/5349 [=====================>........] - ETA: 0s - loss: 0.4372 - accuracy: 0.8406\n",
      "4187/5349 [======================>.......] - ETA: 0s - loss: 0.4375 - accuracy: 0.8404\n",
      "4417/5349 [=======================>......] - ETA: 0s - loss: 0.4375 - accuracy: 0.8404\n",
      "4649/5349 [=========================>....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8403\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.4372 - accuracy: 0.8406\n",
      "5228/5349 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8405\n",
      "5339/5349 [============================>.] - ETA: 0s - loss: 0.4371 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 614us/step - loss: 0.4371 - accuracy: 0.8406 - val_loss: 0.4372 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 12/20\n",
      " 123/5349 [..............................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8415\n",
      " 358/5349 [=>............................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8419\n",
      " 601/5349 [==>...........................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8412\n",
      " 813/5349 [===>..........................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8415\n",
      "1049/5349 [====>.........................] - ETA: 1s - loss: 0.4381 - accuracy: 0.8399\n",
      "1277/5349 [======>.......................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8411\n",
      "1521/5349 [=======>......................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8411\n",
      "1759/5349 [========>.....................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8415\n",
      "2003/5349 [==========>...................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8412\n",
      "2234/5349 [===========>..................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8415\n",
      "2476/5349 [============>.................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8410\n",
      "2713/5349 [==============>...............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8407\n",
      "2959/5349 [===============>..............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8407\n",
      "3311/5349 [=================>............] - ETA: 0s - loss: 0.4367 - accuracy: 0.8408\n",
      "3553/5349 [==================>...........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8408\n",
      "3787/5349 [====================>.........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8405\n",
      "4029/5349 [=====================>........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8405\n",
      "4251/5349 [======================>.......] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "4482/5349 [========================>.....] - ETA: 0s - loss: 0.4373 - accuracy: 0.8404\n",
      "4686/5349 [=========================>....] - ETA: 0s - loss: 0.4372 - accuracy: 0.8405\n",
      "4929/5349 [==========================>...] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "5162/5349 [===========================>..] - ETA: 0s - loss: 0.4368 - accuracy: 0.8407\n",
      "5283/5349 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 3s 643us/step - loss: 0.4369 - accuracy: 0.8406 - val_loss: 0.4369 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 13/20\n",
      "  75/5349 [..............................] - ETA: 3s - loss: 0.4352 - accuracy: 0.8416\n",
      " 284/5349 [>.............................] - ETA: 2s - loss: 0.4398 - accuracy: 0.8388\n",
      " 504/5349 [=>............................] - ETA: 2s - loss: 0.4394 - accuracy: 0.8390\n",
      " 735/5349 [===>..........................] - ETA: 2s - loss: 0.4422 - accuracy: 0.8373\n",
      " 967/5349 [====>.........................] - ETA: 2s - loss: 0.4407 - accuracy: 0.8382\n",
      "1194/5349 [=====>........................] - ETA: 1s - loss: 0.4401 - accuracy: 0.8386\n",
      "1434/5349 [=======>......................] - ETA: 1s - loss: 0.4387 - accuracy: 0.8394\n",
      "1648/5349 [========>.....................] - ETA: 1s - loss: 0.4377 - accuracy: 0.8400\n",
      "1883/5349 [=========>....................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8405\n",
      "2105/5349 [==========>...................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8407\n",
      "2341/5349 [============>.................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8407\n",
      "2575/5349 [=============>................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8405\n",
      "2938/5349 [===============>..............] - ETA: 1s - loss: 0.4373 - accuracy: 0.8402\n",
      "3167/5349 [================>.............] - ETA: 0s - loss: 0.4374 - accuracy: 0.8402\n",
      "3402/5349 [==================>...........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8401\n",
      "3633/5349 [===================>..........] - ETA: 0s - loss: 0.4378 - accuracy: 0.8399\n",
      "3868/5349 [====================>.........] - ETA: 0s - loss: 0.4378 - accuracy: 0.8399\n",
      "4098/5349 [=====================>........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8402\n",
      "4339/5349 [=======================>......] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8404\n",
      "4801/5349 [=========================>....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "5017/5349 [===========================>..] - ETA: 0s - loss: 0.4366 - accuracy: 0.8407\n",
      "5258/5349 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 613us/step - loss: 0.4366 - accuracy: 0.8406 - val_loss: 0.4367 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 14/20\n",
      " 117/5349 [..............................] - ETA: 2s - loss: 0.4381 - accuracy: 0.8397\n",
      " 470/5349 [=>............................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8417\n",
      " 709/5349 [==>...........................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8405\n",
      " 940/5349 [====>.........................] - ETA: 1s - loss: 0.4357 - accuracy: 0.8411\n",
      "1175/5349 [=====>........................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8407\n",
      "1395/5349 [======>.......................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8403\n",
      "1622/5349 [========>.....................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8406\n",
      "1820/5349 [=========>....................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8400\n",
      "2055/5349 [==========>...................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8404\n",
      "2262/5349 [===========>..................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8401\n",
      "2489/5349 [============>.................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8402\n",
      "2721/5349 [==============>...............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8404\n",
      "2959/5349 [===============>..............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8404\n",
      "3188/5349 [================>.............] - ETA: 0s - loss: 0.4367 - accuracy: 0.8404\n",
      "3429/5349 [==================>...........] - ETA: 0s - loss: 0.4366 - accuracy: 0.8405\n",
      "3664/5349 [===================>..........] - ETA: 0s - loss: 0.4366 - accuracy: 0.8405\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8405\n",
      "4017/5349 [=====================>........] - ETA: 0s - loss: 0.4369 - accuracy: 0.8403\n",
      "4250/5349 [======================>.......] - ETA: 0s - loss: 0.4368 - accuracy: 0.8404\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.4365 - accuracy: 0.8405\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.4365 - accuracy: 0.8406\n",
      "4963/5349 [==========================>...] - ETA: 0s - loss: 0.4365 - accuracy: 0.8406\n",
      "5171/5349 [============================>.] - ETA: 0s - loss: 0.4362 - accuracy: 0.8407\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.4364 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 608us/step - loss: 0.4364 - accuracy: 0.8406 - val_loss: 0.4364 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 15/20\n",
      " 121/5349 [..............................] - ETA: 2s - loss: 0.4360 - accuracy: 0.8407\n",
      " 364/5349 [=>............................] - ETA: 2s - loss: 0.4366 - accuracy: 0.8404\n",
      " 600/5349 [==>...........................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8399\n",
      " 829/5349 [===>..........................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8402\n",
      "1074/5349 [=====>........................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8405\n",
      "1303/5349 [======>.......................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8410\n",
      "1545/5349 [=======>......................] - ETA: 1s - loss: 0.4354 - accuracy: 0.8411\n",
      "1777/5349 [========>.....................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8410\n",
      "2014/5349 [==========>...................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8412\n",
      "2252/5349 [===========>..................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8407\n",
      "2486/5349 [============>.................] - ETA: 1s - loss: 0.4357 - accuracy: 0.8409\n",
      "2719/5349 [==============>...............] - ETA: 1s - loss: 0.4358 - accuracy: 0.8408\n",
      "3082/5349 [================>.............] - ETA: 0s - loss: 0.4359 - accuracy: 0.8408\n",
      "3316/5349 [=================>............] - ETA: 0s - loss: 0.4360 - accuracy: 0.8407\n",
      "3555/5349 [==================>...........] - ETA: 0s - loss: 0.4361 - accuracy: 0.8407\n",
      "3768/5349 [====================>.........] - ETA: 0s - loss: 0.4363 - accuracy: 0.8405\n",
      "4011/5349 [=====================>........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8406\n",
      "4244/5349 [======================>.......] - ETA: 0s - loss: 0.4363 - accuracy: 0.8405\n",
      "4485/5349 [========================>.....] - ETA: 0s - loss: 0.4360 - accuracy: 0.8407\n",
      "4717/5349 [=========================>....] - ETA: 0s - loss: 0.4360 - accuracy: 0.8406\n",
      "4960/5349 [==========================>...] - ETA: 0s - loss: 0.4359 - accuracy: 0.8407\n",
      "5195/5349 [============================>.] - ETA: 0s - loss: 0.4359 - accuracy: 0.8407\n",
      "5313/5349 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 3s 614us/step - loss: 0.4361 - accuracy: 0.8406 - val_loss: 0.4360 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 16/20\n",
      "  71/5349 [..............................] - ETA: 3s - loss: 0.4437 - accuracy: 0.8359 \n",
      " 233/5349 [>.............................] - ETA: 3s - loss: 0.4363 - accuracy: 0.8403\n",
      " 400/5349 [=>............................] - ETA: 3s - loss: 0.4337 - accuracy: 0.8419\n",
      " 576/5349 [==>...........................] - ETA: 2s - loss: 0.4326 - accuracy: 0.8426\n",
      " 778/5349 [===>..........................] - ETA: 2s - loss: 0.4339 - accuracy: 0.8418\n",
      " 878/5349 [===>..........................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8415\n",
      " 991/5349 [====>.........................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8415\n",
      "1175/5349 [=====>........................] - ETA: 2s - loss: 0.4341 - accuracy: 0.8417\n",
      "1369/5349 [======>.......................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8412\n",
      "1568/5349 [=======>......................] - ETA: 2s - loss: 0.4352 - accuracy: 0.8410\n",
      "1799/5349 [=========>....................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8406\n",
      "2038/5349 [==========>...................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8403\n",
      "2270/5349 [===========>..................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8401\n",
      "2504/5349 [=============>................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8401\n",
      "2735/5349 [==============>...............] - ETA: 1s - loss: 0.4365 - accuracy: 0.8402\n",
      "2977/5349 [===============>..............] - ETA: 1s - loss: 0.4370 - accuracy: 0.8399\n",
      "3204/5349 [================>.............] - ETA: 1s - loss: 0.4367 - accuracy: 0.8401\n",
      "3444/5349 [==================>...........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8402\n",
      "3674/5349 [===================>..........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8404\n",
      "4030/5349 [=====================>........] - ETA: 0s - loss: 0.4360 - accuracy: 0.8405\n",
      "4261/5349 [======================>.......] - ETA: 0s - loss: 0.4358 - accuracy: 0.8406\n",
      "4500/5349 [========================>.....] - ETA: 0s - loss: 0.4358 - accuracy: 0.8406\n",
      "4710/5349 [=========================>....] - ETA: 0s - loss: 0.4357 - accuracy: 0.8406\n",
      "4948/5349 [==========================>...] - ETA: 0s - loss: 0.4358 - accuracy: 0.8406\n",
      "5177/5349 [============================>.] - ETA: 0s - loss: 0.4357 - accuracy: 0.8407\n",
      "5296/5349 [============================>.] - ETA: 0s - loss: 0.4357 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 649us/step - loss: 0.4357 - accuracy: 0.8406 - val_loss: 0.4357 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.2880 - accuracy: 0.9300\n",
      " 175/5349 [..............................] - ETA: 2s - loss: 0.4376 - accuracy: 0.8394\n",
      " 395/5349 [=>............................] - ETA: 2s - loss: 0.4397 - accuracy: 0.8381\n",
      " 609/5349 [==>...........................] - ETA: 2s - loss: 0.4384 - accuracy: 0.8389\n",
      " 833/5349 [===>..........................] - ETA: 2s - loss: 0.4365 - accuracy: 0.8400\n",
      " 954/5349 [====>.........................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8404\n",
      "1176/5349 [=====>........................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8404\n",
      "1407/5349 [======>.......................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8401\n",
      "1614/5349 [========>.....................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8401\n",
      "1844/5349 [=========>....................] - ETA: 1s - loss: 0.4354 - accuracy: 0.8407\n",
      "2056/5349 [==========>...................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8406\n",
      "2271/5349 [===========>..................] - ETA: 1s - loss: 0.4352 - accuracy: 0.8407\n",
      "2508/5349 [=============>................] - ETA: 1s - loss: 0.4357 - accuracy: 0.8405\n",
      "2747/5349 [==============>...............] - ETA: 1s - loss: 0.4351 - accuracy: 0.8408\n",
      "2977/5349 [===============>..............] - ETA: 1s - loss: 0.4353 - accuracy: 0.8407\n",
      "3219/5349 [=================>............] - ETA: 0s - loss: 0.4350 - accuracy: 0.8409\n",
      "3450/5349 [==================>...........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8410\n",
      "3689/5349 [===================>..........] - ETA: 0s - loss: 0.4345 - accuracy: 0.8412\n",
      "3927/5349 [=====================>........] - ETA: 0s - loss: 0.4347 - accuracy: 0.8410\n",
      "4163/5349 [======================>.......] - ETA: 0s - loss: 0.4347 - accuracy: 0.8410\n",
      "4524/5349 [========================>.....] - ETA: 0s - loss: 0.4349 - accuracy: 0.8409\n",
      "4762/5349 [=========================>....] - ETA: 0s - loss: 0.4352 - accuracy: 0.8407\n",
      "4990/5349 [==========================>...] - ETA: 0s - loss: 0.4350 - accuracy: 0.8408\n",
      "5224/5349 [============================>.] - ETA: 0s - loss: 0.4352 - accuracy: 0.8407\n",
      "5321/5349 [============================>.] - ETA: 0s - loss: 0.4353 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 611us/step - loss: 0.4353 - accuracy: 0.8406 - val_loss: 0.4352 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 18/20\n",
      " 115/5349 [..............................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8398\n",
      " 335/5349 [>.............................] - ETA: 2s - loss: 0.4356 - accuracy: 0.8403\n",
      " 575/5349 [==>...........................] - ETA: 2s - loss: 0.4396 - accuracy: 0.8378\n",
      " 795/5349 [===>..........................] - ETA: 2s - loss: 0.4395 - accuracy: 0.8379\n",
      "1036/5349 [====>.........................] - ETA: 1s - loss: 0.4381 - accuracy: 0.8387\n",
      "1269/5349 [======>.......................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8390\n",
      "1514/5349 [=======>......................] - ETA: 1s - loss: 0.4379 - accuracy: 0.8389\n",
      "1638/5349 [========>.....................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8391\n",
      "1877/5349 [=========>....................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8397\n",
      "2121/5349 [==========>...................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8400\n",
      "2356/5349 [============>.................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8401\n",
      "2597/5349 [=============>................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8400\n",
      "2832/5349 [==============>...............] - ETA: 1s - loss: 0.4357 - accuracy: 0.8401\n",
      "3074/5349 [================>.............] - ETA: 0s - loss: 0.4359 - accuracy: 0.8401\n",
      "3309/5349 [=================>............] - ETA: 0s - loss: 0.4358 - accuracy: 0.8401\n",
      "3548/5349 [==================>...........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8400\n",
      "3760/5349 [====================>.........] - ETA: 0s - loss: 0.4357 - accuracy: 0.8402\n",
      "3974/5349 [=====================>........] - ETA: 0s - loss: 0.4353 - accuracy: 0.8404\n",
      "4202/5349 [======================>.......] - ETA: 0s - loss: 0.4353 - accuracy: 0.8404\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.4353 - accuracy: 0.8404\n",
      "4799/5349 [=========================>....] - ETA: 0s - loss: 0.4350 - accuracy: 0.8405\n",
      "5043/5349 [===========================>..] - ETA: 0s - loss: 0.4351 - accuracy: 0.8405\n",
      "5277/5349 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 596us/step - loss: 0.4348 - accuracy: 0.8406 - val_loss: 0.4347 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.3367 - accuracy: 0.9000\n",
      " 235/5349 [>.............................] - ETA: 2s - loss: 0.4370 - accuracy: 0.8391\n",
      " 420/5349 [=>............................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8400\n",
      " 589/5349 [==>...........................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8398\n",
      " 765/5349 [===>..........................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8400\n",
      " 942/5349 [====>.........................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8403\n",
      "1154/5349 [=====>........................] - ETA: 2s - loss: 0.4346 - accuracy: 0.8405\n",
      "1348/5349 [======>.......................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8407\n",
      "1558/5349 [=======>......................] - ETA: 1s - loss: 0.4346 - accuracy: 0.8405\n",
      "1659/5349 [========>.....................] - ETA: 1s - loss: 0.4348 - accuracy: 0.8404\n",
      "1854/5349 [=========>....................] - ETA: 1s - loss: 0.4347 - accuracy: 0.8405\n",
      "2056/5349 [==========>...................] - ETA: 1s - loss: 0.4345 - accuracy: 0.8406\n",
      "2252/5349 [===========>..................] - ETA: 1s - loss: 0.4342 - accuracy: 0.8408\n",
      "2384/5349 [============>.................] - ETA: 1s - loss: 0.4342 - accuracy: 0.8407\n",
      "2538/5349 [=============>................] - ETA: 1s - loss: 0.4339 - accuracy: 0.8409\n",
      "2714/5349 [==============>...............] - ETA: 1s - loss: 0.4338 - accuracy: 0.8410\n",
      "2912/5349 [===============>..............] - ETA: 1s - loss: 0.4343 - accuracy: 0.8407\n",
      "3145/5349 [================>.............] - ETA: 1s - loss: 0.4351 - accuracy: 0.8402\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.4348 - accuracy: 0.8404\n",
      "3605/5349 [===================>..........] - ETA: 0s - loss: 0.4349 - accuracy: 0.8403\n",
      "3820/5349 [====================>.........] - ETA: 0s - loss: 0.4347 - accuracy: 0.8404\n",
      "4152/5349 [======================>.......] - ETA: 0s - loss: 0.4347 - accuracy: 0.8404\n",
      "4348/5349 [=======================>......] - ETA: 0s - loss: 0.4346 - accuracy: 0.8404\n",
      "4574/5349 [========================>.....] - ETA: 0s - loss: 0.4349 - accuracy: 0.8403\n",
      "4777/5349 [=========================>....] - ETA: 0s - loss: 0.4346 - accuracy: 0.8404\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.4344 - accuracy: 0.8406\n",
      "5201/5349 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8406\n",
      "5304/5349 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 686us/step - loss: 0.4343 - accuracy: 0.8406 - val_loss: 0.4341 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5426)\u001B[0m Epoch 20/20\n",
      " 110/5349 [..............................] - ETA: 2s - loss: 0.4274 - accuracy: 0.8446\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8404\n",
      " 574/5349 [==>...........................] - ETA: 2s - loss: 0.4372 - accuracy: 0.8386\n",
      " 791/5349 [===>..........................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8400\n",
      "1032/5349 [====>.........................] - ETA: 1s - loss: 0.4337 - accuracy: 0.8408\n",
      "1152/5349 [=====>........................] - ETA: 1s - loss: 0.4339 - accuracy: 0.8407\n",
      "1328/5349 [======>.......................] - ETA: 1s - loss: 0.4340 - accuracy: 0.8405\n",
      "1494/5349 [=======>......................] - ETA: 1s - loss: 0.4335 - accuracy: 0.8409\n",
      "1681/5349 [========>.....................] - ETA: 1s - loss: 0.4338 - accuracy: 0.8407\n",
      "1900/5349 [=========>....................] - ETA: 1s - loss: 0.4349 - accuracy: 0.8400\n",
      "2133/5349 [==========>...................] - ETA: 1s - loss: 0.4342 - accuracy: 0.8404\n",
      "2341/5349 [============>.................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8407\n",
      "2551/5349 [=============>................] - ETA: 1s - loss: 0.4337 - accuracy: 0.8407\n",
      "2769/5349 [==============>...............] - ETA: 1s - loss: 0.4338 - accuracy: 0.8406\n",
      "3001/5349 [===============>..............] - ETA: 1s - loss: 0.4337 - accuracy: 0.8407\n",
      "3229/5349 [=================>............] - ETA: 0s - loss: 0.4335 - accuracy: 0.8408\n",
      "3571/5349 [===================>..........] - ETA: 0s - loss: 0.4337 - accuracy: 0.8406\n",
      "3794/5349 [====================>.........] - ETA: 0s - loss: 0.4339 - accuracy: 0.8405\n",
      "4028/5349 [=====================>........] - ETA: 0s - loss: 0.4340 - accuracy: 0.8405\n",
      "4268/5349 [======================>.......] - ETA: 0s - loss: 0.4339 - accuracy: 0.8405\n",
      "4491/5349 [========================>.....] - ETA: 0s - loss: 0.4337 - accuracy: 0.8406\n",
      "4732/5349 [=========================>....] - ETA: 0s - loss: 0.4337 - accuracy: 0.8406\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.4335 - accuracy: 0.8407\n",
      "5175/5349 [============================>.] - ETA: 0s - loss: 0.4336 - accuracy: 0.8407\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.4336 - accuracy: 0.8407\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 24:36 - loss: 1.0231 - accuracy: 0.1000\n",
      " 166/5349 [..............................] - ETA: 3s - loss: 0.5093 - accuracy: 0.7374\n",
      " 337/5349 [>.............................] - ETA: 3s - loss: 0.4133 - accuracy: 0.7876\n",
      " 555/5349 [==>...........................] - ETA: 3s - loss: 0.3413 - accuracy: 0.8213\n",
      " 707/5349 [==>...........................] - ETA: 2s - loss: 0.3092 - accuracy: 0.8397\n",
      " 865/5349 [===>..........................] - ETA: 2s - loss: 0.2852 - accuracy: 0.8533\n",
      "1040/5349 [====>.........................] - ETA: 2s - loss: 0.2661 - accuracy: 0.8638\n",
      "1190/5349 [=====>........................] - ETA: 2s - loss: 0.2539 - accuracy: 0.8698\n",
      "1348/5349 [======>.......................] - ETA: 2s - loss: 0.2436 - accuracy: 0.8753\n",
      "1506/5349 [=======>......................] - ETA: 2s - loss: 0.2354 - accuracy: 0.8793\n",
      "1676/5349 [========>.....................] - ETA: 2s - loss: 0.2278 - accuracy: 0.8831\n",
      "1842/5349 [=========>....................] - ETA: 2s - loss: 0.2217 - accuracy: 0.8862\n",
      "2012/5349 [==========>...................] - ETA: 2s - loss: 0.2162 - accuracy: 0.8888\n",
      "2175/5349 [===========>..................] - ETA: 1s - loss: 0.2122 - accuracy: 0.8907\n",
      "2426/5349 [============>.................] - ETA: 1s - loss: 0.2062 - accuracy: 0.8937\n",
      "2592/5349 [=============>................] - ETA: 1s - loss: 0.2029 - accuracy: 0.8954\n",
      "2760/5349 [==============>...............] - ETA: 1s - loss: 0.2002 - accuracy: 0.8966\n",
      "2922/5349 [===============>..............] - ETA: 1s - loss: 0.1972 - accuracy: 0.8982\n",
      "3087/5349 [================>.............] - ETA: 1s - loss: 0.1947 - accuracy: 0.8995\n",
      "3249/5349 [=================>............] - ETA: 1s - loss: 0.1924 - accuracy: 0.9006\n",
      "3420/5349 [==================>...........] - ETA: 1s - loss: 0.1906 - accuracy: 0.9015\n",
      "3568/5349 [===================>..........] - ETA: 1s - loss: 0.1891 - accuracy: 0.9021\n",
      "3735/5349 [===================>..........] - ETA: 0s - loss: 0.1876 - accuracy: 0.9029\n",
      "3895/5349 [====================>.........] - ETA: 0s - loss: 0.1862 - accuracy: 0.9035\n",
      "4066/5349 [=====================>........] - ETA: 0s - loss: 0.1848 - accuracy: 0.9042\n",
      "4237/5349 [======================>.......] - ETA: 0s - loss: 0.1836 - accuracy: 0.9046\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.1818 - accuracy: 0.9054\n",
      "4663/5349 [=========================>....] - ETA: 0s - loss: 0.1807 - accuracy: 0.9059\n",
      "4836/5349 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.9065\n",
      "5000/5349 [===========================>..] - ETA: 0s - loss: 0.1786 - accuracy: 0.9068\n",
      "5171/5349 [============================>.] - ETA: 0s - loss: 0.1777 - accuracy: 0.9072\n",
      "5337/5349 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9077\n",
      "5349/5349 [==============================] - 5s 809us/step - loss: 0.1766 - accuracy: 0.9077 - val_loss: 0.1475 - val_accuracy: 0.9208\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 2/20\n",
      "  86/5349 [..............................] - ETA: 3s - loss: 0.1524 - accuracy: 0.9167\n",
      " 260/5349 [>.............................] - ETA: 2s - loss: 0.1521 - accuracy: 0.9165\n",
      " 510/5349 [=>............................] - ETA: 2s - loss: 0.1498 - accuracy: 0.9184\n",
      " 663/5349 [==>...........................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9184\n",
      " 836/5349 [===>..........................] - ETA: 2s - loss: 0.1486 - accuracy: 0.9189\n",
      "1000/5349 [====>.........................] - ETA: 2s - loss: 0.1481 - accuracy: 0.9194\n",
      "1169/5349 [=====>........................] - ETA: 2s - loss: 0.1478 - accuracy: 0.9198\n",
      "1329/5349 [======>.......................] - ETA: 2s - loss: 0.1479 - accuracy: 0.9197\n",
      "1501/5349 [=======>......................] - ETA: 2s - loss: 0.1476 - accuracy: 0.9199\n",
      "1668/5349 [========>.....................] - ETA: 2s - loss: 0.1473 - accuracy: 0.9200\n",
      "1837/5349 [=========>....................] - ETA: 2s - loss: 0.1473 - accuracy: 0.9200\n",
      "2006/5349 [==========>...................] - ETA: 2s - loss: 0.1469 - accuracy: 0.9204\n",
      "2179/5349 [===========>..................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9205\n",
      "2266/5349 [===========>..................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9204\n",
      "2435/5349 [============>.................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9206\n",
      "2603/5349 [=============>................] - ETA: 1s - loss: 0.1463 - accuracy: 0.9206\n",
      "2753/5349 [==============>...............] - ETA: 1s - loss: 0.1462 - accuracy: 0.9206\n",
      "2924/5349 [===============>..............] - ETA: 1s - loss: 0.1460 - accuracy: 0.9207\n",
      "3093/5349 [================>.............] - ETA: 1s - loss: 0.1459 - accuracy: 0.9208\n",
      "3265/5349 [=================>............] - ETA: 1s - loss: 0.1456 - accuracy: 0.9210\n",
      "3428/5349 [==================>...........] - ETA: 1s - loss: 0.1457 - accuracy: 0.9210\n",
      "3598/5349 [===================>..........] - ETA: 1s - loss: 0.1454 - accuracy: 0.9211\n",
      "3758/5349 [====================>.........] - ETA: 0s - loss: 0.1454 - accuracy: 0.9212\n",
      "3917/5349 [====================>.........] - ETA: 0s - loss: 0.1455 - accuracy: 0.9210\n",
      "4040/5349 [=====================>........] - ETA: 0s - loss: 0.1455 - accuracy: 0.9211\n",
      "4168/5349 [======================>.......] - ETA: 0s - loss: 0.1454 - accuracy: 0.9212\n",
      "4287/5349 [=======================>......] - ETA: 0s - loss: 0.1452 - accuracy: 0.9214\n",
      "4374/5349 [=======================>......] - ETA: 0s - loss: 0.1452 - accuracy: 0.9214\n",
      "4432/5349 [=======================>......] - ETA: 0s - loss: 0.1452 - accuracy: 0.9213\n",
      "4563/5349 [========================>.....] - ETA: 0s - loss: 0.1452 - accuracy: 0.9214\n",
      "4701/5349 [=========================>....] - ETA: 0s - loss: 0.1451 - accuracy: 0.9214\n",
      "4825/5349 [==========================>...] - ETA: 0s - loss: 0.1450 - accuracy: 0.9215\n",
      "4972/5349 [==========================>...] - ETA: 0s - loss: 0.1450 - accuracy: 0.9214\n",
      "5089/5349 [===========================>..] - ETA: 0s - loss: 0.1450 - accuracy: 0.9214\n",
      "5199/5349 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9215\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9214\n",
      "5349/5349 [==============================] - 5s 844us/step - loss: 0.1450 - accuracy: 0.9214 - val_loss: 0.1414 - val_accuracy: 0.9232\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 3/20\n",
      "  82/5349 [..............................] - ETA: 3s - loss: 0.1378 - accuracy: 0.9261\n",
      " 251/5349 [>.............................] - ETA: 3s - loss: 0.1390 - accuracy: 0.9255\n",
      " 412/5349 [=>............................] - ETA: 3s - loss: 0.1397 - accuracy: 0.9249\n",
      " 570/5349 [==>...........................] - ETA: 2s - loss: 0.1391 - accuracy: 0.9256\n",
      " 740/5349 [===>..........................] - ETA: 2s - loss: 0.1397 - accuracy: 0.9246\n",
      " 895/5349 [====>.........................] - ETA: 2s - loss: 0.1406 - accuracy: 0.9242\n",
      "1061/5349 [====>.........................] - ETA: 2s - loss: 0.1413 - accuracy: 0.9237\n",
      "1218/5349 [=====>........................] - ETA: 2s - loss: 0.1416 - accuracy: 0.9237\n",
      "1469/5349 [=======>......................] - ETA: 2s - loss: 0.1417 - accuracy: 0.9237\n",
      "1631/5349 [========>.....................] - ETA: 2s - loss: 0.1418 - accuracy: 0.9237\n",
      "1795/5349 [=========>....................] - ETA: 2s - loss: 0.1418 - accuracy: 0.9237\n",
      "1961/5349 [=========>....................] - ETA: 2s - loss: 0.1418 - accuracy: 0.9236\n",
      "2118/5349 [==========>...................] - ETA: 1s - loss: 0.1418 - accuracy: 0.9236\n",
      "2260/5349 [===========>..................] - ETA: 1s - loss: 0.1417 - accuracy: 0.9237\n",
      "2429/5349 [============>.................] - ETA: 1s - loss: 0.1416 - accuracy: 0.9237\n",
      "2588/5349 [=============>................] - ETA: 1s - loss: 0.1415 - accuracy: 0.9237\n",
      "2760/5349 [==============>...............] - ETA: 1s - loss: 0.1414 - accuracy: 0.9237\n",
      "2927/5349 [===============>..............] - ETA: 1s - loss: 0.1414 - accuracy: 0.9237\n",
      "3084/5349 [================>.............] - ETA: 1s - loss: 0.1413 - accuracy: 0.9237\n",
      "3220/5349 [=================>............] - ETA: 1s - loss: 0.1413 - accuracy: 0.9237\n",
      "3369/5349 [=================>............] - ETA: 1s - loss: 0.1412 - accuracy: 0.9237\n",
      "3496/5349 [==================>...........] - ETA: 1s - loss: 0.1412 - accuracy: 0.9236\n",
      "3734/5349 [===================>..........] - ETA: 1s - loss: 0.1411 - accuracy: 0.9237\n",
      "3878/5349 [====================>.........] - ETA: 0s - loss: 0.1412 - accuracy: 0.9238\n",
      "4029/5349 [=====================>........] - ETA: 0s - loss: 0.1411 - accuracy: 0.9238\n",
      "4172/5349 [======================>.......] - ETA: 0s - loss: 0.1411 - accuracy: 0.9239\n",
      "4340/5349 [=======================>......] - ETA: 0s - loss: 0.1409 - accuracy: 0.9240\n",
      "4508/5349 [========================>.....] - ETA: 0s - loss: 0.1409 - accuracy: 0.9240\n",
      "4679/5349 [=========================>....] - ETA: 0s - loss: 0.1409 - accuracy: 0.9240\n",
      "4845/5349 [==========================>...] - ETA: 0s - loss: 0.1410 - accuracy: 0.9238\n",
      "5012/5349 [===========================>..] - ETA: 0s - loss: 0.1408 - accuracy: 0.9240\n",
      "5178/5349 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9241\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9240\n",
      "5349/5349 [==============================] - 4s 808us/step - loss: 0.1406 - accuracy: 0.9240 - val_loss: 0.1370 - val_accuracy: 0.9263\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 4/20\n",
      "  57/5349 [..............................] - ETA: 4s - loss: 0.1488 - accuracy: 0.9172 \n",
      " 117/5349 [..............................] - ETA: 4s - loss: 0.1464 - accuracy: 0.9188\n",
      " 271/5349 [>.............................] - ETA: 3s - loss: 0.1451 - accuracy: 0.9209\n",
      " 425/5349 [=>............................] - ETA: 3s - loss: 0.1441 - accuracy: 0.9213\n",
      " 595/5349 [==>...........................] - ETA: 3s - loss: 0.1433 - accuracy: 0.9225\n",
      " 745/5349 [===>..........................] - ETA: 3s - loss: 0.1426 - accuracy: 0.9236\n",
      " 917/5349 [====>.........................] - ETA: 2s - loss: 0.1421 - accuracy: 0.9235\n",
      "1063/5349 [====>.........................] - ETA: 2s - loss: 0.1413 - accuracy: 0.9238\n",
      "1211/5349 [=====>........................] - ETA: 2s - loss: 0.1406 - accuracy: 0.9241\n",
      "1367/5349 [======>.......................] - ETA: 2s - loss: 0.1399 - accuracy: 0.9246\n",
      "1537/5349 [=======>......................] - ETA: 2s - loss: 0.1400 - accuracy: 0.9246\n",
      "1697/5349 [========>.....................] - ETA: 2s - loss: 0.1399 - accuracy: 0.9247\n",
      "1862/5349 [=========>....................] - ETA: 2s - loss: 0.1396 - accuracy: 0.9251\n",
      "2002/5349 [==========>...................] - ETA: 2s - loss: 0.1394 - accuracy: 0.9253\n",
      "2150/5349 [===========>..................] - ETA: 2s - loss: 0.1394 - accuracy: 0.9253\n",
      "2310/5349 [===========>..................] - ETA: 1s - loss: 0.1392 - accuracy: 0.9254\n",
      "2474/5349 [============>.................] - ETA: 1s - loss: 0.1392 - accuracy: 0.9253\n",
      "2724/5349 [==============>...............] - ETA: 1s - loss: 0.1387 - accuracy: 0.9255\n",
      "2879/5349 [===============>..............] - ETA: 1s - loss: 0.1387 - accuracy: 0.9254\n",
      "3010/5349 [===============>..............] - ETA: 1s - loss: 0.1385 - accuracy: 0.9255\n",
      "3179/5349 [================>.............] - ETA: 1s - loss: 0.1385 - accuracy: 0.9255\n",
      "3334/5349 [=================>............] - ETA: 1s - loss: 0.1385 - accuracy: 0.9255\n",
      "3503/5349 [==================>...........] - ETA: 1s - loss: 0.1382 - accuracy: 0.9257\n",
      "3666/5349 [===================>..........] - ETA: 1s - loss: 0.1382 - accuracy: 0.9258\n",
      "3835/5349 [====================>.........] - ETA: 0s - loss: 0.1379 - accuracy: 0.9259\n",
      "3998/5349 [=====================>........] - ETA: 0s - loss: 0.1378 - accuracy: 0.9260\n",
      "4169/5349 [======================>.......] - ETA: 0s - loss: 0.1376 - accuracy: 0.9261\n",
      "4327/5349 [=======================>......] - ETA: 0s - loss: 0.1377 - accuracy: 0.9261\n",
      "4484/5349 [========================>.....] - ETA: 0s - loss: 0.1375 - accuracy: 0.9262\n",
      "4635/5349 [========================>.....] - ETA: 0s - loss: 0.1373 - accuracy: 0.9264\n",
      "4719/5349 [=========================>....] - ETA: 0s - loss: 0.1372 - accuracy: 0.9265\n",
      "4881/5349 [==========================>...] - ETA: 0s - loss: 0.1371 - accuracy: 0.9266\n",
      "5046/5349 [===========================>..] - ETA: 0s - loss: 0.1370 - accuracy: 0.9267\n",
      "5211/5349 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.9267\n",
      "5289/5349 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9268\n",
      "5349/5349 [==============================] - 5s 858us/step - loss: 0.1368 - accuracy: 0.9268 - val_loss: 0.1338 - val_accuracy: 0.9304\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 5/20\n",
      "  46/5349 [..............................] - ETA: 6s - loss: 0.1383 - accuracy: 0.9233\n",
      " 137/5349 [..............................] - ETA: 5s - loss: 0.1367 - accuracy: 0.9256\n",
      " 168/5349 [..............................] - ETA: 6s - loss: 0.1367 - accuracy: 0.9252\n",
      " 277/5349 [>.............................] - ETA: 5s - loss: 0.1346 - accuracy: 0.9261\n",
      " 392/5349 [=>............................] - ETA: 5s - loss: 0.1347 - accuracy: 0.9268\n",
      " 531/5349 [=>............................] - ETA: 4s - loss: 0.1357 - accuracy: 0.9259\n",
      " 673/5349 [==>...........................] - ETA: 4s - loss: 0.1358 - accuracy: 0.9264\n",
      " 847/5349 [===>..........................] - ETA: 3s - loss: 0.1351 - accuracy: 0.9267\n",
      "1007/5349 [====>.........................] - ETA: 3s - loss: 0.1344 - accuracy: 0.9273\n",
      "1173/5349 [=====>........................] - ETA: 3s - loss: 0.1341 - accuracy: 0.9275\n",
      "1331/5349 [======>.......................] - ETA: 3s - loss: 0.1340 - accuracy: 0.9277\n",
      "1488/5349 [=======>......................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9280\n",
      "1650/5349 [========>.....................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9284\n",
      "1820/5349 [=========>....................] - ETA: 2s - loss: 0.1337 - accuracy: 0.9281\n",
      "1987/5349 [==========>...................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9282\n",
      "2158/5349 [===========>..................] - ETA: 2s - loss: 0.1339 - accuracy: 0.9280\n",
      "2319/5349 [============>.................] - ETA: 2s - loss: 0.1340 - accuracy: 0.9281\n",
      "2488/5349 [============>.................] - ETA: 1s - loss: 0.1342 - accuracy: 0.9280\n",
      "2650/5349 [=============>................] - ETA: 1s - loss: 0.1338 - accuracy: 0.9283\n",
      "2895/5349 [===============>..............] - ETA: 1s - loss: 0.1340 - accuracy: 0.9282\n",
      "3050/5349 [================>.............] - ETA: 1s - loss: 0.1339 - accuracy: 0.9283\n",
      "3216/5349 [=================>............] - ETA: 1s - loss: 0.1338 - accuracy: 0.9284\n",
      "3372/5349 [=================>............] - ETA: 1s - loss: 0.1340 - accuracy: 0.9283\n",
      "3543/5349 [==================>...........] - ETA: 1s - loss: 0.1339 - accuracy: 0.9285\n",
      "3707/5349 [===================>..........] - ETA: 1s - loss: 0.1338 - accuracy: 0.9285\n",
      "3867/5349 [====================>.........] - ETA: 0s - loss: 0.1338 - accuracy: 0.9285\n",
      "4031/5349 [=====================>........] - ETA: 0s - loss: 0.1338 - accuracy: 0.9285\n",
      "4193/5349 [======================>.......] - ETA: 0s - loss: 0.1338 - accuracy: 0.9285\n",
      "4347/5349 [=======================>......] - ETA: 0s - loss: 0.1336 - accuracy: 0.9287\n",
      "4485/5349 [========================>.....] - ETA: 0s - loss: 0.1335 - accuracy: 0.9288\n",
      "4639/5349 [=========================>....] - ETA: 0s - loss: 0.1335 - accuracy: 0.9289\n",
      "4813/5349 [=========================>....] - ETA: 0s - loss: 0.1335 - accuracy: 0.9289\n",
      "4951/5349 [==========================>...] - ETA: 0s - loss: 0.1334 - accuracy: 0.9290\n",
      "5119/5349 [===========================>..] - ETA: 0s - loss: 0.1333 - accuracy: 0.9291\n",
      "5277/5349 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.9291\n",
      "5349/5349 [==============================] - 4s 829us/step - loss: 0.1333 - accuracy: 0.9291 - val_loss: 0.1296 - val_accuracy: 0.9315\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0514 - accuracy: 0.9900\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1282 - accuracy: 0.9316\n",
      " 332/5349 [>.............................] - ETA: 3s - loss: 0.1292 - accuracy: 0.9320\n",
      " 492/5349 [=>............................] - ETA: 2s - loss: 0.1297 - accuracy: 0.9313\n",
      " 658/5349 [==>...........................] - ETA: 2s - loss: 0.1299 - accuracy: 0.9313\n",
      " 822/5349 [===>..........................] - ETA: 2s - loss: 0.1297 - accuracy: 0.9312\n",
      "1080/5349 [=====>........................] - ETA: 2s - loss: 0.1306 - accuracy: 0.9307\n",
      "1238/5349 [=====>........................] - ETA: 2s - loss: 0.1308 - accuracy: 0.9305\n",
      "1401/5349 [======>.......................] - ETA: 2s - loss: 0.1304 - accuracy: 0.9306\n",
      "1558/5349 [=======>......................] - ETA: 2s - loss: 0.1303 - accuracy: 0.9307\n",
      "1726/5349 [========>.....................] - ETA: 2s - loss: 0.1305 - accuracy: 0.9307\n",
      "1881/5349 [=========>....................] - ETA: 2s - loss: 0.1307 - accuracy: 0.9304\n",
      "2052/5349 [==========>...................] - ETA: 2s - loss: 0.1310 - accuracy: 0.9303\n",
      "2205/5349 [===========>..................] - ETA: 1s - loss: 0.1308 - accuracy: 0.9305\n",
      "2374/5349 [============>.................] - ETA: 1s - loss: 0.1311 - accuracy: 0.9303\n",
      "2623/5349 [=============>................] - ETA: 1s - loss: 0.1308 - accuracy: 0.9306\n",
      "2793/5349 [==============>...............] - ETA: 1s - loss: 0.1308 - accuracy: 0.9306\n",
      "2952/5349 [===============>..............] - ETA: 1s - loss: 0.1308 - accuracy: 0.9307\n",
      "3119/5349 [================>.............] - ETA: 1s - loss: 0.1306 - accuracy: 0.9309\n",
      "3287/5349 [=================>............] - ETA: 1s - loss: 0.1308 - accuracy: 0.9307\n",
      "3431/5349 [==================>...........] - ETA: 1s - loss: 0.1308 - accuracy: 0.9307\n",
      "3552/5349 [==================>...........] - ETA: 1s - loss: 0.1309 - accuracy: 0.9307\n",
      "3641/5349 [===================>..........] - ETA: 1s - loss: 0.1310 - accuracy: 0.9306\n",
      "3795/5349 [====================>.........] - ETA: 0s - loss: 0.1309 - accuracy: 0.9306\n",
      "3963/5349 [=====================>........] - ETA: 0s - loss: 0.1309 - accuracy: 0.9306\n",
      "4212/5349 [======================>.......] - ETA: 0s - loss: 0.1309 - accuracy: 0.9307\n",
      "4377/5349 [=======================>......] - ETA: 0s - loss: 0.1308 - accuracy: 0.9307\n",
      "4519/5349 [========================>.....] - ETA: 0s - loss: 0.1306 - accuracy: 0.9309\n",
      "4686/5349 [=========================>....] - ETA: 0s - loss: 0.1306 - accuracy: 0.9309\n",
      "4847/5349 [==========================>...] - ETA: 0s - loss: 0.1305 - accuracy: 0.9310\n",
      "5011/5349 [===========================>..] - ETA: 0s - loss: 0.1305 - accuracy: 0.9308\n",
      "5178/5349 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9308\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9309\n",
      "5349/5349 [==============================] - 4s 811us/step - loss: 0.1303 - accuracy: 0.9308 - val_loss: 0.1276 - val_accuracy: 0.9314\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 7/20\n",
      "  82/5349 [..............................] - ETA: 3s - loss: 0.1273 - accuracy: 0.9330\n",
      " 254/5349 [>.............................] - ETA: 3s - loss: 0.1290 - accuracy: 0.9304\n",
      " 424/5349 [=>............................] - ETA: 2s - loss: 0.1287 - accuracy: 0.9298\n",
      " 507/5349 [=>............................] - ETA: 2s - loss: 0.1286 - accuracy: 0.9306\n",
      " 668/5349 [==>...........................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9301\n",
      " 832/5349 [===>..........................] - ETA: 2s - loss: 0.1303 - accuracy: 0.9297\n",
      " 999/5349 [====>.........................] - ETA: 2s - loss: 0.1293 - accuracy: 0.9303\n",
      "1164/5349 [=====>........................] - ETA: 2s - loss: 0.1291 - accuracy: 0.9306\n",
      "1317/5349 [======>.......................] - ETA: 2s - loss: 0.1292 - accuracy: 0.9308\n",
      "1489/5349 [=======>......................] - ETA: 2s - loss: 0.1288 - accuracy: 0.9313\n",
      "1651/5349 [========>.....................] - ETA: 2s - loss: 0.1288 - accuracy: 0.9312\n",
      "1815/5349 [=========>....................] - ETA: 2s - loss: 0.1289 - accuracy: 0.9311\n",
      "2073/5349 [==========>...................] - ETA: 1s - loss: 0.1286 - accuracy: 0.9314\n",
      "2240/5349 [===========>..................] - ETA: 1s - loss: 0.1286 - accuracy: 0.9315\n",
      "2403/5349 [============>.................] - ETA: 1s - loss: 0.1284 - accuracy: 0.9316\n",
      "2559/5349 [=============>................] - ETA: 1s - loss: 0.1284 - accuracy: 0.9318\n",
      "2727/5349 [==============>...............] - ETA: 1s - loss: 0.1284 - accuracy: 0.9319\n",
      "2891/5349 [===============>..............] - ETA: 1s - loss: 0.1285 - accuracy: 0.9318\n",
      "3037/5349 [================>.............] - ETA: 1s - loss: 0.1283 - accuracy: 0.9320\n",
      "3165/5349 [================>.............] - ETA: 1s - loss: 0.1282 - accuracy: 0.9320\n",
      "3254/5349 [=================>............] - ETA: 1s - loss: 0.1283 - accuracy: 0.9320\n",
      "3437/5349 [==================>...........] - ETA: 1s - loss: 0.1282 - accuracy: 0.9319\n",
      "3555/5349 [==================>...........] - ETA: 1s - loss: 0.1282 - accuracy: 0.9320\n",
      "3688/5349 [===================>..........] - ETA: 1s - loss: 0.1280 - accuracy: 0.9322\n",
      "3820/5349 [====================>.........] - ETA: 1s - loss: 0.1280 - accuracy: 0.9323\n",
      "3949/5349 [=====================>........] - ETA: 0s - loss: 0.1281 - accuracy: 0.9323\n",
      "4078/5349 [=====================>........] - ETA: 0s - loss: 0.1280 - accuracy: 0.9323\n",
      "4149/5349 [======================>.......] - ETA: 0s - loss: 0.1280 - accuracy: 0.9323\n",
      "4288/5349 [=======================>......] - ETA: 0s - loss: 0.1279 - accuracy: 0.9322\n",
      "4381/5349 [=======================>......] - ETA: 0s - loss: 0.1279 - accuracy: 0.9323\n",
      "4482/5349 [========================>.....] - ETA: 0s - loss: 0.1279 - accuracy: 0.9323\n",
      "4614/5349 [========================>.....] - ETA: 0s - loss: 0.1280 - accuracy: 0.9323\n",
      "4753/5349 [=========================>....] - ETA: 0s - loss: 0.1279 - accuracy: 0.9323\n",
      "4911/5349 [==========================>...] - ETA: 0s - loss: 0.1278 - accuracy: 0.9324\n",
      "5082/5349 [===========================>..] - ETA: 0s - loss: 0.1277 - accuracy: 0.9324\n",
      "5247/5349 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9324\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9324\n",
      "5349/5349 [==============================] - 5s 854us/step - loss: 0.1277 - accuracy: 0.9324 - val_loss: 0.1277 - val_accuracy: 0.9318\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 8/20\n",
      "  83/5349 [..............................] - ETA: 3s - loss: 0.1289 - accuracy: 0.9306 \n",
      " 245/5349 [>.............................] - ETA: 3s - loss: 0.1269 - accuracy: 0.9327\n",
      " 409/5349 [=>............................] - ETA: 3s - loss: 0.1266 - accuracy: 0.9336\n",
      " 564/5349 [==>...........................] - ETA: 2s - loss: 0.1259 - accuracy: 0.9341\n",
      " 730/5349 [===>..........................] - ETA: 2s - loss: 0.1255 - accuracy: 0.9343\n",
      " 809/5349 [===>..........................] - ETA: 2s - loss: 0.1256 - accuracy: 0.9342\n",
      " 957/5349 [====>.........................] - ETA: 2s - loss: 0.1257 - accuracy: 0.9338\n",
      "1126/5349 [=====>........................] - ETA: 2s - loss: 0.1261 - accuracy: 0.9334\n",
      "1291/5349 [======>.......................] - ETA: 2s - loss: 0.1263 - accuracy: 0.9336\n",
      "1463/5349 [=======>......................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9339\n",
      "1621/5349 [========>.....................] - ETA: 2s - loss: 0.1261 - accuracy: 0.9335\n",
      "1791/5349 [=========>....................] - ETA: 2s - loss: 0.1261 - accuracy: 0.9334\n",
      "1941/5349 [=========>....................] - ETA: 2s - loss: 0.1259 - accuracy: 0.9335\n",
      "2111/5349 [==========>...................] - ETA: 2s - loss: 0.1262 - accuracy: 0.9334\n",
      "2268/5349 [===========>..................] - ETA: 1s - loss: 0.1264 - accuracy: 0.9334\n",
      "2435/5349 [============>.................] - ETA: 1s - loss: 0.1262 - accuracy: 0.9335\n",
      "2539/5349 [=============>................] - ETA: 1s - loss: 0.1260 - accuracy: 0.9335\n",
      "2676/5349 [==============>...............] - ETA: 1s - loss: 0.1260 - accuracy: 0.9335\n",
      "2804/5349 [==============>...............] - ETA: 1s - loss: 0.1257 - accuracy: 0.9338\n",
      "2969/5349 [===============>..............] - ETA: 1s - loss: 0.1257 - accuracy: 0.9338\n",
      "3213/5349 [=================>............] - ETA: 1s - loss: 0.1258 - accuracy: 0.9337\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1259 - accuracy: 0.9337\n",
      "3536/5349 [==================>...........] - ETA: 1s - loss: 0.1257 - accuracy: 0.9337\n",
      "3703/5349 [===================>..........] - ETA: 1s - loss: 0.1258 - accuracy: 0.9336\n",
      "3859/5349 [====================>.........] - ETA: 0s - loss: 0.1259 - accuracy: 0.9336\n",
      "4021/5349 [=====================>........] - ETA: 0s - loss: 0.1256 - accuracy: 0.9337\n",
      "4180/5349 [======================>.......] - ETA: 0s - loss: 0.1257 - accuracy: 0.9335\n",
      "4341/5349 [=======================>......] - ETA: 0s - loss: 0.1257 - accuracy: 0.9335\n",
      "4482/5349 [========================>.....] - ETA: 0s - loss: 0.1256 - accuracy: 0.9335\n",
      "4653/5349 [=========================>....] - ETA: 0s - loss: 0.1257 - accuracy: 0.9335\n",
      "4812/5349 [=========================>....] - ETA: 0s - loss: 0.1256 - accuracy: 0.9336\n",
      "4968/5349 [==========================>...] - ETA: 0s - loss: 0.1256 - accuracy: 0.9336\n",
      "5219/5349 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9336\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9336\n",
      "5349/5349 [==============================] - 4s 811us/step - loss: 0.1256 - accuracy: 0.9336 - val_loss: 0.1242 - val_accuracy: 0.9334\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1334 - accuracy: 0.9300\n",
      " 157/5349 [..............................] - ETA: 3s - loss: 0.1248 - accuracy: 0.9322\n",
      " 317/5349 [>.............................] - ETA: 3s - loss: 0.1223 - accuracy: 0.9352\n",
      " 479/5349 [=>............................] - ETA: 3s - loss: 0.1212 - accuracy: 0.9355\n",
      " 739/5349 [===>..........................] - ETA: 2s - loss: 0.1233 - accuracy: 0.9340\n",
      " 899/5349 [====>.........................] - ETA: 2s - loss: 0.1228 - accuracy: 0.9341\n",
      "1058/5349 [====>.........................] - ETA: 2s - loss: 0.1233 - accuracy: 0.9338\n",
      "1206/5349 [=====>........................] - ETA: 2s - loss: 0.1229 - accuracy: 0.9341\n",
      "1376/5349 [======>.......................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9341\n",
      "1539/5349 [=======>......................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9340\n",
      "1675/5349 [========>.....................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9340\n",
      "1924/5349 [=========>....................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9343\n",
      "2095/5349 [==========>...................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9344\n",
      "2259/5349 [===========>..................] - ETA: 1s - loss: 0.1234 - accuracy: 0.9345\n",
      "2426/5349 [============>.................] - ETA: 1s - loss: 0.1237 - accuracy: 0.9344\n",
      "2595/5349 [=============>................] - ETA: 1s - loss: 0.1235 - accuracy: 0.9345\n",
      "2764/5349 [==============>...............] - ETA: 1s - loss: 0.1235 - accuracy: 0.9346\n",
      "2926/5349 [===============>..............] - ETA: 1s - loss: 0.1234 - accuracy: 0.9346\n",
      "3093/5349 [================>.............] - ETA: 1s - loss: 0.1233 - accuracy: 0.9348\n",
      "3248/5349 [=================>............] - ETA: 1s - loss: 0.1232 - accuracy: 0.9348\n",
      "3385/5349 [=================>............] - ETA: 1s - loss: 0.1235 - accuracy: 0.9347\n",
      "3539/5349 [==================>...........] - ETA: 1s - loss: 0.1236 - accuracy: 0.9347\n",
      "3794/5349 [====================>.........] - ETA: 0s - loss: 0.1237 - accuracy: 0.9345\n",
      "3955/5349 [=====================>........] - ETA: 0s - loss: 0.1237 - accuracy: 0.9345\n",
      "4128/5349 [======================>.......] - ETA: 0s - loss: 0.1238 - accuracy: 0.9345\n",
      "4294/5349 [=======================>......] - ETA: 0s - loss: 0.1238 - accuracy: 0.9345\n",
      "4462/5349 [========================>.....] - ETA: 0s - loss: 0.1238 - accuracy: 0.9345\n",
      "4629/5349 [========================>.....] - ETA: 0s - loss: 0.1237 - accuracy: 0.9344\n",
      "4801/5349 [=========================>....] - ETA: 0s - loss: 0.1237 - accuracy: 0.9345\n",
      "4965/5349 [==========================>...] - ETA: 0s - loss: 0.1237 - accuracy: 0.9344\n",
      "5136/5349 [===========================>..] - ETA: 0s - loss: 0.1238 - accuracy: 0.9343\n",
      "5290/5349 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.9344\n",
      "5349/5349 [==============================] - 4s 782us/step - loss: 0.1238 - accuracy: 0.9344 - val_loss: 0.1217 - val_accuracy: 0.9356\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 10/20\n",
      "  82/5349 [..............................] - ETA: 3s - loss: 0.1213 - accuracy: 0.9338\n",
      " 209/5349 [>.............................] - ETA: 3s - loss: 0.1224 - accuracy: 0.9339\n",
      " 421/5349 [=>............................] - ETA: 3s - loss: 0.1222 - accuracy: 0.9353\n",
      " 539/5349 [==>...........................] - ETA: 3s - loss: 0.1229 - accuracy: 0.9349\n",
      " 674/5349 [==>...........................] - ETA: 3s - loss: 0.1227 - accuracy: 0.9351\n",
      " 793/5349 [===>..........................] - ETA: 3s - loss: 0.1227 - accuracy: 0.9351\n",
      " 930/5349 [====>.........................] - ETA: 3s - loss: 0.1230 - accuracy: 0.9353\n",
      "1061/5349 [====>.........................] - ETA: 3s - loss: 0.1227 - accuracy: 0.9353\n",
      "1262/5349 [======>.......................] - ETA: 3s - loss: 0.1227 - accuracy: 0.9352\n",
      "1389/5349 [======>.......................] - ETA: 3s - loss: 0.1227 - accuracy: 0.9350\n",
      "1475/5349 [=======>......................] - ETA: 3s - loss: 0.1228 - accuracy: 0.9349\n",
      "1595/5349 [=======>......................] - ETA: 2s - loss: 0.1228 - accuracy: 0.9348\n",
      "1733/5349 [========>.....................] - ETA: 2s - loss: 0.1227 - accuracy: 0.9348\n",
      "1875/5349 [=========>....................] - ETA: 2s - loss: 0.1227 - accuracy: 0.9350\n",
      "2011/5349 [==========>...................] - ETA: 2s - loss: 0.1228 - accuracy: 0.9351\n",
      "2250/5349 [===========>..................] - ETA: 2s - loss: 0.1227 - accuracy: 0.9349\n",
      "2415/5349 [============>.................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9349\n",
      "2577/5349 [=============>................] - ETA: 2s - loss: 0.1227 - accuracy: 0.9351\n",
      "2737/5349 [==============>...............] - ETA: 1s - loss: 0.1228 - accuracy: 0.9349\n",
      "2900/5349 [===============>..............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9350\n",
      "3062/5349 [================>.............] - ETA: 1s - loss: 0.1227 - accuracy: 0.9348\n",
      "3217/5349 [=================>............] - ETA: 1s - loss: 0.1228 - accuracy: 0.9347\n",
      "3385/5349 [=================>............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9349\n",
      "3551/5349 [==================>...........] - ETA: 1s - loss: 0.1227 - accuracy: 0.9348\n",
      "3795/5349 [====================>.........] - ETA: 1s - loss: 0.1225 - accuracy: 0.9349\n",
      "3959/5349 [=====================>........] - ETA: 0s - loss: 0.1224 - accuracy: 0.9349\n",
      "4125/5349 [======================>.......] - ETA: 0s - loss: 0.1223 - accuracy: 0.9351\n",
      "4288/5349 [=======================>......] - ETA: 0s - loss: 0.1222 - accuracy: 0.9352\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.1223 - accuracy: 0.9351\n",
      "4594/5349 [========================>.....] - ETA: 0s - loss: 0.1223 - accuracy: 0.9352\n",
      "4754/5349 [=========================>....] - ETA: 0s - loss: 0.1222 - accuracy: 0.9352\n",
      "4918/5349 [==========================>...] - ETA: 0s - loss: 0.1222 - accuracy: 0.9352\n",
      "5165/5349 [===========================>..] - ETA: 0s - loss: 0.1222 - accuracy: 0.9353\n",
      "5327/5349 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9354\n",
      "5349/5349 [==============================] - 5s 856us/step - loss: 0.1221 - accuracy: 0.9354 - val_loss: 0.1209 - val_accuracy: 0.9361\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 15s - loss: 0.0878 - accuracy: 0.9600\n",
      " 144/5349 [..............................] - ETA: 3s - loss: 0.1212 - accuracy: 0.9367\n",
      " 305/5349 [>.............................] - ETA: 3s - loss: 0.1190 - accuracy: 0.9380\n",
      " 456/5349 [=>............................] - ETA: 3s - loss: 0.1187 - accuracy: 0.9379\n",
      " 610/5349 [==>...........................] - ETA: 3s - loss: 0.1193 - accuracy: 0.9378\n",
      " 750/5349 [===>..........................] - ETA: 3s - loss: 0.1192 - accuracy: 0.9377\n",
      " 920/5349 [====>.........................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9368\n",
      "1081/5349 [=====>........................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9367\n",
      "1253/5349 [======>.......................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9364\n",
      "1491/5349 [=======>......................] - ETA: 2s - loss: 0.1206 - accuracy: 0.9360\n",
      "1647/5349 [========>.....................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9362\n",
      "1815/5349 [=========>....................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9363\n",
      "1988/5349 [==========>...................] - ETA: 2s - loss: 0.1200 - accuracy: 0.9363\n",
      "2158/5349 [===========>..................] - ETA: 2s - loss: 0.1200 - accuracy: 0.9364\n",
      "2330/5349 [============>.................] - ETA: 1s - loss: 0.1200 - accuracy: 0.9363\n",
      "2489/5349 [============>.................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9365\n",
      "2633/5349 [=============>................] - ETA: 1s - loss: 0.1203 - accuracy: 0.9363\n",
      "2786/5349 [==============>...............] - ETA: 1s - loss: 0.1202 - accuracy: 0.9365\n",
      "3039/5349 [================>.............] - ETA: 1s - loss: 0.1203 - accuracy: 0.9364\n",
      "3173/5349 [================>.............] - ETA: 1s - loss: 0.1204 - accuracy: 0.9363\n",
      "3339/5349 [=================>............] - ETA: 1s - loss: 0.1202 - accuracy: 0.9364\n",
      "3505/5349 [==================>...........] - ETA: 1s - loss: 0.1203 - accuracy: 0.9364\n",
      "3671/5349 [===================>..........] - ETA: 1s - loss: 0.1204 - accuracy: 0.9364\n",
      "3839/5349 [====================>.........] - ETA: 0s - loss: 0.1204 - accuracy: 0.9364\n",
      "4004/5349 [=====================>........] - ETA: 0s - loss: 0.1203 - accuracy: 0.9363\n",
      "4173/5349 [======================>.......] - ETA: 0s - loss: 0.1203 - accuracy: 0.9363\n",
      "4413/5349 [=======================>......] - ETA: 0s - loss: 0.1206 - accuracy: 0.9362\n",
      "4579/5349 [========================>.....] - ETA: 0s - loss: 0.1206 - accuracy: 0.9361\n",
      "4749/5349 [=========================>....] - ETA: 0s - loss: 0.1205 - accuracy: 0.9363\n",
      "4906/5349 [==========================>...] - ETA: 0s - loss: 0.1206 - accuracy: 0.9361\n",
      "5065/5349 [===========================>..] - ETA: 0s - loss: 0.1207 - accuracy: 0.9361\n",
      "5203/5349 [============================>.] - ETA: 0s - loss: 0.1207 - accuracy: 0.9361\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9361\n",
      "5349/5349 [==============================] - 4s 795us/step - loss: 0.1205 - accuracy: 0.9361 - val_loss: 0.1182 - val_accuracy: 0.9393\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 12/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1226 - accuracy: 0.9370\n",
      " 170/5349 [..............................] - ETA: 3s - loss: 0.1197 - accuracy: 0.9375\n",
      " 338/5349 [>.............................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9368\n",
      " 509/5349 [=>............................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9362\n",
      " 671/5349 [==>...........................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9365\n",
      " 843/5349 [===>..........................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9367\n",
      "1001/5349 [====>.........................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9372\n",
      "1140/5349 [=====>........................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9371\n",
      "1289/5349 [======>.......................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9369\n",
      "1546/5349 [=======>......................] - ETA: 2s - loss: 0.1193 - accuracy: 0.9370\n",
      "1706/5349 [========>.....................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9368\n",
      "1878/5349 [=========>....................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9370\n",
      "2042/5349 [==========>...................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9368\n",
      "2202/5349 [===========>..................] - ETA: 1s - loss: 0.1191 - accuracy: 0.9369\n",
      "2355/5349 [============>.................] - ETA: 1s - loss: 0.1191 - accuracy: 0.9367\n",
      "2524/5349 [=============>................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9367\n",
      "2770/5349 [==============>...............] - ETA: 1s - loss: 0.1198 - accuracy: 0.9366\n",
      "2929/5349 [===============>..............] - ETA: 1s - loss: 0.1199 - accuracy: 0.9364\n",
      "3067/5349 [================>.............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9362\n",
      "3230/5349 [=================>............] - ETA: 1s - loss: 0.1198 - accuracy: 0.9361\n",
      "3386/5349 [=================>............] - ETA: 1s - loss: 0.1198 - accuracy: 0.9361\n",
      "3548/5349 [==================>...........] - ETA: 1s - loss: 0.1198 - accuracy: 0.9361\n",
      "3700/5349 [===================>..........] - ETA: 1s - loss: 0.1198 - accuracy: 0.9361\n",
      "3847/5349 [====================>.........] - ETA: 0s - loss: 0.1200 - accuracy: 0.9361\n",
      "3999/5349 [=====================>........] - ETA: 0s - loss: 0.1200 - accuracy: 0.9361\n",
      "4130/5349 [======================>.......] - ETA: 0s - loss: 0.1198 - accuracy: 0.9362\n",
      "4230/5349 [======================>.......] - ETA: 0s - loss: 0.1198 - accuracy: 0.9363\n",
      "4339/5349 [=======================>......] - ETA: 0s - loss: 0.1198 - accuracy: 0.9363\n",
      "4434/5349 [=======================>......] - ETA: 0s - loss: 0.1198 - accuracy: 0.9364\n",
      "4548/5349 [========================>.....] - ETA: 0s - loss: 0.1198 - accuracy: 0.9364\n",
      "4674/5349 [=========================>....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9365\n",
      "4803/5349 [=========================>....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9364\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.1195 - accuracy: 0.9365\n",
      "5078/5349 [===========================>..] - ETA: 0s - loss: 0.1195 - accuracy: 0.9364\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9366\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.9366\n",
      "5349/5349 [==============================] - 5s 879us/step - loss: 0.1193 - accuracy: 0.9366 - val_loss: 0.1174 - val_accuracy: 0.9373\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 13/20\n",
      "  83/5349 [..............................] - ETA: 3s - loss: 0.1235 - accuracy: 0.9342\n",
      " 236/5349 [>.............................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9394\n",
      " 321/5349 [>.............................] - ETA: 3s - loss: 0.1183 - accuracy: 0.9379\n",
      " 480/5349 [=>............................] - ETA: 3s - loss: 0.1183 - accuracy: 0.9378\n",
      " 640/5349 [==>...........................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9374\n",
      " 812/5349 [===>..........................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9368\n",
      " 979/5349 [====>.........................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9370\n",
      "1145/5349 [=====>........................] - ETA: 2s - loss: 0.1197 - accuracy: 0.9366\n",
      "1309/5349 [======>.......................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9366\n",
      "1479/5349 [=======>......................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9365\n",
      "1728/5349 [========>.....................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9368\n",
      "1895/5349 [=========>....................] - ETA: 2s - loss: 0.1187 - accuracy: 0.9367\n",
      "2055/5349 [==========>...................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9368\n",
      "2218/5349 [===========>..................] - ETA: 1s - loss: 0.1185 - accuracy: 0.9367\n",
      "2376/5349 [============>.................] - ETA: 1s - loss: 0.1186 - accuracy: 0.9366\n",
      "2546/5349 [=============>................] - ETA: 1s - loss: 0.1182 - accuracy: 0.9368\n",
      "2699/5349 [==============>...............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9367\n",
      "2866/5349 [===============>..............] - ETA: 1s - loss: 0.1181 - accuracy: 0.9369\n",
      "3031/5349 [===============>..............] - ETA: 1s - loss: 0.1181 - accuracy: 0.9370\n",
      "3115/5349 [================>.............] - ETA: 1s - loss: 0.1180 - accuracy: 0.9371\n",
      "3284/5349 [=================>............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9370\n",
      "3451/5349 [==================>...........] - ETA: 1s - loss: 0.1184 - accuracy: 0.9369\n",
      "3562/5349 [==================>...........] - ETA: 1s - loss: 0.1184 - accuracy: 0.9369\n",
      "3726/5349 [===================>..........] - ETA: 1s - loss: 0.1183 - accuracy: 0.9369\n",
      "3896/5349 [====================>.........] - ETA: 0s - loss: 0.1183 - accuracy: 0.9370\n",
      "4064/5349 [=====================>........] - ETA: 0s - loss: 0.1181 - accuracy: 0.9371\n",
      "4234/5349 [======================>.......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9371\n",
      "4393/5349 [=======================>......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9370\n",
      "4563/5349 [========================>.....] - ETA: 0s - loss: 0.1182 - accuracy: 0.9369\n",
      "4650/5349 [=========================>....] - ETA: 0s - loss: 0.1182 - accuracy: 0.9369\n",
      "4811/5349 [=========================>....] - ETA: 0s - loss: 0.1183 - accuracy: 0.9369\n",
      "4980/5349 [==========================>...] - ETA: 0s - loss: 0.1183 - accuracy: 0.9370\n",
      "5094/5349 [===========================>..] - ETA: 0s - loss: 0.1184 - accuracy: 0.9370\n",
      "5260/5349 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9369\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9370\n",
      "5349/5349 [==============================] - 4s 789us/step - loss: 0.1183 - accuracy: 0.9370 - val_loss: 0.1158 - val_accuracy: 0.9377\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0960 - accuracy: 0.9400\n",
      " 171/5349 [..............................] - ETA: 3s - loss: 0.1161 - accuracy: 0.9346\n",
      " 342/5349 [>.............................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9356\n",
      " 509/5349 [=>............................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9369\n",
      " 678/5349 [==>...........................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9381\n",
      " 838/5349 [===>..........................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9381\n",
      "1010/5349 [====>.........................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9382\n",
      "1173/5349 [=====>........................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9386\n",
      "1429/5349 [=======>......................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9382\n",
      "1596/5349 [=======>......................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9383\n",
      "1760/5349 [========>.....................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9380\n",
      "1925/5349 [=========>....................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9376\n",
      "2098/5349 [==========>...................] - ETA: 1s - loss: 0.1174 - accuracy: 0.9374\n",
      "2265/5349 [===========>..................] - ETA: 1s - loss: 0.1173 - accuracy: 0.9375\n",
      "2414/5349 [============>.................] - ETA: 1s - loss: 0.1173 - accuracy: 0.9375\n",
      "2571/5349 [=============>................] - ETA: 1s - loss: 0.1176 - accuracy: 0.9373\n",
      "2742/5349 [==============>...............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9375\n",
      "2908/5349 [===============>..............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9377\n",
      "3164/5349 [================>.............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9376\n",
      "3326/5349 [=================>............] - ETA: 1s - loss: 0.1171 - accuracy: 0.9377\n",
      "3494/5349 [==================>...........] - ETA: 1s - loss: 0.1170 - accuracy: 0.9376\n",
      "3648/5349 [===================>..........] - ETA: 1s - loss: 0.1169 - accuracy: 0.9377\n",
      "3817/5349 [====================>.........] - ETA: 0s - loss: 0.1172 - accuracy: 0.9375\n",
      "3970/5349 [=====================>........] - ETA: 0s - loss: 0.1172 - accuracy: 0.9373\n",
      "4218/5349 [======================>.......] - ETA: 0s - loss: 0.1172 - accuracy: 0.9373\n",
      "4381/5349 [=======================>......] - ETA: 0s - loss: 0.1173 - accuracy: 0.9372\n",
      "4554/5349 [========================>.....] - ETA: 0s - loss: 0.1173 - accuracy: 0.9373\n",
      "4722/5349 [=========================>....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9373\n",
      "4893/5349 [==========================>...] - ETA: 0s - loss: 0.1171 - accuracy: 0.9373\n",
      "5050/5349 [===========================>..] - ETA: 0s - loss: 0.1171 - accuracy: 0.9374\n",
      "5221/5349 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9374\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9374\n",
      "5349/5349 [==============================] - 4s 770us/step - loss: 0.1171 - accuracy: 0.9374 - val_loss: 0.1144 - val_accuracy: 0.9394\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.0604 - accuracy: 0.9900\n",
      " 170/5349 [..............................] - ETA: 3s - loss: 0.1171 - accuracy: 0.9370\n",
      " 335/5349 [>.............................] - ETA: 3s - loss: 0.1136 - accuracy: 0.9397\n",
      " 576/5349 [==>...........................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9390\n",
      " 743/5349 [===>..........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9383\n",
      " 907/5349 [====>.........................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9376\n",
      "1002/5349 [====>.........................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9374\n",
      "1127/5349 [=====>........................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9376\n",
      "1237/5349 [=====>........................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9375\n",
      "1349/5349 [======>.......................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9378\n",
      "1450/5349 [=======>......................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9379\n",
      "1581/5349 [=======>......................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9375\n",
      "1725/5349 [========>.....................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9372\n",
      "1920/5349 [=========>....................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9373\n",
      "2066/5349 [==========>...................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9372\n",
      "2189/5349 [===========>..................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9374\n",
      "2269/5349 [===========>..................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9374\n",
      "2405/5349 [============>.................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9377\n",
      "2529/5349 [=============>................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9376\n",
      "2623/5349 [=============>................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9378\n",
      "2793/5349 [==============>...............] - ETA: 1s - loss: 0.1167 - accuracy: 0.9377\n",
      "2956/5349 [===============>..............] - ETA: 1s - loss: 0.1165 - accuracy: 0.9377\n",
      "3121/5349 [================>.............] - ETA: 1s - loss: 0.1165 - accuracy: 0.9378\n",
      "3206/5349 [================>.............] - ETA: 1s - loss: 0.1163 - accuracy: 0.9379\n",
      "3355/5349 [=================>............] - ETA: 1s - loss: 0.1164 - accuracy: 0.9378\n",
      "3519/5349 [==================>...........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9379\n",
      "3678/5349 [===================>..........] - ETA: 1s - loss: 0.1162 - accuracy: 0.9379\n",
      "3835/5349 [====================>.........] - ETA: 1s - loss: 0.1159 - accuracy: 0.9382\n",
      "3982/5349 [=====================>........] - ETA: 0s - loss: 0.1159 - accuracy: 0.9381\n",
      "4120/5349 [======================>.......] - ETA: 0s - loss: 0.1160 - accuracy: 0.9381\n",
      "4266/5349 [======================>.......] - ETA: 0s - loss: 0.1161 - accuracy: 0.9380\n",
      "4432/5349 [=======================>......] - ETA: 0s - loss: 0.1161 - accuracy: 0.9379\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9378\n",
      "4683/5349 [=========================>....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9379\n",
      "4850/5349 [==========================>...] - ETA: 0s - loss: 0.1162 - accuracy: 0.9379\n",
      "5001/5349 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9378\n",
      "5170/5349 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9377\n",
      "5334/5349 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.9377\n",
      "5349/5349 [==============================] - 5s 867us/step - loss: 0.1163 - accuracy: 0.9377 - val_loss: 0.1170 - val_accuracy: 0.9377\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 16/20\n",
      "  76/5349 [..............................] - ETA: 3s - loss: 0.1204 - accuracy: 0.9363\n",
      " 191/5349 [>.............................] - ETA: 4s - loss: 0.1202 - accuracy: 0.9350\n",
      " 362/5349 [=>............................] - ETA: 3s - loss: 0.1175 - accuracy: 0.9367\n",
      " 516/5349 [=>............................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9365\n",
      " 681/5349 [==>...........................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9377\n",
      " 844/5349 [===>..........................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9374\n",
      " 931/5349 [====>.........................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9375\n",
      "1089/5349 [=====>........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9379\n",
      "1229/5349 [=====>........................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9376\n",
      "1389/5349 [======>.......................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9373\n",
      "1554/5349 [=======>......................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9374\n",
      "1714/5349 [========>.....................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9376\n",
      "1927/5349 [=========>....................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9377\n",
      "2080/5349 [==========>...................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9378\n",
      "2243/5349 [===========>..................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9380\n",
      "2390/5349 [============>.................] - ETA: 1s - loss: 0.1161 - accuracy: 0.9378\n",
      "2547/5349 [=============>................] - ETA: 1s - loss: 0.1162 - accuracy: 0.9378\n",
      "2709/5349 [==============>...............] - ETA: 1s - loss: 0.1162 - accuracy: 0.9380\n",
      "2871/5349 [===============>..............] - ETA: 1s - loss: 0.1162 - accuracy: 0.9380\n",
      "3042/5349 [================>.............] - ETA: 1s - loss: 0.1160 - accuracy: 0.9381\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1159 - accuracy: 0.9380\n",
      "3448/5349 [==================>...........] - ETA: 1s - loss: 0.1160 - accuracy: 0.9378\n",
      "3598/5349 [===================>..........] - ETA: 1s - loss: 0.1160 - accuracy: 0.9378\n",
      "3744/5349 [===================>..........] - ETA: 1s - loss: 0.1161 - accuracy: 0.9379\n",
      "3899/5349 [====================>.........] - ETA: 0s - loss: 0.1162 - accuracy: 0.9379\n",
      "4061/5349 [=====================>........] - ETA: 0s - loss: 0.1161 - accuracy: 0.9380\n",
      "4230/5349 [======================>.......] - ETA: 0s - loss: 0.1161 - accuracy: 0.9380\n",
      "4395/5349 [=======================>......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9381\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.1160 - accuracy: 0.9381\n",
      "4730/5349 [=========================>....] - ETA: 0s - loss: 0.1159 - accuracy: 0.9380\n",
      "4982/5349 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.9381\n",
      "5140/5349 [===========================>..] - ETA: 0s - loss: 0.1157 - accuracy: 0.9382\n",
      "5303/5349 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9382\n",
      "5349/5349 [==============================] - 4s 800us/step - loss: 0.1156 - accuracy: 0.9381 - val_loss: 0.1142 - val_accuracy: 0.9361\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0994 - accuracy: 0.9500\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9394\n",
      " 336/5349 [>.............................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9377\n",
      " 499/5349 [=>............................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9384\n",
      " 755/5349 [===>..........................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9369\n",
      " 916/5349 [====>.........................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9369\n",
      "1088/5349 [=====>........................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9374\n",
      "1245/5349 [=====>........................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9375\n",
      "1412/5349 [======>.......................] - ETA: 2s - loss: 0.1160 - accuracy: 0.9381\n",
      "1578/5349 [=======>......................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9385\n",
      "1747/5349 [========>.....................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9385\n",
      "1887/5349 [=========>....................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9387\n",
      "2051/5349 [==========>...................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9384\n",
      "2216/5349 [===========>..................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9387\n",
      "2300/5349 [===========>..................] - ETA: 1s - loss: 0.1152 - accuracy: 0.9387\n",
      "2470/5349 [============>.................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9386\n",
      "2629/5349 [=============>................] - ETA: 1s - loss: 0.1151 - accuracy: 0.9386\n",
      "2797/5349 [==============>...............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9384\n",
      "2956/5349 [===============>..............] - ETA: 1s - loss: 0.1150 - accuracy: 0.9385\n",
      "3124/5349 [================>.............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9383\n",
      "3288/5349 [=================>............] - ETA: 1s - loss: 0.1152 - accuracy: 0.9383\n",
      "3438/5349 [==================>...........] - ETA: 1s - loss: 0.1153 - accuracy: 0.9382\n",
      "3595/5349 [===================>..........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9383\n",
      "3843/5349 [====================>.........] - ETA: 0s - loss: 0.1153 - accuracy: 0.9381\n",
      "3984/5349 [=====================>........] - ETA: 0s - loss: 0.1153 - accuracy: 0.9381\n",
      "4143/5349 [======================>.......] - ETA: 0s - loss: 0.1152 - accuracy: 0.9381\n",
      "4310/5349 [=======================>......] - ETA: 0s - loss: 0.1153 - accuracy: 0.9381\n",
      "4475/5349 [========================>.....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9380\n",
      "4592/5349 [========================>.....] - ETA: 0s - loss: 0.1152 - accuracy: 0.9381\n",
      "4706/5349 [=========================>....] - ETA: 0s - loss: 0.1152 - accuracy: 0.9381\n",
      "4835/5349 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9381\n",
      "4966/5349 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9381\n",
      "5098/5349 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9381\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9382\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9383\n",
      "5349/5349 [==============================] - 5s 846us/step - loss: 0.1150 - accuracy: 0.9383 - val_loss: 0.1164 - val_accuracy: 0.9357\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.0805 - accuracy: 0.9500\n",
      " 162/5349 [..............................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9359\n",
      " 416/5349 [=>............................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9363\n",
      " 573/5349 [==>...........................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9359\n",
      " 746/5349 [===>..........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9368\n",
      " 884/5349 [===>..........................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9372\n",
      "1035/5349 [====>.........................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9376\n",
      "1202/5349 [=====>........................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9379\n",
      "1366/5349 [======>.......................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9379\n",
      "1527/5349 [=======>......................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9377\n",
      "1694/5349 [========>.....................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9376\n",
      "1845/5349 [=========>....................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9376\n",
      "1925/5349 [=========>....................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9377\n",
      "2093/5349 [==========>...................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9379\n",
      "2246/5349 [===========>..................] - ETA: 1s - loss: 0.1146 - accuracy: 0.9381\n",
      "2402/5349 [============>.................] - ETA: 1s - loss: 0.1146 - accuracy: 0.9383\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9385\n",
      "2690/5349 [==============>...............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9384\n",
      "2850/5349 [==============>...............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9383\n",
      "3008/5349 [===============>..............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9384\n",
      "3160/5349 [================>.............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9384\n",
      "3398/5349 [==================>...........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9386\n",
      "3549/5349 [==================>...........] - ETA: 1s - loss: 0.1143 - accuracy: 0.9386\n",
      "3700/5349 [===================>..........] - ETA: 1s - loss: 0.1143 - accuracy: 0.9387\n",
      "3841/5349 [====================>.........] - ETA: 0s - loss: 0.1144 - accuracy: 0.9386\n",
      "3941/5349 [=====================>........] - ETA: 0s - loss: 0.1143 - accuracy: 0.9386\n",
      "4095/5349 [=====================>........] - ETA: 0s - loss: 0.1143 - accuracy: 0.9387\n",
      "4259/5349 [======================>.......] - ETA: 0s - loss: 0.1143 - accuracy: 0.9388\n",
      "4506/5349 [========================>.....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9387\n",
      "4662/5349 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9388\n",
      "4819/5349 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9387\n",
      "4985/5349 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9388\n",
      "5129/5349 [===========================>..] - ETA: 0s - loss: 0.1145 - accuracy: 0.9387\n",
      "5288/5349 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9387\n",
      "5349/5349 [==============================] - 4s 811us/step - loss: 0.1145 - accuracy: 0.9387 - val_loss: 0.1171 - val_accuracy: 0.9367\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 19/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9358\n",
      " 254/5349 [>.............................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9384\n",
      " 428/5349 [=>............................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9368\n",
      " 595/5349 [==>...........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9371\n",
      " 766/5349 [===>..........................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9376\n",
      " 933/5349 [====>.........................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9380\n",
      "1106/5349 [=====>........................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9382\n",
      "1263/5349 [======>.......................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9384\n",
      "1433/5349 [=======>......................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9386\n",
      "1596/5349 [=======>......................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9384\n",
      "1853/5349 [=========>....................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9384\n",
      "2006/5349 [==========>...................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9383\n",
      "2163/5349 [===========>..................] - ETA: 1s - loss: 0.1141 - accuracy: 0.9387\n",
      "2324/5349 [============>.................] - ETA: 1s - loss: 0.1142 - accuracy: 0.9387\n",
      "2485/5349 [============>.................] - ETA: 1s - loss: 0.1141 - accuracy: 0.9387\n",
      "2634/5349 [=============>................] - ETA: 1s - loss: 0.1141 - accuracy: 0.9386\n",
      "2804/5349 [==============>...............] - ETA: 1s - loss: 0.1140 - accuracy: 0.9386\n",
      "3049/5349 [================>.............] - ETA: 1s - loss: 0.1136 - accuracy: 0.9388\n",
      "3221/5349 [=================>............] - ETA: 1s - loss: 0.1132 - accuracy: 0.9389\n",
      "3388/5349 [==================>...........] - ETA: 1s - loss: 0.1132 - accuracy: 0.9391\n",
      "3557/5349 [==================>...........] - ETA: 1s - loss: 0.1134 - accuracy: 0.9389\n",
      "3722/5349 [===================>..........] - ETA: 0s - loss: 0.1134 - accuracy: 0.9389\n",
      "3870/5349 [====================>.........] - ETA: 0s - loss: 0.1133 - accuracy: 0.9388\n",
      "4038/5349 [=====================>........] - ETA: 0s - loss: 0.1135 - accuracy: 0.9387\n",
      "4208/5349 [======================>.......] - ETA: 0s - loss: 0.1137 - accuracy: 0.9386\n",
      "4376/5349 [=======================>......] - ETA: 0s - loss: 0.1138 - accuracy: 0.9385\n",
      "4625/5349 [========================>.....] - ETA: 0s - loss: 0.1138 - accuracy: 0.9385\n",
      "4792/5349 [=========================>....] - ETA: 0s - loss: 0.1138 - accuracy: 0.9385\n",
      "4959/5349 [==========================>...] - ETA: 0s - loss: 0.1138 - accuracy: 0.9386\n",
      "5106/5349 [===========================>..] - ETA: 0s - loss: 0.1139 - accuracy: 0.9385\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.9386\n",
      "5349/5349 [==============================] - 4s 778us/step - loss: 0.1138 - accuracy: 0.9386 - val_loss: 0.1108 - val_accuracy: 0.9441\n",
      "\u001B[36m(train_DNN pid=5445)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0893 - accuracy: 0.9600\n",
      " 168/5349 [..............................] - ETA: 3s - loss: 0.1122 - accuracy: 0.9380\n",
      " 336/5349 [>.............................] - ETA: 3s - loss: 0.1127 - accuracy: 0.9391\n",
      " 498/5349 [=>............................] - ETA: 2s - loss: 0.1119 - accuracy: 0.9394\n",
      " 757/5349 [===>..........................] - ETA: 2s - loss: 0.1120 - accuracy: 0.9395\n",
      " 923/5349 [====>.........................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9390\n",
      "1090/5349 [=====>........................] - ETA: 2s - loss: 0.1126 - accuracy: 0.9393\n",
      "1250/5349 [======>.......................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9391\n",
      "1372/5349 [======>.......................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9390\n",
      "1479/5349 [=======>......................] - ETA: 2s - loss: 0.1136 - accuracy: 0.9392\n",
      "1619/5349 [========>.....................] - ETA: 2s - loss: 0.1136 - accuracy: 0.9393\n",
      "1741/5349 [========>.....................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9393\n",
      "1875/5349 [=========>....................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9395\n",
      "2009/5349 [==========>...................] - ETA: 2s - loss: 0.1132 - accuracy: 0.9396\n",
      "2083/5349 [==========>...................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9393\n",
      "2229/5349 [===========>..................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9394\n",
      "2368/5349 [============>.................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9392\n",
      "2506/5349 [=============>................] - ETA: 1s - loss: 0.1134 - accuracy: 0.9391\n",
      "2602/5349 [=============>................] - ETA: 1s - loss: 0.1135 - accuracy: 0.9391\n",
      "2695/5349 [==============>...............] - ETA: 1s - loss: 0.1136 - accuracy: 0.9390\n",
      "2825/5349 [==============>...............] - ETA: 1s - loss: 0.1136 - accuracy: 0.9390\n",
      "2966/5349 [===============>..............] - ETA: 1s - loss: 0.1134 - accuracy: 0.9391\n",
      "3104/5349 [================>.............] - ETA: 1s - loss: 0.1133 - accuracy: 0.9393\n",
      "3271/5349 [=================>............] - ETA: 1s - loss: 0.1136 - accuracy: 0.9389\n",
      "3507/5349 [==================>...........] - ETA: 1s - loss: 0.1135 - accuracy: 0.9390\n",
      "3678/5349 [===================>..........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9388\n",
      "3829/5349 [====================>.........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9389\n",
      "3998/5349 [=====================>........] - ETA: 0s - loss: 0.1136 - accuracy: 0.9390\n",
      "4164/5349 [======================>.......] - ETA: 0s - loss: 0.1135 - accuracy: 0.9390\n",
      "4332/5349 [=======================>......] - ETA: 0s - loss: 0.1135 - accuracy: 0.9390\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.1134 - accuracy: 0.9390\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1132 - accuracy: 0.9392\n",
      "4896/5349 [==========================>...] - ETA: 0s - loss: 0.1132 - accuracy: 0.9393\n",
      "5062/5349 [===========================>..] - ETA: 0s - loss: 0.1133 - accuracy: 0.9392\n",
      "5224/5349 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9392\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9392\n",
      "5349/5349 [==============================] - 5s 843us/step - loss: 0.1132 - accuracy: 0.9392 - val_loss: 0.1126 - val_accuracy: 0.9400\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 22:59 - loss: 0.7434 - accuracy: 0.1800\n",
      " 183/5349 [>.............................] - ETA: 2s - loss: 0.7153 - accuracy: 0.4102\n",
      " 363/5349 [=>............................] - ETA: 2s - loss: 0.6889 - accuracy: 0.6250\n",
      " 636/5349 [==>...........................] - ETA: 2s - loss: 0.6584 - accuracy: 0.7214\n",
      " 784/5349 [===>..........................] - ETA: 2s - loss: 0.6441 - accuracy: 0.7445\n",
      " 990/5349 [====>.........................] - ETA: 2s - loss: 0.6247 - accuracy: 0.7661\n",
      "1202/5349 [=====>........................] - ETA: 2s - loss: 0.6058 - accuracy: 0.7809\n",
      "1408/5349 [======>.......................] - ETA: 2s - loss: 0.5880 - accuracy: 0.7918\n",
      "1783/5349 [=========>....................] - ETA: 1s - loss: 0.5572 - accuracy: 0.8050\n",
      "2026/5349 [==========>...................] - ETA: 1s - loss: 0.5386 - accuracy: 0.8113\n",
      "2275/5349 [===========>..................] - ETA: 1s - loss: 0.5206 - accuracy: 0.8163\n",
      "2506/5349 [=============>................] - ETA: 1s - loss: 0.5045 - accuracy: 0.8202\n",
      "2759/5349 [==============>...............] - ETA: 1s - loss: 0.4873 - accuracy: 0.8244\n",
      "2994/5349 [===============>..............] - ETA: 1s - loss: 0.4721 - accuracy: 0.8281\n",
      "3243/5349 [=================>............] - ETA: 0s - loss: 0.4569 - accuracy: 0.8318\n",
      "3488/5349 [==================>...........] - ETA: 0s - loss: 0.4433 - accuracy: 0.8350\n",
      "3611/5349 [===================>..........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8365\n",
      "3841/5349 [====================>.........] - ETA: 0s - loss: 0.4252 - accuracy: 0.8394\n",
      "4061/5349 [=====================>........] - ETA: 0s - loss: 0.4147 - accuracy: 0.8421\n",
      "4310/5349 [=======================>......] - ETA: 0s - loss: 0.4041 - accuracy: 0.8449\n",
      "4559/5349 [========================>.....] - ETA: 0s - loss: 0.3939 - accuracy: 0.8477\n",
      "4804/5349 [=========================>....] - ETA: 0s - loss: 0.3848 - accuracy: 0.8502\n",
      "5045/5349 [===========================>..] - ETA: 0s - loss: 0.3765 - accuracy: 0.8525\n",
      "5290/5349 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8547\n",
      "5349/5349 [==============================] - 4s 646us/step - loss: 0.3670 - accuracy: 0.8551 - val_loss: 0.2054 - val_accuracy: 0.9003\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 2/20\n",
      " 124/5349 [..............................] - ETA: 2s - loss: 0.2047 - accuracy: 0.9006\n",
      " 375/5349 [=>............................] - ETA: 2s - loss: 0.2018 - accuracy: 0.9013\n",
      " 751/5349 [===>..........................] - ETA: 1s - loss: 0.2010 - accuracy: 0.9008\n",
      " 966/5349 [====>.........................] - ETA: 1s - loss: 0.2000 - accuracy: 0.9010\n",
      "1218/5349 [=====>........................] - ETA: 1s - loss: 0.1997 - accuracy: 0.9012\n",
      "1455/5349 [=======>......................] - ETA: 1s - loss: 0.1977 - accuracy: 0.9022\n",
      "1696/5349 [========>.....................] - ETA: 1s - loss: 0.1969 - accuracy: 0.9025\n",
      "1933/5349 [=========>....................] - ETA: 1s - loss: 0.1964 - accuracy: 0.9026\n",
      "2183/5349 [===========>..................] - ETA: 1s - loss: 0.1957 - accuracy: 0.9029\n",
      "2423/5349 [============>.................] - ETA: 1s - loss: 0.1949 - accuracy: 0.9033\n",
      "2676/5349 [==============>...............] - ETA: 1s - loss: 0.1943 - accuracy: 0.9035\n",
      "2921/5349 [===============>..............] - ETA: 1s - loss: 0.1936 - accuracy: 0.9037\n",
      "3038/5349 [================>.............] - ETA: 0s - loss: 0.1930 - accuracy: 0.9038\n",
      "3286/5349 [=================>............] - ETA: 0s - loss: 0.1924 - accuracy: 0.9040\n",
      "3518/5349 [==================>...........] - ETA: 0s - loss: 0.1917 - accuracy: 0.9041\n",
      "3759/5349 [====================>.........] - ETA: 0s - loss: 0.1910 - accuracy: 0.9043\n",
      "3993/5349 [=====================>........] - ETA: 0s - loss: 0.1903 - accuracy: 0.9045\n",
      "4223/5349 [======================>.......] - ETA: 0s - loss: 0.1899 - accuracy: 0.9046\n",
      "4458/5349 [========================>.....] - ETA: 0s - loss: 0.1892 - accuracy: 0.9048\n",
      "4713/5349 [=========================>....] - ETA: 0s - loss: 0.1887 - accuracy: 0.9047\n",
      "4945/5349 [==========================>...] - ETA: 0s - loss: 0.1882 - accuracy: 0.9048\n",
      "5196/5349 [============================>.] - ETA: 0s - loss: 0.1876 - accuracy: 0.9049\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9049\n",
      "5349/5349 [==============================] - 3s 578us/step - loss: 0.1874 - accuracy: 0.9050 - val_loss: 0.1773 - val_accuracy: 0.9095\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1730 - accuracy: 0.9100\n",
      " 249/5349 [>.............................] - ETA: 2s - loss: 0.1801 - accuracy: 0.9096\n",
      " 586/5349 [==>...........................] - ETA: 2s - loss: 0.1795 - accuracy: 0.9080\n",
      " 835/5349 [===>..........................] - ETA: 1s - loss: 0.1785 - accuracy: 0.9096\n",
      "1077/5349 [=====>........................] - ETA: 1s - loss: 0.1769 - accuracy: 0.9100\n",
      "1304/5349 [======>.......................] - ETA: 1s - loss: 0.1770 - accuracy: 0.9096\n",
      "1551/5349 [=======>......................] - ETA: 1s - loss: 0.1763 - accuracy: 0.9102\n",
      "1787/5349 [=========>....................] - ETA: 1s - loss: 0.1759 - accuracy: 0.9105\n",
      "2149/5349 [===========>..................] - ETA: 1s - loss: 0.1758 - accuracy: 0.9105\n",
      "2392/5349 [============>.................] - ETA: 1s - loss: 0.1754 - accuracy: 0.9106\n",
      "2638/5349 [=============>................] - ETA: 1s - loss: 0.1754 - accuracy: 0.9106\n",
      "2881/5349 [===============>..............] - ETA: 1s - loss: 0.1754 - accuracy: 0.9107\n",
      "3106/5349 [================>.............] - ETA: 0s - loss: 0.1754 - accuracy: 0.9108\n",
      "3352/5349 [=================>............] - ETA: 0s - loss: 0.1749 - accuracy: 0.9110\n",
      "3597/5349 [===================>..........] - ETA: 0s - loss: 0.1746 - accuracy: 0.9112\n",
      "3966/5349 [=====================>........] - ETA: 0s - loss: 0.1742 - accuracy: 0.9114\n",
      "4199/5349 [======================>.......] - ETA: 0s - loss: 0.1739 - accuracy: 0.9114\n",
      "4443/5349 [=======================>......] - ETA: 0s - loss: 0.1735 - accuracy: 0.9116\n",
      "4686/5349 [=========================>....] - ETA: 0s - loss: 0.1734 - accuracy: 0.9116\n",
      "4909/5349 [==========================>...] - ETA: 0s - loss: 0.1734 - accuracy: 0.9115\n",
      "5273/5349 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9115\n",
      "5349/5349 [==============================] - 3s 582us/step - loss: 0.1731 - accuracy: 0.9116 - val_loss: 0.1694 - val_accuracy: 0.9124\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1575 - accuracy: 0.9100\n",
      " 245/5349 [>.............................] - ETA: 2s - loss: 0.1699 - accuracy: 0.9108\n",
      " 621/5349 [==>...........................] - ETA: 1s - loss: 0.1694 - accuracy: 0.9111\n",
      " 862/5349 [===>..........................] - ETA: 1s - loss: 0.1686 - accuracy: 0.9125\n",
      "1046/5349 [====>.........................] - ETA: 1s - loss: 0.1677 - accuracy: 0.9132\n",
      "1233/5349 [=====>........................] - ETA: 1s - loss: 0.1683 - accuracy: 0.9131\n",
      "1435/5349 [=======>......................] - ETA: 1s - loss: 0.1684 - accuracy: 0.9131\n",
      "1634/5349 [========>.....................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9130\n",
      "1835/5349 [=========>....................] - ETA: 1s - loss: 0.1687 - accuracy: 0.9130\n",
      "2036/5349 [==========>...................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9132\n",
      "2251/5349 [===========>..................] - ETA: 1s - loss: 0.1683 - accuracy: 0.9132\n",
      "2546/5349 [=============>................] - ETA: 1s - loss: 0.1690 - accuracy: 0.9129\n",
      "2751/5349 [==============>...............] - ETA: 1s - loss: 0.1689 - accuracy: 0.9129\n",
      "2894/5349 [===============>..............] - ETA: 1s - loss: 0.1687 - accuracy: 0.9132\n",
      "3001/5349 [===============>..............] - ETA: 1s - loss: 0.1686 - accuracy: 0.9132\n",
      "3186/5349 [================>.............] - ETA: 1s - loss: 0.1685 - accuracy: 0.9134\n",
      "3393/5349 [==================>...........] - ETA: 0s - loss: 0.1684 - accuracy: 0.9134\n",
      "3605/5349 [===================>..........] - ETA: 0s - loss: 0.1682 - accuracy: 0.9134\n",
      "3847/5349 [====================>.........] - ETA: 0s - loss: 0.1680 - accuracy: 0.9135\n",
      "4216/5349 [======================>.......] - ETA: 0s - loss: 0.1679 - accuracy: 0.9134\n",
      "4426/5349 [=======================>......] - ETA: 0s - loss: 0.1677 - accuracy: 0.9136\n",
      "4667/5349 [=========================>....] - ETA: 0s - loss: 0.1676 - accuracy: 0.9136\n",
      "4917/5349 [==========================>...] - ETA: 0s - loss: 0.1676 - accuracy: 0.9136\n",
      "5156/5349 [===========================>..] - ETA: 0s - loss: 0.1675 - accuracy: 0.9136\n",
      "5272/5349 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9135\n",
      "5349/5349 [==============================] - 3s 641us/step - loss: 0.1674 - accuracy: 0.9136 - val_loss: 0.1652 - val_accuracy: 0.9146\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 5/20\n",
      " 123/5349 [..............................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9107\n",
      " 372/5349 [=>............................] - ETA: 2s - loss: 0.1643 - accuracy: 0.9143\n",
      " 735/5349 [===>..........................] - ETA: 1s - loss: 0.1658 - accuracy: 0.9139\n",
      " 963/5349 [====>.........................] - ETA: 1s - loss: 0.1663 - accuracy: 0.9133\n",
      "1201/5349 [=====>........................] - ETA: 1s - loss: 0.1659 - accuracy: 0.9136\n",
      "1442/5349 [=======>......................] - ETA: 1s - loss: 0.1654 - accuracy: 0.9138\n",
      "1687/5349 [========>.....................] - ETA: 1s - loss: 0.1658 - accuracy: 0.9135\n",
      "1927/5349 [=========>....................] - ETA: 1s - loss: 0.1655 - accuracy: 0.9137\n",
      "2179/5349 [===========>..................] - ETA: 1s - loss: 0.1654 - accuracy: 0.9139\n",
      "2402/5349 [============>.................] - ETA: 1s - loss: 0.1651 - accuracy: 0.9140\n",
      "2577/5349 [=============>................] - ETA: 1s - loss: 0.1650 - accuracy: 0.9141\n",
      "2926/5349 [===============>..............] - ETA: 1s - loss: 0.1649 - accuracy: 0.9141\n",
      "3171/5349 [================>.............] - ETA: 0s - loss: 0.1647 - accuracy: 0.9142\n",
      "3406/5349 [==================>...........] - ETA: 0s - loss: 0.1647 - accuracy: 0.9140\n",
      "3648/5349 [===================>..........] - ETA: 0s - loss: 0.1648 - accuracy: 0.9140\n",
      "3881/5349 [====================>.........] - ETA: 0s - loss: 0.1646 - accuracy: 0.9141\n",
      "4114/5349 [======================>.......] - ETA: 0s - loss: 0.1646 - accuracy: 0.9141\n",
      "4356/5349 [=======================>......] - ETA: 0s - loss: 0.1646 - accuracy: 0.9139\n",
      "4595/5349 [========================>.....] - ETA: 0s - loss: 0.1644 - accuracy: 0.9140\n",
      "4722/5349 [=========================>....] - ETA: 0s - loss: 0.1644 - accuracy: 0.9139\n",
      "4958/5349 [==========================>...] - ETA: 0s - loss: 0.1642 - accuracy: 0.9140\n",
      "5194/5349 [============================>.] - ETA: 0s - loss: 0.1642 - accuracy: 0.9141\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9142\n",
      "5349/5349 [==============================] - 3s 588us/step - loss: 0.1641 - accuracy: 0.9142 - val_loss: 0.1623 - val_accuracy: 0.9148\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1387 - accuracy: 0.9400\n",
      " 237/5349 [>.............................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9161\n",
      " 485/5349 [=>............................] - ETA: 2s - loss: 0.1618 - accuracy: 0.9148\n",
      " 724/5349 [===>..........................] - ETA: 1s - loss: 0.1623 - accuracy: 0.9149\n",
      " 976/5349 [====>.........................] - ETA: 1s - loss: 0.1618 - accuracy: 0.9154\n",
      "1222/5349 [=====>........................] - ETA: 1s - loss: 0.1619 - accuracy: 0.9151\n",
      "1576/5349 [=======>......................] - ETA: 1s - loss: 0.1619 - accuracy: 0.9152\n",
      "1817/5349 [=========>....................] - ETA: 1s - loss: 0.1621 - accuracy: 0.9149\n",
      "2057/5349 [==========>...................] - ETA: 1s - loss: 0.1623 - accuracy: 0.9148\n",
      "2287/5349 [===========>..................] - ETA: 1s - loss: 0.1619 - accuracy: 0.9149\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.1619 - accuracy: 0.9149\n",
      "2775/5349 [==============>...............] - ETA: 1s - loss: 0.1619 - accuracy: 0.9149\n",
      "3152/5349 [================>.............] - ETA: 0s - loss: 0.1622 - accuracy: 0.9145\n",
      "3369/5349 [=================>............] - ETA: 0s - loss: 0.1621 - accuracy: 0.9144\n",
      "3617/5349 [===================>..........] - ETA: 0s - loss: 0.1621 - accuracy: 0.9144\n",
      "3860/5349 [====================>.........] - ETA: 0s - loss: 0.1621 - accuracy: 0.9144\n",
      "4105/5349 [======================>.......] - ETA: 0s - loss: 0.1620 - accuracy: 0.9144\n",
      "4332/5349 [=======================>......] - ETA: 0s - loss: 0.1618 - accuracy: 0.9145\n",
      "4579/5349 [========================>.....] - ETA: 0s - loss: 0.1618 - accuracy: 0.9144\n",
      "4825/5349 [==========================>...] - ETA: 0s - loss: 0.1617 - accuracy: 0.9145\n",
      "5192/5349 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9147\n",
      "5314/5349 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9146\n",
      "5349/5349 [==============================] - 3s 581us/step - loss: 0.1616 - accuracy: 0.9146 - val_loss: 0.1601 - val_accuracy: 0.9153\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1391 - accuracy: 0.9300\n",
      " 243/5349 [>.............................] - ETA: 2s - loss: 0.1621 - accuracy: 0.9140\n",
      " 493/5349 [=>............................] - ETA: 1s - loss: 0.1627 - accuracy: 0.9138\n",
      " 716/5349 [===>..........................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9137\n",
      " 968/5349 [====>.........................] - ETA: 1s - loss: 0.1621 - accuracy: 0.9133\n",
      "1203/5349 [=====>........................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9138\n",
      "1456/5349 [=======>......................] - ETA: 1s - loss: 0.1609 - accuracy: 0.9143\n",
      "1701/5349 [========>.....................] - ETA: 1s - loss: 0.1609 - accuracy: 0.9141\n",
      "2081/5349 [==========>...................] - ETA: 1s - loss: 0.1608 - accuracy: 0.9142\n",
      "2319/5349 [============>.................] - ETA: 1s - loss: 0.1608 - accuracy: 0.9143\n",
      "2518/5349 [=============>................] - ETA: 1s - loss: 0.1607 - accuracy: 0.9142\n",
      "2752/5349 [==============>...............] - ETA: 1s - loss: 0.1606 - accuracy: 0.9144\n",
      "3002/5349 [===============>..............] - ETA: 0s - loss: 0.1606 - accuracy: 0.9143\n",
      "3244/5349 [=================>............] - ETA: 0s - loss: 0.1605 - accuracy: 0.9145\n",
      "3492/5349 [==================>...........] - ETA: 0s - loss: 0.1602 - accuracy: 0.9147\n",
      "3721/5349 [===================>..........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9148\n",
      "3949/5349 [=====================>........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9149\n",
      "4212/5349 [======================>.......] - ETA: 0s - loss: 0.1602 - accuracy: 0.9148\n",
      "4413/5349 [=======================>......] - ETA: 0s - loss: 0.1599 - accuracy: 0.9150\n",
      "4594/5349 [========================>.....] - ETA: 0s - loss: 0.1600 - accuracy: 0.9149\n",
      "4802/5349 [=========================>....] - ETA: 0s - loss: 0.1597 - accuracy: 0.9151\n",
      "4991/5349 [==========================>...] - ETA: 0s - loss: 0.1596 - accuracy: 0.9152\n",
      "5189/5349 [============================>.] - ETA: 0s - loss: 0.1596 - accuracy: 0.9152\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9152\n",
      "5349/5349 [==============================] - 3s 636us/step - loss: 0.1596 - accuracy: 0.9151 - val_loss: 0.1583 - val_accuracy: 0.9158\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 8/20\n",
      " 124/5349 [..............................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9156\n",
      " 372/5349 [=>............................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9153\n",
      " 613/5349 [==>...........................] - ETA: 1s - loss: 0.1605 - accuracy: 0.9142\n",
      " 848/5349 [===>..........................] - ETA: 1s - loss: 0.1598 - accuracy: 0.9145\n",
      "1213/5349 [=====>........................] - ETA: 1s - loss: 0.1591 - accuracy: 0.9153\n",
      "1412/5349 [======>.......................] - ETA: 1s - loss: 0.1588 - accuracy: 0.9153\n",
      "1645/5349 [========>.....................] - ETA: 1s - loss: 0.1589 - accuracy: 0.9153\n",
      "1839/5349 [=========>....................] - ETA: 1s - loss: 0.1590 - accuracy: 0.9154\n",
      "2080/5349 [==========>...................] - ETA: 1s - loss: 0.1589 - accuracy: 0.9156\n",
      "2326/5349 [============>.................] - ETA: 1s - loss: 0.1585 - accuracy: 0.9157\n",
      "2565/5349 [=============>................] - ETA: 1s - loss: 0.1586 - accuracy: 0.9155\n",
      "2800/5349 [==============>...............] - ETA: 1s - loss: 0.1587 - accuracy: 0.9155\n",
      "3048/5349 [================>.............] - ETA: 0s - loss: 0.1587 - accuracy: 0.9154\n",
      "3293/5349 [=================>............] - ETA: 0s - loss: 0.1586 - accuracy: 0.9153\n",
      "3544/5349 [==================>...........] - ETA: 0s - loss: 0.1588 - accuracy: 0.9152\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.1588 - accuracy: 0.9152\n",
      "4147/5349 [======================>.......] - ETA: 0s - loss: 0.1585 - accuracy: 0.9153\n",
      "4379/5349 [=======================>......] - ETA: 0s - loss: 0.1584 - accuracy: 0.9154\n",
      "4627/5349 [========================>.....] - ETA: 0s - loss: 0.1583 - accuracy: 0.9155\n",
      "4856/5349 [==========================>...] - ETA: 0s - loss: 0.1582 - accuracy: 0.9155\n",
      "5100/5349 [===========================>..] - ETA: 0s - loss: 0.1580 - accuracy: 0.9156\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9156\n",
      "5349/5349 [==============================] - 3s 598us/step - loss: 0.1580 - accuracy: 0.9156 - val_loss: 0.1568 - val_accuracy: 0.9162\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1877 - accuracy: 0.8800\n",
      " 252/5349 [>.............................] - ETA: 2s - loss: 0.1622 - accuracy: 0.9120\n",
      " 611/5349 [==>...........................] - ETA: 1s - loss: 0.1599 - accuracy: 0.9139\n",
      " 850/5349 [===>..........................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9155\n",
      "1082/5349 [=====>........................] - ETA: 1s - loss: 0.1580 - accuracy: 0.9152\n",
      "1323/5349 [======>.......................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9149\n",
      "1576/5349 [=======>......................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9156\n",
      "1815/5349 [=========>....................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9157\n",
      "2062/5349 [==========>...................] - ETA: 1s - loss: 0.1571 - accuracy: 0.9158\n",
      "2297/5349 [===========>..................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9160\n",
      "2629/5349 [=============>................] - ETA: 1s - loss: 0.1571 - accuracy: 0.9158\n",
      "2875/5349 [===============>..............] - ETA: 1s - loss: 0.1572 - accuracy: 0.9157\n",
      "3118/5349 [================>.............] - ETA: 0s - loss: 0.1572 - accuracy: 0.9158\n",
      "3357/5349 [=================>............] - ETA: 0s - loss: 0.1571 - accuracy: 0.9157\n",
      "3601/5349 [===================>..........] - ETA: 0s - loss: 0.1573 - accuracy: 0.9155\n",
      "3979/5349 [=====================>........] - ETA: 0s - loss: 0.1569 - accuracy: 0.9157\n",
      "4225/5349 [======================>.......] - ETA: 0s - loss: 0.1567 - accuracy: 0.9158\n",
      "4442/5349 [=======================>......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9158\n",
      "4687/5349 [=========================>....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9159\n",
      "4931/5349 [==========================>...] - ETA: 0s - loss: 0.1567 - accuracy: 0.9160\n",
      "5171/5349 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9160\n",
      "5294/5349 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9159\n",
      "5349/5349 [==============================] - 3s 582us/step - loss: 0.1567 - accuracy: 0.9160 - val_loss: 0.1556 - val_accuracy: 0.9166\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1280 - accuracy: 0.9400\n",
      " 248/5349 [>.............................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9150\n",
      " 498/5349 [=>............................] - ETA: 1s - loss: 0.1571 - accuracy: 0.9152\n",
      " 865/5349 [===>..........................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9155\n",
      "1114/5349 [=====>........................] - ETA: 1s - loss: 0.1563 - accuracy: 0.9157\n",
      "1339/5349 [======>.......................] - ETA: 1s - loss: 0.1564 - accuracy: 0.9156\n",
      "1590/5349 [=======>......................] - ETA: 1s - loss: 0.1565 - accuracy: 0.9155\n",
      "1832/5349 [=========>....................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9155\n",
      "2082/5349 [==========>...................] - ETA: 1s - loss: 0.1567 - accuracy: 0.9153\n",
      "2326/5349 [============>.................] - ETA: 1s - loss: 0.1563 - accuracy: 0.9156\n",
      "2579/5349 [=============>................] - ETA: 1s - loss: 0.1558 - accuracy: 0.9161\n",
      "2944/5349 [===============>..............] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "3194/5349 [================>.............] - ETA: 0s - loss: 0.1556 - accuracy: 0.9164\n",
      "3429/5349 [==================>...........] - ETA: 0s - loss: 0.1555 - accuracy: 0.9164\n",
      "3680/5349 [===================>..........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9164\n",
      "3922/5349 [====================>.........] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "4176/5349 [======================>.......] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "4412/5349 [=======================>......] - ETA: 0s - loss: 0.1558 - accuracy: 0.9162\n",
      "4651/5349 [=========================>....] - ETA: 0s - loss: 0.1558 - accuracy: 0.9161\n",
      "5005/5349 [===========================>..] - ETA: 0s - loss: 0.1558 - accuracy: 0.9162\n",
      "5258/5349 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9164\n",
      "5349/5349 [==============================] - 3s 583us/step - loss: 0.1556 - accuracy: 0.9164 - val_loss: 0.1546 - val_accuracy: 0.9168\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 11/20\n",
      " 108/5349 [..............................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9109\n",
      " 306/5349 [>.............................] - ETA: 2s - loss: 0.1578 - accuracy: 0.9140\n",
      " 606/5349 [==>...........................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9156\n",
      " 807/5349 [===>..........................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9158\n",
      "1028/5349 [====>.........................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9158\n",
      "1231/5349 [=====>........................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9162\n",
      "1409/5349 [======>.......................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9160\n",
      "1546/5349 [=======>......................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9161\n",
      "1744/5349 [========>.....................] - ETA: 1s - loss: 0.1553 - accuracy: 0.9160\n",
      "1946/5349 [=========>....................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9162\n",
      "2168/5349 [===========>..................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9164\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9164\n",
      "2773/5349 [==============>...............] - ETA: 1s - loss: 0.1547 - accuracy: 0.9165\n",
      "3017/5349 [===============>..............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9164\n",
      "3268/5349 [=================>............] - ETA: 0s - loss: 0.1549 - accuracy: 0.9164\n",
      "3511/5349 [==================>...........] - ETA: 0s - loss: 0.1548 - accuracy: 0.9165\n",
      "3759/5349 [====================>.........] - ETA: 0s - loss: 0.1549 - accuracy: 0.9165\n",
      "3996/5349 [=====================>........] - ETA: 0s - loss: 0.1547 - accuracy: 0.9167\n",
      "4246/5349 [======================>.......] - ETA: 0s - loss: 0.1548 - accuracy: 0.9166\n",
      "4606/5349 [========================>.....] - ETA: 0s - loss: 0.1547 - accuracy: 0.9166\n",
      "4854/5349 [==========================>...] - ETA: 0s - loss: 0.1547 - accuracy: 0.9166\n",
      "5083/5349 [===========================>..] - ETA: 0s - loss: 0.1547 - accuracy: 0.9166\n",
      "5328/5349 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9166\n",
      "5349/5349 [==============================] - 3s 625us/step - loss: 0.1547 - accuracy: 0.9166 - val_loss: 0.1537 - val_accuracy: 0.9172\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 12/20\n",
      " 120/5349 [..............................] - ETA: 2s - loss: 0.1516 - accuracy: 0.9193\n",
      " 363/5349 [=>............................] - ETA: 2s - loss: 0.1521 - accuracy: 0.9176\n",
      " 613/5349 [==>...........................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9167\n",
      " 848/5349 [===>..........................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "1001/5349 [====>.........................] - ETA: 1s - loss: 0.1544 - accuracy: 0.9166\n",
      "1229/5349 [=====>........................] - ETA: 1s - loss: 0.1546 - accuracy: 0.9167\n",
      "1473/5349 [=======>......................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9164\n",
      "1697/5349 [========>.....................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9164\n",
      "1935/5349 [=========>....................] - ETA: 1s - loss: 0.1546 - accuracy: 0.9165\n",
      "2268/5349 [===========>..................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9164\n",
      "2488/5349 [============>.................] - ETA: 1s - loss: 0.1546 - accuracy: 0.9163\n",
      "2712/5349 [==============>...............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9164\n",
      "2944/5349 [===============>..............] - ETA: 1s - loss: 0.1547 - accuracy: 0.9163\n",
      "3157/5349 [================>.............] - ETA: 0s - loss: 0.1545 - accuracy: 0.9163\n",
      "3388/5349 [==================>...........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9163\n",
      "3614/5349 [===================>..........] - ETA: 0s - loss: 0.1542 - accuracy: 0.9166\n",
      "3856/5349 [====================>.........] - ETA: 0s - loss: 0.1542 - accuracy: 0.9166\n",
      "4233/5349 [======================>.......] - ETA: 0s - loss: 0.1539 - accuracy: 0.9167\n",
      "4477/5349 [========================>.....] - ETA: 0s - loss: 0.1539 - accuracy: 0.9167\n",
      "4692/5349 [=========================>....] - ETA: 0s - loss: 0.1538 - accuracy: 0.9169\n",
      "4936/5349 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.9169\n",
      "5175/5349 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9170\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5349/5349 [==============================] - 3s 598us/step - loss: 0.1538 - accuracy: 0.9169 - val_loss: 0.1528 - val_accuracy: 0.9174\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1143 - accuracy: 0.9400\n",
      " 249/5349 [>.............................] - ETA: 2s - loss: 0.1531 - accuracy: 0.9164\n",
      " 501/5349 [=>............................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9161\n",
      " 727/5349 [===>..........................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9170\n",
      "1098/5349 [=====>........................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9171\n",
      "1315/5349 [======>.......................] - ETA: 1s - loss: 0.1530 - accuracy: 0.9169\n",
      "1567/5349 [=======>......................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9172\n",
      "1809/5349 [=========>....................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9173\n",
      "2034/5349 [==========>...................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9166\n",
      "2273/5349 [===========>..................] - ETA: 1s - loss: 0.1532 - accuracy: 0.9169\n",
      "2524/5349 [=============>................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9172\n",
      "2893/5349 [===============>..............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9173\n",
      "3149/5349 [================>.............] - ETA: 0s - loss: 0.1528 - accuracy: 0.9176\n",
      "3381/5349 [=================>............] - ETA: 0s - loss: 0.1526 - accuracy: 0.9176\n",
      "3632/5349 [===================>..........] - ETA: 0s - loss: 0.1527 - accuracy: 0.9175\n",
      "3876/5349 [====================>.........] - ETA: 0s - loss: 0.1527 - accuracy: 0.9175\n",
      "4132/5349 [======================>.......] - ETA: 0s - loss: 0.1526 - accuracy: 0.9175\n",
      "4377/5349 [=======================>......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9175\n",
      "4625/5349 [========================>.....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9174\n",
      "4856/5349 [==========================>...] - ETA: 0s - loss: 0.1527 - accuracy: 0.9173\n",
      "5236/5349 [============================>.] - ETA: 0s - loss: 0.1529 - accuracy: 0.9170\n",
      "5349/5349 [==============================] - 3s 573us/step - loss: 0.1530 - accuracy: 0.9170 - val_loss: 0.1520 - val_accuracy: 0.9175\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1454 - accuracy: 0.9100\n",
      " 249/5349 [>.............................] - ETA: 2s - loss: 0.1503 - accuracy: 0.9187\n",
      " 500/5349 [=>............................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9179\n",
      " 732/5349 [===>..........................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9184\n",
      " 981/5349 [====>.........................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9179\n",
      "1223/5349 [=====>........................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9181\n",
      "1477/5349 [=======>......................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9177\n",
      "1848/5349 [=========>....................] - ETA: 1s - loss: 0.1520 - accuracy: 0.9179\n",
      "2094/5349 [==========>...................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9179\n",
      "2318/5349 [============>.................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9179\n",
      "2521/5349 [=============>................] - ETA: 1s - loss: 0.1524 - accuracy: 0.9177\n",
      "2714/5349 [==============>...............] - ETA: 1s - loss: 0.1525 - accuracy: 0.9176\n",
      "2916/5349 [===============>..............] - ETA: 1s - loss: 0.1525 - accuracy: 0.9175\n",
      "3105/5349 [================>.............] - ETA: 0s - loss: 0.1524 - accuracy: 0.9175\n",
      "3318/5349 [=================>............] - ETA: 0s - loss: 0.1520 - accuracy: 0.9176\n",
      "3601/5349 [===================>..........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9174\n",
      "3807/5349 [====================>.........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9173\n",
      "4005/5349 [=====================>........] - ETA: 0s - loss: 0.1524 - accuracy: 0.9172\n",
      "4204/5349 [======================>.......] - ETA: 0s - loss: 0.1524 - accuracy: 0.9173\n",
      "4354/5349 [=======================>......] - ETA: 0s - loss: 0.1524 - accuracy: 0.9173\n",
      "4504/5349 [========================>.....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9174\n",
      "4612/5349 [========================>.....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9174\n",
      "4810/5349 [=========================>....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9173\n",
      "5009/5349 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.9174\n",
      "5220/5349 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9174\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.1522 - accuracy: 0.9173\n",
      "5349/5349 [==============================] - 3s 635us/step - loss: 0.1522 - accuracy: 0.9173 - val_loss: 0.1513 - val_accuracy: 0.9178\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.2106 - accuracy: 0.8700\n",
      " 230/5349 [>.............................] - ETA: 2s - loss: 0.1509 - accuracy: 0.9181\n",
      " 582/5349 [==>...........................] - ETA: 2s - loss: 0.1498 - accuracy: 0.9189\n",
      " 818/5349 [===>..........................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9182\n",
      "1058/5349 [====>.........................] - ETA: 1s - loss: 0.1510 - accuracy: 0.9183\n",
      "1283/5349 [======>.......................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9179\n",
      "1535/5349 [=======>......................] - ETA: 1s - loss: 0.1515 - accuracy: 0.9178\n",
      "1781/5349 [========>.....................] - ETA: 1s - loss: 0.1516 - accuracy: 0.9178\n",
      "2018/5349 [==========>...................] - ETA: 1s - loss: 0.1521 - accuracy: 0.9172\n",
      "2249/5349 [===========>..................] - ETA: 1s - loss: 0.1518 - accuracy: 0.9177\n",
      "2498/5349 [=============>................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9181\n",
      "2827/5349 [==============>...............] - ETA: 1s - loss: 0.1514 - accuracy: 0.9179\n",
      "3076/5349 [================>.............] - ETA: 0s - loss: 0.1515 - accuracy: 0.9178\n",
      "3315/5349 [=================>............] - ETA: 0s - loss: 0.1515 - accuracy: 0.9178\n",
      "3545/5349 [==================>...........] - ETA: 0s - loss: 0.1516 - accuracy: 0.9178\n",
      "3785/5349 [====================>.........] - ETA: 0s - loss: 0.1515 - accuracy: 0.9176\n",
      "4006/5349 [=====================>........] - ETA: 0s - loss: 0.1514 - accuracy: 0.9177\n",
      "4181/5349 [======================>.......] - ETA: 0s - loss: 0.1513 - accuracy: 0.9178\n",
      "4418/5349 [=======================>......] - ETA: 0s - loss: 0.1513 - accuracy: 0.9178\n",
      "4777/5349 [=========================>....] - ETA: 0s - loss: 0.1514 - accuracy: 0.9177\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.1514 - accuracy: 0.9177\n",
      "5272/5349 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9177\n",
      "5349/5349 [==============================] - 3s 592us/step - loss: 0.1515 - accuracy: 0.9177 - val_loss: 0.1506 - val_accuracy: 0.9183\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 2s - loss: 0.1445 - accuracy: 0.9100\n",
      " 370/5349 [=>............................] - ETA: 2s - loss: 0.1491 - accuracy: 0.9193\n",
      " 625/5349 [==>...........................] - ETA: 1s - loss: 0.1497 - accuracy: 0.9183\n",
      " 837/5349 [===>..........................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9173\n",
      "1090/5349 [=====>........................] - ETA: 1s - loss: 0.1506 - accuracy: 0.9175\n",
      "1333/5349 [======>.......................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9174\n",
      "1585/5349 [=======>......................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9175\n",
      "1828/5349 [=========>....................] - ETA: 1s - loss: 0.1515 - accuracy: 0.9173\n",
      "2076/5349 [==========>...................] - ETA: 1s - loss: 0.1516 - accuracy: 0.9172\n",
      "2319/5349 [============>.................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9176\n",
      "2569/5349 [=============>................] - ETA: 1s - loss: 0.1511 - accuracy: 0.9177\n",
      "2816/5349 [==============>...............] - ETA: 1s - loss: 0.1512 - accuracy: 0.9178\n",
      "3183/5349 [================>.............] - ETA: 0s - loss: 0.1514 - accuracy: 0.9177\n",
      "3416/5349 [==================>...........] - ETA: 0s - loss: 0.1510 - accuracy: 0.9179\n",
      "3668/5349 [===================>..........] - ETA: 0s - loss: 0.1510 - accuracy: 0.9180\n",
      "3916/5349 [====================>.........] - ETA: 0s - loss: 0.1511 - accuracy: 0.9180\n",
      "4171/5349 [======================>.......] - ETA: 0s - loss: 0.1512 - accuracy: 0.9180\n",
      "4394/5349 [=======================>......] - ETA: 0s - loss: 0.1511 - accuracy: 0.9179\n",
      "4648/5349 [=========================>....] - ETA: 0s - loss: 0.1511 - accuracy: 0.9179\n",
      "4833/5349 [==========================>...] - ETA: 0s - loss: 0.1511 - accuracy: 0.9180\n",
      "4979/5349 [==========================>...] - ETA: 0s - loss: 0.1510 - accuracy: 0.9180\n",
      "5218/5349 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9181\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1509 - accuracy: 0.9181\n",
      "5349/5349 [==============================] - 3s 591us/step - loss: 0.1509 - accuracy: 0.9181 - val_loss: 0.1500 - val_accuracy: 0.9186\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 17/20\n",
      " 107/5349 [..............................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9186\n",
      " 333/5349 [>.............................] - ETA: 2s - loss: 0.1480 - accuracy: 0.9204\n",
      " 576/5349 [==>...........................] - ETA: 2s - loss: 0.1497 - accuracy: 0.9190\n",
      " 814/5349 [===>..........................] - ETA: 1s - loss: 0.1509 - accuracy: 0.9186\n",
      "1061/5349 [====>.........................] - ETA: 1s - loss: 0.1501 - accuracy: 0.9189\n",
      "1295/5349 [======>.......................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9178\n",
      "1510/5349 [=======>......................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9177\n",
      "1850/5349 [=========>....................] - ETA: 1s - loss: 0.1514 - accuracy: 0.9176\n",
      "2093/5349 [==========>...................] - ETA: 1s - loss: 0.1511 - accuracy: 0.9179\n",
      "2328/5349 [============>.................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9180\n",
      "2576/5349 [=============>................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9184\n",
      "2815/5349 [==============>...............] - ETA: 1s - loss: 0.1503 - accuracy: 0.9186\n",
      "3063/5349 [================>.............] - ETA: 0s - loss: 0.1500 - accuracy: 0.9187\n",
      "3305/5349 [=================>............] - ETA: 0s - loss: 0.1502 - accuracy: 0.9185\n",
      "3685/5349 [===================>..........] - ETA: 0s - loss: 0.1501 - accuracy: 0.9187\n",
      "3932/5349 [=====================>........] - ETA: 0s - loss: 0.1502 - accuracy: 0.9186\n",
      "4173/5349 [======================>.......] - ETA: 0s - loss: 0.1501 - accuracy: 0.9187\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1502 - accuracy: 0.9187\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1502 - accuracy: 0.9187\n",
      "4867/5349 [==========================>...] - ETA: 0s - loss: 0.1503 - accuracy: 0.9186\n",
      "5102/5349 [===========================>..] - ETA: 0s - loss: 0.1503 - accuracy: 0.9185\n",
      "5339/5349 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9185\n",
      "5349/5349 [==============================] - 3s 621us/step - loss: 0.1503 - accuracy: 0.9185 - val_loss: 0.1495 - val_accuracy: 0.9189\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1498 - accuracy: 0.9200\n",
      " 278/5349 [>.............................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9167\n",
      " 397/5349 [=>............................] - ETA: 3s - loss: 0.1523 - accuracy: 0.9165\n",
      " 582/5349 [==>...........................] - ETA: 2s - loss: 0.1509 - accuracy: 0.9169\n",
      " 786/5349 [===>..........................] - ETA: 2s - loss: 0.1508 - accuracy: 0.9174\n",
      " 984/5349 [====>.........................] - ETA: 2s - loss: 0.1504 - accuracy: 0.9181\n",
      "1218/5349 [=====>........................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9187\n",
      "1460/5349 [=======>......................] - ETA: 2s - loss: 0.1498 - accuracy: 0.9185\n",
      "1823/5349 [=========>....................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9182\n",
      "2063/5349 [==========>...................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9184\n",
      "2304/5349 [===========>..................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9185\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9187\n",
      "2764/5349 [==============>...............] - ETA: 1s - loss: 0.1500 - accuracy: 0.9187\n",
      "3002/5349 [===============>..............] - ETA: 1s - loss: 0.1502 - accuracy: 0.9187\n",
      "3250/5349 [=================>............] - ETA: 0s - loss: 0.1500 - accuracy: 0.9188\n",
      "3488/5349 [==================>...........] - ETA: 0s - loss: 0.1499 - accuracy: 0.9189\n",
      "3735/5349 [===================>..........] - ETA: 0s - loss: 0.1499 - accuracy: 0.9189\n",
      "3965/5349 [=====================>........] - ETA: 0s - loss: 0.1497 - accuracy: 0.9190\n",
      "4327/5349 [=======================>......] - ETA: 0s - loss: 0.1497 - accuracy: 0.9189\n",
      "4566/5349 [========================>.....] - ETA: 0s - loss: 0.1498 - accuracy: 0.9188\n",
      "4815/5349 [==========================>...] - ETA: 0s - loss: 0.1498 - accuracy: 0.9187\n",
      "5055/5349 [===========================>..] - ETA: 0s - loss: 0.1498 - accuracy: 0.9188\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9187\n",
      "5349/5349 [==============================] - 3s 612us/step - loss: 0.1499 - accuracy: 0.9187 - val_loss: 0.1490 - val_accuracy: 0.9192\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1204 - accuracy: 0.9400\n",
      "  71/5349 [..............................] - ETA: 3s - loss: 0.1481 - accuracy: 0.9206\n",
      " 274/5349 [>.............................] - ETA: 2s - loss: 0.1512 - accuracy: 0.9182\n",
      " 521/5349 [=>............................] - ETA: 2s - loss: 0.1527 - accuracy: 0.9169\n",
      " 750/5349 [===>..........................] - ETA: 2s - loss: 0.1508 - accuracy: 0.9182\n",
      " 989/5349 [====>.........................] - ETA: 1s - loss: 0.1509 - accuracy: 0.9182\n",
      "1227/5349 [=====>........................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9179\n",
      "1433/5349 [=======>......................] - ETA: 1s - loss: 0.1506 - accuracy: 0.9180\n",
      "1589/5349 [=======>......................] - ETA: 1s - loss: 0.1505 - accuracy: 0.9180\n",
      "1810/5349 [=========>....................] - ETA: 1s - loss: 0.1506 - accuracy: 0.9180\n",
      "2149/5349 [===========>..................] - ETA: 1s - loss: 0.1503 - accuracy: 0.9186\n",
      "2392/5349 [============>.................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9187\n",
      "2628/5349 [=============>................] - ETA: 1s - loss: 0.1498 - accuracy: 0.9190\n",
      "2872/5349 [===============>..............] - ETA: 1s - loss: 0.1495 - accuracy: 0.9192\n",
      "3106/5349 [================>.............] - ETA: 1s - loss: 0.1496 - accuracy: 0.9191\n",
      "3349/5349 [=================>............] - ETA: 0s - loss: 0.1492 - accuracy: 0.9195\n",
      "3565/5349 [==================>...........] - ETA: 0s - loss: 0.1493 - accuracy: 0.9193\n",
      "3810/5349 [====================>.........] - ETA: 0s - loss: 0.1493 - accuracy: 0.9193\n",
      "4038/5349 [=====================>........] - ETA: 0s - loss: 0.1495 - accuracy: 0.9190\n",
      "4411/5349 [=======================>......] - ETA: 0s - loss: 0.1494 - accuracy: 0.9190\n",
      "4648/5349 [=========================>....] - ETA: 0s - loss: 0.1495 - accuracy: 0.9189\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.1496 - accuracy: 0.9188\n",
      "5112/5349 [===========================>..] - ETA: 0s - loss: 0.1494 - accuracy: 0.9189\n",
      "5236/5349 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9189\n",
      "5349/5349 [==============================] - 3s 604us/step - loss: 0.1494 - accuracy: 0.9188 - val_loss: 0.1486 - val_accuracy: 0.9195\n",
      "\u001B[36m(train_DNN pid=5480)\u001B[0m Epoch 20/20\n",
      " 125/5349 [..............................] - ETA: 2s - loss: 0.1510 - accuracy: 0.9174\n",
      " 373/5349 [=>............................] - ETA: 2s - loss: 0.1505 - accuracy: 0.9174\n",
      " 616/5349 [==>...........................] - ETA: 1s - loss: 0.1494 - accuracy: 0.9187\n",
      " 853/5349 [===>..........................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9195\n",
      " 971/5349 [====>.........................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9198\n",
      "1186/5349 [=====>........................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9196\n",
      "1404/5349 [======>.......................] - ETA: 1s - loss: 0.1484 - accuracy: 0.9195\n",
      "1659/5349 [========>.....................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9196\n",
      "1906/5349 [=========>....................] - ETA: 1s - loss: 0.1484 - accuracy: 0.9195\n",
      "2161/5349 [===========>..................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9193\n",
      "2388/5349 [============>.................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9190\n",
      "2768/5349 [==============>...............] - ETA: 1s - loss: 0.1488 - accuracy: 0.9192\n",
      "3003/5349 [===============>..............] - ETA: 0s - loss: 0.1488 - accuracy: 0.9192\n",
      "3242/5349 [=================>............] - ETA: 0s - loss: 0.1487 - accuracy: 0.9193\n",
      "3449/5349 [==================>...........] - ETA: 0s - loss: 0.1487 - accuracy: 0.9193\n",
      "3687/5349 [===================>..........] - ETA: 0s - loss: 0.1486 - accuracy: 0.9193\n",
      "3934/5349 [=====================>........] - ETA: 0s - loss: 0.1487 - accuracy: 0.9193\n",
      "4181/5349 [======================>.......] - ETA: 0s - loss: 0.1486 - accuracy: 0.9193\n",
      "4554/5349 [========================>.....] - ETA: 0s - loss: 0.1487 - accuracy: 0.9191\n",
      "4792/5349 [=========================>....] - ETA: 0s - loss: 0.1489 - accuracy: 0.9190\n",
      "5032/5349 [===========================>..] - ETA: 0s - loss: 0.1489 - accuracy: 0.9190\n",
      "5257/5349 [============================>.] - ETA: 0s - loss: 0.1489 - accuracy: 0.9191\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 1/20\n",
      "  53/5349 [..............................] - ETA: 5s - loss: 0.9258 - accuracy: 0.1602   \n",
      " 203/5349 [>.............................] - ETA: 3s - loss: 0.7873 - accuracy: 0.3892\n",
      " 364/5349 [=>............................] - ETA: 3s - loss: 0.6945 - accuracy: 0.5900\n",
      " 522/5349 [=>............................] - ETA: 3s - loss: 0.6340 - accuracy: 0.6749\n",
      " 688/5349 [==>...........................] - ETA: 3s - loss: 0.5848 - accuracy: 0.7261\n",
      " 838/5349 [===>..........................] - ETA: 2s - loss: 0.5510 - accuracy: 0.7552\n",
      " 924/5349 [====>.........................] - ETA: 2s - loss: 0.5342 - accuracy: 0.7679\n",
      "1095/5349 [=====>........................] - ETA: 2s - loss: 0.5052 - accuracy: 0.7875\n",
      "1253/5349 [======>.......................] - ETA: 2s - loss: 0.4824 - accuracy: 0.8011\n",
      "1424/5349 [======>.......................] - ETA: 2s - loss: 0.4613 - accuracy: 0.8129\n",
      "1586/5349 [=======>......................] - ETA: 2s - loss: 0.4444 - accuracy: 0.8211\n",
      "1753/5349 [========>.....................] - ETA: 2s - loss: 0.4290 - accuracy: 0.8283\n",
      "1918/5349 [=========>....................] - ETA: 2s - loss: 0.4158 - accuracy: 0.8341\n",
      "2078/5349 [==========>...................] - ETA: 2s - loss: 0.4043 - accuracy: 0.8389\n",
      "2240/5349 [===========>..................] - ETA: 1s - loss: 0.3939 - accuracy: 0.8428\n",
      "2497/5349 [=============>................] - ETA: 1s - loss: 0.3790 - accuracy: 0.8487\n",
      "2662/5349 [=============>................] - ETA: 1s - loss: 0.3707 - accuracy: 0.8518\n",
      "2834/5349 [==============>...............] - ETA: 1s - loss: 0.3626 - accuracy: 0.8547\n",
      "2993/5349 [===============>..............] - ETA: 1s - loss: 0.3557 - accuracy: 0.8571\n",
      "3162/5349 [================>.............] - ETA: 1s - loss: 0.3488 - accuracy: 0.8595\n",
      "3315/5349 [=================>............] - ETA: 1s - loss: 0.3433 - accuracy: 0.8613\n",
      "3487/5349 [==================>...........] - ETA: 1s - loss: 0.3374 - accuracy: 0.8632\n",
      "3656/5349 [===================>..........] - ETA: 1s - loss: 0.3320 - accuracy: 0.8649\n",
      "3820/5349 [====================>.........] - ETA: 0s - loss: 0.3270 - accuracy: 0.8665\n",
      "3989/5349 [=====================>........] - ETA: 0s - loss: 0.3221 - accuracy: 0.8682\n",
      "4158/5349 [======================>.......] - ETA: 0s - loss: 0.3173 - accuracy: 0.8698\n",
      "4410/5349 [=======================>......] - ETA: 0s - loss: 0.3111 - accuracy: 0.8717\n",
      "4536/5349 [========================>.....] - ETA: 0s - loss: 0.3082 - accuracy: 0.8727\n",
      "4674/5349 [=========================>....] - ETA: 0s - loss: 0.3052 - accuracy: 0.8736\n",
      "4820/5349 [==========================>...] - ETA: 0s - loss: 0.3022 - accuracy: 0.8744\n",
      "4959/5349 [==========================>...] - ETA: 0s - loss: 0.2996 - accuracy: 0.8752\n",
      "5101/5349 [===========================>..] - ETA: 0s - loss: 0.2968 - accuracy: 0.8760\n",
      "5244/5349 [============================>.] - ETA: 0s - loss: 0.2943 - accuracy: 0.8766\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.8770\n",
      "5349/5349 [==============================] - 5s 894us/step - loss: 0.2925 - accuracy: 0.8771 - val_loss: 0.1915 - val_accuracy: 0.9056\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 2/20\n",
      "  73/5349 [..............................] - ETA: 3s - loss: 0.2000 - accuracy: 0.9040\n",
      " 224/5349 [>.............................] - ETA: 3s - loss: 0.2019 - accuracy: 0.9009\n",
      " 379/5349 [=>............................] - ETA: 3s - loss: 0.1991 - accuracy: 0.9026\n",
      " 542/5349 [==>...........................] - ETA: 3s - loss: 0.1994 - accuracy: 0.9018\n",
      " 709/5349 [==>...........................] - ETA: 2s - loss: 0.1980 - accuracy: 0.9027\n",
      " 875/5349 [===>..........................] - ETA: 2s - loss: 0.1961 - accuracy: 0.9033\n",
      "1039/5349 [====>.........................] - ETA: 2s - loss: 0.1957 - accuracy: 0.9031\n",
      "1122/5349 [=====>........................] - ETA: 2s - loss: 0.1956 - accuracy: 0.9031\n",
      "1272/5349 [======>.......................] - ETA: 2s - loss: 0.1950 - accuracy: 0.9036\n",
      "1434/5349 [=======>......................] - ETA: 2s - loss: 0.1947 - accuracy: 0.9036\n",
      "1598/5349 [=======>......................] - ETA: 2s - loss: 0.1944 - accuracy: 0.9038\n",
      "1761/5349 [========>.....................] - ETA: 2s - loss: 0.1939 - accuracy: 0.9040\n",
      "1918/5349 [=========>....................] - ETA: 2s - loss: 0.1936 - accuracy: 0.9041\n",
      "2077/5349 [==========>...................] - ETA: 2s - loss: 0.1933 - accuracy: 0.9039\n",
      "2234/5349 [===========>..................] - ETA: 1s - loss: 0.1930 - accuracy: 0.9040\n",
      "2467/5349 [============>.................] - ETA: 1s - loss: 0.1925 - accuracy: 0.9039\n",
      "2627/5349 [=============>................] - ETA: 1s - loss: 0.1923 - accuracy: 0.9039\n",
      "2780/5349 [==============>...............] - ETA: 1s - loss: 0.1921 - accuracy: 0.9039\n",
      "2945/5349 [===============>..............] - ETA: 1s - loss: 0.1916 - accuracy: 0.9040\n",
      "3110/5349 [================>.............] - ETA: 1s - loss: 0.1913 - accuracy: 0.9041\n",
      "3248/5349 [=================>............] - ETA: 1s - loss: 0.1910 - accuracy: 0.9043\n",
      "3389/5349 [==================>...........] - ETA: 1s - loss: 0.1908 - accuracy: 0.9042\n",
      "3537/5349 [==================>...........] - ETA: 1s - loss: 0.1905 - accuracy: 0.9043\n",
      "3787/5349 [====================>.........] - ETA: 0s - loss: 0.1899 - accuracy: 0.9045\n",
      "3951/5349 [=====================>........] - ETA: 0s - loss: 0.1896 - accuracy: 0.9046\n",
      "4116/5349 [======================>.......] - ETA: 0s - loss: 0.1894 - accuracy: 0.9047\n",
      "4277/5349 [======================>.......] - ETA: 0s - loss: 0.1889 - accuracy: 0.9050\n",
      "4441/5349 [=======================>......] - ETA: 0s - loss: 0.1887 - accuracy: 0.9051\n",
      "4609/5349 [========================>.....] - ETA: 0s - loss: 0.1884 - accuracy: 0.9052\n",
      "4850/5349 [==========================>...] - ETA: 0s - loss: 0.1880 - accuracy: 0.9053\n",
      "4973/5349 [==========================>...] - ETA: 0s - loss: 0.1876 - accuracy: 0.9055\n",
      "5125/5349 [===========================>..] - ETA: 0s - loss: 0.1874 - accuracy: 0.9055\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1871 - accuracy: 0.9057\n",
      "5349/5349 [==============================] - 4s 826us/step - loss: 0.1870 - accuracy: 0.9057 - val_loss: 0.1737 - val_accuracy: 0.9114\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.2555 - accuracy: 0.8400\n",
      " 166/5349 [..............................] - ETA: 3s - loss: 0.1789 - accuracy: 0.9067\n",
      " 337/5349 [>.............................] - ETA: 3s - loss: 0.1786 - accuracy: 0.9074\n",
      " 499/5349 [=>............................] - ETA: 2s - loss: 0.1791 - accuracy: 0.9072\n",
      " 757/5349 [===>..........................] - ETA: 2s - loss: 0.1787 - accuracy: 0.9069\n",
      " 897/5349 [====>.........................] - ETA: 2s - loss: 0.1791 - accuracy: 0.9070\n",
      "1059/5349 [====>.........................] - ETA: 2s - loss: 0.1784 - accuracy: 0.9074\n",
      "1216/5349 [=====>........................] - ETA: 2s - loss: 0.1784 - accuracy: 0.9075\n",
      "1381/5349 [======>.......................] - ETA: 2s - loss: 0.1784 - accuracy: 0.9073\n",
      "1547/5349 [=======>......................] - ETA: 2s - loss: 0.1786 - accuracy: 0.9069\n",
      "1715/5349 [========>.....................] - ETA: 2s - loss: 0.1784 - accuracy: 0.9070\n",
      "1865/5349 [=========>....................] - ETA: 2s - loss: 0.1782 - accuracy: 0.9073\n",
      "2104/5349 [==========>...................] - ETA: 2s - loss: 0.1780 - accuracy: 0.9071\n",
      "2268/5349 [===========>..................] - ETA: 1s - loss: 0.1779 - accuracy: 0.9072\n",
      "2438/5349 [============>.................] - ETA: 1s - loss: 0.1776 - accuracy: 0.9074\n",
      "2604/5349 [=============>................] - ETA: 1s - loss: 0.1775 - accuracy: 0.9074\n",
      "2770/5349 [==============>...............] - ETA: 1s - loss: 0.1772 - accuracy: 0.9075\n",
      "2931/5349 [===============>..............] - ETA: 1s - loss: 0.1770 - accuracy: 0.9076\n",
      "3171/5349 [================>.............] - ETA: 1s - loss: 0.1767 - accuracy: 0.9080\n",
      "3323/5349 [=================>............] - ETA: 1s - loss: 0.1765 - accuracy: 0.9081\n",
      "3488/5349 [==================>...........] - ETA: 1s - loss: 0.1763 - accuracy: 0.9081\n",
      "3652/5349 [===================>..........] - ETA: 1s - loss: 0.1761 - accuracy: 0.9082\n",
      "3813/5349 [====================>.........] - ETA: 0s - loss: 0.1761 - accuracy: 0.9083\n",
      "3982/5349 [=====================>........] - ETA: 0s - loss: 0.1758 - accuracy: 0.9084\n",
      "4149/5349 [======================>.......] - ETA: 0s - loss: 0.1757 - accuracy: 0.9085\n",
      "4378/5349 [=======================>......] - ETA: 0s - loss: 0.1754 - accuracy: 0.9086\n",
      "4521/5349 [========================>.....] - ETA: 0s - loss: 0.1752 - accuracy: 0.9086\n",
      "4683/5349 [=========================>....] - ETA: 0s - loss: 0.1752 - accuracy: 0.9086\n",
      "4840/5349 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.9087\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1750 - accuracy: 0.9087\n",
      "5248/5349 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9086\n",
      "5325/5349 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9087\n",
      "5349/5349 [==============================] - 4s 813us/step - loss: 0.1748 - accuracy: 0.9087 - val_loss: 0.1671 - val_accuracy: 0.9134\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 4/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1705 - accuracy: 0.9104\n",
      " 253/5349 [>.............................] - ETA: 3s - loss: 0.1697 - accuracy: 0.9111\n",
      " 422/5349 [=>............................] - ETA: 2s - loss: 0.1726 - accuracy: 0.9082\n",
      " 648/5349 [==>...........................] - ETA: 2s - loss: 0.1728 - accuracy: 0.9085\n",
      " 792/5349 [===>..........................] - ETA: 2s - loss: 0.1726 - accuracy: 0.9082\n",
      " 936/5349 [====>.........................] - ETA: 2s - loss: 0.1720 - accuracy: 0.9087\n",
      "1084/5349 [=====>........................] - ETA: 2s - loss: 0.1715 - accuracy: 0.9092\n",
      "1219/5349 [=====>........................] - ETA: 2s - loss: 0.1712 - accuracy: 0.9095\n",
      "1360/5349 [======>.......................] - ETA: 2s - loss: 0.1712 - accuracy: 0.9094\n",
      "1496/5349 [=======>......................] - ETA: 2s - loss: 0.1712 - accuracy: 0.9093\n",
      "1641/5349 [========>.....................] - ETA: 2s - loss: 0.1708 - accuracy: 0.9094\n",
      "1787/5349 [=========>....................] - ETA: 2s - loss: 0.1709 - accuracy: 0.9094\n",
      "1971/5349 [==========>...................] - ETA: 2s - loss: 0.1707 - accuracy: 0.9095\n",
      "2076/5349 [==========>...................] - ETA: 2s - loss: 0.1708 - accuracy: 0.9095\n",
      "2208/5349 [===========>..................] - ETA: 2s - loss: 0.1706 - accuracy: 0.9095\n",
      "2348/5349 [============>.................] - ETA: 2s - loss: 0.1704 - accuracy: 0.9097\n",
      "2495/5349 [============>.................] - ETA: 2s - loss: 0.1704 - accuracy: 0.9096\n",
      "2661/5349 [=============>................] - ETA: 1s - loss: 0.1703 - accuracy: 0.9096\n",
      "2828/5349 [==============>...............] - ETA: 1s - loss: 0.1705 - accuracy: 0.9095\n",
      "3073/5349 [================>.............] - ETA: 1s - loss: 0.1703 - accuracy: 0.9095\n",
      "3236/5349 [=================>............] - ETA: 1s - loss: 0.1702 - accuracy: 0.9096\n",
      "3394/5349 [==================>...........] - ETA: 1s - loss: 0.1701 - accuracy: 0.9096\n",
      "3555/5349 [==================>...........] - ETA: 1s - loss: 0.1698 - accuracy: 0.9097\n",
      "3722/5349 [===================>..........] - ETA: 1s - loss: 0.1697 - accuracy: 0.9098\n",
      "3891/5349 [====================>.........] - ETA: 0s - loss: 0.1695 - accuracy: 0.9100\n",
      "4055/5349 [=====================>........] - ETA: 0s - loss: 0.1694 - accuracy: 0.9101\n",
      "4226/5349 [======================>.......] - ETA: 0s - loss: 0.1693 - accuracy: 0.9101\n",
      "4475/5349 [========================>.....] - ETA: 0s - loss: 0.1691 - accuracy: 0.9102\n",
      "4626/5349 [========================>.....] - ETA: 0s - loss: 0.1690 - accuracy: 0.9103\n",
      "4794/5349 [=========================>....] - ETA: 0s - loss: 0.1689 - accuracy: 0.9104\n",
      "4955/5349 [==========================>...] - ETA: 0s - loss: 0.1689 - accuracy: 0.9104\n",
      "5110/5349 [===========================>..] - ETA: 0s - loss: 0.1690 - accuracy: 0.9102\n",
      "5271/5349 [============================>.] - ETA: 0s - loss: 0.1689 - accuracy: 0.9102\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9102\n",
      "5349/5349 [==============================] - 5s 869us/step - loss: 0.1690 - accuracy: 0.9102 - val_loss: 0.1638 - val_accuracy: 0.9137\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 12s - loss: 0.2002 - accuracy: 0.8900\n",
      " 141/5349 [..............................] - ETA: 3s - loss: 0.1662 - accuracy: 0.9094\n",
      " 308/5349 [>.............................] - ETA: 3s - loss: 0.1679 - accuracy: 0.9100\n",
      " 466/5349 [=>............................] - ETA: 3s - loss: 0.1675 - accuracy: 0.9106\n",
      " 633/5349 [==>...........................] - ETA: 3s - loss: 0.1673 - accuracy: 0.9106\n",
      " 787/5349 [===>..........................] - ETA: 2s - loss: 0.1678 - accuracy: 0.9099\n",
      " 949/5349 [====>.........................] - ETA: 2s - loss: 0.1673 - accuracy: 0.9106\n",
      "1103/5349 [=====>........................] - ETA: 2s - loss: 0.1666 - accuracy: 0.9111\n",
      "1342/5349 [======>.......................] - ETA: 2s - loss: 0.1662 - accuracy: 0.9114\n",
      "1504/5349 [=======>......................] - ETA: 2s - loss: 0.1660 - accuracy: 0.9114\n",
      "1673/5349 [========>.....................] - ETA: 2s - loss: 0.1658 - accuracy: 0.9115\n",
      "1836/5349 [=========>....................] - ETA: 2s - loss: 0.1656 - accuracy: 0.9115\n",
      "2009/5349 [==========>...................] - ETA: 2s - loss: 0.1661 - accuracy: 0.9111\n",
      "2170/5349 [===========>..................] - ETA: 1s - loss: 0.1661 - accuracy: 0.9110\n",
      "2335/5349 [============>.................] - ETA: 1s - loss: 0.1660 - accuracy: 0.9110\n",
      "2484/5349 [============>.................] - ETA: 1s - loss: 0.1660 - accuracy: 0.9110\n",
      "2652/5349 [=============>................] - ETA: 1s - loss: 0.1659 - accuracy: 0.9111\n",
      "2822/5349 [==============>...............] - ETA: 1s - loss: 0.1659 - accuracy: 0.9111\n",
      "3064/5349 [================>.............] - ETA: 1s - loss: 0.1656 - accuracy: 0.9114\n",
      "3233/5349 [=================>............] - ETA: 1s - loss: 0.1656 - accuracy: 0.9113\n",
      "3407/5349 [==================>...........] - ETA: 1s - loss: 0.1655 - accuracy: 0.9115\n",
      "3575/5349 [===================>..........] - ETA: 1s - loss: 0.1656 - accuracy: 0.9113\n",
      "3747/5349 [====================>.........] - ETA: 0s - loss: 0.1654 - accuracy: 0.9115\n",
      "3911/5349 [====================>.........] - ETA: 0s - loss: 0.1654 - accuracy: 0.9115\n",
      "4083/5349 [=====================>........] - ETA: 0s - loss: 0.1652 - accuracy: 0.9116\n",
      "4252/5349 [======================>.......] - ETA: 0s - loss: 0.1652 - accuracy: 0.9117\n",
      "4508/5349 [========================>.....] - ETA: 0s - loss: 0.1652 - accuracy: 0.9116\n",
      "4649/5349 [=========================>....] - ETA: 0s - loss: 0.1652 - accuracy: 0.9116\n",
      "4818/5349 [==========================>...] - ETA: 0s - loss: 0.1651 - accuracy: 0.9116\n",
      "4962/5349 [==========================>...] - ETA: 0s - loss: 0.1651 - accuracy: 0.9117\n",
      "5119/5349 [===========================>..] - ETA: 0s - loss: 0.1651 - accuracy: 0.9117\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.1653 - accuracy: 0.9115\n",
      "5349/5349 [==============================] - 4s 811us/step - loss: 0.1653 - accuracy: 0.9114 - val_loss: 0.1610 - val_accuracy: 0.9143\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1260 - accuracy: 0.9500\n",
      " 150/5349 [..............................] - ETA: 3s - loss: 0.1672 - accuracy: 0.9076\n",
      " 317/5349 [>.............................] - ETA: 3s - loss: 0.1656 - accuracy: 0.9106\n",
      " 482/5349 [=>............................] - ETA: 3s - loss: 0.1660 - accuracy: 0.9107\n",
      " 652/5349 [==>...........................] - ETA: 2s - loss: 0.1657 - accuracy: 0.9107\n",
      " 818/5349 [===>..........................] - ETA: 2s - loss: 0.1654 - accuracy: 0.9104\n",
      " 982/5349 [====>.........................] - ETA: 2s - loss: 0.1659 - accuracy: 0.9097\n",
      "1150/5349 [=====>........................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9104\n",
      "1409/5349 [======>.......................] - ETA: 2s - loss: 0.1642 - accuracy: 0.9111\n",
      "1560/5349 [=======>......................] - ETA: 2s - loss: 0.1641 - accuracy: 0.9113\n",
      "1728/5349 [========>.....................] - ETA: 2s - loss: 0.1640 - accuracy: 0.9112\n",
      "1890/5349 [=========>....................] - ETA: 2s - loss: 0.1636 - accuracy: 0.9115\n",
      "2060/5349 [==========>...................] - ETA: 2s - loss: 0.1636 - accuracy: 0.9116\n",
      "2226/5349 [===========>..................] - ETA: 1s - loss: 0.1635 - accuracy: 0.9117\n",
      "2395/5349 [============>.................] - ETA: 1s - loss: 0.1633 - accuracy: 0.9118\n",
      "2557/5349 [=============>................] - ETA: 1s - loss: 0.1633 - accuracy: 0.9118\n",
      "2730/5349 [==============>...............] - ETA: 1s - loss: 0.1631 - accuracy: 0.9120\n",
      "2983/5349 [===============>..............] - ETA: 1s - loss: 0.1625 - accuracy: 0.9125\n",
      "3152/5349 [================>.............] - ETA: 1s - loss: 0.1626 - accuracy: 0.9124\n",
      "3321/5349 [=================>............] - ETA: 1s - loss: 0.1628 - accuracy: 0.9123\n",
      "3485/5349 [==================>...........] - ETA: 1s - loss: 0.1629 - accuracy: 0.9122\n",
      "3652/5349 [===================>..........] - ETA: 1s - loss: 0.1629 - accuracy: 0.9123\n",
      "3824/5349 [====================>.........] - ETA: 0s - loss: 0.1629 - accuracy: 0.9123\n",
      "3980/5349 [=====================>........] - ETA: 0s - loss: 0.1628 - accuracy: 0.9124\n",
      "4147/5349 [======================>.......] - ETA: 0s - loss: 0.1629 - accuracy: 0.9123\n",
      "4219/5349 [======================>.......] - ETA: 0s - loss: 0.1629 - accuracy: 0.9122\n",
      "4357/5349 [=======================>......] - ETA: 0s - loss: 0.1629 - accuracy: 0.9122\n",
      "4506/5349 [========================>.....] - ETA: 0s - loss: 0.1630 - accuracy: 0.9122\n",
      "4647/5349 [=========================>....] - ETA: 0s - loss: 0.1630 - accuracy: 0.9121\n",
      "4793/5349 [=========================>....] - ETA: 0s - loss: 0.1630 - accuracy: 0.9121\n",
      "4926/5349 [==========================>...] - ETA: 0s - loss: 0.1630 - accuracy: 0.9121\n",
      "5070/5349 [===========================>..] - ETA: 0s - loss: 0.1630 - accuracy: 0.9122\n",
      "5212/5349 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9122\n",
      "5288/5349 [============================>.] - ETA: 0s - loss: 0.1629 - accuracy: 0.9122\n",
      "5349/5349 [==============================] - 4s 841us/step - loss: 0.1630 - accuracy: 0.9122 - val_loss: 0.1591 - val_accuracy: 0.9153\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 7/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.1622 - accuracy: 0.9120\n",
      " 254/5349 [>.............................] - ETA: 3s - loss: 0.1638 - accuracy: 0.9117\n",
      " 427/5349 [=>............................] - ETA: 2s - loss: 0.1635 - accuracy: 0.9108\n",
      " 589/5349 [==>...........................] - ETA: 2s - loss: 0.1625 - accuracy: 0.9117\n",
      " 761/5349 [===>..........................] - ETA: 2s - loss: 0.1625 - accuracy: 0.9121\n",
      " 928/5349 [====>.........................] - ETA: 2s - loss: 0.1623 - accuracy: 0.9120\n",
      "1180/5349 [=====>........................] - ETA: 2s - loss: 0.1617 - accuracy: 0.9124\n",
      "1344/5349 [======>.......................] - ETA: 2s - loss: 0.1609 - accuracy: 0.9131\n",
      "1512/5349 [=======>......................] - ETA: 2s - loss: 0.1609 - accuracy: 0.9131\n",
      "1679/5349 [========>.....................] - ETA: 2s - loss: 0.1609 - accuracy: 0.9133\n",
      "1852/5349 [=========>....................] - ETA: 2s - loss: 0.1608 - accuracy: 0.9134\n",
      "2017/5349 [==========>...................] - ETA: 1s - loss: 0.1609 - accuracy: 0.9135\n",
      "2189/5349 [===========>..................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9132\n",
      "2355/5349 [============>.................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9133\n",
      "2526/5349 [=============>................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9133\n",
      "2676/5349 [==============>...............] - ETA: 1s - loss: 0.1609 - accuracy: 0.9134\n",
      "2930/5349 [===============>..............] - ETA: 1s - loss: 0.1611 - accuracy: 0.9131\n",
      "3094/5349 [================>.............] - ETA: 1s - loss: 0.1611 - accuracy: 0.9132\n",
      "3262/5349 [=================>............] - ETA: 1s - loss: 0.1611 - accuracy: 0.9131\n",
      "3431/5349 [==================>...........] - ETA: 1s - loss: 0.1612 - accuracy: 0.9129\n",
      "3558/5349 [==================>...........] - ETA: 1s - loss: 0.1613 - accuracy: 0.9128\n",
      "3724/5349 [===================>..........] - ETA: 0s - loss: 0.1614 - accuracy: 0.9127\n",
      "3892/5349 [====================>.........] - ETA: 0s - loss: 0.1614 - accuracy: 0.9127\n",
      "4062/5349 [=====================>........] - ETA: 0s - loss: 0.1614 - accuracy: 0.9128\n",
      "4321/5349 [=======================>......] - ETA: 0s - loss: 0.1613 - accuracy: 0.9129\n",
      "4480/5349 [========================>.....] - ETA: 0s - loss: 0.1612 - accuracy: 0.9129\n",
      "4651/5349 [=========================>....] - ETA: 0s - loss: 0.1611 - accuracy: 0.9128\n",
      "4819/5349 [==========================>...] - ETA: 0s - loss: 0.1611 - accuracy: 0.9128\n",
      "4991/5349 [==========================>...] - ETA: 0s - loss: 0.1612 - accuracy: 0.9127\n",
      "5139/5349 [===========================>..] - ETA: 0s - loss: 0.1611 - accuracy: 0.9128\n",
      "5301/5349 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 0.9127\n",
      "5349/5349 [==============================] - 4s 795us/step - loss: 0.1612 - accuracy: 0.9127 - val_loss: 0.1576 - val_accuracy: 0.9158\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 8/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.1638 - accuracy: 0.9132\n",
      " 257/5349 [>.............................] - ETA: 2s - loss: 0.1581 - accuracy: 0.9161\n",
      " 428/5349 [=>............................] - ETA: 2s - loss: 0.1611 - accuracy: 0.9129\n",
      " 594/5349 [==>...........................] - ETA: 2s - loss: 0.1603 - accuracy: 0.9135\n",
      " 756/5349 [===>..........................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9137\n",
      "1009/5349 [====>.........................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9135\n",
      "1180/5349 [=====>........................] - ETA: 2s - loss: 0.1602 - accuracy: 0.9133\n",
      "1334/5349 [======>.......................] - ETA: 2s - loss: 0.1601 - accuracy: 0.9132\n",
      "1505/5349 [=======>......................] - ETA: 2s - loss: 0.1600 - accuracy: 0.9133\n",
      "1672/5349 [========>.....................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9133\n",
      "1841/5349 [=========>....................] - ETA: 2s - loss: 0.1598 - accuracy: 0.9135\n",
      "2010/5349 [==========>...................] - ETA: 2s - loss: 0.1596 - accuracy: 0.9139\n",
      "2257/5349 [===========>..................] - ETA: 1s - loss: 0.1595 - accuracy: 0.9138\n",
      "2421/5349 [============>.................] - ETA: 1s - loss: 0.1595 - accuracy: 0.9138\n",
      "2590/5349 [=============>................] - ETA: 1s - loss: 0.1594 - accuracy: 0.9138\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.1592 - accuracy: 0.9138\n",
      "2926/5349 [===============>..............] - ETA: 1s - loss: 0.1591 - accuracy: 0.9139\n",
      "3092/5349 [================>.............] - ETA: 1s - loss: 0.1593 - accuracy: 0.9138\n",
      "3259/5349 [=================>............] - ETA: 1s - loss: 0.1595 - accuracy: 0.9137\n",
      "3422/5349 [==================>...........] - ETA: 1s - loss: 0.1594 - accuracy: 0.9138\n",
      "3596/5349 [===================>..........] - ETA: 1s - loss: 0.1595 - accuracy: 0.9136\n",
      "3753/5349 [====================>.........] - ETA: 0s - loss: 0.1595 - accuracy: 0.9136\n",
      "4008/5349 [=====================>........] - ETA: 0s - loss: 0.1594 - accuracy: 0.9137\n",
      "4172/5349 [======================>.......] - ETA: 0s - loss: 0.1593 - accuracy: 0.9137\n",
      "4344/5349 [=======================>......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9136\n",
      "4513/5349 [========================>.....] - ETA: 0s - loss: 0.1594 - accuracy: 0.9136\n",
      "4680/5349 [=========================>....] - ETA: 0s - loss: 0.1595 - accuracy: 0.9136\n",
      "4845/5349 [==========================>...] - ETA: 0s - loss: 0.1594 - accuracy: 0.9136\n",
      "5015/5349 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9135\n",
      "5182/5349 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9135\n",
      "5267/5349 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9136\n",
      "5349/5349 [==============================] - 4s 790us/step - loss: 0.1595 - accuracy: 0.9136 - val_loss: 0.1561 - val_accuracy: 0.9160\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 9/20\n",
      "  86/5349 [..............................] - ETA: 3s - loss: 0.1579 - accuracy: 0.9151\n",
      " 256/5349 [>.............................] - ETA: 3s - loss: 0.1606 - accuracy: 0.9123\n",
      " 412/5349 [=>............................] - ETA: 3s - loss: 0.1600 - accuracy: 0.9134\n",
      " 525/5349 [=>............................] - ETA: 3s - loss: 0.1601 - accuracy: 0.9127\n",
      " 666/5349 [==>...........................] - ETA: 3s - loss: 0.1607 - accuracy: 0.9122\n",
      " 804/5349 [===>..........................] - ETA: 3s - loss: 0.1599 - accuracy: 0.9130\n",
      "1032/5349 [====>.........................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9134\n",
      "1171/5349 [=====>........................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9136\n",
      "1328/5349 [======>.......................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9135\n",
      "1473/5349 [=======>......................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9137\n",
      "1632/5349 [========>.....................] - ETA: 2s - loss: 0.1587 - accuracy: 0.9137\n",
      "1734/5349 [========>.....................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9138\n",
      "1871/5349 [=========>....................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9139\n",
      "2087/5349 [==========>...................] - ETA: 2s - loss: 0.1581 - accuracy: 0.9140\n",
      "2251/5349 [===========>..................] - ETA: 2s - loss: 0.1580 - accuracy: 0.9142\n",
      "2402/5349 [============>.................] - ETA: 2s - loss: 0.1581 - accuracy: 0.9142\n",
      "2570/5349 [=============>................] - ETA: 1s - loss: 0.1583 - accuracy: 0.9140\n",
      "2736/5349 [==============>...............] - ETA: 1s - loss: 0.1586 - accuracy: 0.9138\n",
      "2909/5349 [===============>..............] - ETA: 1s - loss: 0.1586 - accuracy: 0.9137\n",
      "3074/5349 [================>.............] - ETA: 1s - loss: 0.1585 - accuracy: 0.9137\n",
      "3247/5349 [=================>............] - ETA: 1s - loss: 0.1585 - accuracy: 0.9136\n",
      "3489/5349 [==================>...........] - ETA: 1s - loss: 0.1585 - accuracy: 0.9137\n",
      "3657/5349 [===================>..........] - ETA: 1s - loss: 0.1585 - accuracy: 0.9137\n",
      "3822/5349 [====================>.........] - ETA: 1s - loss: 0.1586 - accuracy: 0.9137\n",
      "3995/5349 [=====================>........] - ETA: 0s - loss: 0.1585 - accuracy: 0.9137\n",
      "4163/5349 [======================>.......] - ETA: 0s - loss: 0.1586 - accuracy: 0.9137\n",
      "4332/5349 [=======================>......] - ETA: 0s - loss: 0.1585 - accuracy: 0.9138\n",
      "4492/5349 [========================>.....] - ETA: 0s - loss: 0.1586 - accuracy: 0.9137\n",
      "4657/5349 [=========================>....] - ETA: 0s - loss: 0.1587 - accuracy: 0.9137\n",
      "4812/5349 [=========================>....] - ETA: 0s - loss: 0.1587 - accuracy: 0.9138\n",
      "4983/5349 [==========================>...] - ETA: 0s - loss: 0.1587 - accuracy: 0.9137\n",
      "5228/5349 [============================>.] - ETA: 0s - loss: 0.1587 - accuracy: 0.9137\n",
      "5311/5349 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9137\n",
      "5349/5349 [==============================] - 4s 839us/step - loss: 0.1587 - accuracy: 0.9137 - val_loss: 0.1557 - val_accuracy: 0.9162\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1968 - accuracy: 0.9100\n",
      " 169/5349 [..............................] - ETA: 3s - loss: 0.1596 - accuracy: 0.9124\n",
      " 342/5349 [>.............................] - ETA: 2s - loss: 0.1604 - accuracy: 0.9119\n",
      " 504/5349 [=>............................] - ETA: 2s - loss: 0.1602 - accuracy: 0.9119\n",
      " 752/5349 [===>..........................] - ETA: 2s - loss: 0.1595 - accuracy: 0.9125\n",
      " 916/5349 [====>.........................] - ETA: 2s - loss: 0.1597 - accuracy: 0.9118\n",
      "1085/5349 [=====>........................] - ETA: 2s - loss: 0.1602 - accuracy: 0.9112\n",
      "1236/5349 [=====>........................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9120\n",
      "1405/5349 [======>.......................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9122\n",
      "1571/5349 [=======>......................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9123\n",
      "1737/5349 [========>.....................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9127\n",
      "1993/5349 [==========>...................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9130\n",
      "2160/5349 [===========>..................] - ETA: 1s - loss: 0.1589 - accuracy: 0.9129\n",
      "2327/5349 [============>.................] - ETA: 1s - loss: 0.1588 - accuracy: 0.9131\n",
      "2499/5349 [=============>................] - ETA: 1s - loss: 0.1587 - accuracy: 0.9133\n",
      "2663/5349 [=============>................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9136\n",
      "2835/5349 [==============>...............] - ETA: 1s - loss: 0.1585 - accuracy: 0.9134\n",
      "2998/5349 [===============>..............] - ETA: 1s - loss: 0.1584 - accuracy: 0.9135\n",
      "3168/5349 [================>.............] - ETA: 1s - loss: 0.1583 - accuracy: 0.9135\n",
      "3335/5349 [=================>............] - ETA: 1s - loss: 0.1583 - accuracy: 0.9135\n",
      "3592/5349 [===================>..........] - ETA: 1s - loss: 0.1581 - accuracy: 0.9136\n",
      "3751/5349 [====================>.........] - ETA: 0s - loss: 0.1581 - accuracy: 0.9136\n",
      "3917/5349 [====================>.........] - ETA: 0s - loss: 0.1581 - accuracy: 0.9136\n",
      "4087/5349 [=====================>........] - ETA: 0s - loss: 0.1580 - accuracy: 0.9137\n",
      "4257/5349 [======================>.......] - ETA: 0s - loss: 0.1579 - accuracy: 0.9138\n",
      "4426/5349 [=======================>......] - ETA: 0s - loss: 0.1577 - accuracy: 0.9139\n",
      "4601/5349 [========================>.....] - ETA: 0s - loss: 0.1577 - accuracy: 0.9140\n",
      "4767/5349 [=========================>....] - ETA: 0s - loss: 0.1577 - accuracy: 0.9140\n",
      "5015/5349 [===========================>..] - ETA: 0s - loss: 0.1575 - accuracy: 0.9141\n",
      "5183/5349 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9141\n",
      "5268/5349 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9141\n",
      "5349/5349 [==============================] - 4s 790us/step - loss: 0.1576 - accuracy: 0.9141 - val_loss: 0.1551 - val_accuracy: 0.9169\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 11/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1625 - accuracy: 0.9104\n",
      " 253/5349 [>.............................] - ETA: 3s - loss: 0.1592 - accuracy: 0.9132\n",
      " 423/5349 [=>............................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9131\n",
      " 577/5349 [==>...........................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9130\n",
      " 750/5349 [===>..........................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9128\n",
      " 922/5349 [====>.........................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9131\n",
      "1090/5349 [=====>........................] - ETA: 2s - loss: 0.1581 - accuracy: 0.9133\n",
      "1180/5349 [=====>........................] - ETA: 2s - loss: 0.1580 - accuracy: 0.9132\n",
      "1348/5349 [======>.......................] - ETA: 2s - loss: 0.1577 - accuracy: 0.9138\n",
      "1520/5349 [=======>......................] - ETA: 2s - loss: 0.1575 - accuracy: 0.9140\n",
      "1686/5349 [========>.....................] - ETA: 2s - loss: 0.1575 - accuracy: 0.9142\n",
      "1847/5349 [=========>....................] - ETA: 2s - loss: 0.1572 - accuracy: 0.9144\n",
      "2012/5349 [==========>...................] - ETA: 2s - loss: 0.1573 - accuracy: 0.9142\n",
      "2184/5349 [===========>..................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9141\n",
      "2355/5349 [============>.................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9142\n",
      "2616/5349 [=============>................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9145\n",
      "2767/5349 [==============>...............] - ETA: 1s - loss: 0.1572 - accuracy: 0.9143\n",
      "2936/5349 [===============>..............] - ETA: 1s - loss: 0.1575 - accuracy: 0.9141\n",
      "3103/5349 [================>.............] - ETA: 1s - loss: 0.1572 - accuracy: 0.9144\n",
      "3272/5349 [=================>............] - ETA: 1s - loss: 0.1570 - accuracy: 0.9145\n",
      "3418/5349 [==================>...........] - ETA: 1s - loss: 0.1569 - accuracy: 0.9148\n",
      "3537/5349 [==================>...........] - ETA: 1s - loss: 0.1568 - accuracy: 0.9148\n",
      "3677/5349 [===================>..........] - ETA: 1s - loss: 0.1569 - accuracy: 0.9147\n",
      "3902/5349 [====================>.........] - ETA: 0s - loss: 0.1571 - accuracy: 0.9146\n",
      "4045/5349 [=====================>........] - ETA: 0s - loss: 0.1570 - accuracy: 0.9146\n",
      "4193/5349 [======================>.......] - ETA: 0s - loss: 0.1570 - accuracy: 0.9146\n",
      "4331/5349 [=======================>......] - ETA: 0s - loss: 0.1571 - accuracy: 0.9146\n",
      "4478/5349 [========================>.....] - ETA: 0s - loss: 0.1570 - accuracy: 0.9146\n",
      "4619/5349 [========================>.....] - ETA: 0s - loss: 0.1571 - accuracy: 0.9145\n",
      "4716/5349 [=========================>....] - ETA: 0s - loss: 0.1572 - accuracy: 0.9145\n",
      "4828/5349 [==========================>...] - ETA: 0s - loss: 0.1570 - accuracy: 0.9145\n",
      "5051/5349 [===========================>..] - ETA: 0s - loss: 0.1570 - accuracy: 0.9144\n",
      "5192/5349 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9145\n",
      "5277/5349 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9146\n",
      "5349/5349 [==============================] - 4s 837us/step - loss: 0.1569 - accuracy: 0.9145 - val_loss: 0.1547 - val_accuracy: 0.9167\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.0985 - accuracy: 0.9600\n",
      " 168/5349 [..............................] - ETA: 3s - loss: 0.1535 - accuracy: 0.9163\n",
      " 425/5349 [=>............................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9160\n",
      " 592/5349 [==>...........................] - ETA: 2s - loss: 0.1559 - accuracy: 0.9156\n",
      " 764/5349 [===>..........................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9165\n",
      " 928/5349 [====>.........................] - ETA: 2s - loss: 0.1552 - accuracy: 0.9159\n",
      "1097/5349 [=====>........................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9159\n",
      "1260/5349 [======>.......................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9156\n",
      "1515/5349 [=======>......................] - ETA: 2s - loss: 0.1548 - accuracy: 0.9159\n",
      "1662/5349 [========>.....................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9159\n",
      "1832/5349 [=========>....................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9159\n",
      "1993/5349 [==========>...................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9157\n",
      "2163/5349 [===========>..................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9156\n",
      "2328/5349 [============>.................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9155\n",
      "2466/5349 [============>.................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9153\n",
      "2635/5349 [=============>................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9153\n",
      "2878/5349 [===============>..............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9150\n",
      "3042/5349 [================>.............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9149\n",
      "3195/5349 [================>.............] - ETA: 1s - loss: 0.1557 - accuracy: 0.9149\n",
      "3365/5349 [=================>............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9149\n",
      "3531/5349 [==================>...........] - ETA: 1s - loss: 0.1558 - accuracy: 0.9148\n",
      "3694/5349 [===================>..........] - ETA: 1s - loss: 0.1559 - accuracy: 0.9148\n",
      "3860/5349 [====================>.........] - ETA: 0s - loss: 0.1556 - accuracy: 0.9150\n",
      "4117/5349 [======================>.......] - ETA: 0s - loss: 0.1556 - accuracy: 0.9151\n",
      "4268/5349 [======================>.......] - ETA: 0s - loss: 0.1557 - accuracy: 0.9150\n",
      "4434/5349 [=======================>......] - ETA: 0s - loss: 0.1556 - accuracy: 0.9150\n",
      "4601/5349 [========================>.....] - ETA: 0s - loss: 0.1559 - accuracy: 0.9149\n",
      "4771/5349 [=========================>....] - ETA: 0s - loss: 0.1558 - accuracy: 0.9150\n",
      "4940/5349 [==========================>...] - ETA: 0s - loss: 0.1559 - accuracy: 0.9149\n",
      "5191/5349 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9149\n",
      "5272/5349 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9150\n",
      "5349/5349 [==============================] - 4s 797us/step - loss: 0.1558 - accuracy: 0.9149 - val_loss: 0.1533 - val_accuracy: 0.9174\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1249 - accuracy: 0.9100\n",
      " 171/5349 [..............................] - ETA: 3s - loss: 0.1533 - accuracy: 0.9187\n",
      " 258/5349 [>.............................] - ETA: 3s - loss: 0.1532 - accuracy: 0.9190\n",
      " 429/5349 [=>............................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9181\n",
      " 592/5349 [==>...........................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9171\n",
      " 749/5349 [===>..........................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9160\n",
      " 915/5349 [====>.........................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9160\n",
      "1072/5349 [=====>........................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9159\n",
      "1239/5349 [=====>........................] - ETA: 2s - loss: 0.1542 - accuracy: 0.9160\n",
      "1412/5349 [======>.......................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9158\n",
      "1578/5349 [=======>......................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9153\n",
      "1747/5349 [========>.....................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9157\n",
      "1916/5349 [=========>....................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9156\n",
      "2087/5349 [==========>...................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9157\n",
      "2329/5349 [============>.................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9156\n",
      "2496/5349 [============>.................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9156\n",
      "2665/5349 [=============>................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9153\n",
      "2836/5349 [==============>...............] - ETA: 1s - loss: 0.1554 - accuracy: 0.9150\n",
      "3005/5349 [===============>..............] - ETA: 1s - loss: 0.1554 - accuracy: 0.9151\n",
      "3177/5349 [================>.............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9152\n",
      "3338/5349 [=================>............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9153\n",
      "3599/5349 [===================>..........] - ETA: 1s - loss: 0.1555 - accuracy: 0.9152\n",
      "3765/5349 [====================>.........] - ETA: 0s - loss: 0.1555 - accuracy: 0.9152\n",
      "3937/5349 [=====================>........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9153\n",
      "4103/5349 [======================>.......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9153\n",
      "4259/5349 [======================>.......] - ETA: 0s - loss: 0.1551 - accuracy: 0.9154\n",
      "4427/5349 [=======================>......] - ETA: 0s - loss: 0.1551 - accuracy: 0.9155\n",
      "4600/5349 [========================>.....] - ETA: 0s - loss: 0.1552 - accuracy: 0.9154\n",
      "4853/5349 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9155\n",
      "5021/5349 [===========================>..] - ETA: 0s - loss: 0.1553 - accuracy: 0.9153\n",
      "5187/5349 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9153\n",
      "5273/5349 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9153\n",
      "5349/5349 [==============================] - 4s 804us/step - loss: 0.1553 - accuracy: 0.9153 - val_loss: 0.1524 - val_accuracy: 0.9176\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 14/20\n",
      "  71/5349 [..............................] - ETA: 3s - loss: 0.1563 - accuracy: 0.9117\n",
      " 227/5349 [>.............................] - ETA: 3s - loss: 0.1598 - accuracy: 0.9105\n",
      " 380/5349 [=>............................] - ETA: 3s - loss: 0.1579 - accuracy: 0.9126\n",
      " 512/5349 [=>............................] - ETA: 3s - loss: 0.1569 - accuracy: 0.9136\n",
      " 661/5349 [==>...........................] - ETA: 3s - loss: 0.1568 - accuracy: 0.9138\n",
      " 819/5349 [===>..........................] - ETA: 3s - loss: 0.1565 - accuracy: 0.9139\n",
      " 949/5349 [====>.........................] - ETA: 3s - loss: 0.1570 - accuracy: 0.9137\n",
      "1089/5349 [=====>........................] - ETA: 3s - loss: 0.1566 - accuracy: 0.9141\n",
      "1240/5349 [=====>........................] - ETA: 3s - loss: 0.1566 - accuracy: 0.9138\n",
      "1407/5349 [======>.......................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9144\n",
      "1579/5349 [=======>......................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9147\n",
      "1740/5349 [========>.....................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9148\n",
      "1913/5349 [=========>....................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9148\n",
      "2065/5349 [==========>...................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9151\n",
      "2225/5349 [===========>..................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9149\n",
      "2384/5349 [============>.................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9149\n",
      "2631/5349 [=============>................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9152\n",
      "2796/5349 [==============>...............] - ETA: 1s - loss: 0.1552 - accuracy: 0.9152\n",
      "2967/5349 [===============>..............] - ETA: 1s - loss: 0.1552 - accuracy: 0.9153\n",
      "3132/5349 [================>.............] - ETA: 1s - loss: 0.1550 - accuracy: 0.9155\n",
      "3298/5349 [=================>............] - ETA: 1s - loss: 0.1550 - accuracy: 0.9155\n",
      "3380/5349 [=================>............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9157\n",
      "3541/5349 [==================>...........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9157\n",
      "3710/5349 [===================>..........] - ETA: 1s - loss: 0.1546 - accuracy: 0.9158\n",
      "3874/5349 [====================>.........] - ETA: 0s - loss: 0.1546 - accuracy: 0.9158\n",
      "4043/5349 [=====================>........] - ETA: 0s - loss: 0.1547 - accuracy: 0.9157\n",
      "4203/5349 [======================>.......] - ETA: 0s - loss: 0.1548 - accuracy: 0.9156\n",
      "4372/5349 [=======================>......] - ETA: 0s - loss: 0.1547 - accuracy: 0.9157\n",
      "4530/5349 [========================>.....] - ETA: 0s - loss: 0.1547 - accuracy: 0.9157\n",
      "4703/5349 [=========================>....] - ETA: 0s - loss: 0.1547 - accuracy: 0.9156\n",
      "4868/5349 [==========================>...] - ETA: 0s - loss: 0.1547 - accuracy: 0.9156\n",
      "5028/5349 [===========================>..] - ETA: 0s - loss: 0.1546 - accuracy: 0.9157\n",
      "5106/5349 [===========================>..] - ETA: 0s - loss: 0.1547 - accuracy: 0.9157\n",
      "5265/5349 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9157\n",
      "5324/5349 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9157\n",
      "5349/5349 [==============================] - 4s 841us/step - loss: 0.1547 - accuracy: 0.9157 - val_loss: 0.1521 - val_accuracy: 0.9173\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1471 - accuracy: 0.9100\n",
      " 169/5349 [..............................] - ETA: 3s - loss: 0.1591 - accuracy: 0.9132\n",
      " 338/5349 [>.............................] - ETA: 3s - loss: 0.1572 - accuracy: 0.9143\n",
      " 498/5349 [=>............................] - ETA: 2s - loss: 0.1568 - accuracy: 0.9137\n",
      " 666/5349 [==>...........................] - ETA: 2s - loss: 0.1568 - accuracy: 0.9139\n",
      " 747/5349 [===>..........................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9141\n",
      " 897/5349 [====>.........................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9143\n",
      "1067/5349 [====>.........................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9146\n",
      "1226/5349 [=====>........................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9146\n",
      "1393/5349 [======>.......................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9147\n",
      "1557/5349 [=======>......................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9152\n",
      "1728/5349 [========>.....................] - ETA: 2s - loss: 0.1552 - accuracy: 0.9153\n",
      "1894/5349 [=========>....................] - ETA: 2s - loss: 0.1548 - accuracy: 0.9156\n",
      "2061/5349 [==========>...................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9159\n",
      "2227/5349 [===========>..................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9158\n",
      "2389/5349 [============>.................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9159\n",
      "2553/5349 [=============>................] - ETA: 1s - loss: 0.1544 - accuracy: 0.9160\n",
      "2718/5349 [==============>...............] - ETA: 1s - loss: 0.1542 - accuracy: 0.9161\n",
      "2798/5349 [==============>...............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9159\n",
      "2959/5349 [===============>..............] - ETA: 1s - loss: 0.1545 - accuracy: 0.9157\n",
      "3129/5349 [================>.............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9157\n",
      "3283/5349 [=================>............] - ETA: 1s - loss: 0.1543 - accuracy: 0.9158\n",
      "3456/5349 [==================>...........] - ETA: 1s - loss: 0.1544 - accuracy: 0.9157\n",
      "3612/5349 [===================>..........] - ETA: 1s - loss: 0.1543 - accuracy: 0.9157\n",
      "3781/5349 [====================>.........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9156\n",
      "3949/5349 [=====================>........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9156\n",
      "4191/5349 [======================>.......] - ETA: 0s - loss: 0.1545 - accuracy: 0.9156\n",
      "4353/5349 [=======================>......] - ETA: 0s - loss: 0.1544 - accuracy: 0.9157\n",
      "4520/5349 [========================>.....] - ETA: 0s - loss: 0.1545 - accuracy: 0.9156\n",
      "4686/5349 [=========================>....] - ETA: 0s - loss: 0.1546 - accuracy: 0.9155\n",
      "4858/5349 [==========================>...] - ETA: 0s - loss: 0.1546 - accuracy: 0.9155\n",
      "5016/5349 [===========================>..] - ETA: 0s - loss: 0.1545 - accuracy: 0.9156\n",
      "5186/5349 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9157\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9158\n",
      "5349/5349 [==============================] - 4s 800us/step - loss: 0.1543 - accuracy: 0.9158 - val_loss: 0.1515 - val_accuracy: 0.9179\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 16/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1568 - accuracy: 0.9120\n",
      " 255/5349 [>.............................] - ETA: 3s - loss: 0.1544 - accuracy: 0.9164\n",
      " 513/5349 [=>............................] - ETA: 2s - loss: 0.1560 - accuracy: 0.9148\n",
      " 678/5349 [==>...........................] - ETA: 2s - loss: 0.1559 - accuracy: 0.9151\n",
      " 844/5349 [===>..........................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9156\n",
      "1008/5349 [====>.........................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9151\n",
      "1176/5349 [=====>........................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9155\n",
      "1343/5349 [======>.......................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9155\n",
      "1515/5349 [=======>......................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9155\n",
      "1675/5349 [========>.....................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9155\n",
      "1842/5349 [=========>....................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9156\n",
      "2007/5349 [==========>...................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9157\n",
      "2176/5349 [===========>..................] - ETA: 1s - loss: 0.1543 - accuracy: 0.9157\n",
      "2263/5349 [===========>..................] - ETA: 1s - loss: 0.1543 - accuracy: 0.9158\n",
      "2387/5349 [============>.................] - ETA: 1s - loss: 0.1542 - accuracy: 0.9160\n",
      "2521/5349 [=============>................] - ETA: 1s - loss: 0.1542 - accuracy: 0.9161\n",
      "2656/5349 [=============>................] - ETA: 1s - loss: 0.1542 - accuracy: 0.9160\n",
      "2799/5349 [==============>...............] - ETA: 1s - loss: 0.1541 - accuracy: 0.9160\n",
      "2939/5349 [===============>..............] - ETA: 1s - loss: 0.1540 - accuracy: 0.9161\n",
      "3087/5349 [================>.............] - ETA: 1s - loss: 0.1540 - accuracy: 0.9161\n",
      "3225/5349 [=================>............] - ETA: 1s - loss: 0.1541 - accuracy: 0.9159\n",
      "3375/5349 [=================>............] - ETA: 1s - loss: 0.1541 - accuracy: 0.9160\n",
      "3519/5349 [==================>...........] - ETA: 1s - loss: 0.1541 - accuracy: 0.9159\n",
      "3633/5349 [===================>..........] - ETA: 1s - loss: 0.1542 - accuracy: 0.9158\n",
      "3781/5349 [====================>.........] - ETA: 1s - loss: 0.1541 - accuracy: 0.9159\n",
      "3928/5349 [=====================>........] - ETA: 0s - loss: 0.1541 - accuracy: 0.9160\n",
      "4068/5349 [=====================>........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9160\n",
      "4235/5349 [======================>.......] - ETA: 0s - loss: 0.1540 - accuracy: 0.9160\n",
      "4387/5349 [=======================>......] - ETA: 0s - loss: 0.1541 - accuracy: 0.9160\n",
      "4548/5349 [========================>.....] - ETA: 0s - loss: 0.1543 - accuracy: 0.9159\n",
      "4710/5349 [=========================>....] - ETA: 0s - loss: 0.1542 - accuracy: 0.9159\n",
      "4876/5349 [==========================>...] - ETA: 0s - loss: 0.1542 - accuracy: 0.9159\n",
      "5042/5349 [===========================>..] - ETA: 0s - loss: 0.1541 - accuracy: 0.9159\n",
      "5212/5349 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9160\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9160\n",
      "5349/5349 [==============================] - 5s 849us/step - loss: 0.1540 - accuracy: 0.9160 - val_loss: 0.1513 - val_accuracy: 0.9181\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 17/20\n",
      "  81/5349 [..............................] - ETA: 3s - loss: 0.1465 - accuracy: 0.9237 \n",
      " 247/5349 [>.............................] - ETA: 3s - loss: 0.1527 - accuracy: 0.9164\n",
      " 498/5349 [=>............................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9180\n",
      " 652/5349 [==>...........................] - ETA: 2s - loss: 0.1517 - accuracy: 0.9183\n",
      " 815/5349 [===>..........................] - ETA: 2s - loss: 0.1519 - accuracy: 0.9179\n",
      " 962/5349 [====>.........................] - ETA: 2s - loss: 0.1519 - accuracy: 0.9178\n",
      "1131/5349 [=====>........................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9174\n",
      "1265/5349 [======>.......................] - ETA: 2s - loss: 0.1523 - accuracy: 0.9172\n",
      "1431/5349 [=======>......................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9171\n",
      "1518/5349 [=======>......................] - ETA: 2s - loss: 0.1521 - accuracy: 0.9171\n",
      "1681/5349 [========>.....................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9170\n",
      "1850/5349 [=========>....................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9171\n",
      "2009/5349 [==========>...................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9170\n",
      "2178/5349 [===========>..................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9168\n",
      "2344/5349 [============>.................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9167\n",
      "2510/5349 [=============>................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9165\n",
      "2746/5349 [==============>...............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9164\n",
      "2914/5349 [===============>..............] - ETA: 1s - loss: 0.1528 - accuracy: 0.9165\n",
      "3080/5349 [================>.............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9164\n",
      "3247/5349 [=================>............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9163\n",
      "3399/5349 [==================>...........] - ETA: 1s - loss: 0.1528 - accuracy: 0.9165\n",
      "3569/5349 [===================>..........] - ETA: 1s - loss: 0.1530 - accuracy: 0.9164\n",
      "3734/5349 [===================>..........] - ETA: 1s - loss: 0.1530 - accuracy: 0.9163\n",
      "3905/5349 [====================>.........] - ETA: 0s - loss: 0.1532 - accuracy: 0.9162\n",
      "4155/5349 [======================>.......] - ETA: 0s - loss: 0.1529 - accuracy: 0.9164\n",
      "4327/5349 [=======================>......] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "4489/5349 [========================>.....] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "4658/5349 [=========================>....] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "4815/5349 [==========================>...] - ETA: 0s - loss: 0.1530 - accuracy: 0.9163\n",
      "4981/5349 [==========================>...] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "5146/5349 [===========================>..] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "5318/5349 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "5349/5349 [==============================] - 4s 804us/step - loss: 0.1530 - accuracy: 0.9164 - val_loss: 0.1517 - val_accuracy: 0.9176\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1518 - accuracy: 0.9100\n",
      " 170/5349 [..............................] - ETA: 3s - loss: 0.1532 - accuracy: 0.9168\n",
      " 425/5349 [=>............................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9167\n",
      " 587/5349 [==>...........................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9165\n",
      " 758/5349 [===>..........................] - ETA: 2s - loss: 0.1533 - accuracy: 0.9167\n",
      " 914/5349 [====>.........................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9158\n",
      "1064/5349 [====>.........................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9159\n",
      "1215/5349 [=====>........................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9159\n",
      "1384/5349 [======>.......................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9158\n",
      "1543/5349 [=======>......................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9159\n",
      "1619/5349 [========>.....................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9158\n",
      "1774/5349 [========>.....................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9158\n",
      "1930/5349 [=========>....................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9157\n",
      "2093/5349 [==========>...................] - ETA: 2s - loss: 0.1534 - accuracy: 0.9161\n",
      "2236/5349 [===========>..................] - ETA: 1s - loss: 0.1533 - accuracy: 0.9162\n",
      "2402/5349 [============>.................] - ETA: 1s - loss: 0.1533 - accuracy: 0.9162\n",
      "2558/5349 [=============>................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9164\n",
      "2802/5349 [==============>...............] - ETA: 1s - loss: 0.1529 - accuracy: 0.9166\n",
      "2959/5349 [===============>..............] - ETA: 1s - loss: 0.1528 - accuracy: 0.9167\n",
      "3129/5349 [================>.............] - ETA: 1s - loss: 0.1527 - accuracy: 0.9168\n",
      "3294/5349 [=================>............] - ETA: 1s - loss: 0.1527 - accuracy: 0.9168\n",
      "3462/5349 [==================>...........] - ETA: 1s - loss: 0.1528 - accuracy: 0.9168\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.1530 - accuracy: 0.9166\n",
      "3788/5349 [====================>.........] - ETA: 0s - loss: 0.1530 - accuracy: 0.9165\n",
      "3953/5349 [=====================>........] - ETA: 0s - loss: 0.1529 - accuracy: 0.9165\n",
      "4120/5349 [======================>.......] - ETA: 0s - loss: 0.1529 - accuracy: 0.9165\n",
      "4275/5349 [======================>.......] - ETA: 0s - loss: 0.1529 - accuracy: 0.9166\n",
      "4436/5349 [=======================>......] - ETA: 0s - loss: 0.1526 - accuracy: 0.9168\n",
      "4601/5349 [========================>.....] - ETA: 0s - loss: 0.1527 - accuracy: 0.9167\n",
      "4861/5349 [==========================>...] - ETA: 0s - loss: 0.1528 - accuracy: 0.9165\n",
      "5024/5349 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.9165\n",
      "5190/5349 [============================>.] - ETA: 0s - loss: 0.1529 - accuracy: 0.9164\n",
      "5266/5349 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9164\n",
      "5349/5349 [==============================] - 5s 872us/step - loss: 0.1529 - accuracy: 0.9164 - val_loss: 0.1502 - val_accuracy: 0.9184\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 10s - loss: 0.1992 - accuracy: 0.8700\n",
      " 193/5349 [>.............................] - ETA: 4s - loss: 0.1576 - accuracy: 0.9145\n",
      " 343/5349 [>.............................] - ETA: 3s - loss: 0.1562 - accuracy: 0.9149\n",
      " 506/5349 [=>............................] - ETA: 3s - loss: 0.1555 - accuracy: 0.9144\n",
      " 677/5349 [==>...........................] - ETA: 3s - loss: 0.1554 - accuracy: 0.9138\n",
      " 844/5349 [===>..........................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9141\n",
      "1094/5349 [=====>........................] - ETA: 2s - loss: 0.1544 - accuracy: 0.9149\n",
      "1238/5349 [=====>........................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9153\n",
      "1410/5349 [======>.......................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9158\n",
      "1570/5349 [=======>......................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9161\n",
      "1730/5349 [========>.....................] - ETA: 2s - loss: 0.1534 - accuracy: 0.9160\n",
      "1890/5349 [=========>....................] - ETA: 2s - loss: 0.1528 - accuracy: 0.9164\n",
      "2059/5349 [==========>...................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9167\n",
      "2227/5349 [===========>..................] - ETA: 1s - loss: 0.1523 - accuracy: 0.9169\n",
      "2398/5349 [============>.................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9169\n",
      "2482/5349 [============>.................] - ETA: 1s - loss: 0.1522 - accuracy: 0.9169\n",
      "2642/5349 [=============>................] - ETA: 1s - loss: 0.1524 - accuracy: 0.9169\n",
      "2811/5349 [==============>...............] - ETA: 1s - loss: 0.1523 - accuracy: 0.9169\n",
      "2972/5349 [===============>..............] - ETA: 1s - loss: 0.1523 - accuracy: 0.9169\n",
      "3142/5349 [================>.............] - ETA: 1s - loss: 0.1522 - accuracy: 0.9169\n",
      "3289/5349 [=================>............] - ETA: 1s - loss: 0.1522 - accuracy: 0.9169\n",
      "3447/5349 [==================>...........] - ETA: 1s - loss: 0.1522 - accuracy: 0.9170\n",
      "3615/5349 [===================>..........] - ETA: 1s - loss: 0.1521 - accuracy: 0.9170\n",
      "3865/5349 [====================>.........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9169\n",
      "4030/5349 [=====================>........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9169\n",
      "4195/5349 [======================>.......] - ETA: 0s - loss: 0.1523 - accuracy: 0.9168\n",
      "4358/5349 [=======================>......] - ETA: 0s - loss: 0.1524 - accuracy: 0.9168\n",
      "4523/5349 [========================>.....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9170\n",
      "4671/5349 [=========================>....] - ETA: 0s - loss: 0.1522 - accuracy: 0.9170\n",
      "4802/5349 [=========================>....] - ETA: 0s - loss: 0.1520 - accuracy: 0.9171\n",
      "4954/5349 [==========================>...] - ETA: 0s - loss: 0.1520 - accuracy: 0.9171\n",
      "5118/5349 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.9170\n",
      "5277/5349 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9172\n",
      "5349/5349 [==============================] - 4s 840us/step - loss: 0.1521 - accuracy: 0.9171 - val_loss: 0.1500 - val_accuracy: 0.9189\n",
      "\u001B[36m(train_DNN pid=5487)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1490 - accuracy: 0.8900\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1526 - accuracy: 0.9169\n",
      " 336/5349 [>.............................] - ETA: 3s - loss: 0.1538 - accuracy: 0.9152\n",
      " 497/5349 [=>............................] - ETA: 2s - loss: 0.1526 - accuracy: 0.9161\n",
      " 666/5349 [==>...........................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9164\n",
      " 828/5349 [===>..........................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9168\n",
      " 995/5349 [====>.........................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9167\n",
      "1146/5349 [=====>........................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9163\n",
      "1317/5349 [======>.......................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9161\n",
      "1405/5349 [======>.......................] - ETA: 2s - loss: 0.1531 - accuracy: 0.9162\n",
      "1571/5349 [=======>......................] - ETA: 2s - loss: 0.1528 - accuracy: 0.9165\n",
      "1744/5349 [========>.....................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9161\n",
      "1906/5349 [=========>....................] - ETA: 2s - loss: 0.1531 - accuracy: 0.9161\n",
      "2075/5349 [==========>...................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9164\n",
      "2243/5349 [===========>..................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9164\n",
      "2413/5349 [============>.................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9164\n",
      "2573/5349 [=============>................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9162\n",
      "2737/5349 [==============>...............] - ETA: 1s - loss: 0.1529 - accuracy: 0.9161\n",
      "2902/5349 [===============>..............] - ETA: 1s - loss: 0.1525 - accuracy: 0.9165\n",
      "3155/5349 [================>.............] - ETA: 1s - loss: 0.1524 - accuracy: 0.9166\n",
      "3323/5349 [=================>............] - ETA: 1s - loss: 0.1522 - accuracy: 0.9167\n",
      "3487/5349 [==================>...........] - ETA: 1s - loss: 0.1522 - accuracy: 0.9167\n",
      "3615/5349 [===================>..........] - ETA: 1s - loss: 0.1522 - accuracy: 0.9167\n",
      "3757/5349 [====================>.........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9167\n",
      "3898/5349 [====================>.........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9167\n",
      "4143/5349 [======================>.......] - ETA: 0s - loss: 0.1525 - accuracy: 0.9166\n",
      "4308/5349 [=======================>......] - ETA: 0s - loss: 0.1526 - accuracy: 0.9165\n",
      "4473/5349 [========================>.....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9167\n",
      "4628/5349 [========================>.....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9166\n",
      "4799/5349 [=========================>....] - ETA: 0s - loss: 0.1522 - accuracy: 0.9167\n",
      "4967/5349 [==========================>...] - ETA: 0s - loss: 0.1522 - accuracy: 0.9167\n",
      "5140/5349 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.9168\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.9169\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 26:49 - loss: 0.8881 - accuracy: 0.1700\n",
      " 145/5349 [..............................] - ETA: 3s - loss: 0.5187 - accuracy: 0.7495\n",
      " 294/5349 [>.............................] - ETA: 3s - loss: 0.4493 - accuracy: 0.7983\n",
      " 424/5349 [=>............................] - ETA: 3s - loss: 0.4012 - accuracy: 0.8099\n",
      " 575/5349 [==>...........................] - ETA: 3s - loss: 0.3503 - accuracy: 0.8337\n",
      " 797/5349 [===>..........................] - ETA: 3s - loss: 0.3009 - accuracy: 0.8568\n",
      " 953/5349 [====>.........................] - ETA: 3s - loss: 0.2790 - accuracy: 0.8665\n",
      "1093/5349 [=====>........................] - ETA: 2s - loss: 0.2642 - accuracy: 0.8730\n",
      "1238/5349 [=====>........................] - ETA: 2s - loss: 0.2520 - accuracy: 0.8784\n",
      "1385/5349 [======>.......................] - ETA: 2s - loss: 0.2421 - accuracy: 0.8827\n",
      "1534/5349 [=======>......................] - ETA: 2s - loss: 0.2340 - accuracy: 0.8863\n",
      "1686/5349 [========>.....................] - ETA: 2s - loss: 0.2276 - accuracy: 0.8887\n",
      "1915/5349 [=========>....................] - ETA: 2s - loss: 0.2194 - accuracy: 0.8922\n",
      "2065/5349 [==========>...................] - ETA: 2s - loss: 0.2147 - accuracy: 0.8943\n",
      "2216/5349 [===========>..................] - ETA: 2s - loss: 0.2107 - accuracy: 0.8959\n",
      "2367/5349 [============>.................] - ETA: 2s - loss: 0.2076 - accuracy: 0.8971\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.2046 - accuracy: 0.8982\n",
      "2661/5349 [=============>................] - ETA: 1s - loss: 0.2021 - accuracy: 0.8991\n",
      "2892/5349 [===============>..............] - ETA: 1s - loss: 0.1981 - accuracy: 0.9009\n",
      "3031/5349 [===============>..............] - ETA: 1s - loss: 0.1963 - accuracy: 0.9016\n",
      "3183/5349 [================>.............] - ETA: 1s - loss: 0.1944 - accuracy: 0.9024\n",
      "3301/5349 [=================>............] - ETA: 1s - loss: 0.1928 - accuracy: 0.9031\n",
      "3413/5349 [==================>...........] - ETA: 1s - loss: 0.1917 - accuracy: 0.9034\n",
      "3557/5349 [==================>...........] - ETA: 1s - loss: 0.1901 - accuracy: 0.9040\n",
      "3705/5349 [===================>..........] - ETA: 1s - loss: 0.1886 - accuracy: 0.9047\n",
      "3857/5349 [====================>.........] - ETA: 1s - loss: 0.1874 - accuracy: 0.9051\n",
      "4008/5349 [=====================>........] - ETA: 0s - loss: 0.1863 - accuracy: 0.9055\n",
      "4159/5349 [======================>.......] - ETA: 0s - loss: 0.1851 - accuracy: 0.9059\n",
      "4381/5349 [=======================>......] - ETA: 0s - loss: 0.1835 - accuracy: 0.9064\n",
      "4527/5349 [========================>.....] - ETA: 0s - loss: 0.1825 - accuracy: 0.9069\n",
      "4674/5349 [=========================>....] - ETA: 0s - loss: 0.1816 - accuracy: 0.9073\n",
      "4778/5349 [=========================>....] - ETA: 0s - loss: 0.1809 - accuracy: 0.9076\n",
      "4851/5349 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.9077\n",
      "4963/5349 [==========================>...] - ETA: 0s - loss: 0.1799 - accuracy: 0.9080\n",
      "5086/5349 [===========================>..] - ETA: 0s - loss: 0.1794 - accuracy: 0.9081\n",
      "5210/5349 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.9085\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.9087\n",
      "5349/5349 [==============================] - 5s 942us/step - loss: 0.1780 - accuracy: 0.9087 - val_loss: 0.1504 - val_accuracy: 0.9206\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 2/20\n",
      "  64/5349 [..............................] - ETA: 4s - loss: 0.1500 - accuracy: 0.9233\n",
      " 210/5349 [>.............................] - ETA: 3s - loss: 0.1499 - accuracy: 0.9213\n",
      " 359/5349 [=>............................] - ETA: 3s - loss: 0.1493 - accuracy: 0.9212\n",
      " 581/5349 [==>...........................] - ETA: 3s - loss: 0.1506 - accuracy: 0.9196\n",
      " 727/5349 [===>..........................] - ETA: 3s - loss: 0.1515 - accuracy: 0.9193\n",
      " 860/5349 [===>..........................] - ETA: 3s - loss: 0.1516 - accuracy: 0.9191\n",
      "1013/5349 [====>.........................] - ETA: 3s - loss: 0.1518 - accuracy: 0.9188\n",
      "1164/5349 [=====>........................] - ETA: 2s - loss: 0.1518 - accuracy: 0.9186\n",
      "1318/5349 [======>.......................] - ETA: 2s - loss: 0.1515 - accuracy: 0.9189\n",
      "1467/5349 [=======>......................] - ETA: 2s - loss: 0.1510 - accuracy: 0.9191\n",
      "1543/5349 [=======>......................] - ETA: 2s - loss: 0.1509 - accuracy: 0.9191\n",
      "1695/5349 [========>.....................] - ETA: 2s - loss: 0.1508 - accuracy: 0.9189\n",
      "1842/5349 [=========>....................] - ETA: 2s - loss: 0.1508 - accuracy: 0.9191\n",
      "1973/5349 [==========>...................] - ETA: 2s - loss: 0.1507 - accuracy: 0.9192\n",
      "2122/5349 [==========>...................] - ETA: 2s - loss: 0.1503 - accuracy: 0.9195\n",
      "2270/5349 [===========>..................] - ETA: 2s - loss: 0.1500 - accuracy: 0.9197\n",
      "2422/5349 [============>.................] - ETA: 2s - loss: 0.1498 - accuracy: 0.9196\n",
      "2573/5349 [=============>................] - ETA: 1s - loss: 0.1496 - accuracy: 0.9198\n",
      "2724/5349 [==============>...............] - ETA: 1s - loss: 0.1495 - accuracy: 0.9198\n",
      "2878/5349 [===============>..............] - ETA: 1s - loss: 0.1494 - accuracy: 0.9198\n",
      "3013/5349 [===============>..............] - ETA: 1s - loss: 0.1496 - accuracy: 0.9196\n",
      "3166/5349 [================>.............] - ETA: 1s - loss: 0.1494 - accuracy: 0.9197\n",
      "3358/5349 [=================>............] - ETA: 1s - loss: 0.1491 - accuracy: 0.9199\n",
      "3512/5349 [==================>...........] - ETA: 1s - loss: 0.1489 - accuracy: 0.9199\n",
      "3658/5349 [===================>..........] - ETA: 1s - loss: 0.1486 - accuracy: 0.9201\n",
      "3811/5349 [====================>.........] - ETA: 1s - loss: 0.1484 - accuracy: 0.9201\n",
      "3960/5349 [=====================>........] - ETA: 0s - loss: 0.1483 - accuracy: 0.9202\n",
      "4107/5349 [======================>.......] - ETA: 0s - loss: 0.1482 - accuracy: 0.9201\n",
      "4253/5349 [======================>.......] - ETA: 0s - loss: 0.1482 - accuracy: 0.9201\n",
      "4402/5349 [=======================>......] - ETA: 0s - loss: 0.1480 - accuracy: 0.9202\n",
      "4551/5349 [========================>.....] - ETA: 0s - loss: 0.1478 - accuracy: 0.9204\n",
      "4765/5349 [=========================>....] - ETA: 0s - loss: 0.1477 - accuracy: 0.9204\n",
      "4907/5349 [==========================>...] - ETA: 0s - loss: 0.1476 - accuracy: 0.9204\n",
      "5056/5349 [===========================>..] - ETA: 0s - loss: 0.1474 - accuracy: 0.9205\n",
      "5185/5349 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9206\n",
      "5338/5349 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9207\n",
      "5349/5349 [==============================] - 5s 855us/step - loss: 0.1472 - accuracy: 0.9207 - val_loss: 0.1426 - val_accuracy: 0.9238\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 3/20\n",
      "  75/5349 [..............................] - ETA: 3s - loss: 0.1433 - accuracy: 0.9228\n",
      " 225/5349 [>.............................] - ETA: 3s - loss: 0.1419 - accuracy: 0.9236\n",
      " 376/5349 [=>............................] - ETA: 3s - loss: 0.1414 - accuracy: 0.9235\n",
      " 523/5349 [=>............................] - ETA: 3s - loss: 0.1414 - accuracy: 0.9237\n",
      " 673/5349 [==>...........................] - ETA: 3s - loss: 0.1419 - accuracy: 0.9232\n",
      " 820/5349 [===>..........................] - ETA: 3s - loss: 0.1423 - accuracy: 0.9231\n",
      " 964/5349 [====>.........................] - ETA: 2s - loss: 0.1421 - accuracy: 0.9233\n",
      "1102/5349 [=====>........................] - ETA: 2s - loss: 0.1424 - accuracy: 0.9231\n",
      "1180/5349 [=====>........................] - ETA: 2s - loss: 0.1422 - accuracy: 0.9234\n",
      "1331/5349 [======>.......................] - ETA: 2s - loss: 0.1424 - accuracy: 0.9231\n",
      "1460/5349 [=======>......................] - ETA: 2s - loss: 0.1427 - accuracy: 0.9230\n",
      "1609/5349 [========>.....................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9230\n",
      "1747/5349 [========>.....................] - ETA: 2s - loss: 0.1422 - accuracy: 0.9231\n",
      "1896/5349 [=========>....................] - ETA: 2s - loss: 0.1423 - accuracy: 0.9230\n",
      "2049/5349 [==========>...................] - ETA: 2s - loss: 0.1423 - accuracy: 0.9230\n",
      "2262/5349 [===========>..................] - ETA: 2s - loss: 0.1420 - accuracy: 0.9231\n",
      "2410/5349 [============>.................] - ETA: 2s - loss: 0.1422 - accuracy: 0.9231\n",
      "2563/5349 [=============>................] - ETA: 1s - loss: 0.1420 - accuracy: 0.9231\n",
      "2711/5349 [==============>...............] - ETA: 1s - loss: 0.1419 - accuracy: 0.9232\n",
      "2862/5349 [===============>..............] - ETA: 1s - loss: 0.1417 - accuracy: 0.9235\n",
      "3015/5349 [===============>..............] - ETA: 1s - loss: 0.1415 - accuracy: 0.9237\n",
      "3169/5349 [================>.............] - ETA: 1s - loss: 0.1413 - accuracy: 0.9239\n",
      "3386/5349 [=================>............] - ETA: 1s - loss: 0.1411 - accuracy: 0.9240\n",
      "3535/5349 [==================>...........] - ETA: 1s - loss: 0.1410 - accuracy: 0.9240\n",
      "3687/5349 [===================>..........] - ETA: 1s - loss: 0.1408 - accuracy: 0.9241\n",
      "3839/5349 [====================>.........] - ETA: 1s - loss: 0.1408 - accuracy: 0.9242\n",
      "3990/5349 [=====================>........] - ETA: 0s - loss: 0.1407 - accuracy: 0.9243\n",
      "4141/5349 [======================>.......] - ETA: 0s - loss: 0.1405 - accuracy: 0.9244\n",
      "4293/5349 [=======================>......] - ETA: 0s - loss: 0.1405 - accuracy: 0.9245\n",
      "4507/5349 [========================>.....] - ETA: 0s - loss: 0.1405 - accuracy: 0.9244\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1404 - accuracy: 0.9244\n",
      "4801/5349 [=========================>....] - ETA: 0s - loss: 0.1403 - accuracy: 0.9245\n",
      "4947/5349 [==========================>...] - ETA: 0s - loss: 0.1402 - accuracy: 0.9246\n",
      "5094/5349 [===========================>..] - ETA: 0s - loss: 0.1402 - accuracy: 0.9246\n",
      "5244/5349 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9247\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1401 - accuracy: 0.9248\n",
      "5349/5349 [==============================] - 5s 849us/step - loss: 0.1401 - accuracy: 0.9248 - val_loss: 0.1383 - val_accuracy: 0.9278\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1849 - accuracy: 0.9300\n",
      " 152/5349 [..............................] - ETA: 3s - loss: 0.1385 - accuracy: 0.9276\n",
      " 304/5349 [>.............................] - ETA: 3s - loss: 0.1388 - accuracy: 0.9270\n",
      " 429/5349 [=>............................] - ETA: 3s - loss: 0.1377 - accuracy: 0.9272\n",
      " 590/5349 [==>...........................] - ETA: 3s - loss: 0.1355 - accuracy: 0.9288\n",
      " 694/5349 [==>...........................] - ETA: 3s - loss: 0.1348 - accuracy: 0.9289\n",
      " 814/5349 [===>..........................] - ETA: 3s - loss: 0.1356 - accuracy: 0.9281\n",
      " 934/5349 [====>.........................] - ETA: 3s - loss: 0.1351 - accuracy: 0.9286\n",
      "1053/5349 [====>.........................] - ETA: 3s - loss: 0.1351 - accuracy: 0.9286\n",
      "1210/5349 [=====>........................] - ETA: 3s - loss: 0.1349 - accuracy: 0.9285\n",
      "1314/5349 [======>.......................] - ETA: 3s - loss: 0.1352 - accuracy: 0.9282\n",
      "1428/5349 [=======>......................] - ETA: 3s - loss: 0.1352 - accuracy: 0.9282\n",
      "1508/5349 [=======>......................] - ETA: 3s - loss: 0.1353 - accuracy: 0.9282\n",
      "1579/5349 [=======>......................] - ETA: 3s - loss: 0.1357 - accuracy: 0.9279\n",
      "1691/5349 [========>.....................] - ETA: 3s - loss: 0.1354 - accuracy: 0.9280\n",
      "1798/5349 [=========>....................] - ETA: 3s - loss: 0.1354 - accuracy: 0.9280\n",
      "2003/5349 [==========>...................] - ETA: 2s - loss: 0.1350 - accuracy: 0.9282\n",
      "2153/5349 [===========>..................] - ETA: 2s - loss: 0.1351 - accuracy: 0.9282\n",
      "2303/5349 [===========>..................] - ETA: 2s - loss: 0.1349 - accuracy: 0.9284\n",
      "2449/5349 [============>.................] - ETA: 2s - loss: 0.1349 - accuracy: 0.9283\n",
      "2594/5349 [=============>................] - ETA: 2s - loss: 0.1350 - accuracy: 0.9282\n",
      "2739/5349 [==============>...............] - ETA: 2s - loss: 0.1348 - accuracy: 0.9283\n",
      "2889/5349 [===============>..............] - ETA: 2s - loss: 0.1346 - accuracy: 0.9285\n",
      "3105/5349 [================>.............] - ETA: 1s - loss: 0.1345 - accuracy: 0.9284\n",
      "3252/5349 [=================>............] - ETA: 1s - loss: 0.1346 - accuracy: 0.9284\n",
      "3384/5349 [=================>............] - ETA: 1s - loss: 0.1346 - accuracy: 0.9285\n",
      "3535/5349 [==================>...........] - ETA: 1s - loss: 0.1347 - accuracy: 0.9285\n",
      "3677/5349 [===================>..........] - ETA: 1s - loss: 0.1347 - accuracy: 0.9284\n",
      "3819/5349 [====================>.........] - ETA: 1s - loss: 0.1345 - accuracy: 0.9285\n",
      "3966/5349 [=====================>........] - ETA: 1s - loss: 0.1345 - accuracy: 0.9284\n",
      "4113/5349 [======================>.......] - ETA: 0s - loss: 0.1344 - accuracy: 0.9285\n",
      "4265/5349 [======================>.......] - ETA: 0s - loss: 0.1345 - accuracy: 0.9284\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1344 - accuracy: 0.9285\n",
      "4549/5349 [========================>.....] - ETA: 0s - loss: 0.1343 - accuracy: 0.9286\n",
      "4625/5349 [========================>.....] - ETA: 0s - loss: 0.1341 - accuracy: 0.9286\n",
      "4771/5349 [=========================>....] - ETA: 0s - loss: 0.1341 - accuracy: 0.9287\n",
      "4913/5349 [==========================>...] - ETA: 0s - loss: 0.1342 - accuracy: 0.9286\n",
      "5064/5349 [===========================>..] - ETA: 0s - loss: 0.1342 - accuracy: 0.9287\n",
      "5209/5349 [============================>.] - ETA: 0s - loss: 0.1341 - accuracy: 0.9287\n",
      "5286/5349 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.9288\n",
      "5349/5349 [==============================] - 5s 941us/step - loss: 0.1340 - accuracy: 0.9288 - val_loss: 0.1307 - val_accuracy: 0.9313\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1410 - accuracy: 0.9500\n",
      " 120/5349 [..............................] - ETA: 4s - loss: 0.1358 - accuracy: 0.9268\n",
      " 273/5349 [>.............................] - ETA: 3s - loss: 0.1325 - accuracy: 0.9292\n",
      " 419/5349 [=>............................] - ETA: 3s - loss: 0.1305 - accuracy: 0.9315\n",
      " 570/5349 [==>...........................] - ETA: 3s - loss: 0.1302 - accuracy: 0.9317\n",
      " 716/5349 [===>..........................] - ETA: 3s - loss: 0.1306 - accuracy: 0.9310\n",
      " 946/5349 [====>.........................] - ETA: 3s - loss: 0.1300 - accuracy: 0.9315\n",
      "1092/5349 [=====>........................] - ETA: 2s - loss: 0.1296 - accuracy: 0.9319\n",
      "1246/5349 [=====>........................] - ETA: 2s - loss: 0.1296 - accuracy: 0.9317\n",
      "1394/5349 [======>.......................] - ETA: 2s - loss: 0.1301 - accuracy: 0.9310\n",
      "1547/5349 [=======>......................] - ETA: 2s - loss: 0.1307 - accuracy: 0.9304\n",
      "1681/5349 [========>.....................] - ETA: 2s - loss: 0.1304 - accuracy: 0.9306\n",
      "1830/5349 [=========>....................] - ETA: 2s - loss: 0.1303 - accuracy: 0.9306\n",
      "1979/5349 [==========>...................] - ETA: 2s - loss: 0.1305 - accuracy: 0.9305\n",
      "2127/5349 [==========>...................] - ETA: 2s - loss: 0.1307 - accuracy: 0.9305\n",
      "2270/5349 [===========>..................] - ETA: 2s - loss: 0.1306 - accuracy: 0.9304\n",
      "2346/5349 [============>.................] - ETA: 2s - loss: 0.1304 - accuracy: 0.9305\n",
      "2496/5349 [============>.................] - ETA: 1s - loss: 0.1306 - accuracy: 0.9305\n",
      "2639/5349 [=============>................] - ETA: 1s - loss: 0.1304 - accuracy: 0.9307\n",
      "2791/5349 [==============>...............] - ETA: 1s - loss: 0.1301 - accuracy: 0.9309\n",
      "2930/5349 [===============>..............] - ETA: 1s - loss: 0.1302 - accuracy: 0.9309\n",
      "3081/5349 [================>.............] - ETA: 1s - loss: 0.1302 - accuracy: 0.9309\n",
      "3231/5349 [=================>............] - ETA: 1s - loss: 0.1298 - accuracy: 0.9311\n",
      "3459/5349 [==================>...........] - ETA: 1s - loss: 0.1299 - accuracy: 0.9310\n",
      "3609/5349 [===================>..........] - ETA: 1s - loss: 0.1298 - accuracy: 0.9310\n",
      "3759/5349 [====================>.........] - ETA: 1s - loss: 0.1298 - accuracy: 0.9311\n",
      "3894/5349 [====================>.........] - ETA: 0s - loss: 0.1297 - accuracy: 0.9312\n",
      "4047/5349 [=====================>........] - ETA: 0s - loss: 0.1296 - accuracy: 0.9312\n",
      "4184/5349 [======================>.......] - ETA: 0s - loss: 0.1296 - accuracy: 0.9313\n",
      "4333/5349 [=======================>......] - ETA: 0s - loss: 0.1296 - accuracy: 0.9313\n",
      "4407/5349 [=======================>......] - ETA: 0s - loss: 0.1297 - accuracy: 0.9312\n",
      "4554/5349 [========================>.....] - ETA: 0s - loss: 0.1297 - accuracy: 0.9312\n",
      "4709/5349 [=========================>....] - ETA: 0s - loss: 0.1295 - accuracy: 0.9313\n",
      "4857/5349 [==========================>...] - ETA: 0s - loss: 0.1296 - accuracy: 0.9313\n",
      "5010/5349 [===========================>..] - ETA: 0s - loss: 0.1296 - accuracy: 0.9313\n",
      "5149/5349 [===========================>..] - ETA: 0s - loss: 0.1297 - accuracy: 0.9313\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9312\n",
      "5349/5349 [==============================] - 5s 854us/step - loss: 0.1299 - accuracy: 0.9312 - val_loss: 0.1261 - val_accuracy: 0.9341\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1488 - accuracy: 0.9100\n",
      " 153/5349 [..............................] - ETA: 3s - loss: 0.1260 - accuracy: 0.9321\n",
      " 306/5349 [>.............................] - ETA: 3s - loss: 0.1279 - accuracy: 0.9320\n",
      " 441/5349 [=>............................] - ETA: 3s - loss: 0.1274 - accuracy: 0.9321\n",
      " 666/5349 [==>...........................] - ETA: 3s - loss: 0.1279 - accuracy: 0.9316\n",
      " 807/5349 [===>..........................] - ETA: 3s - loss: 0.1283 - accuracy: 0.9312\n",
      " 949/5349 [====>.........................] - ETA: 3s - loss: 0.1285 - accuracy: 0.9311\n",
      "1090/5349 [=====>........................] - ETA: 2s - loss: 0.1280 - accuracy: 0.9317\n",
      "1241/5349 [=====>........................] - ETA: 2s - loss: 0.1282 - accuracy: 0.9316\n",
      "1379/5349 [======>.......................] - ETA: 2s - loss: 0.1279 - accuracy: 0.9320\n",
      "1528/5349 [=======>......................] - ETA: 2s - loss: 0.1275 - accuracy: 0.9324\n",
      "1676/5349 [========>.....................] - ETA: 2s - loss: 0.1276 - accuracy: 0.9325\n",
      "1826/5349 [=========>....................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9328\n",
      "1973/5349 [==========>...................] - ETA: 2s - loss: 0.1273 - accuracy: 0.9328\n",
      "2115/5349 [==========>...................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9330\n",
      "2184/5349 [===========>..................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9329\n",
      "2304/5349 [===========>..................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9330\n",
      "2428/5349 [============>.................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9331\n",
      "2539/5349 [=============>................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9330\n",
      "2660/5349 [=============>................] - ETA: 1s - loss: 0.1270 - accuracy: 0.9330\n",
      "2766/5349 [==============>...............] - ETA: 1s - loss: 0.1273 - accuracy: 0.9327\n",
      "2886/5349 [===============>..............] - ETA: 1s - loss: 0.1276 - accuracy: 0.9326\n",
      "3069/5349 [================>.............] - ETA: 1s - loss: 0.1277 - accuracy: 0.9324\n",
      "3188/5349 [================>.............] - ETA: 1s - loss: 0.1275 - accuracy: 0.9325\n",
      "3282/5349 [=================>............] - ETA: 1s - loss: 0.1276 - accuracy: 0.9324\n",
      "3385/5349 [=================>............] - ETA: 1s - loss: 0.1275 - accuracy: 0.9325\n",
      "3463/5349 [==================>...........] - ETA: 1s - loss: 0.1275 - accuracy: 0.9325\n",
      "3547/5349 [==================>...........] - ETA: 1s - loss: 0.1276 - accuracy: 0.9325\n",
      "3659/5349 [===================>..........] - ETA: 1s - loss: 0.1274 - accuracy: 0.9326\n",
      "3848/5349 [====================>.........] - ETA: 1s - loss: 0.1272 - accuracy: 0.9327\n",
      "3973/5349 [=====================>........] - ETA: 1s - loss: 0.1272 - accuracy: 0.9328\n",
      "4125/5349 [======================>.......] - ETA: 0s - loss: 0.1271 - accuracy: 0.9328\n",
      "4269/5349 [======================>.......] - ETA: 0s - loss: 0.1270 - accuracy: 0.9329\n",
      "4412/5349 [=======================>......] - ETA: 0s - loss: 0.1270 - accuracy: 0.9329\n",
      "4560/5349 [========================>.....] - ETA: 0s - loss: 0.1271 - accuracy: 0.9329\n",
      "4781/5349 [=========================>....] - ETA: 0s - loss: 0.1270 - accuracy: 0.9329\n",
      "4931/5349 [==========================>...] - ETA: 0s - loss: 0.1271 - accuracy: 0.9329\n",
      "5067/5349 [===========================>..] - ETA: 0s - loss: 0.1271 - accuracy: 0.9328\n",
      "5218/5349 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9327\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9327\n",
      "5349/5349 [==============================] - 5s 933us/step - loss: 0.1271 - accuracy: 0.9327 - val_loss: 0.1265 - val_accuracy: 0.9337\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 7/20\n",
      "  75/5349 [..............................] - ETA: 3s - loss: 0.1275 - accuracy: 0.9300\n",
      " 226/5349 [>.............................] - ETA: 3s - loss: 0.1257 - accuracy: 0.9322\n",
      " 450/5349 [=>............................] - ETA: 3s - loss: 0.1249 - accuracy: 0.9338\n",
      " 595/5349 [==>...........................] - ETA: 3s - loss: 0.1255 - accuracy: 0.9334\n",
      " 736/5349 [===>..........................] - ETA: 3s - loss: 0.1254 - accuracy: 0.9337\n",
      " 865/5349 [===>..........................] - ETA: 3s - loss: 0.1247 - accuracy: 0.9339\n",
      "1010/5349 [====>.........................] - ETA: 3s - loss: 0.1246 - accuracy: 0.9341\n",
      "1153/5349 [=====>........................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9339\n",
      "1304/5349 [======>.......................] - ETA: 2s - loss: 0.1249 - accuracy: 0.9340\n",
      "1523/5349 [=======>......................] - ETA: 2s - loss: 0.1249 - accuracy: 0.9341\n",
      "1673/5349 [========>.....................] - ETA: 2s - loss: 0.1250 - accuracy: 0.9341\n",
      "1821/5349 [=========>....................] - ETA: 2s - loss: 0.1251 - accuracy: 0.9338\n",
      "1973/5349 [==========>...................] - ETA: 2s - loss: 0.1249 - accuracy: 0.9337\n",
      "2118/5349 [==========>...................] - ETA: 2s - loss: 0.1249 - accuracy: 0.9337\n",
      "2261/5349 [===========>..................] - ETA: 2s - loss: 0.1250 - accuracy: 0.9337\n",
      "2401/5349 [============>.................] - ETA: 2s - loss: 0.1253 - accuracy: 0.9335\n",
      "2623/5349 [=============>................] - ETA: 1s - loss: 0.1253 - accuracy: 0.9333\n",
      "2766/5349 [==============>...............] - ETA: 1s - loss: 0.1252 - accuracy: 0.9333\n",
      "2914/5349 [===============>..............] - ETA: 1s - loss: 0.1252 - accuracy: 0.9333\n",
      "3053/5349 [================>.............] - ETA: 1s - loss: 0.1252 - accuracy: 0.9334\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.1254 - accuracy: 0.9333\n",
      "3356/5349 [=================>............] - ETA: 1s - loss: 0.1254 - accuracy: 0.9334\n",
      "3501/5349 [==================>...........] - ETA: 1s - loss: 0.1253 - accuracy: 0.9335\n",
      "3640/5349 [===================>..........] - ETA: 1s - loss: 0.1251 - accuracy: 0.9336\n",
      "3865/5349 [====================>.........] - ETA: 1s - loss: 0.1249 - accuracy: 0.9338\n",
      "4012/5349 [=====================>........] - ETA: 0s - loss: 0.1249 - accuracy: 0.9337\n",
      "4161/5349 [======================>.......] - ETA: 0s - loss: 0.1248 - accuracy: 0.9338\n",
      "4309/5349 [=======================>......] - ETA: 0s - loss: 0.1247 - accuracy: 0.9339\n",
      "4458/5349 [========================>.....] - ETA: 0s - loss: 0.1247 - accuracy: 0.9339\n",
      "4606/5349 [========================>.....] - ETA: 0s - loss: 0.1248 - accuracy: 0.9337\n",
      "4756/5349 [=========================>....] - ETA: 0s - loss: 0.1248 - accuracy: 0.9337\n",
      "4909/5349 [==========================>...] - ETA: 0s - loss: 0.1250 - accuracy: 0.9336\n",
      "5132/5349 [===========================>..] - ETA: 0s - loss: 0.1249 - accuracy: 0.9338\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9338\n",
      "5344/5349 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9337\n",
      "5349/5349 [==============================] - 5s 857us/step - loss: 0.1250 - accuracy: 0.9337 - val_loss: 0.1222 - val_accuracy: 0.9358\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 8/20\n",
      "  76/5349 [..............................] - ETA: 3s - loss: 0.1218 - accuracy: 0.9366\n",
      " 227/5349 [>.............................] - ETA: 3s - loss: 0.1226 - accuracy: 0.9364\n",
      " 381/5349 [=>............................] - ETA: 3s - loss: 0.1223 - accuracy: 0.9361\n",
      " 530/5349 [=>............................] - ETA: 3s - loss: 0.1219 - accuracy: 0.9362\n",
      " 680/5349 [==>...........................] - ETA: 3s - loss: 0.1221 - accuracy: 0.9358\n",
      " 823/5349 [===>..........................] - ETA: 3s - loss: 0.1229 - accuracy: 0.9351\n",
      "1048/5349 [====>.........................] - ETA: 2s - loss: 0.1238 - accuracy: 0.9345\n",
      "1191/5349 [=====>........................] - ETA: 2s - loss: 0.1236 - accuracy: 0.9348\n",
      "1340/5349 [======>.......................] - ETA: 2s - loss: 0.1235 - accuracy: 0.9349\n",
      "1487/5349 [=======>......................] - ETA: 2s - loss: 0.1236 - accuracy: 0.9348\n",
      "1633/5349 [========>.....................] - ETA: 2s - loss: 0.1236 - accuracy: 0.9349\n",
      "1773/5349 [========>.....................] - ETA: 2s - loss: 0.1239 - accuracy: 0.9348\n",
      "1925/5349 [=========>....................] - ETA: 2s - loss: 0.1242 - accuracy: 0.9346\n",
      "2077/5349 [==========>...................] - ETA: 2s - loss: 0.1240 - accuracy: 0.9346\n",
      "2300/5349 [===========>..................] - ETA: 2s - loss: 0.1239 - accuracy: 0.9346\n",
      "2449/5349 [============>.................] - ETA: 1s - loss: 0.1238 - accuracy: 0.9347\n",
      "2601/5349 [=============>................] - ETA: 1s - loss: 0.1239 - accuracy: 0.9346\n",
      "2748/5349 [==============>...............] - ETA: 1s - loss: 0.1238 - accuracy: 0.9347\n",
      "2894/5349 [===============>..............] - ETA: 1s - loss: 0.1237 - accuracy: 0.9348\n",
      "3039/5349 [================>.............] - ETA: 1s - loss: 0.1238 - accuracy: 0.9346\n",
      "3184/5349 [================>.............] - ETA: 1s - loss: 0.1238 - accuracy: 0.9345\n",
      "3318/5349 [=================>............] - ETA: 1s - loss: 0.1237 - accuracy: 0.9346\n",
      "3547/5349 [==================>...........] - ETA: 1s - loss: 0.1234 - accuracy: 0.9348\n",
      "3689/5349 [===================>..........] - ETA: 1s - loss: 0.1232 - accuracy: 0.9349\n",
      "3835/5349 [====================>.........] - ETA: 1s - loss: 0.1232 - accuracy: 0.9349\n",
      "3983/5349 [=====================>........] - ETA: 0s - loss: 0.1233 - accuracy: 0.9349\n",
      "4133/5349 [======================>.......] - ETA: 0s - loss: 0.1232 - accuracy: 0.9349\n",
      "4260/5349 [======================>.......] - ETA: 0s - loss: 0.1233 - accuracy: 0.9349\n",
      "4319/5349 [=======================>......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9349\n",
      "4409/5349 [=======================>......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9348\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.1235 - accuracy: 0.9349\n",
      "4650/5349 [=========================>....] - ETA: 0s - loss: 0.1234 - accuracy: 0.9349\n",
      "4778/5349 [=========================>....] - ETA: 0s - loss: 0.1234 - accuracy: 0.9349\n",
      "4896/5349 [==========================>...] - ETA: 0s - loss: 0.1233 - accuracy: 0.9349\n",
      "5025/5349 [===========================>..] - ETA: 0s - loss: 0.1233 - accuracy: 0.9348\n",
      "5213/5349 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9349\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9349\n",
      "5325/5349 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9349\n",
      "5349/5349 [==============================] - 5s 906us/step - loss: 0.1234 - accuracy: 0.9349 - val_loss: 0.1242 - val_accuracy: 0.9350\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1532 - accuracy: 0.9200\n",
      " 146/5349 [..............................] - ETA: 3s - loss: 0.1233 - accuracy: 0.9339\n",
      " 362/5349 [=>............................] - ETA: 3s - loss: 0.1194 - accuracy: 0.9372\n",
      " 489/5349 [=>............................] - ETA: 3s - loss: 0.1194 - accuracy: 0.9368\n",
      " 633/5349 [==>...........................] - ETA: 3s - loss: 0.1199 - accuracy: 0.9368\n",
      " 774/5349 [===>..........................] - ETA: 3s - loss: 0.1212 - accuracy: 0.9362\n",
      " 909/5349 [====>.........................] - ETA: 3s - loss: 0.1213 - accuracy: 0.9362\n",
      "1136/5349 [=====>........................] - ETA: 2s - loss: 0.1216 - accuracy: 0.9357\n",
      "1288/5349 [======>.......................] - ETA: 2s - loss: 0.1221 - accuracy: 0.9355\n",
      "1426/5349 [======>.......................] - ETA: 2s - loss: 0.1221 - accuracy: 0.9353\n",
      "1576/5349 [=======>......................] - ETA: 2s - loss: 0.1222 - accuracy: 0.9353\n",
      "1721/5349 [========>.....................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9353\n",
      "1869/5349 [=========>....................] - ETA: 2s - loss: 0.1220 - accuracy: 0.9354\n",
      "2016/5349 [==========>...................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9355\n",
      "2165/5349 [===========>..................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9354\n",
      "2311/5349 [===========>..................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9352\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.1221 - accuracy: 0.9352\n",
      "2674/5349 [=============>................] - ETA: 1s - loss: 0.1220 - accuracy: 0.9353\n",
      "2799/5349 [==============>...............] - ETA: 1s - loss: 0.1219 - accuracy: 0.9354\n",
      "2942/5349 [===============>..............] - ETA: 1s - loss: 0.1218 - accuracy: 0.9356\n",
      "3082/5349 [================>.............] - ETA: 1s - loss: 0.1217 - accuracy: 0.9356\n",
      "3227/5349 [=================>............] - ETA: 1s - loss: 0.1217 - accuracy: 0.9356\n",
      "3361/5349 [=================>............] - ETA: 1s - loss: 0.1218 - accuracy: 0.9355\n",
      "3510/5349 [==================>...........] - ETA: 1s - loss: 0.1218 - accuracy: 0.9357\n",
      "3663/5349 [===================>..........] - ETA: 1s - loss: 0.1218 - accuracy: 0.9357\n",
      "3886/5349 [====================>.........] - ETA: 1s - loss: 0.1218 - accuracy: 0.9357\n",
      "4038/5349 [=====================>........] - ETA: 0s - loss: 0.1217 - accuracy: 0.9358\n",
      "4185/5349 [======================>.......] - ETA: 0s - loss: 0.1217 - accuracy: 0.9358\n",
      "4336/5349 [=======================>......] - ETA: 0s - loss: 0.1218 - accuracy: 0.9357\n",
      "4483/5349 [========================>.....] - ETA: 0s - loss: 0.1218 - accuracy: 0.9358\n",
      "4630/5349 [========================>.....] - ETA: 0s - loss: 0.1218 - accuracy: 0.9358\n",
      "4780/5349 [=========================>....] - ETA: 0s - loss: 0.1217 - accuracy: 0.9360\n",
      "4930/5349 [==========================>...] - ETA: 0s - loss: 0.1218 - accuracy: 0.9359\n",
      "5072/5349 [===========================>..] - ETA: 0s - loss: 0.1218 - accuracy: 0.9358\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9358\n",
      "5349/5349 [==============================] - 5s 863us/step - loss: 0.1219 - accuracy: 0.9358 - val_loss: 0.1200 - val_accuracy: 0.9352\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 10/20\n",
      "  75/5349 [..............................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9425\n",
      " 222/5349 [>.............................] - ETA: 3s - loss: 0.1197 - accuracy: 0.9370\n",
      " 375/5349 [=>............................] - ETA: 3s - loss: 0.1215 - accuracy: 0.9358\n",
      " 599/5349 [==>...........................] - ETA: 3s - loss: 0.1226 - accuracy: 0.9345\n",
      " 748/5349 [===>..........................] - ETA: 3s - loss: 0.1228 - accuracy: 0.9348\n",
      " 890/5349 [===>..........................] - ETA: 3s - loss: 0.1235 - accuracy: 0.9347\n",
      "1040/5349 [====>.........................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9349\n",
      "1179/5349 [=====>........................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9346\n",
      "1330/5349 [======>.......................] - ETA: 2s - loss: 0.1228 - accuracy: 0.9350\n",
      "1474/5349 [=======>......................] - ETA: 2s - loss: 0.1221 - accuracy: 0.9356\n",
      "1695/5349 [========>.....................] - ETA: 2s - loss: 0.1221 - accuracy: 0.9360\n",
      "1835/5349 [=========>....................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9363\n",
      "1965/5349 [==========>...................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9361\n",
      "2104/5349 [==========>...................] - ETA: 2s - loss: 0.1220 - accuracy: 0.9360\n",
      "2252/5349 [===========>..................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9360\n",
      "2386/5349 [============>.................] - ETA: 2s - loss: 0.1221 - accuracy: 0.9358\n",
      "2536/5349 [=============>................] - ETA: 1s - loss: 0.1220 - accuracy: 0.9357\n",
      "2684/5349 [==============>...............] - ETA: 1s - loss: 0.1218 - accuracy: 0.9358\n",
      "2839/5349 [==============>...............] - ETA: 1s - loss: 0.1214 - accuracy: 0.9361\n",
      "2979/5349 [===============>..............] - ETA: 1s - loss: 0.1216 - accuracy: 0.9360\n",
      "3202/5349 [================>.............] - ETA: 1s - loss: 0.1216 - accuracy: 0.9357\n",
      "3352/5349 [=================>............] - ETA: 1s - loss: 0.1214 - accuracy: 0.9359\n",
      "3503/5349 [==================>...........] - ETA: 1s - loss: 0.1212 - accuracy: 0.9359\n",
      "3653/5349 [===================>..........] - ETA: 1s - loss: 0.1213 - accuracy: 0.9359\n",
      "3795/5349 [====================>.........] - ETA: 1s - loss: 0.1210 - accuracy: 0.9361\n",
      "3927/5349 [=====================>........] - ETA: 0s - loss: 0.1210 - accuracy: 0.9361\n",
      "4071/5349 [=====================>........] - ETA: 0s - loss: 0.1211 - accuracy: 0.9361\n",
      "4221/5349 [======================>.......] - ETA: 0s - loss: 0.1211 - accuracy: 0.9361\n",
      "4450/5349 [=======================>......] - ETA: 0s - loss: 0.1211 - accuracy: 0.9360\n",
      "4594/5349 [========================>.....] - ETA: 0s - loss: 0.1212 - accuracy: 0.9360\n",
      "4744/5349 [=========================>....] - ETA: 0s - loss: 0.1211 - accuracy: 0.9360\n",
      "4893/5349 [==========================>...] - ETA: 0s - loss: 0.1210 - accuracy: 0.9361\n",
      "5043/5349 [===========================>..] - ETA: 0s - loss: 0.1209 - accuracy: 0.9361\n",
      "5190/5349 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9361\n",
      "5338/5349 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9360\n",
      "5349/5349 [==============================] - 5s 881us/step - loss: 0.1210 - accuracy: 0.9360 - val_loss: 0.1227 - val_accuracy: 0.9369\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 11/20\n",
      "  51/5349 [..............................] - ETA: 5s - loss: 0.1154 - accuracy: 0.9408\n",
      " 159/5349 [..............................] - ETA: 4s - loss: 0.1141 - accuracy: 0.9418\n",
      " 279/5349 [>.............................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9405\n",
      " 398/5349 [=>............................] - ETA: 4s - loss: 0.1176 - accuracy: 0.9388\n",
      " 457/5349 [=>............................] - ETA: 4s - loss: 0.1173 - accuracy: 0.9388\n",
      " 583/5349 [==>...........................] - ETA: 4s - loss: 0.1177 - accuracy: 0.9385\n",
      " 712/5349 [==>...........................] - ETA: 3s - loss: 0.1182 - accuracy: 0.9384\n",
      " 787/5349 [===>..........................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9383\n",
      " 938/5349 [====>.........................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9376\n",
      "1170/5349 [=====>........................] - ETA: 3s - loss: 0.1194 - accuracy: 0.9375\n",
      "1303/5349 [======>.......................] - ETA: 3s - loss: 0.1197 - accuracy: 0.9372\n",
      "1371/5349 [======>.......................] - ETA: 3s - loss: 0.1195 - accuracy: 0.9374\n",
      "1445/5349 [=======>......................] - ETA: 3s - loss: 0.1195 - accuracy: 0.9373\n",
      "1542/5349 [=======>......................] - ETA: 3s - loss: 0.1198 - accuracy: 0.9371\n",
      "1623/5349 [========>.....................] - ETA: 3s - loss: 0.1197 - accuracy: 0.9371\n",
      "1725/5349 [========>.....................] - ETA: 3s - loss: 0.1193 - accuracy: 0.9373\n",
      "1857/5349 [=========>....................] - ETA: 3s - loss: 0.1193 - accuracy: 0.9373\n",
      "2070/5349 [==========>...................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9372\n",
      "2210/5349 [===========>..................] - ETA: 2s - loss: 0.1193 - accuracy: 0.9373\n",
      "2357/5349 [============>.................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9372\n",
      "2497/5349 [=============>................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9370\n",
      "2638/5349 [=============>................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9370\n",
      "2780/5349 [==============>...............] - ETA: 2s - loss: 0.1195 - accuracy: 0.9369\n",
      "2928/5349 [===============>..............] - ETA: 2s - loss: 0.1196 - accuracy: 0.9369\n",
      "3061/5349 [================>.............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9368\n",
      "3212/5349 [=================>............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9368\n",
      "3349/5349 [=================>............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9368\n",
      "3577/5349 [===================>..........] - ETA: 1s - loss: 0.1196 - accuracy: 0.9366\n",
      "3721/5349 [===================>..........] - ETA: 1s - loss: 0.1197 - accuracy: 0.9365\n",
      "3865/5349 [====================>.........] - ETA: 1s - loss: 0.1197 - accuracy: 0.9365\n",
      "3973/5349 [=====================>........] - ETA: 1s - loss: 0.1197 - accuracy: 0.9366\n",
      "4108/5349 [======================>.......] - ETA: 0s - loss: 0.1196 - accuracy: 0.9366\n",
      "4230/5349 [======================>.......] - ETA: 0s - loss: 0.1196 - accuracy: 0.9366\n",
      "4372/5349 [=======================>......] - ETA: 0s - loss: 0.1196 - accuracy: 0.9366\n",
      "4520/5349 [========================>.....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9365\n",
      "4667/5349 [=========================>....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9365\n",
      "4874/5349 [==========================>...] - ETA: 0s - loss: 0.1197 - accuracy: 0.9365\n",
      "5023/5349 [===========================>..] - ETA: 0s - loss: 0.1197 - accuracy: 0.9365\n",
      "5171/5349 [============================>.] - ETA: 0s - loss: 0.1197 - accuracy: 0.9365\n",
      "5248/5349 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.9366\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.1197 - accuracy: 0.9366\n",
      "5349/5349 [==============================] - 5s 956us/step - loss: 0.1197 - accuracy: 0.9366 - val_loss: 0.1178 - val_accuracy: 0.9385\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 12/20\n",
      " 142/5349 [..............................] - ETA: 3s - loss: 0.1169 - accuracy: 0.9368\n",
      " 289/5349 [>.............................] - ETA: 3s - loss: 0.1204 - accuracy: 0.9356\n",
      " 436/5349 [=>............................] - ETA: 3s - loss: 0.1200 - accuracy: 0.9358\n",
      " 589/5349 [==>...........................] - ETA: 3s - loss: 0.1201 - accuracy: 0.9359\n",
      " 740/5349 [===>..........................] - ETA: 3s - loss: 0.1186 - accuracy: 0.9373\n",
      " 887/5349 [===>..........................] - ETA: 3s - loss: 0.1188 - accuracy: 0.9367\n",
      "1032/5349 [====>.........................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9366\n",
      "1176/5349 [=====>........................] - ETA: 2s - loss: 0.1196 - accuracy: 0.9361\n",
      "1327/5349 [======>.......................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9361\n",
      "1457/5349 [=======>......................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9362\n",
      "1604/5349 [=======>......................] - ETA: 2s - loss: 0.1193 - accuracy: 0.9362\n",
      "1757/5349 [========>.....................] - ETA: 2s - loss: 0.1190 - accuracy: 0.9364\n",
      "1988/5349 [==========>...................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9362\n",
      "2134/5349 [==========>...................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9362\n",
      "2282/5349 [===========>..................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9361\n",
      "2418/5349 [============>.................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9360\n",
      "2568/5349 [=============>................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9359\n",
      "2719/5349 [==============>...............] - ETA: 1s - loss: 0.1191 - accuracy: 0.9360\n",
      "2869/5349 [===============>..............] - ETA: 1s - loss: 0.1191 - accuracy: 0.9360\n",
      "3021/5349 [===============>..............] - ETA: 1s - loss: 0.1193 - accuracy: 0.9361\n",
      "3166/5349 [================>.............] - ETA: 1s - loss: 0.1193 - accuracy: 0.9363\n",
      "3315/5349 [=================>............] - ETA: 1s - loss: 0.1192 - accuracy: 0.9364\n",
      "3391/5349 [==================>...........] - ETA: 1s - loss: 0.1190 - accuracy: 0.9365\n",
      "3544/5349 [==================>...........] - ETA: 1s - loss: 0.1191 - accuracy: 0.9365\n",
      "3681/5349 [===================>..........] - ETA: 1s - loss: 0.1189 - accuracy: 0.9366\n",
      "3833/5349 [====================>.........] - ETA: 1s - loss: 0.1189 - accuracy: 0.9366\n",
      "3962/5349 [=====================>........] - ETA: 0s - loss: 0.1188 - accuracy: 0.9366\n",
      "4116/5349 [======================>.......] - ETA: 0s - loss: 0.1188 - accuracy: 0.9366\n",
      "4256/5349 [======================>.......] - ETA: 0s - loss: 0.1187 - accuracy: 0.9366\n",
      "4407/5349 [=======================>......] - ETA: 0s - loss: 0.1187 - accuracy: 0.9366\n",
      "4549/5349 [========================>.....] - ETA: 0s - loss: 0.1187 - accuracy: 0.9367\n",
      "4699/5349 [=========================>....] - ETA: 0s - loss: 0.1187 - accuracy: 0.9367\n",
      "4849/5349 [==========================>...] - ETA: 0s - loss: 0.1187 - accuracy: 0.9367\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1188 - accuracy: 0.9367\n",
      "5148/5349 [===========================>..] - ETA: 0s - loss: 0.1189 - accuracy: 0.9366\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9365\n",
      "5349/5349 [==============================] - 5s 850us/step - loss: 0.1188 - accuracy: 0.9365 - val_loss: 0.1156 - val_accuracy: 0.9423\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 13/20\n",
      "  78/5349 [..............................] - ETA: 3s - loss: 0.1229 - accuracy: 0.9355\n",
      " 228/5349 [>.............................] - ETA: 3s - loss: 0.1201 - accuracy: 0.9373\n",
      " 377/5349 [=>............................] - ETA: 3s - loss: 0.1193 - accuracy: 0.9366\n",
      " 528/5349 [=>............................] - ETA: 3s - loss: 0.1189 - accuracy: 0.9372\n",
      " 680/5349 [==>...........................] - ETA: 3s - loss: 0.1182 - accuracy: 0.9373\n",
      " 828/5349 [===>..........................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9377\n",
      " 974/5349 [====>.........................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9376\n",
      "1120/5349 [=====>........................] - ETA: 2s - loss: 0.1180 - accuracy: 0.9377\n",
      "1197/5349 [=====>........................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9378\n",
      "1349/5349 [======>.......................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9378\n",
      "1499/5349 [=======>......................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9379\n",
      "1646/5349 [========>.....................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9378\n",
      "1796/5349 [=========>....................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9373\n",
      "1947/5349 [=========>....................] - ETA: 2s - loss: 0.1183 - accuracy: 0.9372\n",
      "2088/5349 [==========>...................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9372\n",
      "2214/5349 [===========>..................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9375\n",
      "2323/5349 [============>.................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9375\n",
      "2437/5349 [============>.................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9374\n",
      "2611/5349 [=============>................] - ETA: 1s - loss: 0.1182 - accuracy: 0.9375\n",
      "2732/5349 [==============>...............] - ETA: 1s - loss: 0.1183 - accuracy: 0.9371\n",
      "2852/5349 [==============>...............] - ETA: 1s - loss: 0.1183 - accuracy: 0.9370\n",
      "2969/5349 [===============>..............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9372\n",
      "3084/5349 [================>.............] - ETA: 1s - loss: 0.1183 - accuracy: 0.9370\n",
      "3210/5349 [=================>............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9372\n",
      "3345/5349 [=================>............] - ETA: 1s - loss: 0.1181 - accuracy: 0.9372\n",
      "3455/5349 [==================>...........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9373\n",
      "3581/5349 [===================>..........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9373\n",
      "3703/5349 [===================>..........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9372\n",
      "3847/5349 [====================>.........] - ETA: 1s - loss: 0.1181 - accuracy: 0.9372\n",
      "3990/5349 [=====================>........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9372\n",
      "4128/5349 [======================>.......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9372\n",
      "4272/5349 [======================>.......] - ETA: 0s - loss: 0.1182 - accuracy: 0.9370\n",
      "4417/5349 [=======================>......] - ETA: 0s - loss: 0.1182 - accuracy: 0.9371\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.1180 - accuracy: 0.9372\n",
      "4776/5349 [=========================>....] - ETA: 0s - loss: 0.1180 - accuracy: 0.9372\n",
      "4919/5349 [==========================>...] - ETA: 0s - loss: 0.1179 - accuracy: 0.9373\n",
      "5067/5349 [===========================>..] - ETA: 0s - loss: 0.1179 - accuracy: 0.9373\n",
      "5204/5349 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9373\n",
      "5280/5349 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9372\n",
      "5349/5349 [==============================] - 5s 915us/step - loss: 0.1179 - accuracy: 0.9373 - val_loss: 0.1143 - val_accuracy: 0.9425\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 14/20\n",
      "  76/5349 [..............................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9389\n",
      " 228/5349 [>.............................] - ETA: 3s - loss: 0.1165 - accuracy: 0.9395\n",
      " 379/5349 [=>............................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9393\n",
      " 527/5349 [=>............................] - ETA: 3s - loss: 0.1166 - accuracy: 0.9383\n",
      " 675/5349 [==>...........................] - ETA: 3s - loss: 0.1172 - accuracy: 0.9378\n",
      " 825/5349 [===>..........................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9376\n",
      "1053/5349 [====>.........................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9376\n",
      "1152/5349 [=====>........................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9371\n",
      "1297/5349 [======>.......................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9370\n",
      "1431/5349 [=======>......................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9372\n",
      "1582/5349 [=======>......................] - ETA: 2s - loss: 0.1177 - accuracy: 0.9375\n",
      "1723/5349 [========>.....................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9374\n",
      "1866/5349 [=========>....................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9375\n",
      "2006/5349 [==========>...................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9376\n",
      "2232/5349 [===========>..................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9375\n",
      "2378/5349 [============>.................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9376\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.1172 - accuracy: 0.9377\n",
      "2662/5349 [=============>................] - ETA: 1s - loss: 0.1170 - accuracy: 0.9377\n",
      "2787/5349 [==============>...............] - ETA: 1s - loss: 0.1171 - accuracy: 0.9377\n",
      "2930/5349 [===============>..............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9376\n",
      "3156/5349 [================>.............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9375\n",
      "3300/5349 [=================>............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9374\n",
      "3454/5349 [==================>...........] - ETA: 1s - loss: 0.1173 - accuracy: 0.9374\n",
      "3590/5349 [===================>..........] - ETA: 1s - loss: 0.1171 - accuracy: 0.9376\n",
      "3740/5349 [===================>..........] - ETA: 1s - loss: 0.1172 - accuracy: 0.9374\n",
      "3887/5349 [====================>.........] - ETA: 1s - loss: 0.1172 - accuracy: 0.9375\n",
      "4033/5349 [=====================>........] - ETA: 0s - loss: 0.1171 - accuracy: 0.9376\n",
      "4185/5349 [======================>.......] - ETA: 0s - loss: 0.1169 - accuracy: 0.9376\n",
      "4412/5349 [=======================>......] - ETA: 0s - loss: 0.1171 - accuracy: 0.9375\n",
      "4556/5349 [========================>.....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9375\n",
      "4709/5349 [=========================>....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9376\n",
      "4860/5349 [==========================>...] - ETA: 0s - loss: 0.1172 - accuracy: 0.9375\n",
      "5010/5349 [===========================>..] - ETA: 0s - loss: 0.1172 - accuracy: 0.9375\n",
      "5159/5349 [===========================>..] - ETA: 0s - loss: 0.1173 - accuracy: 0.9374\n",
      "5313/5349 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9373\n",
      "5349/5349 [==============================] - 5s 862us/step - loss: 0.1173 - accuracy: 0.9374 - val_loss: 0.1153 - val_accuracy: 0.9390\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.2003 - accuracy: 0.8700\n",
      " 152/5349 [..............................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9371\n",
      " 306/5349 [>.............................] - ETA: 3s - loss: 0.1173 - accuracy: 0.9382\n",
      " 452/5349 [=>............................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9386\n",
      " 605/5349 [==>...........................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9387\n",
      " 755/5349 [===>..........................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9390\n",
      " 905/5349 [====>.........................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9386\n",
      "1124/5349 [=====>........................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9386\n",
      "1277/5349 [======>.......................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9383\n",
      "1423/5349 [======>.......................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9383\n",
      "1573/5349 [=======>......................] - ETA: 2s - loss: 0.1160 - accuracy: 0.9383\n",
      "1722/5349 [========>.....................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9382\n",
      "1951/5349 [=========>....................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9380\n",
      "2086/5349 [==========>...................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9377\n",
      "2240/5349 [===========>..................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9378\n",
      "2373/5349 [============>.................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9375\n",
      "2511/5349 [=============>................] - ETA: 1s - loss: 0.1167 - accuracy: 0.9375\n",
      "2654/5349 [=============>................] - ETA: 1s - loss: 0.1165 - accuracy: 0.9376\n",
      "2807/5349 [==============>...............] - ETA: 1s - loss: 0.1165 - accuracy: 0.9376\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1163 - accuracy: 0.9377\n",
      "3102/5349 [================>.............] - ETA: 1s - loss: 0.1163 - accuracy: 0.9378\n",
      "3245/5349 [=================>............] - ETA: 1s - loss: 0.1161 - accuracy: 0.9379\n",
      "3396/5349 [==================>...........] - ETA: 1s - loss: 0.1160 - accuracy: 0.9379\n",
      "3543/5349 [==================>...........] - ETA: 1s - loss: 0.1160 - accuracy: 0.9380\n",
      "3772/5349 [====================>.........] - ETA: 1s - loss: 0.1159 - accuracy: 0.9380\n",
      "3920/5349 [====================>.........] - ETA: 0s - loss: 0.1161 - accuracy: 0.9379\n",
      "4070/5349 [=====================>........] - ETA: 0s - loss: 0.1162 - accuracy: 0.9379\n",
      "4210/5349 [======================>.......] - ETA: 0s - loss: 0.1162 - accuracy: 0.9378\n",
      "4361/5349 [=======================>......] - ETA: 0s - loss: 0.1162 - accuracy: 0.9378\n",
      "4479/5349 [========================>.....] - ETA: 0s - loss: 0.1163 - accuracy: 0.9377\n",
      "4590/5349 [========================>.....] - ETA: 0s - loss: 0.1164 - accuracy: 0.9377\n",
      "4698/5349 [=========================>....] - ETA: 0s - loss: 0.1164 - accuracy: 0.9377\n",
      "4886/5349 [==========================>...] - ETA: 0s - loss: 0.1163 - accuracy: 0.9377\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9377\n",
      "5118/5349 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.9377\n",
      "5231/5349 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9377\n",
      "5294/5349 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9378\n",
      "5349/5349 [==============================] - 5s 914us/step - loss: 0.1163 - accuracy: 0.9378 - val_loss: 0.1131 - val_accuracy: 0.9402\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1064 - accuracy: 0.9600\n",
      " 150/5349 [..............................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9383\n",
      " 299/5349 [>.............................] - ETA: 3s - loss: 0.1185 - accuracy: 0.9373\n",
      " 448/5349 [=>............................] - ETA: 3s - loss: 0.1174 - accuracy: 0.9377\n",
      " 666/5349 [==>...........................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9383\n",
      " 807/5349 [===>..........................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9382\n",
      " 956/5349 [====>.........................] - ETA: 3s - loss: 0.1165 - accuracy: 0.9380\n",
      "1098/5349 [=====>........................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9387\n",
      "1232/5349 [=====>........................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9389\n",
      "1372/5349 [======>.......................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9386\n",
      "1521/5349 [=======>......................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9388\n",
      "1672/5349 [========>.....................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9384\n",
      "1822/5349 [=========>....................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9386\n",
      "2040/5349 [==========>...................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9386\n",
      "2191/5349 [===========>..................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9386\n",
      "2327/5349 [============>.................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9385\n",
      "2475/5349 [============>.................] - ETA: 1s - loss: 0.1155 - accuracy: 0.9384\n",
      "2625/5349 [=============>................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9385\n",
      "2764/5349 [==============>...............] - ETA: 1s - loss: 0.1157 - accuracy: 0.9383\n",
      "2912/5349 [===============>..............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9382\n",
      "3060/5349 [================>.............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9383\n",
      "3209/5349 [================>.............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9382\n",
      "3301/5349 [=================>............] - ETA: 1s - loss: 0.1158 - accuracy: 0.9381\n",
      "3505/5349 [==================>...........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9382\n",
      "3651/5349 [===================>..........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9382\n",
      "3792/5349 [====================>.........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9382\n",
      "3937/5349 [=====================>........] - ETA: 0s - loss: 0.1156 - accuracy: 0.9381\n",
      "4076/5349 [=====================>........] - ETA: 0s - loss: 0.1158 - accuracy: 0.9380\n",
      "4219/5349 [======================>.......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9380\n",
      "4343/5349 [=======================>......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9380\n",
      "4574/5349 [========================>.....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9379\n",
      "4719/5349 [=========================>....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9379\n",
      "4859/5349 [==========================>...] - ETA: 0s - loss: 0.1159 - accuracy: 0.9378\n",
      "5004/5349 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9377\n",
      "5156/5349 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9377\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9376\n",
      "5349/5349 [==============================] - 5s 872us/step - loss: 0.1161 - accuracy: 0.9376 - val_loss: 0.1139 - val_accuracy: 0.9425\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1212 - accuracy: 0.9300\n",
      " 225/5349 [>.............................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9371\n",
      " 376/5349 [=>............................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9384\n",
      " 524/5349 [=>............................] - ETA: 3s - loss: 0.1162 - accuracy: 0.9381\n",
      " 676/5349 [==>...........................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9387\n",
      " 814/5349 [===>..........................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9386\n",
      " 966/5349 [====>.........................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9394\n",
      "1102/5349 [=====>........................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9392\n",
      "1254/5349 [======>.......................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9389\n",
      "1405/5349 [======>.......................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9388\n",
      "1554/5349 [=======>......................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9387\n",
      "1694/5349 [========>.....................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9386\n",
      "1918/5349 [=========>....................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9385\n",
      "2066/5349 [==========>...................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9387\n",
      "2217/5349 [===========>..................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9382\n",
      "2368/5349 [============>.................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9379\n",
      "2522/5349 [=============>................] - ETA: 1s - loss: 0.1159 - accuracy: 0.9378\n",
      "2660/5349 [=============>................] - ETA: 1s - loss: 0.1160 - accuracy: 0.9377\n",
      "2735/5349 [==============>...............] - ETA: 1s - loss: 0.1158 - accuracy: 0.9378\n",
      "2885/5349 [===============>..............] - ETA: 1s - loss: 0.1157 - accuracy: 0.9379\n",
      "3036/5349 [================>.............] - ETA: 1s - loss: 0.1154 - accuracy: 0.9381\n",
      "3175/5349 [================>.............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9381\n",
      "3318/5349 [=================>............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9380\n",
      "3470/5349 [==================>...........] - ETA: 1s - loss: 0.1157 - accuracy: 0.9378\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.1157 - accuracy: 0.9378\n",
      "3773/5349 [====================>.........] - ETA: 1s - loss: 0.1154 - accuracy: 0.9379\n",
      "4000/5349 [=====================>........] - ETA: 0s - loss: 0.1153 - accuracy: 0.9381\n",
      "4148/5349 [======================>.......] - ETA: 0s - loss: 0.1154 - accuracy: 0.9380\n",
      "4297/5349 [=======================>......] - ETA: 0s - loss: 0.1153 - accuracy: 0.9381\n",
      "4450/5349 [=======================>......] - ETA: 0s - loss: 0.1155 - accuracy: 0.9379\n",
      "4600/5349 [========================>.....] - ETA: 0s - loss: 0.1156 - accuracy: 0.9378\n",
      "4750/5349 [=========================>....] - ETA: 0s - loss: 0.1157 - accuracy: 0.9378\n",
      "4887/5349 [==========================>...] - ETA: 0s - loss: 0.1156 - accuracy: 0.9378\n",
      "5039/5349 [===========================>..] - ETA: 0s - loss: 0.1157 - accuracy: 0.9378\n",
      "5191/5349 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9379\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9378\n",
      "5349/5349 [==============================] - 5s 851us/step - loss: 0.1157 - accuracy: 0.9378 - val_loss: 0.1132 - val_accuracy: 0.9398\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 18/20\n",
      "  44/5349 [..............................] - ETA: 6s - loss: 0.1130 - accuracy: 0.9439 \n",
      " 125/5349 [..............................] - ETA: 6s - loss: 0.1145 - accuracy: 0.9399\n",
      " 210/5349 [>.............................] - ETA: 6s - loss: 0.1127 - accuracy: 0.9410\n",
      " 311/5349 [>.............................] - ETA: 5s - loss: 0.1136 - accuracy: 0.9403\n",
      " 418/5349 [=>............................] - ETA: 5s - loss: 0.1145 - accuracy: 0.9392\n",
      " 543/5349 [==>...........................] - ETA: 4s - loss: 0.1149 - accuracy: 0.9382\n",
      " 735/5349 [===>..........................] - ETA: 4s - loss: 0.1152 - accuracy: 0.9372\n",
      " 842/5349 [===>..........................] - ETA: 4s - loss: 0.1153 - accuracy: 0.9372\n",
      " 958/5349 [====>.........................] - ETA: 4s - loss: 0.1158 - accuracy: 0.9369\n",
      "1038/5349 [====>.........................] - ETA: 4s - loss: 0.1160 - accuracy: 0.9368\n",
      "1131/5349 [=====>........................] - ETA: 4s - loss: 0.1159 - accuracy: 0.9368\n",
      "1244/5349 [=====>........................] - ETA: 4s - loss: 0.1154 - accuracy: 0.9370\n",
      "1370/5349 [======>.......................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9369\n",
      "1499/5349 [=======>......................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9364\n",
      "1725/5349 [========>.....................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9366\n",
      "1872/5349 [=========>....................] - ETA: 3s - loss: 0.1161 - accuracy: 0.9368\n",
      "2013/5349 [==========>...................] - ETA: 2s - loss: 0.1160 - accuracy: 0.9371\n",
      "2158/5349 [===========>..................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9372\n",
      "2308/5349 [===========>..................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9375\n",
      "2449/5349 [============>.................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9377\n",
      "2597/5349 [=============>................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9379\n",
      "2796/5349 [==============>...............] - ETA: 2s - loss: 0.1147 - accuracy: 0.9382\n",
      "2935/5349 [===============>..............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9382\n",
      "3064/5349 [================>.............] - ETA: 1s - loss: 0.1148 - accuracy: 0.9383\n",
      "3207/5349 [================>.............] - ETA: 1s - loss: 0.1150 - accuracy: 0.9382\n",
      "3346/5349 [=================>............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9383\n",
      "3491/5349 [==================>...........] - ETA: 1s - loss: 0.1148 - accuracy: 0.9383\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9381\n",
      "3843/5349 [====================>.........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9381\n",
      "3985/5349 [=====================>........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9382\n",
      "4133/5349 [======================>.......] - ETA: 0s - loss: 0.1150 - accuracy: 0.9383\n",
      "4279/5349 [======================>.......] - ETA: 0s - loss: 0.1150 - accuracy: 0.9383\n",
      "4431/5349 [=======================>......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9383\n",
      "4579/5349 [========================>.....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9383\n",
      "4733/5349 [=========================>....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9383\n",
      "4932/5349 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9383\n",
      "5084/5349 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.9383\n",
      "5229/5349 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9383\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9383\n",
      "5349/5349 [==============================] - 5s 955us/step - loss: 0.1151 - accuracy: 0.9383 - val_loss: 0.1149 - val_accuracy: 0.9375\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1678 - accuracy: 0.8900\n",
      " 141/5349 [..............................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9377\n",
      " 271/5349 [>.............................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9385\n",
      " 404/5349 [=>............................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9370\n",
      " 536/5349 [==>...........................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9376\n",
      " 676/5349 [==>...........................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9381\n",
      " 817/5349 [===>..........................] - ETA: 3s - loss: 0.1147 - accuracy: 0.9384\n",
      " 958/5349 [====>.........................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9384\n",
      "1035/5349 [====>.........................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9382\n",
      "1187/5349 [=====>........................] - ETA: 3s - loss: 0.1141 - accuracy: 0.9381\n",
      "1327/5349 [======>.......................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9383\n",
      "1472/5349 [=======>......................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9379\n",
      "1604/5349 [=======>......................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9376\n",
      "1748/5349 [========>.....................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9376\n",
      "1876/5349 [=========>....................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9373\n",
      "2094/5349 [==========>...................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9373\n",
      "2240/5349 [===========>..................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9372\n",
      "2386/5349 [============>.................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9372\n",
      "2536/5349 [=============>................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9373\n",
      "2668/5349 [=============>................] - ETA: 1s - loss: 0.1155 - accuracy: 0.9373\n",
      "2808/5349 [==============>...............] - ETA: 1s - loss: 0.1154 - accuracy: 0.9374\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1154 - accuracy: 0.9376\n",
      "3171/5349 [================>.............] - ETA: 1s - loss: 0.1152 - accuracy: 0.9378\n",
      "3311/5349 [=================>............] - ETA: 1s - loss: 0.1152 - accuracy: 0.9378\n",
      "3458/5349 [==================>...........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9379\n",
      "3595/5349 [===================>..........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9378\n",
      "3730/5349 [===================>..........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9378\n",
      "3870/5349 [====================>.........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9379\n",
      "3947/5349 [=====================>........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9379\n",
      "4084/5349 [=====================>........] - ETA: 0s - loss: 0.1151 - accuracy: 0.9379\n",
      "4216/5349 [======================>.......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9380\n",
      "4364/5349 [=======================>......] - ETA: 0s - loss: 0.1152 - accuracy: 0.9378\n",
      "4510/5349 [========================>.....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9378\n",
      "4656/5349 [=========================>....] - ETA: 0s - loss: 0.1150 - accuracy: 0.9379\n",
      "4795/5349 [=========================>....] - ETA: 0s - loss: 0.1149 - accuracy: 0.9379\n",
      "4946/5349 [==========================>...] - ETA: 0s - loss: 0.1148 - accuracy: 0.9380\n",
      "5170/5349 [===========================>..] - ETA: 0s - loss: 0.1147 - accuracy: 0.9380\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9379\n",
      "5349/5349 [==============================] - 5s 878us/step - loss: 0.1147 - accuracy: 0.9379 - val_loss: 0.1121 - val_accuracy: 0.9422\n",
      "\u001B[36m(train_DNN pid=5508)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.0703 - accuracy: 0.9600\n",
      " 153/5349 [..............................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9393\n",
      " 302/5349 [>.............................] - ETA: 3s - loss: 0.1146 - accuracy: 0.9392\n",
      " 449/5349 [=>............................] - ETA: 3s - loss: 0.1147 - accuracy: 0.9393\n",
      " 570/5349 [==>...........................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9384\n",
      " 628/5349 [==>...........................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9385\n",
      " 770/5349 [===>..........................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9393\n",
      " 918/5349 [====>.........................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9396\n",
      "1059/5349 [====>.........................] - ETA: 3s - loss: 0.1139 - accuracy: 0.9395\n",
      "1211/5349 [=====>........................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9394\n",
      "1355/5349 [======>.......................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9395\n",
      "1503/5349 [=======>......................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9390\n",
      "1651/5349 [========>.....................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9388\n",
      "1801/5349 [=========>....................] - ETA: 2s - loss: 0.1141 - accuracy: 0.9392\n",
      "1953/5349 [=========>....................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9390\n",
      "2178/5349 [===========>..................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9391\n",
      "2319/5349 [============>.................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9389\n",
      "2430/5349 [============>.................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9387\n",
      "2546/5349 [=============>................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9386\n",
      "2660/5349 [=============>................] - ETA: 1s - loss: 0.1145 - accuracy: 0.9386\n",
      "2760/5349 [==============>...............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9385\n",
      "2875/5349 [===============>..............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9386\n",
      "3030/5349 [===============>..............] - ETA: 1s - loss: 0.1143 - accuracy: 0.9387\n",
      "3152/5349 [================>.............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9386\n",
      "3266/5349 [=================>............] - ETA: 1s - loss: 0.1143 - accuracy: 0.9385\n",
      "3378/5349 [=================>............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9386\n",
      "3446/5349 [==================>...........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9386\n",
      "3562/5349 [==================>...........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9385\n",
      "3679/5349 [===================>..........] - ETA: 1s - loss: 0.1143 - accuracy: 0.9387\n",
      "3797/5349 [====================>.........] - ETA: 1s - loss: 0.1143 - accuracy: 0.9388\n",
      "3931/5349 [=====================>........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9388\n",
      "4146/5349 [======================>.......] - ETA: 0s - loss: 0.1142 - accuracy: 0.9387\n",
      "4290/5349 [=======================>......] - ETA: 0s - loss: 0.1143 - accuracy: 0.9387\n",
      "4433/5349 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9387\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9387\n",
      "4712/5349 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9386\n",
      "4859/5349 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9386\n",
      "5007/5349 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.9386\n",
      "5156/5349 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.9386\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9386\n",
      "5349/5349 [==============================] - 5s 933us/step - loss: 0.1142 - accuracy: 0.9386 - val_loss: 0.1124 - val_accuracy: 0.9371\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 1/20\n",
      " 134/5349 [..............................] - ETA: 3s - loss: 0.9969 - accuracy: 0.1580\n",
      " 311/5349 [>.............................] - ETA: 3s - loss: 0.8003 - accuracy: 0.4351\n",
      " 412/5349 [=>............................] - ETA: 3s - loss: 0.7339 - accuracy: 0.5347\n",
      " 563/5349 [==>...........................] - ETA: 3s - loss: 0.6663 - accuracy: 0.6178\n",
      " 744/5349 [===>..........................] - ETA: 3s - loss: 0.6160 - accuracy: 0.6719\n",
      " 913/5349 [====>.........................] - ETA: 2s - loss: 0.5842 - accuracy: 0.7036\n",
      "1214/5349 [=====>........................] - ETA: 2s - loss: 0.5486 - accuracy: 0.7377\n",
      "1416/5349 [======>.......................] - ETA: 2s - loss: 0.5325 - accuracy: 0.7527\n",
      "1633/5349 [========>.....................] - ETA: 2s - loss: 0.5215 - accuracy: 0.7635\n",
      "1835/5349 [=========>....................] - ETA: 2s - loss: 0.5122 - accuracy: 0.7721\n",
      "2038/5349 [==========>...................] - ETA: 1s - loss: 0.5048 - accuracy: 0.7789\n",
      "2231/5349 [===========>..................] - ETA: 1s - loss: 0.4995 - accuracy: 0.7840\n",
      "2545/5349 [=============>................] - ETA: 1s - loss: 0.4914 - accuracy: 0.7913\n",
      "2730/5349 [==============>...............] - ETA: 1s - loss: 0.4876 - accuracy: 0.7948\n",
      "2941/5349 [===============>..............] - ETA: 1s - loss: 0.4843 - accuracy: 0.7979\n",
      "3150/5349 [================>.............] - ETA: 1s - loss: 0.4812 - accuracy: 0.8007\n",
      "3359/5349 [=================>............] - ETA: 1s - loss: 0.4787 - accuracy: 0.8031\n",
      "3673/5349 [===================>..........] - ETA: 0s - loss: 0.4752 - accuracy: 0.8063\n",
      "3884/5349 [====================>.........] - ETA: 0s - loss: 0.4730 - accuracy: 0.8083\n",
      "4088/5349 [=====================>........] - ETA: 0s - loss: 0.4712 - accuracy: 0.8100\n",
      "4295/5349 [=======================>......] - ETA: 0s - loss: 0.4694 - accuracy: 0.8115\n",
      "4497/5349 [========================>.....] - ETA: 0s - loss: 0.4681 - accuracy: 0.8128\n",
      "4706/5349 [=========================>....] - ETA: 0s - loss: 0.4670 - accuracy: 0.8139\n",
      "4911/5349 [==========================>...] - ETA: 0s - loss: 0.4656 - accuracy: 0.8151\n",
      "5124/5349 [===========================>..] - ETA: 0s - loss: 0.4643 - accuracy: 0.8163\n",
      "5324/5349 [============================>.] - ETA: 0s - loss: 0.4635 - accuracy: 0.8171\n",
      "5349/5349 [==============================] - 4s 743us/step - loss: 0.4634 - accuracy: 0.8171 - val_loss: 0.4381 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 2/20\n",
      "  92/5349 [..............................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8425\n",
      " 298/5349 [>.............................] - ETA: 2s - loss: 0.4421 - accuracy: 0.8381\n",
      " 508/5349 [=>............................] - ETA: 2s - loss: 0.4401 - accuracy: 0.8393\n",
      " 709/5349 [==>...........................] - ETA: 2s - loss: 0.4397 - accuracy: 0.8396\n",
      "1027/5349 [====>.........................] - ETA: 2s - loss: 0.4400 - accuracy: 0.8394\n",
      "1236/5349 [=====>........................] - ETA: 2s - loss: 0.4390 - accuracy: 0.8400\n",
      "1449/5349 [=======>......................] - ETA: 1s - loss: 0.4394 - accuracy: 0.8397\n",
      "1654/5349 [========>.....................] - ETA: 1s - loss: 0.4387 - accuracy: 0.8402\n",
      "1863/5349 [=========>....................] - ETA: 1s - loss: 0.4381 - accuracy: 0.8405\n",
      "2070/5349 [==========>...................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8409\n",
      "2282/5349 [===========>..................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8408\n",
      "2575/5349 [=============>................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8408\n",
      "2771/5349 [==============>...............] - ETA: 1s - loss: 0.4372 - accuracy: 0.8411\n",
      "2964/5349 [===============>..............] - ETA: 1s - loss: 0.4370 - accuracy: 0.8412\n",
      "3176/5349 [================>.............] - ETA: 1s - loss: 0.4369 - accuracy: 0.8413\n",
      "3375/5349 [=================>............] - ETA: 0s - loss: 0.4370 - accuracy: 0.8412\n",
      "3578/5349 [===================>..........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8412\n",
      "3778/5349 [====================>.........] - ETA: 0s - loss: 0.4368 - accuracy: 0.8413\n",
      "4097/5349 [=====================>........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8412\n",
      "4296/5349 [=======================>......] - ETA: 0s - loss: 0.4373 - accuracy: 0.8410\n",
      "4512/5349 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8412\n",
      "4715/5349 [=========================>....] - ETA: 0s - loss: 0.4373 - accuracy: 0.8410\n",
      "4927/5349 [==========================>...] - ETA: 0s - loss: 0.4376 - accuracy: 0.8408\n",
      "5128/5349 [===========================>..] - ETA: 0s - loss: 0.4378 - accuracy: 0.8407\n",
      "5328/5349 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 668us/step - loss: 0.4379 - accuracy: 0.8406 - val_loss: 0.4380 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.3896 - accuracy: 0.8700\n",
      " 211/5349 [>.............................] - ETA: 2s - loss: 0.4321 - accuracy: 0.8441\n",
      " 420/5349 [=>............................] - ETA: 2s - loss: 0.4360 - accuracy: 0.8417\n",
      " 619/5349 [==>...........................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8424\n",
      " 832/5349 [===>..........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8421\n",
      "1040/5349 [====>.........................] - ETA: 2s - loss: 0.4362 - accuracy: 0.8416\n",
      "1234/5349 [=====>........................] - ETA: 2s - loss: 0.4372 - accuracy: 0.8410\n",
      "1512/5349 [=======>......................] - ETA: 1s - loss: 0.4378 - accuracy: 0.8406\n",
      "1719/5349 [========>.....................] - ETA: 1s - loss: 0.4390 - accuracy: 0.8399\n",
      "1913/5349 [=========>....................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8402\n",
      "2123/5349 [==========>...................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8403\n",
      "2333/5349 [============>.................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8403\n",
      "2543/5349 [=============>................] - ETA: 1s - loss: 0.4378 - accuracy: 0.8406\n",
      "2726/5349 [==============>...............] - ETA: 1s - loss: 0.4384 - accuracy: 0.8403\n",
      "2938/5349 [===============>..............] - ETA: 1s - loss: 0.4388 - accuracy: 0.8400\n",
      "3248/5349 [=================>............] - ETA: 1s - loss: 0.4382 - accuracy: 0.8403\n",
      "3462/5349 [==================>...........] - ETA: 0s - loss: 0.4383 - accuracy: 0.8403\n",
      "3666/5349 [===================>..........] - ETA: 0s - loss: 0.4382 - accuracy: 0.8404\n",
      "3881/5349 [====================>.........] - ETA: 0s - loss: 0.4381 - accuracy: 0.8404\n",
      "4083/5349 [=====================>........] - ETA: 0s - loss: 0.4378 - accuracy: 0.8406\n",
      "4295/5349 [=======================>......] - ETA: 0s - loss: 0.4377 - accuracy: 0.8407\n",
      "4497/5349 [========================>.....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8409\n",
      "4703/5349 [=========================>....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8408\n",
      "4807/5349 [=========================>....] - ETA: 0s - loss: 0.4375 - accuracy: 0.8408\n",
      "5004/5349 [===========================>..] - ETA: 0s - loss: 0.4377 - accuracy: 0.8407\n",
      "5171/5349 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8406\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 736us/step - loss: 0.4377 - accuracy: 0.8406 - val_loss: 0.4378 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.3726 - accuracy: 0.8800\n",
      " 186/5349 [>.............................] - ETA: 2s - loss: 0.4439 - accuracy: 0.8369\n",
      " 396/5349 [=>............................] - ETA: 2s - loss: 0.4395 - accuracy: 0.8395\n",
      " 601/5349 [==>...........................] - ETA: 2s - loss: 0.4389 - accuracy: 0.8399\n",
      " 801/5349 [===>..........................] - ETA: 2s - loss: 0.4383 - accuracy: 0.8402\n",
      "1003/5349 [====>.........................] - ETA: 2s - loss: 0.4367 - accuracy: 0.8412\n",
      "1100/5349 [=====>........................] - ETA: 2s - loss: 0.4372 - accuracy: 0.8409\n",
      "1305/5349 [======>.......................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8414\n",
      "1486/5349 [=======>......................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8416\n",
      "1694/5349 [========>.....................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8417\n",
      "1898/5349 [=========>....................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8412\n",
      "2107/5349 [==========>...................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8413\n",
      "2314/5349 [===========>..................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8411\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8414\n",
      "2726/5349 [==============>...............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8411\n",
      "3036/5349 [================>.............] - ETA: 1s - loss: 0.4369 - accuracy: 0.8410\n",
      "3221/5349 [=================>............] - ETA: 1s - loss: 0.4369 - accuracy: 0.8411\n",
      "3423/5349 [==================>...........] - ETA: 0s - loss: 0.4369 - accuracy: 0.8411\n",
      "3635/5349 [===================>..........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8410\n",
      "3826/5349 [====================>.........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8410\n",
      "4026/5349 [=====================>........] - ETA: 0s - loss: 0.4372 - accuracy: 0.8409\n",
      "4225/5349 [======================>.......] - ETA: 0s - loss: 0.4373 - accuracy: 0.8408\n",
      "4427/5349 [=======================>......] - ETA: 0s - loss: 0.4371 - accuracy: 0.8409\n",
      "4619/5349 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8410\n",
      "4804/5349 [=========================>....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8408\n",
      "4908/5349 [==========================>...] - ETA: 0s - loss: 0.4373 - accuracy: 0.8408\n",
      "5117/5349 [===========================>..] - ETA: 0s - loss: 0.4375 - accuracy: 0.8407\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 700us/step - loss: 0.4376 - accuracy: 0.8406 - val_loss: 0.4377 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 5/20\n",
      "  96/5349 [..............................] - ETA: 2s - loss: 0.4292 - accuracy: 0.8456\n",
      " 204/5349 [>.............................] - ETA: 2s - loss: 0.4326 - accuracy: 0.8436\n",
      " 414/5349 [=>............................] - ETA: 2s - loss: 0.4361 - accuracy: 0.8415\n",
      " 621/5349 [==>...........................] - ETA: 2s - loss: 0.4380 - accuracy: 0.8403\n",
      " 823/5349 [===>..........................] - ETA: 2s - loss: 0.4379 - accuracy: 0.8404\n",
      "1009/5349 [====>.........................] - ETA: 2s - loss: 0.4372 - accuracy: 0.8408\n",
      "1217/5349 [=====>........................] - ETA: 2s - loss: 0.4374 - accuracy: 0.8407\n",
      "1424/5349 [======>.......................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8414\n",
      "1623/5349 [========>.....................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8416\n",
      "1935/5349 [=========>....................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8412\n",
      "2132/5349 [==========>...................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8412\n",
      "2337/5349 [============>.................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8412\n",
      "2542/5349 [=============>................] - ETA: 1s - loss: 0.4364 - accuracy: 0.8413\n",
      "2755/5349 [==============>...............] - ETA: 1s - loss: 0.4361 - accuracy: 0.8414\n",
      "2954/5349 [===============>..............] - ETA: 1s - loss: 0.4365 - accuracy: 0.8412\n",
      "3165/5349 [================>.............] - ETA: 1s - loss: 0.4363 - accuracy: 0.8413\n",
      "3365/5349 [=================>............] - ETA: 0s - loss: 0.4366 - accuracy: 0.8412\n",
      "3686/5349 [===================>..........] - ETA: 0s - loss: 0.4366 - accuracy: 0.8412\n",
      "3888/5349 [====================>.........] - ETA: 0s - loss: 0.4363 - accuracy: 0.8413\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8411\n",
      "4286/5349 [=======================>......] - ETA: 0s - loss: 0.4370 - accuracy: 0.8409\n",
      "4490/5349 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8409\n",
      "4685/5349 [=========================>....] - ETA: 0s - loss: 0.4371 - accuracy: 0.8408\n",
      "4895/5349 [==========================>...] - ETA: 0s - loss: 0.4371 - accuracy: 0.8408\n",
      "5086/5349 [===========================>..] - ETA: 0s - loss: 0.4373 - accuracy: 0.8407\n",
      "5190/5349 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8407\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.4374 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 670us/step - loss: 0.4374 - accuracy: 0.8406 - val_loss: 0.4375 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4218 - accuracy: 0.8500\n",
      " 205/5349 [>.............................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8413\n",
      " 528/5349 [=>............................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8420\n",
      " 724/5349 [===>..........................] - ETA: 2s - loss: 0.4356 - accuracy: 0.8416\n",
      " 931/5349 [====>.........................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8417\n",
      "1114/5349 [=====>........................] - ETA: 2s - loss: 0.4356 - accuracy: 0.8416\n",
      "1227/5349 [=====>........................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8416\n",
      "1416/5349 [======>.......................] - ETA: 2s - loss: 0.4354 - accuracy: 0.8418\n",
      "1630/5349 [========>.....................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8414\n",
      "1833/5349 [=========>....................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8409\n",
      "2135/5349 [==========>...................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8409\n",
      "2334/5349 [============>.................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8409\n",
      "2543/5349 [=============>................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8409\n",
      "2740/5349 [==============>...............] - ETA: 1s - loss: 0.4371 - accuracy: 0.8407\n",
      "2954/5349 [===============>..............] - ETA: 1s - loss: 0.4375 - accuracy: 0.8404\n",
      "3149/5349 [================>.............] - ETA: 1s - loss: 0.4377 - accuracy: 0.8404\n",
      "3423/5349 [==================>...........] - ETA: 0s - loss: 0.4378 - accuracy: 0.8403\n",
      "3621/5349 [===================>..........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8404\n",
      "3835/5349 [====================>.........] - ETA: 0s - loss: 0.4374 - accuracy: 0.8405\n",
      "4029/5349 [=====================>........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8404\n",
      "4232/5349 [======================>.......] - ETA: 0s - loss: 0.4375 - accuracy: 0.8404\n",
      "4418/5349 [=======================>......] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8404\n",
      "4832/5349 [==========================>...] - ETA: 0s - loss: 0.4375 - accuracy: 0.8404\n",
      "5007/5349 [===========================>..] - ETA: 0s - loss: 0.4373 - accuracy: 0.8406\n",
      "5138/5349 [===========================>..] - ETA: 0s - loss: 0.4374 - accuracy: 0.8405\n",
      "5284/5349 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8405\n",
      "5349/5349 [==============================] - 4s 749us/step - loss: 0.4372 - accuracy: 0.8406 - val_loss: 0.4373 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 7/20\n",
      " 102/5349 [..............................] - ETA: 2s - loss: 0.4303 - accuracy: 0.8447\n",
      " 306/5349 [>.............................] - ETA: 2s - loss: 0.4312 - accuracy: 0.8442\n",
      " 513/5349 [=>............................] - ETA: 2s - loss: 0.4322 - accuracy: 0.8435\n",
      " 812/5349 [===>..........................] - ETA: 2s - loss: 0.4325 - accuracy: 0.8434\n",
      "1020/5349 [====>.........................] - ETA: 2s - loss: 0.4321 - accuracy: 0.8436\n",
      "1226/5349 [=====>........................] - ETA: 2s - loss: 0.4328 - accuracy: 0.8432\n",
      "1428/5349 [=======>......................] - ETA: 1s - loss: 0.4337 - accuracy: 0.8427\n",
      "1606/5349 [========>.....................] - ETA: 1s - loss: 0.4346 - accuracy: 0.8421\n",
      "1818/5349 [=========>....................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8417\n",
      "2029/5349 [==========>...................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8411\n",
      "2236/5349 [===========>..................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8413\n",
      "2500/5349 [=============>................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8411\n",
      "2675/5349 [==============>...............] - ETA: 1s - loss: 0.4365 - accuracy: 0.8409\n",
      "2876/5349 [===============>..............] - ETA: 1s - loss: 0.4366 - accuracy: 0.8409\n",
      "3077/5349 [================>.............] - ETA: 1s - loss: 0.4366 - accuracy: 0.8409\n",
      "3277/5349 [=================>............] - ETA: 1s - loss: 0.4366 - accuracy: 0.8409\n",
      "3585/5349 [===================>..........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "3789/5349 [====================>.........] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "3994/5349 [=====================>........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8406\n",
      "4169/5349 [======================>.......] - ETA: 0s - loss: 0.4368 - accuracy: 0.8407\n",
      "4369/5349 [=======================>......] - ETA: 0s - loss: 0.4366 - accuracy: 0.8409\n",
      "4563/5349 [========================>.....] - ETA: 0s - loss: 0.4367 - accuracy: 0.8408\n",
      "4767/5349 [=========================>....] - ETA: 0s - loss: 0.4367 - accuracy: 0.8408\n",
      "5070/5349 [===========================>..] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.4371 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 703us/step - loss: 0.4370 - accuracy: 0.8406 - val_loss: 0.4370 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 8/20\n",
      " 102/5349 [..............................] - ETA: 2s - loss: 0.4314 - accuracy: 0.8439\n",
      " 306/5349 [>.............................] - ETA: 2s - loss: 0.4346 - accuracy: 0.8420\n",
      " 511/5349 [=>............................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8413\n",
      " 717/5349 [===>..........................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8426\n",
      " 909/5349 [====>.........................] - ETA: 2s - loss: 0.4333 - accuracy: 0.8427\n",
      "1108/5349 [=====>........................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8421\n",
      "1315/5349 [======>.......................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8416\n",
      "1515/5349 [=======>......................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8412\n",
      "1727/5349 [========>.....................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8408\n",
      "1924/5349 [=========>....................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8410\n",
      "2230/5349 [===========>..................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8410\n",
      "2432/5349 [============>.................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8410\n",
      "2643/5349 [=============>................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8414\n",
      "2846/5349 [==============>...............] - ETA: 1s - loss: 0.4356 - accuracy: 0.8413\n",
      "3045/5349 [================>.............] - ETA: 1s - loss: 0.4361 - accuracy: 0.8410\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.4366 - accuracy: 0.8408\n",
      "3394/5349 [==================>...........] - ETA: 0s - loss: 0.4368 - accuracy: 0.8406\n",
      "3565/5349 [==================>...........] - ETA: 0s - loss: 0.4372 - accuracy: 0.8404\n",
      "3763/5349 [====================>.........] - ETA: 0s - loss: 0.4372 - accuracy: 0.8404\n",
      "4050/5349 [=====================>........] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "4254/5349 [======================>.......] - ETA: 0s - loss: 0.4368 - accuracy: 0.8406\n",
      "4461/5349 [========================>.....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "4669/5349 [=========================>....] - ETA: 0s - loss: 0.4368 - accuracy: 0.8406\n",
      "4845/5349 [==========================>...] - ETA: 0s - loss: 0.4367 - accuracy: 0.8407\n",
      "5054/5349 [===========================>..] - ETA: 0s - loss: 0.4367 - accuracy: 0.8407\n",
      "5265/5349 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 687us/step - loss: 0.4367 - accuracy: 0.8406 - val_loss: 0.4367 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 9/20\n",
      " 105/5349 [..............................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8422\n",
      " 320/5349 [>.............................] - ETA: 2s - loss: 0.4333 - accuracy: 0.8426\n",
      " 535/5349 [==>...........................] - ETA: 2s - loss: 0.4367 - accuracy: 0.8405\n",
      " 834/5349 [===>..........................] - ETA: 2s - loss: 0.4369 - accuracy: 0.8404\n",
      "1047/5349 [====>.........................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8412\n",
      "1256/5349 [======>.......................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8408\n",
      "1468/5349 [=======>......................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8408\n",
      "1655/5349 [========>.....................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8412\n",
      "1867/5349 [=========>....................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8412\n",
      "2179/5349 [===========>..................] - ETA: 1s - loss: 0.4352 - accuracy: 0.8414\n",
      "2393/5349 [============>.................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8410\n",
      "2607/5349 [=============>................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8410\n",
      "2817/5349 [==============>...............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8408\n",
      "3026/5349 [===============>..............] - ETA: 1s - loss: 0.4364 - accuracy: 0.8407\n",
      "3240/5349 [=================>............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8408\n",
      "3455/5349 [==================>...........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8408\n",
      "3763/5349 [====================>.........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8410\n",
      "3959/5349 [=====================>........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8408\n",
      "4170/5349 [======================>.......] - ETA: 0s - loss: 0.4365 - accuracy: 0.8406\n",
      "4358/5349 [=======================>......] - ETA: 0s - loss: 0.4369 - accuracy: 0.8404\n",
      "4570/5349 [========================>.....] - ETA: 0s - loss: 0.4367 - accuracy: 0.8405\n",
      "4772/5349 [=========================>....] - ETA: 0s - loss: 0.4367 - accuracy: 0.8405\n",
      "4978/5349 [==========================>...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8404\n",
      "5186/5349 [============================>.] - ETA: 0s - loss: 0.4368 - accuracy: 0.8404\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8405\n",
      "5349/5349 [==============================] - 4s 708us/step - loss: 0.4364 - accuracy: 0.8406 - val_loss: 0.4364 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.3375 - accuracy: 0.9000\n",
      " 144/5349 [..............................] - ETA: 3s - loss: 0.4345 - accuracy: 0.8417\n",
      " 462/5349 [=>............................] - ETA: 2s - loss: 0.4372 - accuracy: 0.8400\n",
      " 667/5349 [==>...........................] - ETA: 2s - loss: 0.4384 - accuracy: 0.8393\n",
      " 877/5349 [===>..........................] - ETA: 2s - loss: 0.4371 - accuracy: 0.8401\n",
      "1053/5349 [====>.........................] - ETA: 2s - loss: 0.4369 - accuracy: 0.8402\n",
      "1264/5349 [======>.......................] - ETA: 2s - loss: 0.4365 - accuracy: 0.8404\n",
      "1472/5349 [=======>......................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8408\n",
      "1682/5349 [========>.....................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8402\n",
      "1882/5349 [=========>....................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8408\n",
      "2083/5349 [==========>...................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8408\n",
      "2393/5349 [============>.................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8407\n",
      "2601/5349 [=============>................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8408\n",
      "2803/5349 [==============>...............] - ETA: 1s - loss: 0.4359 - accuracy: 0.8408\n",
      "3012/5349 [===============>..............] - ETA: 1s - loss: 0.4358 - accuracy: 0.8408\n",
      "3211/5349 [=================>............] - ETA: 1s - loss: 0.4360 - accuracy: 0.8407\n",
      "3423/5349 [==================>...........] - ETA: 0s - loss: 0.4360 - accuracy: 0.8408\n",
      "3619/5349 [===================>..........] - ETA: 0s - loss: 0.4361 - accuracy: 0.8406\n",
      "3830/5349 [====================>.........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8406\n",
      "4022/5349 [=====================>........] - ETA: 0s - loss: 0.4363 - accuracy: 0.8405\n",
      "4221/5349 [======================>.......] - ETA: 0s - loss: 0.4360 - accuracy: 0.8407\n",
      "4518/5349 [========================>.....] - ETA: 0s - loss: 0.4362 - accuracy: 0.8406\n",
      "4733/5349 [=========================>....] - ETA: 0s - loss: 0.4358 - accuracy: 0.8408\n",
      "4942/5349 [==========================>...] - ETA: 0s - loss: 0.4360 - accuracy: 0.8407\n",
      "5144/5349 [===========================>..] - ETA: 0s - loss: 0.4362 - accuracy: 0.8406\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.4361 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 685us/step - loss: 0.4361 - accuracy: 0.8406 - val_loss: 0.4361 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 11/20\n",
      " 104/5349 [..............................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8409\n",
      " 314/5349 [>.............................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8404\n",
      " 525/5349 [=>............................] - ETA: 2s - loss: 0.4331 - accuracy: 0.8423\n",
      " 722/5349 [===>..........................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8415\n",
      "1016/5349 [====>.........................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8420\n",
      "1216/5349 [=====>........................] - ETA: 2s - loss: 0.4334 - accuracy: 0.8421\n",
      "1422/5349 [======>.......................] - ETA: 1s - loss: 0.4332 - accuracy: 0.8422\n",
      "1612/5349 [========>.....................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8420\n",
      "1810/5349 [=========>....................] - ETA: 1s - loss: 0.4334 - accuracy: 0.8421\n",
      "1998/5349 [==========>...................] - ETA: 1s - loss: 0.4342 - accuracy: 0.8416\n",
      "2186/5349 [===========>..................] - ETA: 1s - loss: 0.4343 - accuracy: 0.8415\n",
      "2455/5349 [============>.................] - ETA: 1s - loss: 0.4350 - accuracy: 0.8411\n",
      "2645/5349 [=============>................] - ETA: 1s - loss: 0.4351 - accuracy: 0.8410\n",
      "2813/5349 [==============>...............] - ETA: 1s - loss: 0.4351 - accuracy: 0.8410\n",
      "2996/5349 [===============>..............] - ETA: 1s - loss: 0.4351 - accuracy: 0.8410\n",
      "3171/5349 [================>.............] - ETA: 1s - loss: 0.4350 - accuracy: 0.8411\n",
      "3354/5349 [=================>............] - ETA: 1s - loss: 0.4348 - accuracy: 0.8412\n",
      "3643/5349 [===================>..........] - ETA: 0s - loss: 0.4353 - accuracy: 0.8409\n",
      "3784/5349 [====================>.........] - ETA: 0s - loss: 0.4354 - accuracy: 0.8409\n",
      "3938/5349 [=====================>........] - ETA: 0s - loss: 0.4352 - accuracy: 0.8409\n",
      "4120/5349 [======================>.......] - ETA: 0s - loss: 0.4355 - accuracy: 0.8408\n",
      "4287/5349 [=======================>......] - ETA: 0s - loss: 0.4353 - accuracy: 0.8409\n",
      "4475/5349 [========================>.....] - ETA: 0s - loss: 0.4353 - accuracy: 0.8409\n",
      "4681/5349 [=========================>....] - ETA: 0s - loss: 0.4354 - accuracy: 0.8408\n",
      "4874/5349 [==========================>...] - ETA: 0s - loss: 0.4357 - accuracy: 0.8406\n",
      "5042/5349 [===========================>..] - ETA: 0s - loss: 0.4358 - accuracy: 0.8405\n",
      "5133/5349 [===========================>..] - ETA: 0s - loss: 0.4358 - accuracy: 0.8406\n",
      "5327/5349 [============================>.] - ETA: 0s - loss: 0.4356 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 722us/step - loss: 0.4357 - accuracy: 0.8406 - val_loss: 0.4356 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 12/20\n",
      "  96/5349 [..............................] - ETA: 2s - loss: 0.4328 - accuracy: 0.8423\n",
      " 300/5349 [>.............................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8411\n",
      " 507/5349 [=>............................] - ETA: 2s - loss: 0.4362 - accuracy: 0.8402\n",
      " 705/5349 [==>...........................] - ETA: 2s - loss: 0.4348 - accuracy: 0.8410\n",
      "1007/5349 [====>.........................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8406\n",
      "1182/5349 [=====>........................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8409\n",
      "1391/5349 [======>.......................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8408\n",
      "1600/5349 [=======>......................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8407\n",
      "1808/5349 [=========>....................] - ETA: 1s - loss: 0.4354 - accuracy: 0.8407\n",
      "2000/5349 [==========>...................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8407\n",
      "2185/5349 [===========>..................] - ETA: 1s - loss: 0.4347 - accuracy: 0.8410\n",
      "2386/5349 [============>.................] - ETA: 1s - loss: 0.4349 - accuracy: 0.8409\n",
      "2584/5349 [=============>................] - ETA: 1s - loss: 0.4343 - accuracy: 0.8413\n",
      "2892/5349 [===============>..............] - ETA: 1s - loss: 0.4339 - accuracy: 0.8415\n",
      "3099/5349 [================>.............] - ETA: 1s - loss: 0.4347 - accuracy: 0.8410\n",
      "3283/5349 [=================>............] - ETA: 1s - loss: 0.4349 - accuracy: 0.8409\n",
      "3494/5349 [==================>...........] - ETA: 0s - loss: 0.4350 - accuracy: 0.8408\n",
      "3689/5349 [===================>..........] - ETA: 0s - loss: 0.4350 - accuracy: 0.8408\n",
      "3900/5349 [====================>.........] - ETA: 0s - loss: 0.4353 - accuracy: 0.8407\n",
      "4082/5349 [=====================>........] - ETA: 0s - loss: 0.4350 - accuracy: 0.8408\n",
      "4177/5349 [======================>.......] - ETA: 0s - loss: 0.4349 - accuracy: 0.8409\n",
      "4365/5349 [=======================>......] - ETA: 0s - loss: 0.4351 - accuracy: 0.8407\n",
      "4559/5349 [========================>.....] - ETA: 0s - loss: 0.4353 - accuracy: 0.8406\n",
      "4769/5349 [=========================>....] - ETA: 0s - loss: 0.4354 - accuracy: 0.8406\n",
      "4962/5349 [==========================>...] - ETA: 0s - loss: 0.4353 - accuracy: 0.8406\n",
      "5120/5349 [===========================>..] - ETA: 0s - loss: 0.4355 - accuracy: 0.8405\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.4352 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 742us/step - loss: 0.4352 - accuracy: 0.8406 - val_loss: 0.4351 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 13/20\n",
      "  96/5349 [..............................] - ETA: 2s - loss: 0.4254 - accuracy: 0.8465 \n",
      " 297/5349 [>.............................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8410\n",
      " 501/5349 [=>............................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8402\n",
      " 685/5349 [==>...........................] - ETA: 2s - loss: 0.4339 - accuracy: 0.8413\n",
      " 893/5349 [====>.........................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8407\n",
      "1098/5349 [=====>........................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8412\n",
      "1309/5349 [======>.......................] - ETA: 2s - loss: 0.4348 - accuracy: 0.8407\n",
      "1500/5349 [=======>......................] - ETA: 1s - loss: 0.4347 - accuracy: 0.8408\n",
      "1709/5349 [========>.....................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8404\n",
      "1918/5349 [=========>....................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8399\n",
      "2235/5349 [===========>..................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8402\n",
      "2416/5349 [============>.................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8402\n",
      "2626/5349 [=============>................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8400\n",
      "2829/5349 [==============>...............] - ETA: 1s - loss: 0.4361 - accuracy: 0.8399\n",
      "3039/5349 [================>.............] - ETA: 1s - loss: 0.4360 - accuracy: 0.8399\n",
      "3249/5349 [=================>............] - ETA: 1s - loss: 0.4358 - accuracy: 0.8400\n",
      "3450/5349 [==================>...........] - ETA: 0s - loss: 0.4356 - accuracy: 0.8401\n",
      "3655/5349 [===================>..........] - ETA: 0s - loss: 0.4354 - accuracy: 0.8403\n",
      "3868/5349 [====================>.........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8404\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8404\n",
      "4171/5349 [======================>.......] - ETA: 0s - loss: 0.4351 - accuracy: 0.8404\n",
      "4383/5349 [=======================>......] - ETA: 0s - loss: 0.4350 - accuracy: 0.8405\n",
      "4576/5349 [========================>.....] - ETA: 0s - loss: 0.4348 - accuracy: 0.8406\n",
      "4784/5349 [=========================>....] - ETA: 0s - loss: 0.4348 - accuracy: 0.8406\n",
      "4991/5349 [==========================>...] - ETA: 0s - loss: 0.4347 - accuracy: 0.8406\n",
      "5193/5349 [============================>.] - ETA: 0s - loss: 0.4346 - accuracy: 0.8407\n",
      "5282/5349 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 687us/step - loss: 0.4347 - accuracy: 0.8406 - val_loss: 0.4346 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 14/20\n",
      " 106/5349 [..............................] - ETA: 2s - loss: 0.4239 - accuracy: 0.8470\n",
      " 311/5349 [>.............................] - ETA: 2s - loss: 0.4272 - accuracy: 0.8450\n",
      " 504/5349 [=>............................] - ETA: 2s - loss: 0.4276 - accuracy: 0.8447\n",
      " 704/5349 [==>...........................] - ETA: 2s - loss: 0.4290 - accuracy: 0.8439\n",
      " 913/5349 [====>.........................] - ETA: 2s - loss: 0.4300 - accuracy: 0.8433\n",
      "1120/5349 [=====>........................] - ETA: 2s - loss: 0.4318 - accuracy: 0.8422\n",
      "1312/5349 [======>.......................] - ETA: 2s - loss: 0.4318 - accuracy: 0.8421\n",
      "1424/5349 [======>.......................] - ETA: 1s - loss: 0.4311 - accuracy: 0.8426\n",
      "1626/5349 [========>.....................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8422\n",
      "1838/5349 [=========>....................] - ETA: 1s - loss: 0.4315 - accuracy: 0.8423\n",
      "2003/5349 [==========>...................] - ETA: 1s - loss: 0.4321 - accuracy: 0.8420\n",
      "2213/5349 [===========>..................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8418\n",
      "2400/5349 [============>.................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8418\n",
      "2613/5349 [=============>................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8417\n",
      "2772/5349 [==============>...............] - ETA: 1s - loss: 0.4325 - accuracy: 0.8417\n",
      "3040/5349 [================>.............] - ETA: 1s - loss: 0.4326 - accuracy: 0.8416\n",
      "3234/5349 [=================>............] - ETA: 1s - loss: 0.4329 - accuracy: 0.8414\n",
      "3441/5349 [==================>...........] - ETA: 0s - loss: 0.4336 - accuracy: 0.8410\n",
      "3637/5349 [===================>..........] - ETA: 0s - loss: 0.4340 - accuracy: 0.8407\n",
      "3843/5349 [====================>.........] - ETA: 0s - loss: 0.4341 - accuracy: 0.8407\n",
      "4046/5349 [=====================>........] - ETA: 0s - loss: 0.4341 - accuracy: 0.8406\n",
      "4364/5349 [=======================>......] - ETA: 0s - loss: 0.4341 - accuracy: 0.8406\n",
      "4571/5349 [========================>.....] - ETA: 0s - loss: 0.4342 - accuracy: 0.8406\n",
      "4784/5349 [=========================>....] - ETA: 0s - loss: 0.4342 - accuracy: 0.8405\n",
      "4983/5349 [==========================>...] - ETA: 0s - loss: 0.4341 - accuracy: 0.8406\n",
      "5158/5349 [===========================>..] - ETA: 0s - loss: 0.4341 - accuracy: 0.8406\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.4340 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 690us/step - loss: 0.4341 - accuracy: 0.8406 - val_loss: 0.4339 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.3525 - accuracy: 0.8900\n",
      " 205/5349 [>.............................] - ETA: 2s - loss: 0.4371 - accuracy: 0.8385\n",
      " 408/5349 [=>............................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8394\n",
      " 609/5349 [==>...........................] - ETA: 2s - loss: 0.4367 - accuracy: 0.8388\n",
      " 821/5349 [===>..........................] - ETA: 2s - loss: 0.4360 - accuracy: 0.8392\n",
      "1021/5349 [====>.........................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8400\n",
      "1221/5349 [=====>........................] - ETA: 2s - loss: 0.4335 - accuracy: 0.8407\n",
      "1428/5349 [=======>......................] - ETA: 1s - loss: 0.4331 - accuracy: 0.8409\n",
      "1749/5349 [========>.....................] - ETA: 1s - loss: 0.4328 - accuracy: 0.8411\n",
      "1939/5349 [=========>....................] - ETA: 1s - loss: 0.4329 - accuracy: 0.8411\n",
      "2131/5349 [==========>...................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8413\n",
      "2343/5349 [============>.................] - ETA: 1s - loss: 0.4329 - accuracy: 0.8410\n",
      "2552/5349 [=============>................] - ETA: 1s - loss: 0.4335 - accuracy: 0.8407\n",
      "2760/5349 [==============>...............] - ETA: 1s - loss: 0.4339 - accuracy: 0.8404\n",
      "2967/5349 [===============>..............] - ETA: 1s - loss: 0.4342 - accuracy: 0.8402\n",
      "3073/5349 [================>.............] - ETA: 1s - loss: 0.4341 - accuracy: 0.8402\n",
      "3284/5349 [=================>............] - ETA: 1s - loss: 0.4340 - accuracy: 0.8403\n",
      "3486/5349 [==================>...........] - ETA: 0s - loss: 0.4334 - accuracy: 0.8406\n",
      "3678/5349 [===================>..........] - ETA: 0s - loss: 0.4332 - accuracy: 0.8408\n",
      "3883/5349 [====================>.........] - ETA: 0s - loss: 0.4330 - accuracy: 0.8409\n",
      "4088/5349 [=====================>........] - ETA: 0s - loss: 0.4327 - accuracy: 0.8411\n",
      "4297/5349 [=======================>......] - ETA: 0s - loss: 0.4327 - accuracy: 0.8410\n",
      "4503/5349 [========================>.....] - ETA: 0s - loss: 0.4332 - accuracy: 0.8407\n",
      "4820/5349 [==========================>...] - ETA: 0s - loss: 0.4330 - accuracy: 0.8408\n",
      "4989/5349 [==========================>...] - ETA: 0s - loss: 0.4334 - accuracy: 0.8406\n",
      "5143/5349 [===========================>..] - ETA: 0s - loss: 0.4335 - accuracy: 0.8405\n",
      "5325/5349 [============================>.] - ETA: 0s - loss: 0.4332 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 716us/step - loss: 0.4333 - accuracy: 0.8406 - val_loss: 0.4330 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.4175 - accuracy: 0.8500\n",
      " 209/5349 [>.............................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8396\n",
      " 418/5349 [=>............................] - ETA: 2s - loss: 0.4377 - accuracy: 0.8376\n",
      " 731/5349 [===>..........................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8385\n",
      " 942/5349 [====>.........................] - ETA: 2s - loss: 0.4338 - accuracy: 0.8400\n",
      "1146/5349 [=====>........................] - ETA: 2s - loss: 0.4322 - accuracy: 0.8410\n",
      "1358/5349 [======>.......................] - ETA: 1s - loss: 0.4325 - accuracy: 0.8407\n",
      "1557/5349 [=======>......................] - ETA: 1s - loss: 0.4334 - accuracy: 0.8402\n",
      "1767/5349 [========>.....................] - ETA: 1s - loss: 0.4334 - accuracy: 0.8402\n",
      "1967/5349 [==========>...................] - ETA: 1s - loss: 0.4330 - accuracy: 0.8404\n",
      "2178/5349 [===========>..................] - ETA: 1s - loss: 0.4327 - accuracy: 0.8406\n",
      "2280/5349 [===========>..................] - ETA: 1s - loss: 0.4330 - accuracy: 0.8404\n",
      "2469/5349 [============>.................] - ETA: 1s - loss: 0.4330 - accuracy: 0.8404\n",
      "2682/5349 [==============>...............] - ETA: 1s - loss: 0.4326 - accuracy: 0.8406\n",
      "2890/5349 [===============>..............] - ETA: 1s - loss: 0.4322 - accuracy: 0.8408\n",
      "3076/5349 [================>.............] - ETA: 1s - loss: 0.4318 - accuracy: 0.8411\n",
      "3261/5349 [=================>............] - ETA: 1s - loss: 0.4319 - accuracy: 0.8410\n",
      "3455/5349 [==================>...........] - ETA: 0s - loss: 0.4319 - accuracy: 0.8410\n",
      "3657/5349 [===================>..........] - ETA: 0s - loss: 0.4319 - accuracy: 0.8410\n",
      "3973/5349 [=====================>........] - ETA: 0s - loss: 0.4318 - accuracy: 0.8410\n",
      "4177/5349 [======================>.......] - ETA: 0s - loss: 0.4319 - accuracy: 0.8410\n",
      "4386/5349 [=======================>......] - ETA: 0s - loss: 0.4316 - accuracy: 0.8411\n",
      "4569/5349 [========================>.....] - ETA: 0s - loss: 0.4313 - accuracy: 0.8413\n",
      "4774/5349 [=========================>....] - ETA: 0s - loss: 0.4316 - accuracy: 0.8411\n",
      "4976/5349 [==========================>...] - ETA: 0s - loss: 0.4318 - accuracy: 0.8410\n",
      "5142/5349 [===========================>..] - ETA: 0s - loss: 0.4321 - accuracy: 0.8408\n",
      "5349/5349 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 707us/step - loss: 0.4323 - accuracy: 0.8406 - val_loss: 0.4320 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 17/20\n",
      "  83/5349 [..............................] - ETA: 3s - loss: 0.4360 - accuracy: 0.8381\n",
      " 287/5349 [>.............................] - ETA: 2s - loss: 0.4306 - accuracy: 0.8414\n",
      " 498/5349 [=>............................] - ETA: 2s - loss: 0.4299 - accuracy: 0.8418\n",
      " 604/5349 [==>...........................] - ETA: 2s - loss: 0.4316 - accuracy: 0.8408\n",
      " 796/5349 [===>..........................] - ETA: 2s - loss: 0.4316 - accuracy: 0.8407\n",
      "1003/5349 [====>.........................] - ETA: 2s - loss: 0.4321 - accuracy: 0.8404\n",
      "1210/5349 [=====>........................] - ETA: 2s - loss: 0.4313 - accuracy: 0.8408\n",
      "1419/5349 [======>.......................] - ETA: 1s - loss: 0.4319 - accuracy: 0.8405\n",
      "1624/5349 [========>.....................] - ETA: 1s - loss: 0.4312 - accuracy: 0.8409\n",
      "1831/5349 [=========>....................] - ETA: 1s - loss: 0.4305 - accuracy: 0.8413\n",
      "2023/5349 [==========>...................] - ETA: 1s - loss: 0.4309 - accuracy: 0.8411\n",
      "2129/5349 [==========>...................] - ETA: 1s - loss: 0.4308 - accuracy: 0.8411\n",
      "2341/5349 [============>.................] - ETA: 1s - loss: 0.4310 - accuracy: 0.8410\n",
      "2548/5349 [=============>................] - ETA: 1s - loss: 0.4309 - accuracy: 0.8410\n",
      "2758/5349 [==============>...............] - ETA: 1s - loss: 0.4309 - accuracy: 0.8410\n",
      "2956/5349 [===============>..............] - ETA: 1s - loss: 0.4308 - accuracy: 0.8410\n",
      "3166/5349 [================>.............] - ETA: 1s - loss: 0.4309 - accuracy: 0.8410\n",
      "3370/5349 [=================>............] - ETA: 0s - loss: 0.4308 - accuracy: 0.8410\n",
      "3582/5349 [===================>..........] - ETA: 0s - loss: 0.4308 - accuracy: 0.8410\n",
      "3900/5349 [====================>.........] - ETA: 0s - loss: 0.4309 - accuracy: 0.8409\n",
      "4055/5349 [=====================>........] - ETA: 0s - loss: 0.4311 - accuracy: 0.8408\n",
      "4225/5349 [======================>.......] - ETA: 0s - loss: 0.4309 - accuracy: 0.8409\n",
      "4429/5349 [=======================>......] - ETA: 0s - loss: 0.4309 - accuracy: 0.8408\n",
      "4635/5349 [========================>.....] - ETA: 0s - loss: 0.4312 - accuracy: 0.8407\n",
      "4839/5349 [==========================>...] - ETA: 0s - loss: 0.4313 - accuracy: 0.8406\n",
      "5024/5349 [===========================>..] - ETA: 0s - loss: 0.4312 - accuracy: 0.8406\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.4314 - accuracy: 0.8405\n",
      "5338/5349 [============================>.] - ETA: 0s - loss: 0.4312 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 684us/step - loss: 0.4312 - accuracy: 0.8406 - val_loss: 0.4307 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.4311 - accuracy: 0.8400\n",
      " 170/5349 [..............................] - ETA: 3s - loss: 0.4329 - accuracy: 0.8391\n",
      " 271/5349 [>.............................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8375\n",
      " 486/5349 [=>............................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8387\n",
      " 693/5349 [==>...........................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8378\n",
      " 892/5349 [====>.........................] - ETA: 2s - loss: 0.4337 - accuracy: 0.8386\n",
      "1095/5349 [=====>........................] - ETA: 2s - loss: 0.4330 - accuracy: 0.8390\n",
      "1301/5349 [======>.......................] - ETA: 2s - loss: 0.4329 - accuracy: 0.8390\n",
      "1501/5349 [=======>......................] - ETA: 1s - loss: 0.4326 - accuracy: 0.8392\n",
      "1707/5349 [========>.....................] - ETA: 1s - loss: 0.4329 - accuracy: 0.8390\n",
      "1903/5349 [=========>....................] - ETA: 1s - loss: 0.4318 - accuracy: 0.8396\n",
      "2111/5349 [==========>...................] - ETA: 1s - loss: 0.4311 - accuracy: 0.8401\n",
      "2320/5349 [============>.................] - ETA: 1s - loss: 0.4310 - accuracy: 0.8401\n",
      "2534/5349 [=============>................] - ETA: 1s - loss: 0.4313 - accuracy: 0.8399\n",
      "2635/5349 [=============>................] - ETA: 1s - loss: 0.4314 - accuracy: 0.8398\n",
      "2843/5349 [==============>...............] - ETA: 1s - loss: 0.4312 - accuracy: 0.8399\n",
      "3051/5349 [================>.............] - ETA: 1s - loss: 0.4308 - accuracy: 0.8402\n",
      "3260/5349 [=================>............] - ETA: 1s - loss: 0.4300 - accuracy: 0.8407\n",
      "3472/5349 [==================>...........] - ETA: 0s - loss: 0.4298 - accuracy: 0.8408\n",
      "3673/5349 [===================>..........] - ETA: 0s - loss: 0.4299 - accuracy: 0.8407\n",
      "3880/5349 [====================>.........] - ETA: 0s - loss: 0.4299 - accuracy: 0.8406\n",
      "3990/5349 [=====================>........] - ETA: 0s - loss: 0.4297 - accuracy: 0.8408\n",
      "4180/5349 [======================>.......] - ETA: 0s - loss: 0.4300 - accuracy: 0.8406\n",
      "4393/5349 [=======================>......] - ETA: 0s - loss: 0.4300 - accuracy: 0.8405\n",
      "4604/5349 [========================>.....] - ETA: 0s - loss: 0.4299 - accuracy: 0.8406\n",
      "4799/5349 [=========================>....] - ETA: 0s - loss: 0.4298 - accuracy: 0.8406\n",
      "4988/5349 [==========================>...] - ETA: 0s - loss: 0.4296 - accuracy: 0.8408\n",
      "5205/5349 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.8406\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 702us/step - loss: 0.4297 - accuracy: 0.8406 - val_loss: 0.4290 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 19/20\n",
      " 139/5349 [..............................] - ETA: 3s - loss: 0.4330 - accuracy: 0.8381\n",
      " 284/5349 [>.............................] - ETA: 3s - loss: 0.4306 - accuracy: 0.8395\n",
      " 460/5349 [=>............................] - ETA: 3s - loss: 0.4258 - accuracy: 0.8425\n",
      " 612/5349 [==>...........................] - ETA: 3s - loss: 0.4245 - accuracy: 0.8432\n",
      " 725/5349 [===>..........................] - ETA: 3s - loss: 0.4253 - accuracy: 0.8427\n",
      " 884/5349 [===>..........................] - ETA: 3s - loss: 0.4258 - accuracy: 0.8424\n",
      " 971/5349 [====>.........................] - ETA: 2s - loss: 0.4263 - accuracy: 0.8421\n",
      "1149/5349 [=====>........................] - ETA: 2s - loss: 0.4269 - accuracy: 0.8417\n",
      "1350/5349 [======>.......................] - ETA: 2s - loss: 0.4263 - accuracy: 0.8421\n",
      "1560/5349 [=======>......................] - ETA: 2s - loss: 0.4266 - accuracy: 0.8419\n",
      "1756/5349 [========>.....................] - ETA: 2s - loss: 0.4270 - accuracy: 0.8416\n",
      "1940/5349 [=========>....................] - ETA: 2s - loss: 0.4261 - accuracy: 0.8421\n",
      "2132/5349 [==========>...................] - ETA: 1s - loss: 0.4264 - accuracy: 0.8419\n",
      "2398/5349 [============>.................] - ETA: 1s - loss: 0.4264 - accuracy: 0.8419\n",
      "2600/5349 [=============>................] - ETA: 1s - loss: 0.4270 - accuracy: 0.8415\n",
      "2801/5349 [==============>...............] - ETA: 1s - loss: 0.4275 - accuracy: 0.8412\n",
      "3001/5349 [===============>..............] - ETA: 1s - loss: 0.4272 - accuracy: 0.8413\n",
      "3190/5349 [================>.............] - ETA: 1s - loss: 0.4272 - accuracy: 0.8413\n",
      "3394/5349 [==================>...........] - ETA: 1s - loss: 0.4271 - accuracy: 0.8413\n",
      "3698/5349 [===================>..........] - ETA: 0s - loss: 0.4275 - accuracy: 0.8411\n",
      "3892/5349 [====================>.........] - ETA: 0s - loss: 0.4272 - accuracy: 0.8412\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.4274 - accuracy: 0.8411\n",
      "4305/5349 [=======================>......] - ETA: 0s - loss: 0.4275 - accuracy: 0.8410\n",
      "4515/5349 [========================>.....] - ETA: 0s - loss: 0.4276 - accuracy: 0.8409\n",
      "4702/5349 [=========================>....] - ETA: 0s - loss: 0.4277 - accuracy: 0.8408\n",
      "4910/5349 [==========================>...] - ETA: 0s - loss: 0.4279 - accuracy: 0.8407\n",
      "5015/5349 [===========================>..] - ETA: 0s - loss: 0.4280 - accuracy: 0.8406\n",
      "5215/5349 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8408\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.4279 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 730us/step - loss: 0.4279 - accuracy: 0.8406 - val_loss: 0.4269 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5533)\u001B[0m Epoch 20/20\n",
      " 103/5349 [..............................] - ETA: 2s - loss: 0.4337 - accuracy: 0.8362\n",
      " 316/5349 [>.............................] - ETA: 2s - loss: 0.4234 - accuracy: 0.8427\n",
      " 523/5349 [=>............................] - ETA: 2s - loss: 0.4254 - accuracy: 0.8414\n",
      " 711/5349 [==>...........................] - ETA: 2s - loss: 0.4256 - accuracy: 0.8412\n",
      " 915/5349 [====>.........................] - ETA: 2s - loss: 0.4255 - accuracy: 0.8413\n",
      "1112/5349 [=====>........................] - ETA: 2s - loss: 0.4264 - accuracy: 0.8407\n",
      "1317/5349 [======>.......................] - ETA: 2s - loss: 0.4271 - accuracy: 0.8402\n",
      "1506/5349 [=======>......................] - ETA: 1s - loss: 0.4266 - accuracy: 0.8405\n",
      "1814/5349 [=========>....................] - ETA: 1s - loss: 0.4266 - accuracy: 0.8404\n",
      "2010/5349 [==========>...................] - ETA: 1s - loss: 0.4268 - accuracy: 0.8403\n",
      "2198/5349 [===========>..................] - ETA: 1s - loss: 0.4268 - accuracy: 0.8403\n",
      "2367/5349 [============>.................] - ETA: 1s - loss: 0.4266 - accuracy: 0.8404\n",
      "2578/5349 [=============>................] - ETA: 1s - loss: 0.4265 - accuracy: 0.8404\n",
      "2775/5349 [==============>...............] - ETA: 1s - loss: 0.4269 - accuracy: 0.8402\n",
      "3084/5349 [================>.............] - ETA: 1s - loss: 0.4267 - accuracy: 0.8402\n",
      "3289/5349 [=================>............] - ETA: 1s - loss: 0.4268 - accuracy: 0.8401\n",
      "3479/5349 [==================>...........] - ETA: 0s - loss: 0.4265 - accuracy: 0.8403\n",
      "3685/5349 [===================>..........] - ETA: 0s - loss: 0.4263 - accuracy: 0.8404\n",
      "3891/5349 [====================>.........] - ETA: 0s - loss: 0.4262 - accuracy: 0.8404\n",
      "4073/5349 [=====================>........] - ETA: 0s - loss: 0.4264 - accuracy: 0.8403\n",
      "4283/5349 [=======================>......] - ETA: 0s - loss: 0.4262 - accuracy: 0.8404\n",
      "4471/5349 [========================>.....] - ETA: 0s - loss: 0.4258 - accuracy: 0.8405\n",
      "4683/5349 [=========================>....] - ETA: 0s - loss: 0.4257 - accuracy: 0.8406\n",
      "4888/5349 [==========================>...] - ETA: 0s - loss: 0.4257 - accuracy: 0.8406\n",
      "5199/5349 [============================>.] - ETA: 0s - loss: 0.4257 - accuracy: 0.8405\n",
      "5301/5349 [============================>.] - ETA: 0s - loss: 0.4257 - accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 28:07 - loss: 0.8105 - accuracy: 0.4600\n",
      " 123/5349 [..............................] - ETA: 4s - loss: 0.7328 - accuracy: 0.5544\n",
      " 303/5349 [>.............................] - ETA: 3s - loss: 0.6837 - accuracy: 0.6808\n",
      " 482/5349 [=>............................] - ETA: 3s - loss: 0.6441 - accuracy: 0.7419\n",
      " 664/5349 [==>...........................] - ETA: 2s - loss: 0.6081 - accuracy: 0.7787\n",
      " 838/5349 [===>..........................] - ETA: 2s - loss: 0.5826 - accuracy: 0.8002\n",
      " 921/5349 [====>.........................] - ETA: 2s - loss: 0.5712 - accuracy: 0.8076\n",
      "1094/5349 [=====>........................] - ETA: 2s - loss: 0.5491 - accuracy: 0.8204\n",
      "1271/5349 [======>.......................] - ETA: 2s - loss: 0.5288 - accuracy: 0.8299\n",
      "1452/5349 [=======>......................] - ETA: 2s - loss: 0.5106 - accuracy: 0.8376\n",
      "1637/5349 [========>.....................] - ETA: 2s - loss: 0.4937 - accuracy: 0.8436\n",
      "1811/5349 [=========>....................] - ETA: 2s - loss: 0.4797 - accuracy: 0.8482\n",
      "1991/5349 [==========>...................] - ETA: 1s - loss: 0.4663 - accuracy: 0.8523\n",
      "2155/5349 [===========>..................] - ETA: 1s - loss: 0.4551 - accuracy: 0.8554\n",
      "2391/5349 [============>.................] - ETA: 1s - loss: 0.4405 - accuracy: 0.8592\n",
      "2575/5349 [=============>................] - ETA: 1s - loss: 0.4298 - accuracy: 0.8617\n",
      "2750/5349 [==============>...............] - ETA: 1s - loss: 0.4206 - accuracy: 0.8638\n",
      "2911/5349 [===============>..............] - ETA: 1s - loss: 0.4126 - accuracy: 0.8656\n",
      "3080/5349 [================>.............] - ETA: 1s - loss: 0.4048 - accuracy: 0.8670\n",
      "3259/5349 [=================>............] - ETA: 1s - loss: 0.3969 - accuracy: 0.8689\n",
      "3443/5349 [==================>...........] - ETA: 1s - loss: 0.3894 - accuracy: 0.8704\n",
      "3718/5349 [===================>..........] - ETA: 0s - loss: 0.3793 - accuracy: 0.8725\n",
      "3899/5349 [====================>.........] - ETA: 0s - loss: 0.3732 - accuracy: 0.8736\n",
      "4081/5349 [=====================>........] - ETA: 0s - loss: 0.3673 - accuracy: 0.8746\n",
      "4264/5349 [======================>.......] - ETA: 0s - loss: 0.3616 - accuracy: 0.8757\n",
      "4437/5349 [=======================>......] - ETA: 0s - loss: 0.3566 - accuracy: 0.8765\n",
      "4615/5349 [========================>.....] - ETA: 0s - loss: 0.3518 - accuracy: 0.8774\n",
      "4794/5349 [=========================>....] - ETA: 0s - loss: 0.3471 - accuracy: 0.8782\n",
      "4961/5349 [==========================>...] - ETA: 0s - loss: 0.3431 - accuracy: 0.8790\n",
      "5238/5349 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.8802\n",
      "5324/5349 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8805\n",
      "5349/5349 [==============================] - 5s 792us/step - loss: 0.3343 - accuracy: 0.8806 - val_loss: 0.2237 - val_accuracy: 0.9059\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2140 - accuracy: 0.8800\n",
      " 180/5349 [>.............................] - ETA: 2s - loss: 0.2178 - accuracy: 0.9007\n",
      " 352/5349 [>.............................] - ETA: 2s - loss: 0.2172 - accuracy: 0.9018\n",
      " 602/5349 [==>...........................] - ETA: 2s - loss: 0.2146 - accuracy: 0.9027\n",
      " 782/5349 [===>..........................] - ETA: 2s - loss: 0.2137 - accuracy: 0.9029\n",
      " 963/5349 [====>.........................] - ETA: 2s - loss: 0.2133 - accuracy: 0.9026\n",
      "1154/5349 [=====>........................] - ETA: 2s - loss: 0.2119 - accuracy: 0.9030\n",
      "1331/5349 [======>.......................] - ETA: 2s - loss: 0.2113 - accuracy: 0.9029\n",
      "1504/5349 [=======>......................] - ETA: 2s - loss: 0.2110 - accuracy: 0.9027\n",
      "1683/5349 [========>.....................] - ETA: 2s - loss: 0.2108 - accuracy: 0.9021\n",
      "1945/5349 [=========>....................] - ETA: 1s - loss: 0.2096 - accuracy: 0.9026\n",
      "2088/5349 [==========>...................] - ETA: 1s - loss: 0.2091 - accuracy: 0.9026\n",
      "2182/5349 [===========>..................] - ETA: 1s - loss: 0.2089 - accuracy: 0.9026\n",
      "2284/5349 [===========>..................] - ETA: 1s - loss: 0.2087 - accuracy: 0.9025\n",
      "2377/5349 [============>.................] - ETA: 1s - loss: 0.2082 - accuracy: 0.9027\n",
      "2464/5349 [============>.................] - ETA: 1s - loss: 0.2079 - accuracy: 0.9028\n",
      "2585/5349 [=============>................] - ETA: 1s - loss: 0.2073 - accuracy: 0.9031\n",
      "2675/5349 [==============>...............] - ETA: 1s - loss: 0.2070 - accuracy: 0.9031\n",
      "2734/5349 [==============>...............] - ETA: 1s - loss: 0.2069 - accuracy: 0.9030\n",
      "2866/5349 [===============>..............] - ETA: 1s - loss: 0.2061 - accuracy: 0.9033\n",
      "3005/5349 [===============>..............] - ETA: 1s - loss: 0.2059 - accuracy: 0.9032\n",
      "3159/5349 [================>.............] - ETA: 1s - loss: 0.2053 - accuracy: 0.9034\n",
      "3318/5349 [=================>............] - ETA: 1s - loss: 0.2047 - accuracy: 0.9035\n",
      "3517/5349 [==================>...........] - ETA: 1s - loss: 0.2042 - accuracy: 0.9035\n",
      "3634/5349 [===================>..........] - ETA: 1s - loss: 0.2040 - accuracy: 0.9035\n",
      "3770/5349 [====================>.........] - ETA: 1s - loss: 0.2036 - accuracy: 0.9036\n",
      "3912/5349 [====================>.........] - ETA: 0s - loss: 0.2032 - accuracy: 0.9036\n",
      "4071/5349 [=====================>........] - ETA: 0s - loss: 0.2028 - accuracy: 0.9036\n",
      "4334/5349 [=======================>......] - ETA: 0s - loss: 0.2021 - accuracy: 0.9038\n",
      "4502/5349 [========================>.....] - ETA: 0s - loss: 0.2018 - accuracy: 0.9038\n",
      "4684/5349 [=========================>....] - ETA: 0s - loss: 0.2013 - accuracy: 0.9040\n",
      "4862/5349 [==========================>...] - ETA: 0s - loss: 0.2011 - accuracy: 0.9039\n",
      "5022/5349 [===========================>..] - ETA: 0s - loss: 0.2007 - accuracy: 0.9040\n",
      "5197/5349 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9040\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.2002 - accuracy: 0.9040\n",
      "5349/5349 [==============================] - 5s 854us/step - loss: 0.2001 - accuracy: 0.9040 - val_loss: 0.1881 - val_accuracy: 0.9102\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 3/20\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1844 - accuracy: 0.9113\n",
      " 343/5349 [>.............................] - ETA: 2s - loss: 0.1860 - accuracy: 0.9089\n",
      " 519/5349 [=>............................] - ETA: 2s - loss: 0.1863 - accuracy: 0.9088\n",
      " 703/5349 [==>...........................] - ETA: 2s - loss: 0.1869 - accuracy: 0.9083\n",
      " 878/5349 [===>..........................] - ETA: 2s - loss: 0.1863 - accuracy: 0.9085\n",
      "1058/5349 [====>.........................] - ETA: 2s - loss: 0.1860 - accuracy: 0.9085\n",
      "1225/5349 [=====>........................] - ETA: 2s - loss: 0.1857 - accuracy: 0.9081\n",
      "1408/5349 [======>.......................] - ETA: 2s - loss: 0.1856 - accuracy: 0.9082\n",
      "1590/5349 [=======>......................] - ETA: 2s - loss: 0.1855 - accuracy: 0.9083\n",
      "1758/5349 [========>.....................] - ETA: 2s - loss: 0.1855 - accuracy: 0.9081\n",
      "1970/5349 [==========>...................] - ETA: 1s - loss: 0.1857 - accuracy: 0.9079\n",
      "2133/5349 [==========>...................] - ETA: 1s - loss: 0.1853 - accuracy: 0.9080\n",
      "2305/5349 [===========>..................] - ETA: 1s - loss: 0.1849 - accuracy: 0.9081\n",
      "2479/5349 [============>.................] - ETA: 1s - loss: 0.1846 - accuracy: 0.9082\n",
      "2646/5349 [=============>................] - ETA: 1s - loss: 0.1845 - accuracy: 0.9081\n",
      "2816/5349 [==============>...............] - ETA: 1s - loss: 0.1846 - accuracy: 0.9079\n",
      "2994/5349 [===============>..............] - ETA: 1s - loss: 0.1845 - accuracy: 0.9079\n",
      "3172/5349 [================>.............] - ETA: 1s - loss: 0.1846 - accuracy: 0.9078\n",
      "3411/5349 [==================>...........] - ETA: 1s - loss: 0.1844 - accuracy: 0.9080\n",
      "3591/5349 [===================>..........] - ETA: 1s - loss: 0.1842 - accuracy: 0.9081\n",
      "3774/5349 [====================>.........] - ETA: 0s - loss: 0.1841 - accuracy: 0.9080\n",
      "3957/5349 [=====================>........] - ETA: 0s - loss: 0.1841 - accuracy: 0.9080\n",
      "4130/5349 [======================>.......] - ETA: 0s - loss: 0.1839 - accuracy: 0.9080\n",
      "4301/5349 [=======================>......] - ETA: 0s - loss: 0.1836 - accuracy: 0.9080\n",
      "4477/5349 [========================>.....] - ETA: 0s - loss: 0.1836 - accuracy: 0.9079\n",
      "4660/5349 [=========================>....] - ETA: 0s - loss: 0.1833 - accuracy: 0.9080\n",
      "4927/5349 [==========================>...] - ETA: 0s - loss: 0.1831 - accuracy: 0.9080\n",
      "5112/5349 [===========================>..] - ETA: 0s - loss: 0.1829 - accuracy: 0.9081\n",
      "5286/5349 [============================>.] - ETA: 0s - loss: 0.1826 - accuracy: 0.9082\n",
      "5349/5349 [==============================] - 4s 779us/step - loss: 0.1826 - accuracy: 0.9082 - val_loss: 0.1774 - val_accuracy: 0.9130\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 4/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1800 - accuracy: 0.9079\n",
      " 247/5349 [>.............................] - ETA: 3s - loss: 0.1794 - accuracy: 0.9092\n",
      " 493/5349 [=>............................] - ETA: 2s - loss: 0.1764 - accuracy: 0.9098\n",
      " 648/5349 [==>...........................] - ETA: 2s - loss: 0.1761 - accuracy: 0.9100\n",
      " 829/5349 [===>..........................] - ETA: 2s - loss: 0.1758 - accuracy: 0.9101\n",
      "1006/5349 [====>.........................] - ETA: 2s - loss: 0.1758 - accuracy: 0.9104\n",
      "1188/5349 [=====>........................] - ETA: 2s - loss: 0.1758 - accuracy: 0.9104\n",
      "1369/5349 [======>.......................] - ETA: 2s - loss: 0.1755 - accuracy: 0.9106\n",
      "1545/5349 [=======>......................] - ETA: 2s - loss: 0.1755 - accuracy: 0.9105\n",
      "1722/5349 [========>.....................] - ETA: 2s - loss: 0.1757 - accuracy: 0.9104\n",
      "1903/5349 [=========>....................] - ETA: 2s - loss: 0.1756 - accuracy: 0.9103\n",
      "2085/5349 [==========>...................] - ETA: 1s - loss: 0.1757 - accuracy: 0.9102\n",
      "2357/5349 [============>.................] - ETA: 1s - loss: 0.1760 - accuracy: 0.9098\n",
      "2531/5349 [=============>................] - ETA: 1s - loss: 0.1758 - accuracy: 0.9098\n",
      "2714/5349 [==============>...............] - ETA: 1s - loss: 0.1760 - accuracy: 0.9097\n",
      "2883/5349 [===============>..............] - ETA: 1s - loss: 0.1761 - accuracy: 0.9096\n",
      "3065/5349 [================>.............] - ETA: 1s - loss: 0.1762 - accuracy: 0.9095\n",
      "3244/5349 [=================>............] - ETA: 1s - loss: 0.1760 - accuracy: 0.9097\n",
      "3429/5349 [==================>...........] - ETA: 1s - loss: 0.1762 - accuracy: 0.9096\n",
      "3599/5349 [===================>..........] - ETA: 1s - loss: 0.1762 - accuracy: 0.9095\n",
      "3765/5349 [====================>.........] - ETA: 0s - loss: 0.1762 - accuracy: 0.9094\n",
      "4028/5349 [=====================>........] - ETA: 0s - loss: 0.1762 - accuracy: 0.9093\n",
      "4203/5349 [======================>.......] - ETA: 0s - loss: 0.1761 - accuracy: 0.9093\n",
      "4377/5349 [=======================>......] - ETA: 0s - loss: 0.1757 - accuracy: 0.9096\n",
      "4561/5349 [========================>.....] - ETA: 0s - loss: 0.1756 - accuracy: 0.9096\n",
      "4735/5349 [=========================>....] - ETA: 0s - loss: 0.1756 - accuracy: 0.9095\n",
      "4920/5349 [==========================>...] - ETA: 0s - loss: 0.1753 - accuracy: 0.9098\n",
      "5077/5349 [===========================>..] - ETA: 0s - loss: 0.1751 - accuracy: 0.9099\n",
      "5249/5349 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9101\n",
      "5344/5349 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9101\n",
      "5349/5349 [==============================] - 4s 781us/step - loss: 0.1749 - accuracy: 0.9101 - val_loss: 0.1710 - val_accuracy: 0.9138\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.2119 - accuracy: 0.8700\n",
      " 151/5349 [..............................] - ETA: 3s - loss: 0.1758 - accuracy: 0.9090\n",
      " 307/5349 [>.............................] - ETA: 3s - loss: 0.1726 - accuracy: 0.9102\n",
      " 455/5349 [=>............................] - ETA: 3s - loss: 0.1707 - accuracy: 0.9115\n",
      " 682/5349 [==>...........................] - ETA: 3s - loss: 0.1711 - accuracy: 0.9110\n",
      " 829/5349 [===>..........................] - ETA: 3s - loss: 0.1708 - accuracy: 0.9113\n",
      " 916/5349 [====>.........................] - ETA: 3s - loss: 0.1707 - accuracy: 0.9114\n",
      "1047/5349 [====>.........................] - ETA: 3s - loss: 0.1708 - accuracy: 0.9115\n",
      "1202/5349 [=====>........................] - ETA: 2s - loss: 0.1706 - accuracy: 0.9118\n",
      "1352/5349 [======>.......................] - ETA: 2s - loss: 0.1703 - accuracy: 0.9120\n",
      "1529/5349 [=======>......................] - ETA: 2s - loss: 0.1705 - accuracy: 0.9118\n",
      "1690/5349 [========>.....................] - ETA: 2s - loss: 0.1710 - accuracy: 0.9114\n",
      "1868/5349 [=========>....................] - ETA: 2s - loss: 0.1708 - accuracy: 0.9116\n",
      "2136/5349 [==========>...................] - ETA: 2s - loss: 0.1705 - accuracy: 0.9120\n",
      "2320/5349 [============>.................] - ETA: 1s - loss: 0.1705 - accuracy: 0.9119\n",
      "2498/5349 [=============>................] - ETA: 1s - loss: 0.1707 - accuracy: 0.9117\n",
      "2681/5349 [==============>...............] - ETA: 1s - loss: 0.1707 - accuracy: 0.9116\n",
      "2857/5349 [===============>..............] - ETA: 1s - loss: 0.1706 - accuracy: 0.9116\n",
      "3038/5349 [================>.............] - ETA: 1s - loss: 0.1706 - accuracy: 0.9116\n",
      "3217/5349 [=================>............] - ETA: 1s - loss: 0.1705 - accuracy: 0.9116\n",
      "3398/5349 [==================>...........] - ETA: 1s - loss: 0.1704 - accuracy: 0.9117\n",
      "3662/5349 [===================>..........] - ETA: 1s - loss: 0.1703 - accuracy: 0.9117\n",
      "3842/5349 [====================>.........] - ETA: 0s - loss: 0.1702 - accuracy: 0.9117\n",
      "4017/5349 [=====================>........] - ETA: 0s - loss: 0.1702 - accuracy: 0.9116\n",
      "4205/5349 [======================>.......] - ETA: 0s - loss: 0.1704 - accuracy: 0.9115\n",
      "4380/5349 [=======================>......] - ETA: 0s - loss: 0.1704 - accuracy: 0.9115\n",
      "4557/5349 [========================>.....] - ETA: 0s - loss: 0.1705 - accuracy: 0.9113\n",
      "4830/5349 [==========================>...] - ETA: 0s - loss: 0.1703 - accuracy: 0.9114\n",
      "5013/5349 [===========================>..] - ETA: 0s - loss: 0.1702 - accuracy: 0.9116\n",
      "5193/5349 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9115\n",
      "5282/5349 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9116\n",
      "5349/5349 [==============================] - 4s 795us/step - loss: 0.1702 - accuracy: 0.9115 - val_loss: 0.1687 - val_accuracy: 0.9142\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 6/20\n",
      "  88/5349 [..............................] - ETA: 3s - loss: 0.1727 - accuracy: 0.9073\n",
      " 266/5349 [>.............................] - ETA: 2s - loss: 0.1686 - accuracy: 0.9124\n",
      " 442/5349 [=>............................] - ETA: 2s - loss: 0.1705 - accuracy: 0.9113\n",
      " 608/5349 [==>...........................] - ETA: 2s - loss: 0.1701 - accuracy: 0.9114\n",
      " 786/5349 [===>..........................] - ETA: 2s - loss: 0.1693 - accuracy: 0.9117\n",
      " 943/5349 [====>.........................] - ETA: 2s - loss: 0.1683 - accuracy: 0.9122\n",
      "1124/5349 [=====>........................] - ETA: 2s - loss: 0.1682 - accuracy: 0.9122\n",
      "1302/5349 [======>.......................] - ETA: 2s - loss: 0.1681 - accuracy: 0.9123\n",
      "1572/5349 [=======>......................] - ETA: 2s - loss: 0.1675 - accuracy: 0.9127\n",
      "1746/5349 [========>.....................] - ETA: 2s - loss: 0.1675 - accuracy: 0.9128\n",
      "1926/5349 [=========>....................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9127\n",
      "2106/5349 [==========>...................] - ETA: 1s - loss: 0.1679 - accuracy: 0.9125\n",
      "2284/5349 [===========>..................] - ETA: 1s - loss: 0.1682 - accuracy: 0.9120\n",
      "2459/5349 [============>.................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9121\n",
      "2642/5349 [=============>................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9120\n",
      "2731/5349 [==============>...............] - ETA: 1s - loss: 0.1679 - accuracy: 0.9121\n",
      "2907/5349 [===============>..............] - ETA: 1s - loss: 0.1679 - accuracy: 0.9120\n",
      "3087/5349 [================>.............] - ETA: 1s - loss: 0.1678 - accuracy: 0.9121\n",
      "3266/5349 [=================>............] - ETA: 1s - loss: 0.1678 - accuracy: 0.9119\n",
      "3446/5349 [==================>...........] - ETA: 1s - loss: 0.1677 - accuracy: 0.9120\n",
      "3604/5349 [===================>..........] - ETA: 0s - loss: 0.1676 - accuracy: 0.9120\n",
      "3784/5349 [====================>.........] - ETA: 0s - loss: 0.1675 - accuracy: 0.9120\n",
      "3966/5349 [=====================>........] - ETA: 0s - loss: 0.1676 - accuracy: 0.9120\n",
      "4240/5349 [======================>.......] - ETA: 0s - loss: 0.1675 - accuracy: 0.9120\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1676 - accuracy: 0.9119\n",
      "4594/5349 [========================>.....] - ETA: 0s - loss: 0.1673 - accuracy: 0.9122\n",
      "4774/5349 [=========================>....] - ETA: 0s - loss: 0.1672 - accuracy: 0.9123\n",
      "4956/5349 [==========================>...] - ETA: 0s - loss: 0.1671 - accuracy: 0.9124\n",
      "5136/5349 [===========================>..] - ETA: 0s - loss: 0.1669 - accuracy: 0.9124\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9122\n",
      "5349/5349 [==============================] - 4s 750us/step - loss: 0.1671 - accuracy: 0.9122 - val_loss: 0.1651 - val_accuracy: 0.9150\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1923 - accuracy: 0.8700\n",
      " 179/5349 [>.............................] - ETA: 2s - loss: 0.1637 - accuracy: 0.9155\n",
      " 365/5349 [=>............................] - ETA: 2s - loss: 0.1666 - accuracy: 0.9127\n",
      " 530/5349 [=>............................] - ETA: 2s - loss: 0.1671 - accuracy: 0.9115\n",
      " 711/5349 [==>...........................] - ETA: 2s - loss: 0.1669 - accuracy: 0.9120\n",
      " 876/5349 [===>..........................] - ETA: 2s - loss: 0.1675 - accuracy: 0.9116\n",
      "1052/5349 [====>.........................] - ETA: 2s - loss: 0.1675 - accuracy: 0.9115\n",
      "1326/5349 [======>.......................] - ETA: 2s - loss: 0.1677 - accuracy: 0.9112\n",
      "1512/5349 [=======>......................] - ETA: 2s - loss: 0.1669 - accuracy: 0.9118\n",
      "1697/5349 [========>.....................] - ETA: 2s - loss: 0.1666 - accuracy: 0.9119\n",
      "1877/5349 [=========>....................] - ETA: 1s - loss: 0.1662 - accuracy: 0.9123\n",
      "2057/5349 [==========>...................] - ETA: 1s - loss: 0.1658 - accuracy: 0.9127\n",
      "2240/5349 [===========>..................] - ETA: 1s - loss: 0.1660 - accuracy: 0.9125\n",
      "2419/5349 [============>.................] - ETA: 1s - loss: 0.1657 - accuracy: 0.9127\n",
      "2605/5349 [=============>................] - ETA: 1s - loss: 0.1656 - accuracy: 0.9127\n",
      "2766/5349 [==============>...............] - ETA: 1s - loss: 0.1654 - accuracy: 0.9128\n",
      "2947/5349 [===============>..............] - ETA: 1s - loss: 0.1654 - accuracy: 0.9128\n",
      "3126/5349 [================>.............] - ETA: 1s - loss: 0.1653 - accuracy: 0.9128\n",
      "3396/5349 [==================>...........] - ETA: 1s - loss: 0.1654 - accuracy: 0.9126\n",
      "3577/5349 [===================>..........] - ETA: 0s - loss: 0.1653 - accuracy: 0.9127\n",
      "3755/5349 [====================>.........] - ETA: 0s - loss: 0.1651 - accuracy: 0.9128\n",
      "3929/5349 [=====================>........] - ETA: 0s - loss: 0.1650 - accuracy: 0.9128\n",
      "4086/5349 [=====================>........] - ETA: 0s - loss: 0.1647 - accuracy: 0.9129\n",
      "4233/5349 [======================>.......] - ETA: 0s - loss: 0.1647 - accuracy: 0.9130\n",
      "4389/5349 [=======================>......] - ETA: 0s - loss: 0.1648 - accuracy: 0.9128\n",
      "4532/5349 [========================>.....] - ETA: 0s - loss: 0.1648 - accuracy: 0.9127\n",
      "4733/5349 [=========================>....] - ETA: 0s - loss: 0.1646 - accuracy: 0.9129\n",
      "4890/5349 [==========================>...] - ETA: 0s - loss: 0.1646 - accuracy: 0.9129\n",
      "5049/5349 [===========================>..] - ETA: 0s - loss: 0.1646 - accuracy: 0.9128\n",
      "5189/5349 [============================>.] - ETA: 0s - loss: 0.1647 - accuracy: 0.9127\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9128\n",
      "5349/5349 [==============================] - 4s 808us/step - loss: 0.1647 - accuracy: 0.9127 - val_loss: 0.1616 - val_accuracy: 0.9157\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1775 - accuracy: 0.9300\n",
      " 166/5349 [..............................] - ETA: 3s - loss: 0.1658 - accuracy: 0.9119\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1646 - accuracy: 0.9131\n",
      " 518/5349 [=>............................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9131\n",
      " 700/5349 [==>...........................] - ETA: 2s - loss: 0.1646 - accuracy: 0.9131\n",
      " 879/5349 [===>..........................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9131\n",
      " 966/5349 [====>.........................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9126\n",
      "1146/5349 [=====>........................] - ETA: 2s - loss: 0.1652 - accuracy: 0.9125\n",
      "1317/5349 [======>.......................] - ETA: 2s - loss: 0.1647 - accuracy: 0.9127\n",
      "1491/5349 [=======>......................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9131\n",
      "1665/5349 [========>.....................] - ETA: 2s - loss: 0.1643 - accuracy: 0.9131\n",
      "1843/5349 [=========>....................] - ETA: 2s - loss: 0.1643 - accuracy: 0.9131\n",
      "2001/5349 [==========>...................] - ETA: 1s - loss: 0.1641 - accuracy: 0.9133\n",
      "2162/5349 [===========>..................] - ETA: 1s - loss: 0.1639 - accuracy: 0.9134\n",
      "2422/5349 [============>.................] - ETA: 1s - loss: 0.1634 - accuracy: 0.9137\n",
      "2583/5349 [=============>................] - ETA: 1s - loss: 0.1635 - accuracy: 0.9136\n",
      "2748/5349 [==============>...............] - ETA: 1s - loss: 0.1632 - accuracy: 0.9138\n",
      "2922/5349 [===============>..............] - ETA: 1s - loss: 0.1634 - accuracy: 0.9136\n",
      "3081/5349 [================>.............] - ETA: 1s - loss: 0.1633 - accuracy: 0.9136\n",
      "3354/5349 [=================>............] - ETA: 1s - loss: 0.1632 - accuracy: 0.9138\n",
      "3525/5349 [==================>...........] - ETA: 1s - loss: 0.1632 - accuracy: 0.9137\n",
      "3655/5349 [===================>..........] - ETA: 1s - loss: 0.1634 - accuracy: 0.9135\n",
      "3832/5349 [====================>.........] - ETA: 0s - loss: 0.1633 - accuracy: 0.9136\n",
      "4003/5349 [=====================>........] - ETA: 0s - loss: 0.1633 - accuracy: 0.9135\n",
      "4272/5349 [======================>.......] - ETA: 0s - loss: 0.1632 - accuracy: 0.9134\n",
      "4430/5349 [=======================>......] - ETA: 0s - loss: 0.1631 - accuracy: 0.9134\n",
      "4609/5349 [========================>.....] - ETA: 0s - loss: 0.1631 - accuracy: 0.9135\n",
      "4782/5349 [=========================>....] - ETA: 0s - loss: 0.1631 - accuracy: 0.9135\n",
      "4962/5349 [==========================>...] - ETA: 0s - loss: 0.1631 - accuracy: 0.9135\n",
      "5130/5349 [===========================>..] - ETA: 0s - loss: 0.1632 - accuracy: 0.9133\n",
      "5303/5349 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9133\n",
      "5349/5349 [==============================] - 4s 776us/step - loss: 0.1631 - accuracy: 0.9133 - val_loss: 0.1605 - val_accuracy: 0.9161\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 9/20\n",
      "  88/5349 [..............................] - ETA: 3s - loss: 0.1613 - accuracy: 0.9145\n",
      " 271/5349 [>.............................] - ETA: 2s - loss: 0.1628 - accuracy: 0.9141\n",
      " 454/5349 [=>............................] - ETA: 2s - loss: 0.1645 - accuracy: 0.9129\n",
      " 626/5349 [==>...........................] - ETA: 2s - loss: 0.1631 - accuracy: 0.9140\n",
      " 808/5349 [===>..........................] - ETA: 2s - loss: 0.1622 - accuracy: 0.9145\n",
      " 991/5349 [====>.........................] - ETA: 2s - loss: 0.1624 - accuracy: 0.9143\n",
      "1257/5349 [======>.......................] - ETA: 2s - loss: 0.1627 - accuracy: 0.9139\n",
      "1436/5349 [=======>......................] - ETA: 2s - loss: 0.1622 - accuracy: 0.9142\n",
      "1619/5349 [========>.....................] - ETA: 2s - loss: 0.1622 - accuracy: 0.9142\n",
      "1800/5349 [=========>....................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9142\n",
      "1985/5349 [==========>...................] - ETA: 1s - loss: 0.1619 - accuracy: 0.9142\n",
      "2157/5349 [===========>..................] - ETA: 1s - loss: 0.1614 - accuracy: 0.9144\n",
      "2337/5349 [============>.................] - ETA: 1s - loss: 0.1617 - accuracy: 0.9142\n",
      "2516/5349 [=============>................] - ETA: 1s - loss: 0.1616 - accuracy: 0.9143\n",
      "2694/5349 [==============>...............] - ETA: 1s - loss: 0.1616 - accuracy: 0.9143\n",
      "2923/5349 [===============>..............] - ETA: 1s - loss: 0.1618 - accuracy: 0.9143\n",
      "3106/5349 [================>.............] - ETA: 1s - loss: 0.1619 - accuracy: 0.9143\n",
      "3288/5349 [=================>............] - ETA: 1s - loss: 0.1621 - accuracy: 0.9142\n",
      "3471/5349 [==================>...........] - ETA: 1s - loss: 0.1623 - accuracy: 0.9140\n",
      "3652/5349 [===================>..........] - ETA: 0s - loss: 0.1623 - accuracy: 0.9139\n",
      "3916/5349 [====================>.........] - ETA: 0s - loss: 0.1621 - accuracy: 0.9141\n",
      "4095/5349 [=====================>........] - ETA: 0s - loss: 0.1620 - accuracy: 0.9140\n",
      "4277/5349 [======================>.......] - ETA: 0s - loss: 0.1621 - accuracy: 0.9140\n",
      "4440/5349 [=======================>......] - ETA: 0s - loss: 0.1619 - accuracy: 0.9141\n",
      "4623/5349 [========================>.....] - ETA: 0s - loss: 0.1619 - accuracy: 0.9140\n",
      "4891/5349 [==========================>...] - ETA: 0s - loss: 0.1619 - accuracy: 0.9140\n",
      "5071/5349 [===========================>..] - ETA: 0s - loss: 0.1620 - accuracy: 0.9139\n",
      "5249/5349 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9139\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9139\n",
      "5349/5349 [==============================] - 4s 747us/step - loss: 0.1619 - accuracy: 0.9139 - val_loss: 0.1603 - val_accuracy: 0.9158\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1500 - accuracy: 0.9400\n",
      " 183/5349 [>.............................] - ETA: 2s - loss: 0.1583 - accuracy: 0.9159\n",
      " 365/5349 [=>............................] - ETA: 2s - loss: 0.1606 - accuracy: 0.9144\n",
      " 542/5349 [==>...........................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9156\n",
      " 719/5349 [===>..........................] - ETA: 2s - loss: 0.1604 - accuracy: 0.9148\n",
      " 892/5349 [====>.........................] - ETA: 2s - loss: 0.1606 - accuracy: 0.9147\n",
      " 985/5349 [====>.........................] - ETA: 2s - loss: 0.1605 - accuracy: 0.9150\n",
      "1169/5349 [=====>........................] - ETA: 2s - loss: 0.1604 - accuracy: 0.9149\n",
      "1335/5349 [======>.......................] - ETA: 2s - loss: 0.1606 - accuracy: 0.9147\n",
      "1516/5349 [=======>......................] - ETA: 2s - loss: 0.1605 - accuracy: 0.9148\n",
      "1696/5349 [========>.....................] - ETA: 2s - loss: 0.1612 - accuracy: 0.9141\n",
      "1863/5349 [=========>....................] - ETA: 1s - loss: 0.1614 - accuracy: 0.9140\n",
      "1991/5349 [==========>...................] - ETA: 1s - loss: 0.1613 - accuracy: 0.9141\n",
      "2136/5349 [==========>...................] - ETA: 1s - loss: 0.1611 - accuracy: 0.9141\n",
      "2364/5349 [============>.................] - ETA: 1s - loss: 0.1610 - accuracy: 0.9141\n",
      "2515/5349 [=============>................] - ETA: 1s - loss: 0.1613 - accuracy: 0.9139\n",
      "2652/5349 [=============>................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9138\n",
      "2799/5349 [==============>...............] - ETA: 1s - loss: 0.1612 - accuracy: 0.9138\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1611 - accuracy: 0.9138\n",
      "3114/5349 [================>.............] - ETA: 1s - loss: 0.1609 - accuracy: 0.9140\n",
      "3270/5349 [=================>............] - ETA: 1s - loss: 0.1609 - accuracy: 0.9140\n",
      "3420/5349 [==================>...........] - ETA: 1s - loss: 0.1610 - accuracy: 0.9140\n",
      "3557/5349 [==================>...........] - ETA: 1s - loss: 0.1611 - accuracy: 0.9139\n",
      "3691/5349 [===================>..........] - ETA: 1s - loss: 0.1611 - accuracy: 0.9140\n",
      "3847/5349 [====================>.........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9140\n",
      "4029/5349 [=====================>........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9140\n",
      "4205/5349 [======================>.......] - ETA: 0s - loss: 0.1610 - accuracy: 0.9140\n",
      "4473/5349 [========================>.....] - ETA: 0s - loss: 0.1610 - accuracy: 0.9141\n",
      "4652/5349 [=========================>....] - ETA: 0s - loss: 0.1609 - accuracy: 0.9141\n",
      "4836/5349 [==========================>...] - ETA: 0s - loss: 0.1607 - accuracy: 0.9142\n",
      "5002/5349 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.9141\n",
      "5160/5349 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.9142\n",
      "5332/5349 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9142\n",
      "5349/5349 [==============================] - 4s 811us/step - loss: 0.1609 - accuracy: 0.9142 - val_loss: 0.1591 - val_accuracy: 0.9164\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 11/20\n",
      "  87/5349 [..............................] - ETA: 3s - loss: 0.1627 - accuracy: 0.9139\n",
      " 268/5349 [>.............................] - ETA: 2s - loss: 0.1610 - accuracy: 0.9138\n",
      " 452/5349 [=>............................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9153\n",
      " 629/5349 [==>...........................] - ETA: 2s - loss: 0.1597 - accuracy: 0.9141\n",
      " 802/5349 [===>..........................] - ETA: 2s - loss: 0.1600 - accuracy: 0.9141\n",
      " 979/5349 [====>.........................] - ETA: 2s - loss: 0.1607 - accuracy: 0.9134\n",
      "1161/5349 [=====>........................] - ETA: 2s - loss: 0.1607 - accuracy: 0.9138\n",
      "1342/5349 [======>.......................] - ETA: 2s - loss: 0.1604 - accuracy: 0.9140\n",
      "1566/5349 [=======>......................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9144\n",
      "1722/5349 [========>.....................] - ETA: 2s - loss: 0.1599 - accuracy: 0.9144\n",
      "1902/5349 [=========>....................] - ETA: 2s - loss: 0.1597 - accuracy: 0.9146\n",
      "2082/5349 [==========>...................] - ETA: 1s - loss: 0.1599 - accuracy: 0.9146\n",
      "2263/5349 [===========>..................] - ETA: 1s - loss: 0.1599 - accuracy: 0.9145\n",
      "2437/5349 [============>.................] - ETA: 1s - loss: 0.1599 - accuracy: 0.9144\n",
      "2610/5349 [=============>................] - ETA: 1s - loss: 0.1601 - accuracy: 0.9144\n",
      "2876/5349 [===============>..............] - ETA: 1s - loss: 0.1597 - accuracy: 0.9147\n",
      "3061/5349 [================>.............] - ETA: 1s - loss: 0.1599 - accuracy: 0.9145\n",
      "3240/5349 [=================>............] - ETA: 1s - loss: 0.1599 - accuracy: 0.9146\n",
      "3417/5349 [==================>...........] - ETA: 1s - loss: 0.1599 - accuracy: 0.9146\n",
      "3594/5349 [===================>..........] - ETA: 1s - loss: 0.1602 - accuracy: 0.9143\n",
      "3778/5349 [====================>.........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9143\n",
      "3958/5349 [=====================>........] - ETA: 0s - loss: 0.1599 - accuracy: 0.9144\n",
      "4138/5349 [======================>.......] - ETA: 0s - loss: 0.1598 - accuracy: 0.9145\n",
      "4305/5349 [=======================>......] - ETA: 0s - loss: 0.1599 - accuracy: 0.9144\n",
      "4582/5349 [========================>.....] - ETA: 0s - loss: 0.1597 - accuracy: 0.9146\n",
      "4763/5349 [=========================>....] - ETA: 0s - loss: 0.1597 - accuracy: 0.9147\n",
      "4947/5349 [==========================>...] - ETA: 0s - loss: 0.1598 - accuracy: 0.9146\n",
      "5125/5349 [===========================>..] - ETA: 0s - loss: 0.1598 - accuracy: 0.9146\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.1598 - accuracy: 0.9146\n",
      "5349/5349 [==============================] - 4s 750us/step - loss: 0.1598 - accuracy: 0.9146 - val_loss: 0.1603 - val_accuracy: 0.9159\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 12/20\n",
      "  90/5349 [..............................] - ETA: 2s - loss: 0.1645 - accuracy: 0.9112\n",
      " 270/5349 [>.............................] - ETA: 2s - loss: 0.1612 - accuracy: 0.9130\n",
      " 430/5349 [=>............................] - ETA: 2s - loss: 0.1609 - accuracy: 0.9143\n",
      " 694/5349 [==>...........................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9148\n",
      " 874/5349 [===>..........................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9149\n",
      "1033/5349 [====>.........................] - ETA: 2s - loss: 0.1596 - accuracy: 0.9146\n",
      "1214/5349 [=====>........................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9149\n",
      "1395/5349 [======>.......................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9151\n",
      "1576/5349 [=======>......................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9151\n",
      "1753/5349 [========>.....................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9153\n",
      "1935/5349 [=========>....................] - ETA: 1s - loss: 0.1596 - accuracy: 0.9150\n",
      "2113/5349 [==========>...................] - ETA: 1s - loss: 0.1595 - accuracy: 0.9152\n",
      "2386/5349 [============>.................] - ETA: 1s - loss: 0.1593 - accuracy: 0.9154\n",
      "2565/5349 [=============>................] - ETA: 1s - loss: 0.1593 - accuracy: 0.9153\n",
      "2747/5349 [==============>...............] - ETA: 1s - loss: 0.1593 - accuracy: 0.9152\n",
      "2926/5349 [===============>..............] - ETA: 1s - loss: 0.1594 - accuracy: 0.9151\n",
      "3110/5349 [================>.............] - ETA: 1s - loss: 0.1594 - accuracy: 0.9150\n",
      "3291/5349 [=================>............] - ETA: 1s - loss: 0.1594 - accuracy: 0.9151\n",
      "3565/5349 [==================>...........] - ETA: 1s - loss: 0.1593 - accuracy: 0.9151\n",
      "3734/5349 [===================>..........] - ETA: 0s - loss: 0.1592 - accuracy: 0.9152\n",
      "3920/5349 [====================>.........] - ETA: 0s - loss: 0.1593 - accuracy: 0.9150\n",
      "4101/5349 [======================>.......] - ETA: 0s - loss: 0.1593 - accuracy: 0.9150\n",
      "4280/5349 [=======================>......] - ETA: 0s - loss: 0.1593 - accuracy: 0.9149\n",
      "4463/5349 [========================>.....] - ETA: 0s - loss: 0.1593 - accuracy: 0.9149\n",
      "4645/5349 [=========================>....] - ETA: 0s - loss: 0.1592 - accuracy: 0.9150\n",
      "4828/5349 [==========================>...] - ETA: 0s - loss: 0.1591 - accuracy: 0.9150\n",
      "5105/5349 [===========================>..] - ETA: 0s - loss: 0.1590 - accuracy: 0.9150\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9150\n",
      "5349/5349 [==============================] - 4s 768us/step - loss: 0.1590 - accuracy: 0.9150 - val_loss: 0.1570 - val_accuracy: 0.9168\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1516 - accuracy: 0.9100\n",
      " 139/5349 [..............................] - ETA: 3s - loss: 0.1650 - accuracy: 0.9110\n",
      " 297/5349 [>.............................] - ETA: 3s - loss: 0.1626 - accuracy: 0.9120\n",
      " 374/5349 [=>............................] - ETA: 3s - loss: 0.1620 - accuracy: 0.9126\n",
      " 493/5349 [=>............................] - ETA: 3s - loss: 0.1612 - accuracy: 0.9133\n",
      " 585/5349 [==>...........................] - ETA: 3s - loss: 0.1600 - accuracy: 0.9143\n",
      " 702/5349 [==>...........................] - ETA: 3s - loss: 0.1591 - accuracy: 0.9147\n",
      " 855/5349 [===>..........................] - ETA: 3s - loss: 0.1589 - accuracy: 0.9151\n",
      "1000/5349 [====>.........................] - ETA: 3s - loss: 0.1591 - accuracy: 0.9150\n",
      "1162/5349 [=====>........................] - ETA: 3s - loss: 0.1594 - accuracy: 0.9149\n",
      "1339/5349 [======>.......................] - ETA: 2s - loss: 0.1595 - accuracy: 0.9148\n",
      "1608/5349 [========>.....................] - ETA: 2s - loss: 0.1590 - accuracy: 0.9153\n",
      "1781/5349 [========>.....................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9151\n",
      "1948/5349 [=========>....................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9150\n",
      "2124/5349 [==========>...................] - ETA: 2s - loss: 0.1589 - accuracy: 0.9152\n",
      "2308/5349 [===========>..................] - ETA: 1s - loss: 0.1587 - accuracy: 0.9152\n",
      "2491/5349 [============>.................] - ETA: 1s - loss: 0.1585 - accuracy: 0.9154\n",
      "2674/5349 [=============>................] - ETA: 1s - loss: 0.1582 - accuracy: 0.9155\n",
      "2938/5349 [===============>..............] - ETA: 1s - loss: 0.1581 - accuracy: 0.9155\n",
      "3110/5349 [================>.............] - ETA: 1s - loss: 0.1580 - accuracy: 0.9156\n",
      "3278/5349 [=================>............] - ETA: 1s - loss: 0.1580 - accuracy: 0.9155\n",
      "3463/5349 [==================>...........] - ETA: 1s - loss: 0.1579 - accuracy: 0.9157\n",
      "3648/5349 [===================>..........] - ETA: 1s - loss: 0.1580 - accuracy: 0.9156\n",
      "3822/5349 [====================>.........] - ETA: 0s - loss: 0.1579 - accuracy: 0.9157\n",
      "3994/5349 [=====================>........] - ETA: 0s - loss: 0.1579 - accuracy: 0.9157\n",
      "4269/5349 [======================>.......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9157\n",
      "4433/5349 [=======================>......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9157\n",
      "4599/5349 [========================>.....] - ETA: 0s - loss: 0.1581 - accuracy: 0.9154\n",
      "4764/5349 [=========================>....] - ETA: 0s - loss: 0.1582 - accuracy: 0.9154\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.1583 - accuracy: 0.9153\n",
      "5189/5349 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.9154\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9153\n",
      "5349/5349 [==============================] - 4s 811us/step - loss: 0.1582 - accuracy: 0.9153 - val_loss: 0.1563 - val_accuracy: 0.9169\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 14/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.1514 - accuracy: 0.9229 \n",
      " 354/5349 [>.............................] - ETA: 2s - loss: 0.1595 - accuracy: 0.9139\n",
      " 537/5349 [==>...........................] - ETA: 2s - loss: 0.1581 - accuracy: 0.9153\n",
      " 709/5349 [==>...........................] - ETA: 2s - loss: 0.1576 - accuracy: 0.9157\n",
      " 889/5349 [===>..........................] - ETA: 2s - loss: 0.1568 - accuracy: 0.9161\n",
      "1058/5349 [====>.........................] - ETA: 2s - loss: 0.1560 - accuracy: 0.9164\n",
      "1238/5349 [=====>........................] - ETA: 2s - loss: 0.1559 - accuracy: 0.9163\n",
      "1413/5349 [======>.......................] - ETA: 2s - loss: 0.1567 - accuracy: 0.9157\n",
      "1689/5349 [========>.....................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9158\n",
      "1855/5349 [=========>....................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9156\n",
      "1977/5349 [==========>...................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9157\n",
      "2115/5349 [==========>...................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9157\n",
      "2294/5349 [===========>..................] - ETA: 1s - loss: 0.1571 - accuracy: 0.9155\n",
      "2469/5349 [============>.................] - ETA: 1s - loss: 0.1574 - accuracy: 0.9154\n",
      "2620/5349 [=============>................] - ETA: 1s - loss: 0.1575 - accuracy: 0.9154\n",
      "2799/5349 [==============>...............] - ETA: 1s - loss: 0.1575 - accuracy: 0.9154\n",
      "2976/5349 [===============>..............] - ETA: 1s - loss: 0.1574 - accuracy: 0.9155\n",
      "3067/5349 [================>.............] - ETA: 1s - loss: 0.1575 - accuracy: 0.9155\n",
      "3251/5349 [=================>............] - ETA: 1s - loss: 0.1574 - accuracy: 0.9155\n",
      "3431/5349 [==================>...........] - ETA: 1s - loss: 0.1575 - accuracy: 0.9155\n",
      "3606/5349 [===================>..........] - ETA: 1s - loss: 0.1576 - accuracy: 0.9155\n",
      "3793/5349 [====================>.........] - ETA: 0s - loss: 0.1576 - accuracy: 0.9155\n",
      "3950/5349 [=====================>........] - ETA: 0s - loss: 0.1575 - accuracy: 0.9154\n",
      "4108/5349 [======================>.......] - ETA: 0s - loss: 0.1574 - accuracy: 0.9155\n",
      "4373/5349 [=======================>......] - ETA: 0s - loss: 0.1574 - accuracy: 0.9156\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.1575 - accuracy: 0.9155\n",
      "4700/5349 [=========================>....] - ETA: 0s - loss: 0.1576 - accuracy: 0.9154\n",
      "4879/5349 [==========================>...] - ETA: 0s - loss: 0.1577 - accuracy: 0.9153\n",
      "5055/5349 [===========================>..] - ETA: 0s - loss: 0.1578 - accuracy: 0.9152\n",
      "5312/5349 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9153\n",
      "5349/5349 [==============================] - 4s 768us/step - loss: 0.1577 - accuracy: 0.9153 - val_loss: 0.1562 - val_accuracy: 0.9168\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1891 - accuracy: 0.8700\n",
      " 179/5349 [>.............................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9159\n",
      " 452/5349 [=>............................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9162\n",
      " 630/5349 [==>...........................] - ETA: 2s - loss: 0.1567 - accuracy: 0.9160\n",
      " 798/5349 [===>..........................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9155\n",
      " 978/5349 [====>.........................] - ETA: 2s - loss: 0.1567 - accuracy: 0.9153\n",
      "1161/5349 [=====>........................] - ETA: 2s - loss: 0.1567 - accuracy: 0.9155\n",
      "1340/5349 [======>.......................] - ETA: 2s - loss: 0.1567 - accuracy: 0.9155\n",
      "1523/5349 [=======>......................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9159\n",
      "1703/5349 [========>.....................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9159\n",
      "1972/5349 [==========>...................] - ETA: 1s - loss: 0.1568 - accuracy: 0.9159\n",
      "2117/5349 [==========>...................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9157\n",
      "2296/5349 [===========>..................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9157\n",
      "2476/5349 [============>.................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9158\n",
      "2651/5349 [=============>................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9162\n",
      "2833/5349 [==============>...............] - ETA: 1s - loss: 0.1568 - accuracy: 0.9160\n",
      "3106/5349 [================>.............] - ETA: 1s - loss: 0.1565 - accuracy: 0.9162\n",
      "3280/5349 [=================>............] - ETA: 1s - loss: 0.1564 - accuracy: 0.9162\n",
      "3458/5349 [==================>...........] - ETA: 1s - loss: 0.1565 - accuracy: 0.9160\n",
      "3637/5349 [===================>..........] - ETA: 0s - loss: 0.1565 - accuracy: 0.9160\n",
      "3799/5349 [====================>.........] - ETA: 0s - loss: 0.1567 - accuracy: 0.9160\n",
      "3943/5349 [=====================>........] - ETA: 0s - loss: 0.1566 - accuracy: 0.9160\n",
      "4098/5349 [=====================>........] - ETA: 0s - loss: 0.1566 - accuracy: 0.9160\n",
      "4179/5349 [======================>.......] - ETA: 0s - loss: 0.1567 - accuracy: 0.9160\n",
      "4298/5349 [=======================>......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9160\n",
      "4449/5349 [=======================>......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9159\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.1570 - accuracy: 0.9159\n",
      "4755/5349 [=========================>....] - ETA: 0s - loss: 0.1571 - accuracy: 0.9157\n",
      "4911/5349 [==========================>...] - ETA: 0s - loss: 0.1569 - accuracy: 0.9159\n",
      "5138/5349 [===========================>..] - ETA: 0s - loss: 0.1569 - accuracy: 0.9158\n",
      "5263/5349 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9158\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9157\n",
      "5349/5349 [==============================] - 4s 818us/step - loss: 0.1571 - accuracy: 0.9157 - val_loss: 0.1545 - val_accuracy: 0.9173\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1516 - accuracy: 0.9100\n",
      " 173/5349 [..............................] - ETA: 3s - loss: 0.1637 - accuracy: 0.9099\n",
      " 263/5349 [>.............................] - ETA: 2s - loss: 0.1610 - accuracy: 0.9129\n",
      " 446/5349 [=>............................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9147\n",
      " 621/5349 [==>...........................] - ETA: 2s - loss: 0.1576 - accuracy: 0.9152\n",
      " 799/5349 [===>..........................] - ETA: 2s - loss: 0.1573 - accuracy: 0.9155\n",
      " 960/5349 [====>.........................] - ETA: 2s - loss: 0.1566 - accuracy: 0.9156\n",
      "1134/5349 [=====>........................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9155\n",
      "1313/5349 [======>.......................] - ETA: 2s - loss: 0.1566 - accuracy: 0.9158\n",
      "1582/5349 [=======>......................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9154\n",
      "1731/5349 [========>.....................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9154\n",
      "1905/5349 [=========>....................] - ETA: 1s - loss: 0.1567 - accuracy: 0.9155\n",
      "2070/5349 [==========>...................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9155\n",
      "2253/5349 [===========>..................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9156\n",
      "2424/5349 [============>.................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9158\n",
      "2603/5349 [=============>................] - ETA: 1s - loss: 0.1568 - accuracy: 0.9157\n",
      "2779/5349 [==============>...............] - ETA: 1s - loss: 0.1571 - accuracy: 0.9155\n",
      "2862/5349 [===============>..............] - ETA: 1s - loss: 0.1570 - accuracy: 0.9156\n",
      "3044/5349 [================>.............] - ETA: 1s - loss: 0.1570 - accuracy: 0.9156\n",
      "3223/5349 [=================>............] - ETA: 1s - loss: 0.1570 - accuracy: 0.9155\n",
      "3401/5349 [==================>...........] - ETA: 1s - loss: 0.1571 - accuracy: 0.9156\n",
      "3560/5349 [==================>...........] - ETA: 1s - loss: 0.1569 - accuracy: 0.9156\n",
      "3639/5349 [===================>..........] - ETA: 1s - loss: 0.1570 - accuracy: 0.9156\n",
      "3802/5349 [====================>.........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9157\n",
      "3965/5349 [=====================>........] - ETA: 0s - loss: 0.1569 - accuracy: 0.9157\n",
      "4212/5349 [======================>.......] - ETA: 0s - loss: 0.1569 - accuracy: 0.9156\n",
      "4355/5349 [=======================>......] - ETA: 0s - loss: 0.1569 - accuracy: 0.9156\n",
      "4501/5349 [========================>.....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9156\n",
      "4638/5349 [=========================>....] - ETA: 0s - loss: 0.1566 - accuracy: 0.9158\n",
      "4798/5349 [=========================>....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9157\n",
      "4973/5349 [==========================>...] - ETA: 0s - loss: 0.1567 - accuracy: 0.9159\n",
      "5135/5349 [===========================>..] - ETA: 0s - loss: 0.1566 - accuracy: 0.9159\n",
      "5276/5349 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9159\n",
      "5349/5349 [==============================] - 4s 803us/step - loss: 0.1566 - accuracy: 0.9159 - val_loss: 0.1543 - val_accuracy: 0.9172\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.0548 - accuracy: 0.9900\n",
      " 179/5349 [>.............................] - ETA: 2s - loss: 0.1552 - accuracy: 0.9165\n",
      " 356/5349 [>.............................] - ETA: 2s - loss: 0.1582 - accuracy: 0.9147\n",
      " 532/5349 [=>............................] - ETA: 2s - loss: 0.1571 - accuracy: 0.9156\n",
      " 709/5349 [==>...........................] - ETA: 2s - loss: 0.1576 - accuracy: 0.9151\n",
      " 973/5349 [====>.........................] - ETA: 2s - loss: 0.1578 - accuracy: 0.9146\n",
      "1159/5349 [=====>........................] - ETA: 2s - loss: 0.1577 - accuracy: 0.9144\n",
      "1338/5349 [======>.......................] - ETA: 2s - loss: 0.1574 - accuracy: 0.9146\n",
      "1521/5349 [=======>......................] - ETA: 2s - loss: 0.1575 - accuracy: 0.9148\n",
      "1697/5349 [========>.....................] - ETA: 2s - loss: 0.1574 - accuracy: 0.9148\n",
      "1881/5349 [=========>....................] - ETA: 1s - loss: 0.1573 - accuracy: 0.9151\n",
      "2046/5349 [==========>...................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9155\n",
      "2319/5349 [============>.................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9155\n",
      "2496/5349 [============>.................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9154\n",
      "2670/5349 [=============>................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9153\n",
      "2854/5349 [===============>..............] - ETA: 1s - loss: 0.1569 - accuracy: 0.9154\n",
      "3016/5349 [===============>..............] - ETA: 1s - loss: 0.1570 - accuracy: 0.9154\n",
      "3194/5349 [================>.............] - ETA: 1s - loss: 0.1567 - accuracy: 0.9155\n",
      "3373/5349 [=================>............] - ETA: 1s - loss: 0.1568 - accuracy: 0.9155\n",
      "3543/5349 [==================>...........] - ETA: 1s - loss: 0.1568 - accuracy: 0.9155\n",
      "3817/5349 [====================>.........] - ETA: 0s - loss: 0.1565 - accuracy: 0.9158\n",
      "3993/5349 [=====================>........] - ETA: 0s - loss: 0.1564 - accuracy: 0.9159\n",
      "4177/5349 [======================>.......] - ETA: 0s - loss: 0.1563 - accuracy: 0.9159\n",
      "4348/5349 [=======================>......] - ETA: 0s - loss: 0.1564 - accuracy: 0.9159\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.1563 - accuracy: 0.9159\n",
      "4701/5349 [=========================>....] - ETA: 0s - loss: 0.1563 - accuracy: 0.9160\n",
      "4885/5349 [==========================>...] - ETA: 0s - loss: 0.1562 - accuracy: 0.9160\n",
      "4981/5349 [==========================>...] - ETA: 0s - loss: 0.1561 - accuracy: 0.9161\n",
      "5163/5349 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.9160\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9160\n",
      "5349/5349 [==============================] - 4s 749us/step - loss: 0.1561 - accuracy: 0.9160 - val_loss: 0.1541 - val_accuracy: 0.9173\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 18/20\n",
      "  89/5349 [..............................] - ETA: 3s - loss: 0.1603 - accuracy: 0.9121\n",
      " 264/5349 [>.............................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9181\n",
      " 444/5349 [=>............................] - ETA: 2s - loss: 0.1540 - accuracy: 0.9173\n",
      " 719/5349 [===>..........................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9169\n",
      " 897/5349 [====>.........................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9165\n",
      "1078/5349 [=====>........................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9164\n",
      "1261/5349 [======>.......................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9166\n",
      "1430/5349 [=======>......................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9163\n",
      "1610/5349 [========>.....................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9163\n",
      "1763/5349 [========>.....................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9167\n",
      "1993/5349 [==========>...................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9165\n",
      "2144/5349 [===========>..................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9164\n",
      "2300/5349 [===========>..................] - ETA: 1s - loss: 0.1555 - accuracy: 0.9163\n",
      "2435/5349 [============>.................] - ETA: 1s - loss: 0.1556 - accuracy: 0.9163\n",
      "2593/5349 [=============>................] - ETA: 1s - loss: 0.1556 - accuracy: 0.9164\n",
      "2747/5349 [==============>...............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9164\n",
      "2909/5349 [===============>..............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9164\n",
      "3141/5349 [================>.............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9163\n",
      "3222/5349 [=================>............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9163\n",
      "3363/5349 [=================>............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9163\n",
      "3524/5349 [==================>...........] - ETA: 1s - loss: 0.1557 - accuracy: 0.9164\n",
      "3665/5349 [===================>..........] - ETA: 1s - loss: 0.1557 - accuracy: 0.9164\n",
      "3845/5349 [====================>.........] - ETA: 0s - loss: 0.1556 - accuracy: 0.9164\n",
      "4021/5349 [=====================>........] - ETA: 0s - loss: 0.1557 - accuracy: 0.9162\n",
      "4190/5349 [======================>.......] - ETA: 0s - loss: 0.1558 - accuracy: 0.9162\n",
      "4368/5349 [=======================>......] - ETA: 0s - loss: 0.1558 - accuracy: 0.9162\n",
      "4456/5349 [=======================>......] - ETA: 0s - loss: 0.1557 - accuracy: 0.9162\n",
      "4619/5349 [========================>.....] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "4793/5349 [=========================>....] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "4969/5349 [==========================>...] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "5135/5349 [===========================>..] - ETA: 0s - loss: 0.1555 - accuracy: 0.9164\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9163\n",
      "5349/5349 [==============================] - 4s 802us/step - loss: 0.1556 - accuracy: 0.9163 - val_loss: 0.1536 - val_accuracy: 0.9175\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 19/20\n",
      "  89/5349 [..............................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9196\n",
      " 270/5349 [>.............................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9186\n",
      " 452/5349 [=>............................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9185\n",
      " 616/5349 [==>...........................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9185\n",
      " 798/5349 [===>..........................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9176\n",
      " 979/5349 [====>.........................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9177\n",
      "1164/5349 [=====>........................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9174\n",
      "1299/5349 [======>.......................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9172\n",
      "1565/5349 [=======>......................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9169\n",
      "1742/5349 [========>.....................] - ETA: 2s - loss: 0.1554 - accuracy: 0.9169\n",
      "1921/5349 [=========>....................] - ETA: 1s - loss: 0.1555 - accuracy: 0.9167\n",
      "2097/5349 [==========>...................] - ETA: 1s - loss: 0.1556 - accuracy: 0.9167\n",
      "2272/5349 [===========>..................] - ETA: 1s - loss: 0.1556 - accuracy: 0.9165\n",
      "2423/5349 [============>.................] - ETA: 1s - loss: 0.1556 - accuracy: 0.9164\n",
      "2594/5349 [=============>................] - ETA: 1s - loss: 0.1556 - accuracy: 0.9163\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9164\n",
      "2935/5349 [===============>..............] - ETA: 1s - loss: 0.1555 - accuracy: 0.9164\n",
      "3187/5349 [================>.............] - ETA: 1s - loss: 0.1554 - accuracy: 0.9165\n",
      "3369/5349 [=================>............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9164\n",
      "3550/5349 [==================>...........] - ETA: 1s - loss: 0.1554 - accuracy: 0.9163\n",
      "3735/5349 [===================>..........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9164\n",
      "3910/5349 [====================>.........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9164\n",
      "4086/5349 [=====================>........] - ETA: 0s - loss: 0.1552 - accuracy: 0.9164\n",
      "4265/5349 [======================>.......] - ETA: 0s - loss: 0.1552 - accuracy: 0.9164\n",
      "4446/5349 [=======================>......] - ETA: 0s - loss: 0.1551 - accuracy: 0.9166\n",
      "4539/5349 [========================>.....] - ETA: 0s - loss: 0.1551 - accuracy: 0.9167\n",
      "4716/5349 [=========================>....] - ETA: 0s - loss: 0.1552 - accuracy: 0.9166\n",
      "4894/5349 [==========================>...] - ETA: 0s - loss: 0.1553 - accuracy: 0.9165\n",
      "5064/5349 [===========================>..] - ETA: 0s - loss: 0.1554 - accuracy: 0.9164\n",
      "5247/5349 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9163\n",
      "5334/5349 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9163\n",
      "5349/5349 [==============================] - 4s 756us/step - loss: 0.1554 - accuracy: 0.9163 - val_loss: 0.1534 - val_accuracy: 0.9174\n",
      "\u001B[36m(train_DNN pid=5557)\u001B[0m Epoch 20/20\n",
      "  91/5349 [..............................] - ETA: 2s - loss: 0.1518 - accuracy: 0.9212\n",
      " 256/5349 [>.............................] - ETA: 3s - loss: 0.1542 - accuracy: 0.9184\n",
      " 438/5349 [=>............................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9181\n",
      " 613/5349 [==>...........................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9182\n",
      " 796/5349 [===>..........................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9183\n",
      " 976/5349 [====>.........................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9172\n",
      "1160/5349 [=====>........................] - ETA: 2s - loss: 0.1548 - accuracy: 0.9168\n",
      "1428/5349 [=======>......................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9171\n",
      "1610/5349 [========>.....................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9170\n",
      "1788/5349 [=========>....................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9172\n",
      "1965/5349 [==========>...................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9172\n",
      "2131/5349 [==========>...................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9170\n",
      "2305/5349 [===========>..................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9168\n",
      "2483/5349 [============>.................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9168\n",
      "2760/5349 [==============>...............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9167\n",
      "2937/5349 [===============>..............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9166\n",
      "3111/5349 [================>.............] - ETA: 1s - loss: 0.1555 - accuracy: 0.9164\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1555 - accuracy: 0.9164\n",
      "3467/5349 [==================>...........] - ETA: 1s - loss: 0.1555 - accuracy: 0.9163\n",
      "3565/5349 [==================>...........] - ETA: 1s - loss: 0.1554 - accuracy: 0.9165\n",
      "3730/5349 [===================>..........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9165\n",
      "3908/5349 [====================>.........] - ETA: 0s - loss: 0.1552 - accuracy: 0.9166\n",
      "4078/5349 [=====================>........] - ETA: 0s - loss: 0.1551 - accuracy: 0.9166\n",
      "4261/5349 [======================>.......] - ETA: 0s - loss: 0.1550 - accuracy: 0.9167\n",
      "4443/5349 [=======================>......] - ETA: 0s - loss: 0.1550 - accuracy: 0.9167\n",
      "4623/5349 [========================>.....] - ETA: 0s - loss: 0.1550 - accuracy: 0.9167\n",
      "4893/5349 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9167\n",
      "5056/5349 [===========================>..] - ETA: 0s - loss: 0.1551 - accuracy: 0.9167\n",
      "5237/5349 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9166\n",
      "5328/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9166\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 26:14 - loss: 1.1734 - accuracy: 0.1300\n",
      " 128/5349 [..............................] - ETA: 4s - loss: 0.6507 - accuracy: 0.6621\n",
      " 269/5349 [>.............................] - ETA: 3s - loss: 0.4747 - accuracy: 0.7891\n",
      " 339/5349 [>.............................] - ETA: 3s - loss: 0.4259 - accuracy: 0.8153\n",
      " 478/5349 [=>............................] - ETA: 3s - loss: 0.3645 - accuracy: 0.8430\n",
      " 621/5349 [==>...........................] - ETA: 3s - loss: 0.3261 - accuracy: 0.8580\n",
      " 760/5349 [===>..........................] - ETA: 3s - loss: 0.2997 - accuracy: 0.8679\n",
      " 903/5349 [====>.........................] - ETA: 3s - loss: 0.2808 - accuracy: 0.8746\n",
      "1042/5349 [====>.........................] - ETA: 3s - loss: 0.2667 - accuracy: 0.8791\n",
      "1185/5349 [=====>........................] - ETA: 3s - loss: 0.2551 - accuracy: 0.8832\n",
      "1394/5349 [======>.......................] - ETA: 2s - loss: 0.2413 - accuracy: 0.8880\n",
      "1518/5349 [=======>......................] - ETA: 2s - loss: 0.2350 - accuracy: 0.8905\n",
      "1638/5349 [========>.....................] - ETA: 2s - loss: 0.2299 - accuracy: 0.8921\n",
      "1752/5349 [========>.....................] - ETA: 2s - loss: 0.2255 - accuracy: 0.8935\n",
      "1862/5349 [=========>....................] - ETA: 2s - loss: 0.2216 - accuracy: 0.8948\n",
      "1974/5349 [==========>...................] - ETA: 2s - loss: 0.2185 - accuracy: 0.8956\n",
      "2082/5349 [==========>...................] - ETA: 2s - loss: 0.2154 - accuracy: 0.8969\n",
      "2201/5349 [===========>..................] - ETA: 2s - loss: 0.2125 - accuracy: 0.8976\n",
      "2370/5349 [============>.................] - ETA: 2s - loss: 0.2089 - accuracy: 0.8988\n",
      "2482/5349 [============>.................] - ETA: 2s - loss: 0.2067 - accuracy: 0.8995\n",
      "2549/5349 [=============>................] - ETA: 2s - loss: 0.2054 - accuracy: 0.8999\n",
      "2636/5349 [=============>................] - ETA: 2s - loss: 0.2038 - accuracy: 0.9005\n",
      "2715/5349 [==============>...............] - ETA: 2s - loss: 0.2024 - accuracy: 0.9010\n",
      "2837/5349 [==============>...............] - ETA: 2s - loss: 0.2005 - accuracy: 0.9018\n",
      "2966/5349 [===============>..............] - ETA: 1s - loss: 0.1987 - accuracy: 0.9023\n",
      "3180/5349 [================>.............] - ETA: 1s - loss: 0.1961 - accuracy: 0.9032\n",
      "3317/5349 [=================>............] - ETA: 1s - loss: 0.1945 - accuracy: 0.9037\n",
      "3456/5349 [==================>...........] - ETA: 1s - loss: 0.1929 - accuracy: 0.9042\n",
      "3595/5349 [===================>..........] - ETA: 1s - loss: 0.1914 - accuracy: 0.9047\n",
      "3739/5349 [===================>..........] - ETA: 1s - loss: 0.1900 - accuracy: 0.9051\n",
      "3870/5349 [====================>.........] - ETA: 1s - loss: 0.1886 - accuracy: 0.9057\n",
      "4013/5349 [=====================>........] - ETA: 1s - loss: 0.1873 - accuracy: 0.9061\n",
      "4144/5349 [======================>.......] - ETA: 0s - loss: 0.1863 - accuracy: 0.9064\n",
      "4358/5349 [=======================>......] - ETA: 0s - loss: 0.1849 - accuracy: 0.9068\n",
      "4498/5349 [========================>.....] - ETA: 0s - loss: 0.1837 - accuracy: 0.9072\n",
      "4642/5349 [=========================>....] - ETA: 0s - loss: 0.1828 - accuracy: 0.9075\n",
      "4772/5349 [=========================>....] - ETA: 0s - loss: 0.1818 - accuracy: 0.9078\n",
      "4914/5349 [==========================>...] - ETA: 0s - loss: 0.1810 - accuracy: 0.9081\n",
      "5053/5349 [===========================>..] - ETA: 0s - loss: 0.1801 - accuracy: 0.9084\n",
      "5192/5349 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9087\n",
      "5333/5349 [============================>.] - ETA: 0s - loss: 0.1784 - accuracy: 0.9090\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1783 - accuracy: 0.9091 - val_loss: 0.1471 - val_accuracy: 0.9211\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 2/20\n",
      "  66/5349 [..............................] - ETA: 4s - loss: 0.1467 - accuracy: 0.9223\n",
      " 207/5349 [>.............................] - ETA: 3s - loss: 0.1482 - accuracy: 0.9209\n",
      " 349/5349 [>.............................] - ETA: 3s - loss: 0.1489 - accuracy: 0.9204\n",
      " 477/5349 [=>............................] - ETA: 3s - loss: 0.1485 - accuracy: 0.9203\n",
      " 677/5349 [==>...........................] - ETA: 3s - loss: 0.1482 - accuracy: 0.9203\n",
      " 814/5349 [===>..........................] - ETA: 3s - loss: 0.1473 - accuracy: 0.9210\n",
      " 955/5349 [====>.........................] - ETA: 3s - loss: 0.1469 - accuracy: 0.9210\n",
      "1089/5349 [=====>........................] - ETA: 3s - loss: 0.1465 - accuracy: 0.9210\n",
      "1229/5349 [=====>........................] - ETA: 3s - loss: 0.1470 - accuracy: 0.9203\n",
      "1363/5349 [======>.......................] - ETA: 2s - loss: 0.1469 - accuracy: 0.9200\n",
      "1467/5349 [=======>......................] - ETA: 2s - loss: 0.1464 - accuracy: 0.9204\n",
      "1600/5349 [=======>......................] - ETA: 2s - loss: 0.1465 - accuracy: 0.9202\n",
      "1740/5349 [========>.....................] - ETA: 2s - loss: 0.1462 - accuracy: 0.9204\n",
      "1811/5349 [=========>....................] - ETA: 2s - loss: 0.1462 - accuracy: 0.9204\n",
      "1943/5349 [=========>....................] - ETA: 2s - loss: 0.1459 - accuracy: 0.9208\n",
      "2084/5349 [==========>...................] - ETA: 2s - loss: 0.1456 - accuracy: 0.9211\n",
      "2213/5349 [===========>..................] - ETA: 2s - loss: 0.1455 - accuracy: 0.9210\n",
      "2354/5349 [============>.................] - ETA: 2s - loss: 0.1454 - accuracy: 0.9212\n",
      "2495/5349 [============>.................] - ETA: 2s - loss: 0.1454 - accuracy: 0.9211\n",
      "2633/5349 [=============>................] - ETA: 2s - loss: 0.1450 - accuracy: 0.9213\n",
      "2771/5349 [==============>...............] - ETA: 1s - loss: 0.1447 - accuracy: 0.9215\n",
      "2985/5349 [===============>..............] - ETA: 1s - loss: 0.1445 - accuracy: 0.9217\n",
      "3115/5349 [================>.............] - ETA: 1s - loss: 0.1444 - accuracy: 0.9218\n",
      "3250/5349 [=================>............] - ETA: 1s - loss: 0.1442 - accuracy: 0.9219\n",
      "3391/5349 [==================>...........] - ETA: 1s - loss: 0.1440 - accuracy: 0.9220\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1439 - accuracy: 0.9221\n",
      "3669/5349 [===================>..........] - ETA: 1s - loss: 0.1436 - accuracy: 0.9223\n",
      "3805/5349 [====================>.........] - ETA: 1s - loss: 0.1436 - accuracy: 0.9223\n",
      "3926/5349 [=====================>........] - ETA: 1s - loss: 0.1435 - accuracy: 0.9223\n",
      "4128/5349 [======================>.......] - ETA: 0s - loss: 0.1434 - accuracy: 0.9224\n",
      "4253/5349 [======================>.......] - ETA: 0s - loss: 0.1431 - accuracy: 0.9226\n",
      "4396/5349 [=======================>......] - ETA: 0s - loss: 0.1431 - accuracy: 0.9225\n",
      "4534/5349 [========================>.....] - ETA: 0s - loss: 0.1427 - accuracy: 0.9227\n",
      "4652/5349 [=========================>....] - ETA: 0s - loss: 0.1425 - accuracy: 0.9228\n",
      "4787/5349 [=========================>....] - ETA: 0s - loss: 0.1422 - accuracy: 0.9229\n",
      "4927/5349 [==========================>...] - ETA: 0s - loss: 0.1419 - accuracy: 0.9232\n",
      "5066/5349 [===========================>..] - ETA: 0s - loss: 0.1416 - accuracy: 0.9233\n",
      "5275/5349 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9234\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9235\n",
      "5349/5349 [==============================] - 5s 926us/step - loss: 0.1412 - accuracy: 0.9235 - val_loss: 0.1377 - val_accuracy: 0.9249\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 8s - loss: 0.1733 - accuracy: 0.9000\n",
      " 136/5349 [..............................] - ETA: 3s - loss: 0.1331 - accuracy: 0.9282\n",
      " 278/5349 [>.............................] - ETA: 3s - loss: 0.1371 - accuracy: 0.9265\n",
      " 401/5349 [=>............................] - ETA: 3s - loss: 0.1366 - accuracy: 0.9272\n",
      " 473/5349 [=>............................] - ETA: 3s - loss: 0.1364 - accuracy: 0.9275\n",
      " 617/5349 [==>...........................] - ETA: 3s - loss: 0.1364 - accuracy: 0.9273\n",
      " 752/5349 [===>..........................] - ETA: 3s - loss: 0.1359 - accuracy: 0.9274\n",
      " 895/5349 [====>.........................] - ETA: 3s - loss: 0.1356 - accuracy: 0.9276\n",
      "1033/5349 [====>.........................] - ETA: 3s - loss: 0.1348 - accuracy: 0.9278\n",
      "1167/5349 [=====>........................] - ETA: 3s - loss: 0.1346 - accuracy: 0.9276\n",
      "1307/5349 [======>.......................] - ETA: 2s - loss: 0.1341 - accuracy: 0.9275\n",
      "1440/5349 [=======>......................] - ETA: 2s - loss: 0.1337 - accuracy: 0.9278\n",
      "1578/5349 [=======>......................] - ETA: 2s - loss: 0.1336 - accuracy: 0.9277\n",
      "1715/5349 [========>.....................] - ETA: 2s - loss: 0.1338 - accuracy: 0.9278\n",
      "1854/5349 [=========>....................] - ETA: 2s - loss: 0.1334 - accuracy: 0.9281\n",
      "1997/5349 [==========>...................] - ETA: 2s - loss: 0.1332 - accuracy: 0.9281\n",
      "2066/5349 [==========>...................] - ETA: 2s - loss: 0.1335 - accuracy: 0.9278\n",
      "2198/5349 [===========>..................] - ETA: 2s - loss: 0.1335 - accuracy: 0.9280\n",
      "2340/5349 [============>.................] - ETA: 2s - loss: 0.1331 - accuracy: 0.9284\n",
      "2476/5349 [============>.................] - ETA: 2s - loss: 0.1327 - accuracy: 0.9286\n",
      "2573/5349 [=============>................] - ETA: 2s - loss: 0.1327 - accuracy: 0.9285\n",
      "2671/5349 [=============>................] - ETA: 2s - loss: 0.1327 - accuracy: 0.9285\n",
      "2781/5349 [==============>...............] - ETA: 1s - loss: 0.1326 - accuracy: 0.9285\n",
      "2877/5349 [===============>..............] - ETA: 1s - loss: 0.1326 - accuracy: 0.9286\n",
      "2997/5349 [===============>..............] - ETA: 1s - loss: 0.1325 - accuracy: 0.9285\n",
      "3112/5349 [================>.............] - ETA: 1s - loss: 0.1326 - accuracy: 0.9285\n",
      "3169/5349 [================>.............] - ETA: 1s - loss: 0.1325 - accuracy: 0.9285\n",
      "3280/5349 [=================>............] - ETA: 1s - loss: 0.1323 - accuracy: 0.9286\n",
      "3385/5349 [=================>............] - ETA: 1s - loss: 0.1321 - accuracy: 0.9288\n",
      "3497/5349 [==================>...........] - ETA: 1s - loss: 0.1318 - accuracy: 0.9290\n",
      "3591/5349 [===================>..........] - ETA: 1s - loss: 0.1317 - accuracy: 0.9291\n",
      "3676/5349 [===================>..........] - ETA: 1s - loss: 0.1316 - accuracy: 0.9292\n",
      "3778/5349 [====================>.........] - ETA: 1s - loss: 0.1315 - accuracy: 0.9291\n",
      "3896/5349 [====================>.........] - ETA: 1s - loss: 0.1315 - accuracy: 0.9291\n",
      "4030/5349 [=====================>........] - ETA: 1s - loss: 0.1314 - accuracy: 0.9292\n",
      "4171/5349 [======================>.......] - ETA: 0s - loss: 0.1313 - accuracy: 0.9293\n",
      "4309/5349 [=======================>......] - ETA: 0s - loss: 0.1313 - accuracy: 0.9293\n",
      "4515/5349 [========================>.....] - ETA: 0s - loss: 0.1312 - accuracy: 0.9294\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1311 - accuracy: 0.9295\n",
      "4795/5349 [=========================>....] - ETA: 0s - loss: 0.1310 - accuracy: 0.9295\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.1309 - accuracy: 0.9295\n",
      "5070/5349 [===========================>..] - ETA: 0s - loss: 0.1309 - accuracy: 0.9295\n",
      "5202/5349 [============================>.] - ETA: 0s - loss: 0.1307 - accuracy: 0.9296\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9296\n",
      "5349/5349 [==============================] - 5s 983us/step - loss: 0.1306 - accuracy: 0.9296 - val_loss: 0.1246 - val_accuracy: 0.9323\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 4/20\n",
      "  69/5349 [..............................] - ETA: 3s - loss: 0.1288 - accuracy: 0.9293\n",
      " 206/5349 [>.............................] - ETA: 3s - loss: 0.1296 - accuracy: 0.9292\n",
      " 347/5349 [>.............................] - ETA: 3s - loss: 0.1279 - accuracy: 0.9310\n",
      " 481/5349 [=>............................] - ETA: 3s - loss: 0.1281 - accuracy: 0.9309\n",
      " 620/5349 [==>...........................] - ETA: 3s - loss: 0.1275 - accuracy: 0.9316\n",
      " 823/5349 [===>..........................] - ETA: 3s - loss: 0.1273 - accuracy: 0.9315\n",
      " 964/5349 [====>.........................] - ETA: 3s - loss: 0.1265 - accuracy: 0.9317\n",
      "1067/5349 [====>.........................] - ETA: 3s - loss: 0.1264 - accuracy: 0.9317\n",
      "1198/5349 [=====>........................] - ETA: 3s - loss: 0.1269 - accuracy: 0.9313\n",
      "1329/5349 [======>.......................] - ETA: 3s - loss: 0.1263 - accuracy: 0.9315\n",
      "1464/5349 [=======>......................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9314\n",
      "1594/5349 [=======>......................] - ETA: 2s - loss: 0.1269 - accuracy: 0.9311\n",
      "1736/5349 [========>.....................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9314\n",
      "1798/5349 [=========>....................] - ETA: 2s - loss: 0.1267 - accuracy: 0.9313\n",
      "1937/5349 [=========>....................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9314\n",
      "2079/5349 [==========>...................] - ETA: 2s - loss: 0.1267 - accuracy: 0.9312\n",
      "2191/5349 [===========>..................] - ETA: 2s - loss: 0.1268 - accuracy: 0.9311\n",
      "2331/5349 [============>.................] - ETA: 2s - loss: 0.1270 - accuracy: 0.9310\n",
      "2464/5349 [============>.................] - ETA: 2s - loss: 0.1267 - accuracy: 0.9311\n",
      "2604/5349 [=============>................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9311\n",
      "2741/5349 [==============>...............] - ETA: 1s - loss: 0.1265 - accuracy: 0.9312\n",
      "2880/5349 [===============>..............] - ETA: 1s - loss: 0.1266 - accuracy: 0.9312\n",
      "3021/5349 [===============>..............] - ETA: 1s - loss: 0.1265 - accuracy: 0.9314\n",
      "3231/5349 [=================>............] - ETA: 1s - loss: 0.1265 - accuracy: 0.9314\n",
      "3371/5349 [=================>............] - ETA: 1s - loss: 0.1264 - accuracy: 0.9314\n",
      "3513/5349 [==================>...........] - ETA: 1s - loss: 0.1264 - accuracy: 0.9315\n",
      "3647/5349 [===================>..........] - ETA: 1s - loss: 0.1264 - accuracy: 0.9314\n",
      "3788/5349 [====================>.........] - ETA: 1s - loss: 0.1263 - accuracy: 0.9315\n",
      "3925/5349 [=====================>........] - ETA: 1s - loss: 0.1263 - accuracy: 0.9315\n",
      "4070/5349 [=====================>........] - ETA: 0s - loss: 0.1263 - accuracy: 0.9315\n",
      "4274/5349 [======================>.......] - ETA: 0s - loss: 0.1263 - accuracy: 0.9315\n",
      "4415/5349 [=======================>......] - ETA: 0s - loss: 0.1262 - accuracy: 0.9315\n",
      "4549/5349 [========================>.....] - ETA: 0s - loss: 0.1262 - accuracy: 0.9315\n",
      "4690/5349 [=========================>....] - ETA: 0s - loss: 0.1263 - accuracy: 0.9314\n",
      "4825/5349 [==========================>...] - ETA: 0s - loss: 0.1262 - accuracy: 0.9315\n",
      "4966/5349 [==========================>...] - ETA: 0s - loss: 0.1260 - accuracy: 0.9316\n",
      "5107/5349 [===========================>..] - ETA: 0s - loss: 0.1260 - accuracy: 0.9316\n",
      "5318/5349 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9316\n",
      "5349/5349 [==============================] - 5s 916us/step - loss: 0.1259 - accuracy: 0.9317 - val_loss: 0.1204 - val_accuracy: 0.9344\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 5/20\n",
      "  70/5349 [..............................] - ETA: 3s - loss: 0.1228 - accuracy: 0.9320\n",
      " 212/5349 [>.............................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9317\n",
      " 354/5349 [>.............................] - ETA: 3s - loss: 0.1267 - accuracy: 0.9307\n",
      " 483/5349 [=>............................] - ETA: 3s - loss: 0.1257 - accuracy: 0.9319\n",
      " 624/5349 [==>...........................] - ETA: 3s - loss: 0.1242 - accuracy: 0.9327\n",
      " 761/5349 [===>..........................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9319\n",
      " 900/5349 [====>.........................] - ETA: 3s - loss: 0.1252 - accuracy: 0.9322\n",
      "1033/5349 [====>.........................] - ETA: 3s - loss: 0.1249 - accuracy: 0.9324\n",
      "1174/5349 [=====>........................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9321\n",
      "1309/5349 [======>.......................] - ETA: 2s - loss: 0.1251 - accuracy: 0.9321\n",
      "1520/5349 [=======>......................] - ETA: 2s - loss: 0.1251 - accuracy: 0.9320\n",
      "1657/5349 [========>.....................] - ETA: 2s - loss: 0.1250 - accuracy: 0.9321\n",
      "1793/5349 [=========>....................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9324\n",
      "1906/5349 [=========>....................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9325\n",
      "2039/5349 [==========>...................] - ETA: 2s - loss: 0.1248 - accuracy: 0.9325\n",
      "2161/5349 [===========>..................] - ETA: 2s - loss: 0.1246 - accuracy: 0.9327\n",
      "2300/5349 [===========>..................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9326\n",
      "2432/5349 [============>.................] - ETA: 2s - loss: 0.1246 - accuracy: 0.9326\n",
      "2558/5349 [=============>................] - ETA: 2s - loss: 0.1243 - accuracy: 0.9328\n",
      "2690/5349 [==============>...............] - ETA: 1s - loss: 0.1242 - accuracy: 0.9329\n",
      "2760/5349 [==============>...............] - ETA: 1s - loss: 0.1242 - accuracy: 0.9329\n",
      "2901/5349 [===============>..............] - ETA: 1s - loss: 0.1240 - accuracy: 0.9330\n",
      "3037/5349 [================>.............] - ETA: 1s - loss: 0.1237 - accuracy: 0.9332\n",
      "3177/5349 [================>.............] - ETA: 1s - loss: 0.1237 - accuracy: 0.9331\n",
      "3311/5349 [=================>............] - ETA: 1s - loss: 0.1236 - accuracy: 0.9332\n",
      "3445/5349 [==================>...........] - ETA: 1s - loss: 0.1237 - accuracy: 0.9331\n",
      "3582/5349 [===================>..........] - ETA: 1s - loss: 0.1237 - accuracy: 0.9332\n",
      "3650/5349 [===================>..........] - ETA: 1s - loss: 0.1236 - accuracy: 0.9332\n",
      "3780/5349 [====================>.........] - ETA: 1s - loss: 0.1235 - accuracy: 0.9333\n",
      "3894/5349 [====================>.........] - ETA: 1s - loss: 0.1235 - accuracy: 0.9332\n",
      "4003/5349 [=====================>........] - ETA: 1s - loss: 0.1234 - accuracy: 0.9333\n",
      "4113/5349 [======================>.......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9333\n",
      "4223/5349 [======================>.......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9333\n",
      "4335/5349 [=======================>......] - ETA: 0s - loss: 0.1233 - accuracy: 0.9334\n",
      "4449/5349 [=======================>......] - ETA: 0s - loss: 0.1232 - accuracy: 0.9334\n",
      "4611/5349 [========================>.....] - ETA: 0s - loss: 0.1232 - accuracy: 0.9334\n",
      "4725/5349 [=========================>....] - ETA: 0s - loss: 0.1231 - accuracy: 0.9335\n",
      "4842/5349 [==========================>...] - ETA: 0s - loss: 0.1232 - accuracy: 0.9335\n",
      "4930/5349 [==========================>...] - ETA: 0s - loss: 0.1232 - accuracy: 0.9334\n",
      "5018/5349 [===========================>..] - ETA: 0s - loss: 0.1232 - accuracy: 0.9334\n",
      "5142/5349 [===========================>..] - ETA: 0s - loss: 0.1230 - accuracy: 0.9335\n",
      "5250/5349 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9335\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9335\n",
      "5349/5349 [==============================] - 5s 987us/step - loss: 0.1231 - accuracy: 0.9335 - val_loss: 0.1236 - val_accuracy: 0.9339\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1474 - accuracy: 0.9000\n",
      " 143/5349 [..............................] - ETA: 3s - loss: 0.1271 - accuracy: 0.9301\n",
      " 286/5349 [>.............................] - ETA: 3s - loss: 0.1225 - accuracy: 0.9338\n",
      " 419/5349 [=>............................] - ETA: 3s - loss: 0.1206 - accuracy: 0.9352\n",
      " 559/5349 [==>...........................] - ETA: 3s - loss: 0.1201 - accuracy: 0.9354\n",
      " 701/5349 [==>...........................] - ETA: 3s - loss: 0.1205 - accuracy: 0.9353\n",
      " 843/5349 [===>..........................] - ETA: 3s - loss: 0.1203 - accuracy: 0.9356\n",
      "1044/5349 [====>.........................] - ETA: 3s - loss: 0.1200 - accuracy: 0.9355\n",
      "1187/5349 [=====>........................] - ETA: 3s - loss: 0.1204 - accuracy: 0.9349\n",
      "1327/5349 [======>.......................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9350\n",
      "1471/5349 [=======>......................] - ETA: 2s - loss: 0.1208 - accuracy: 0.9346\n",
      "1611/5349 [========>.....................] - ETA: 2s - loss: 0.1206 - accuracy: 0.9346\n",
      "1747/5349 [========>.....................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9347\n",
      "1819/5349 [=========>....................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9347\n",
      "1955/5349 [=========>....................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9349\n",
      "2096/5349 [==========>...................] - ETA: 2s - loss: 0.1208 - accuracy: 0.9346\n",
      "2219/5349 [===========>..................] - ETA: 2s - loss: 0.1206 - accuracy: 0.9347\n",
      "2359/5349 [============>.................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9348\n",
      "2454/5349 [============>.................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9347\n",
      "2651/5349 [=============>................] - ETA: 1s - loss: 0.1206 - accuracy: 0.9347\n",
      "2782/5349 [==============>...............] - ETA: 1s - loss: 0.1208 - accuracy: 0.9348\n",
      "2915/5349 [===============>..............] - ETA: 1s - loss: 0.1209 - accuracy: 0.9348\n",
      "3048/5349 [================>.............] - ETA: 1s - loss: 0.1211 - accuracy: 0.9346\n",
      "3180/5349 [================>.............] - ETA: 1s - loss: 0.1211 - accuracy: 0.9346\n",
      "3316/5349 [=================>............] - ETA: 1s - loss: 0.1212 - accuracy: 0.9345\n",
      "3527/5349 [==================>...........] - ETA: 1s - loss: 0.1212 - accuracy: 0.9344\n",
      "3665/5349 [===================>..........] - ETA: 1s - loss: 0.1212 - accuracy: 0.9343\n",
      "3802/5349 [====================>.........] - ETA: 1s - loss: 0.1214 - accuracy: 0.9343\n",
      "3942/5349 [=====================>........] - ETA: 1s - loss: 0.1212 - accuracy: 0.9344\n",
      "4084/5349 [=====================>........] - ETA: 0s - loss: 0.1212 - accuracy: 0.9343\n",
      "4286/5349 [=======================>......] - ETA: 0s - loss: 0.1211 - accuracy: 0.9343\n",
      "4416/5349 [=======================>......] - ETA: 0s - loss: 0.1210 - accuracy: 0.9345\n",
      "4558/5349 [========================>.....] - ETA: 0s - loss: 0.1211 - accuracy: 0.9344\n",
      "4702/5349 [=========================>....] - ETA: 0s - loss: 0.1212 - accuracy: 0.9344\n",
      "4841/5349 [==========================>...] - ETA: 0s - loss: 0.1213 - accuracy: 0.9343\n",
      "5056/5349 [===========================>..] - ETA: 0s - loss: 0.1212 - accuracy: 0.9343\n",
      "5187/5349 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9343\n",
      "5328/5349 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.9344\n",
      "5349/5349 [==============================] - 5s 916us/step - loss: 0.1209 - accuracy: 0.9344 - val_loss: 0.1149 - val_accuracy: 0.9371\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 7/20\n",
      "  69/5349 [..............................] - ETA: 3s - loss: 0.1217 - accuracy: 0.9343\n",
      " 211/5349 [>.............................] - ETA: 3s - loss: 0.1228 - accuracy: 0.9325\n",
      " 354/5349 [>.............................] - ETA: 3s - loss: 0.1226 - accuracy: 0.9336\n",
      " 471/5349 [=>............................] - ETA: 3s - loss: 0.1223 - accuracy: 0.9334\n",
      " 607/5349 [==>...........................] - ETA: 3s - loss: 0.1217 - accuracy: 0.9332\n",
      " 817/5349 [===>..........................] - ETA: 3s - loss: 0.1209 - accuracy: 0.9341\n",
      " 956/5349 [====>.........................] - ETA: 3s - loss: 0.1201 - accuracy: 0.9347\n",
      "1098/5349 [=====>........................] - ETA: 3s - loss: 0.1206 - accuracy: 0.9344\n",
      "1236/5349 [=====>........................] - ETA: 3s - loss: 0.1203 - accuracy: 0.9346\n",
      "1375/5349 [======>.......................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9348\n",
      "1516/5349 [=======>......................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9349\n",
      "1654/5349 [========>.....................] - ETA: 2s - loss: 0.1206 - accuracy: 0.9345\n",
      "1864/5349 [=========>....................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9346\n",
      "1998/5349 [==========>...................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9347\n",
      "2139/5349 [==========>...................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9348\n",
      "2271/5349 [===========>..................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9350\n",
      "2411/5349 [============>.................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9349\n",
      "2545/5349 [=============>................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9349\n",
      "2677/5349 [==============>...............] - ETA: 1s - loss: 0.1197 - accuracy: 0.9351\n",
      "2817/5349 [==============>...............] - ETA: 1s - loss: 0.1194 - accuracy: 0.9352\n",
      "2956/5349 [===============>..............] - ETA: 1s - loss: 0.1193 - accuracy: 0.9352\n",
      "3166/5349 [================>.............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9352\n",
      "3300/5349 [=================>............] - ETA: 1s - loss: 0.1194 - accuracy: 0.9353\n",
      "3441/5349 [==================>...........] - ETA: 1s - loss: 0.1194 - accuracy: 0.9353\n",
      "3584/5349 [===================>..........] - ETA: 1s - loss: 0.1194 - accuracy: 0.9352\n",
      "3726/5349 [===================>..........] - ETA: 1s - loss: 0.1193 - accuracy: 0.9353\n",
      "3868/5349 [====================>.........] - ETA: 1s - loss: 0.1195 - accuracy: 0.9352\n",
      "4005/5349 [=====================>........] - ETA: 0s - loss: 0.1194 - accuracy: 0.9352\n",
      "4148/5349 [======================>.......] - ETA: 0s - loss: 0.1193 - accuracy: 0.9352\n",
      "4277/5349 [======================>.......] - ETA: 0s - loss: 0.1192 - accuracy: 0.9353\n",
      "4420/5349 [=======================>......] - ETA: 0s - loss: 0.1193 - accuracy: 0.9353\n",
      "4556/5349 [========================>.....] - ETA: 0s - loss: 0.1193 - accuracy: 0.9352\n",
      "4625/5349 [========================>.....] - ETA: 0s - loss: 0.1194 - accuracy: 0.9352\n",
      "4764/5349 [=========================>....] - ETA: 0s - loss: 0.1194 - accuracy: 0.9352\n",
      "4904/5349 [==========================>...] - ETA: 0s - loss: 0.1192 - accuracy: 0.9352\n",
      "5046/5349 [===========================>..] - ETA: 0s - loss: 0.1193 - accuracy: 0.9352\n",
      "5186/5349 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9352\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.9352\n",
      "5349/5349 [==============================] - 5s 963us/step - loss: 0.1193 - accuracy: 0.9352 - val_loss: 0.1185 - val_accuracy: 0.9356\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 17s - loss: 0.1599 - accuracy: 0.9500\n",
      " 108/5349 [..............................] - ETA: 4s - loss: 0.1218 - accuracy: 0.9365\n",
      " 238/5349 [>.............................] - ETA: 4s - loss: 0.1205 - accuracy: 0.9352\n",
      " 310/5349 [>.............................] - ETA: 4s - loss: 0.1194 - accuracy: 0.9354\n",
      " 425/5349 [=>............................] - ETA: 4s - loss: 0.1189 - accuracy: 0.9355\n",
      " 567/5349 [==>...........................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9351\n",
      " 703/5349 [==>...........................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9351\n",
      " 844/5349 [===>..........................] - ETA: 3s - loss: 0.1194 - accuracy: 0.9350\n",
      " 983/5349 [====>.........................] - ETA: 3s - loss: 0.1188 - accuracy: 0.9354\n",
      "1114/5349 [=====>........................] - ETA: 3s - loss: 0.1194 - accuracy: 0.9350\n",
      "1246/5349 [=====>........................] - ETA: 3s - loss: 0.1193 - accuracy: 0.9352\n",
      "1386/5349 [======>.......................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9352\n",
      "1595/5349 [=======>......................] - ETA: 2s - loss: 0.1190 - accuracy: 0.9352\n",
      "1732/5349 [========>.....................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9352\n",
      "1868/5349 [=========>....................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9353\n",
      "2007/5349 [==========>...................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9354\n",
      "2143/5349 [===========>..................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9357\n",
      "2285/5349 [===========>..................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9357\n",
      "2412/5349 [============>.................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9358\n",
      "2546/5349 [=============>................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9357\n",
      "2755/5349 [==============>...............] - ETA: 1s - loss: 0.1186 - accuracy: 0.9356\n",
      "2893/5349 [===============>..............] - ETA: 1s - loss: 0.1185 - accuracy: 0.9356\n",
      "3030/5349 [===============>..............] - ETA: 1s - loss: 0.1184 - accuracy: 0.9359\n",
      "3168/5349 [================>.............] - ETA: 1s - loss: 0.1181 - accuracy: 0.9359\n",
      "3304/5349 [=================>............] - ETA: 1s - loss: 0.1181 - accuracy: 0.9359\n",
      "3447/5349 [==================>...........] - ETA: 1s - loss: 0.1179 - accuracy: 0.9360\n",
      "3587/5349 [===================>..........] - ETA: 1s - loss: 0.1179 - accuracy: 0.9361\n",
      "3764/5349 [====================>.........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9360\n",
      "3902/5349 [====================>.........] - ETA: 1s - loss: 0.1181 - accuracy: 0.9359\n",
      "4042/5349 [=====================>........] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "4182/5349 [======================>.......] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "4322/5349 [=======================>......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "4443/5349 [=======================>......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "4575/5349 [========================>.....] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "4715/5349 [=========================>....] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "4856/5349 [==========================>...] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "4930/5349 [==========================>...] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "5063/5349 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 0.9359\n",
      "5202/5349 [============================>.] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "5331/5349 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "5349/5349 [==============================] - 5s 924us/step - loss: 0.1182 - accuracy: 0.9358 - val_loss: 0.1220 - val_accuracy: 0.9371\n",
      "\u001B[36m(train_DNN pid=5615)\u001B[0m Epoch 9/20\n",
      "  71/5349 [..............................] - ETA: 3s - loss: 0.1139 - accuracy: 0.9424\n",
      " 213/5349 [>.............................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9397\n",
      " 355/5349 [>.............................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9379\n",
      " 492/5349 [=>............................] - ETA: 3s - loss: 0.1171 - accuracy: 0.9371\n",
      " 702/5349 [==>...........................] - ETA: 3s - loss: 0.1189 - accuracy: 0.9356\n",
      " 833/5349 [===>..........................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9358\n",
      " 972/5349 [====>.........................] - ETA: 3s - loss: 0.1179 - accuracy: 0.9358\n",
      "1108/5349 [=====>........................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9356\n",
      "1248/5349 [=====>........................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9354\n",
      "1379/5349 [======>.......................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9358\n",
      "1522/5349 [=======>......................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9358\n",
      "1666/5349 [========>.....................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9360\n",
      "1794/5349 [=========>....................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9359\n",
      "1932/5349 [=========>....................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9361\n",
      "2144/5349 [===========>..................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9356\n",
      "2282/5349 [===========>..................] - ETA: 2s - loss: 0.1180 - accuracy: 0.9358\n",
      "2424/5349 [============>.................] - ETA: 2s - loss: 0.1177 - accuracy: 0.9360\n",
      "2564/5349 [=============>................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9361\n",
      "2703/5349 [==============>...............] - ETA: 1s - loss: 0.1175 - accuracy: 0.9361\n",
      "2839/5349 [==============>...............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9363\n",
      "2982/5349 [===============>..............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9363\n",
      "3120/5349 [================>.............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9362\n",
      "3261/5349 [=================>............] - ETA: 1s - loss: 0.1174 - accuracy: 0.9362\n",
      "3329/5349 [=================>............] - ETA: 1s - loss: 0.1174 - accuracy: 0.9361\n",
      "3466/5349 [==================>...........] - ETA: 1s - loss: 0.1174 - accuracy: 0.9362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-27 11:39:35,175\tERROR tune_controller.py:1331 -- Trial task failed for trial train_DNN_906fd_00009\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(InvalidArgumentError): \u001B[36mray::ImplicitFunc.train()\u001B[39m (pid=5615, ip=127.0.0.1, actor_id=b94a84e8e80b601aed8f6c7801000000, repr=train_DNN)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/finnbeckmann/uni/DLLabs/lab2/utilities.py\", line 154, in train_DNN\n",
      "    model.fit(X_train, y_train,\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_ExpandDims defined at (most recent call last):\n",
      "<stack traces unavailable>\n",
      "'dim' must be a tensor with a single value\n",
      "\t [[{{node ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_ExpandDims}}]] [Op:__inference_train_function_1516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 1/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.6184 - accuracy: 0.8364   \n",
      " 293/5349 [>.............................] - ETA: 2s - loss: 0.5537 - accuracy: 0.8372\n",
      " 499/5349 [=>............................] - ETA: 2s - loss: 0.5195 - accuracy: 0.8386\n",
      " 692/5349 [==>...........................] - ETA: 2s - loss: 0.5012 - accuracy: 0.8388\n",
      " 906/5349 [====>.........................] - ETA: 2s - loss: 0.4883 - accuracy: 0.8389\n",
      "1112/5349 [=====>........................] - ETA: 2s - loss: 0.4800 - accuracy: 0.8390\n",
      "1322/5349 [======>.......................] - ETA: 1s - loss: 0.4730 - accuracy: 0.8397\n",
      "1511/5349 [=======>......................] - ETA: 1s - loss: 0.4686 - accuracy: 0.8399\n",
      "1815/5349 [=========>....................] - ETA: 1s - loss: 0.4636 - accuracy: 0.8400\n",
      "2018/5349 [==========>...................] - ETA: 1s - loss: 0.4616 - accuracy: 0.8398\n",
      "2228/5349 [===========>..................] - ETA: 1s - loss: 0.4595 - accuracy: 0.8398\n",
      "2429/5349 [============>.................] - ETA: 1s - loss: 0.4577 - accuracy: 0.8399\n",
      "2641/5349 [=============>................] - ETA: 1s - loss: 0.4560 - accuracy: 0.8401\n",
      "2831/5349 [==============>...............] - ETA: 1s - loss: 0.4545 - accuracy: 0.8403\n",
      "3044/5349 [================>.............] - ETA: 1s - loss: 0.4534 - accuracy: 0.8403\n",
      "3348/5349 [=================>............] - ETA: 0s - loss: 0.4517 - accuracy: 0.8405\n",
      "3552/5349 [==================>...........] - ETA: 0s - loss: 0.4512 - accuracy: 0.8404\n",
      "3759/5349 [====================>.........] - ETA: 0s - loss: 0.4505 - accuracy: 0.8404\n",
      "3972/5349 [=====================>........] - ETA: 0s - loss: 0.4499 - accuracy: 0.8404\n",
      "4175/5349 [======================>.......] - ETA: 0s - loss: 0.4490 - accuracy: 0.8406\n",
      "4389/5349 [=======================>......] - ETA: 0s - loss: 0.4486 - accuracy: 0.8406\n",
      "4592/5349 [========================>.....] - ETA: 0s - loss: 0.4480 - accuracy: 0.8407\n",
      "4800/5349 [=========================>....] - ETA: 0s - loss: 0.4478 - accuracy: 0.8406\n",
      "5117/5349 [===========================>..] - ETA: 0s - loss: 0.4473 - accuracy: 0.8405\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 696us/step - loss: 0.4467 - accuracy: 0.8406 - val_loss: 0.4387 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.5228 - accuracy: 0.7900\n",
      " 211/5349 [>.............................] - ETA: 2s - loss: 0.4403 - accuracy: 0.8396\n",
      " 304/5349 [>.............................] - ETA: 2s - loss: 0.4380 - accuracy: 0.8409\n",
      " 479/5349 [=>............................] - ETA: 2s - loss: 0.4373 - accuracy: 0.8414\n",
      " 623/5349 [==>...........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8419\n",
      " 797/5349 [===>..........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8419\n",
      " 955/5349 [====>.........................] - ETA: 2s - loss: 0.4352 - accuracy: 0.8426\n",
      "1121/5349 [=====>........................] - ETA: 2s - loss: 0.4358 - accuracy: 0.8422\n",
      "1300/5349 [======>.......................] - ETA: 2s - loss: 0.4362 - accuracy: 0.8420\n",
      "1544/5349 [=======>......................] - ETA: 2s - loss: 0.4373 - accuracy: 0.8413\n",
      "1710/5349 [========>.....................] - ETA: 2s - loss: 0.4373 - accuracy: 0.8414\n",
      "1883/5349 [=========>....................] - ETA: 2s - loss: 0.4370 - accuracy: 0.8415\n",
      "1993/5349 [==========>...................] - ETA: 2s - loss: 0.4375 - accuracy: 0.8412\n",
      "2164/5349 [===========>..................] - ETA: 1s - loss: 0.4381 - accuracy: 0.8408\n",
      "2247/5349 [===========>..................] - ETA: 1s - loss: 0.4382 - accuracy: 0.8408\n",
      "2420/5349 [============>.................] - ETA: 1s - loss: 0.4380 - accuracy: 0.8409\n",
      "2610/5349 [=============>................] - ETA: 1s - loss: 0.4379 - accuracy: 0.8410\n",
      "2799/5349 [==============>...............] - ETA: 1s - loss: 0.4380 - accuracy: 0.8409\n",
      "3004/5349 [===============>..............] - ETA: 1s - loss: 0.4382 - accuracy: 0.8408\n",
      "3209/5349 [================>.............] - ETA: 1s - loss: 0.4377 - accuracy: 0.8411\n",
      "3408/5349 [==================>...........] - ETA: 1s - loss: 0.4376 - accuracy: 0.8411\n",
      "3612/5349 [===================>..........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8412\n",
      "3817/5349 [====================>.........] - ETA: 0s - loss: 0.4379 - accuracy: 0.8410\n",
      "4017/5349 [=====================>........] - ETA: 0s - loss: 0.4381 - accuracy: 0.8408\n",
      "4120/5349 [======================>.......] - ETA: 0s - loss: 0.4379 - accuracy: 0.8410\n",
      "4309/5349 [=======================>......] - ETA: 0s - loss: 0.4379 - accuracy: 0.8409\n",
      "4510/5349 [========================>.....] - ETA: 0s - loss: 0.4382 - accuracy: 0.8408\n",
      "4719/5349 [=========================>....] - ETA: 0s - loss: 0.4381 - accuracy: 0.8408\n",
      "4913/5349 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8410\n",
      "5113/5349 [===========================>..] - ETA: 0s - loss: 0.4381 - accuracy: 0.8408\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.4384 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 731us/step - loss: 0.4384 - accuracy: 0.8406 - val_loss: 0.4385 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 3/20\n",
      " 106/5349 [..............................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8418\n",
      " 262/5349 [>.............................] - ETA: 2s - loss: 0.4367 - accuracy: 0.8416\n",
      " 465/5349 [=>............................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8430\n",
      " 653/5349 [==>...........................] - ETA: 2s - loss: 0.4356 - accuracy: 0.8423\n",
      " 951/5349 [====>.........................] - ETA: 2s - loss: 0.4369 - accuracy: 0.8415\n",
      "1139/5349 [=====>........................] - ETA: 2s - loss: 0.4377 - accuracy: 0.8410\n",
      "1353/5349 [======>.......................] - ETA: 2s - loss: 0.4385 - accuracy: 0.8405\n",
      "1559/5349 [=======>......................] - ETA: 1s - loss: 0.4393 - accuracy: 0.8400\n",
      "1775/5349 [========>.....................] - ETA: 1s - loss: 0.4400 - accuracy: 0.8396\n",
      "1981/5349 [==========>...................] - ETA: 1s - loss: 0.4400 - accuracy: 0.8396\n",
      "2188/5349 [===========>..................] - ETA: 1s - loss: 0.4400 - accuracy: 0.8396\n",
      "2386/5349 [============>.................] - ETA: 1s - loss: 0.4403 - accuracy: 0.8394\n",
      "2601/5349 [=============>................] - ETA: 1s - loss: 0.4397 - accuracy: 0.8398\n",
      "2798/5349 [==============>...............] - ETA: 1s - loss: 0.4392 - accuracy: 0.8401\n",
      "2978/5349 [===============>..............] - ETA: 1s - loss: 0.4391 - accuracy: 0.8401\n",
      "3174/5349 [================>.............] - ETA: 1s - loss: 0.4387 - accuracy: 0.8403\n",
      "3489/5349 [==================>...........] - ETA: 0s - loss: 0.4391 - accuracy: 0.8401\n",
      "3688/5349 [===================>..........] - ETA: 0s - loss: 0.4388 - accuracy: 0.8403\n",
      "3901/5349 [====================>.........] - ETA: 0s - loss: 0.4382 - accuracy: 0.8407\n",
      "4102/5349 [======================>.......] - ETA: 0s - loss: 0.4381 - accuracy: 0.8407\n",
      "4315/5349 [=======================>......] - ETA: 0s - loss: 0.4383 - accuracy: 0.8406\n",
      "4524/5349 [========================>.....] - ETA: 0s - loss: 0.4380 - accuracy: 0.8408\n",
      "4736/5349 [=========================>....] - ETA: 0s - loss: 0.4379 - accuracy: 0.8408\n",
      "4940/5349 [==========================>...] - ETA: 0s - loss: 0.4381 - accuracy: 0.8407\n",
      "5252/5349 [============================>.] - ETA: 0s - loss: 0.4381 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 673us/step - loss: 0.4382 - accuracy: 0.8406 - val_loss: 0.4383 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4226 - accuracy: 0.8500\n",
      " 105/5349 [..............................] - ETA: 2s - loss: 0.4387 - accuracy: 0.8403\n",
      " 314/5349 [>.............................] - ETA: 2s - loss: 0.4385 - accuracy: 0.8404\n",
      " 529/5349 [=>............................] - ETA: 2s - loss: 0.4378 - accuracy: 0.8409\n",
      " 708/5349 [==>...........................] - ETA: 2s - loss: 0.4373 - accuracy: 0.8411\n",
      " 922/5349 [====>.........................] - ETA: 2s - loss: 0.4383 - accuracy: 0.8406\n",
      "1105/5349 [=====>........................] - ETA: 2s - loss: 0.4390 - accuracy: 0.8401\n",
      "1422/5349 [======>.......................] - ETA: 1s - loss: 0.4388 - accuracy: 0.8403\n",
      "1631/5349 [========>.....................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8405\n",
      "1843/5349 [=========>....................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8405\n",
      "2045/5349 [==========>...................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8404\n",
      "2255/5349 [===========>..................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8404\n",
      "2462/5349 [============>.................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8405\n",
      "2674/5349 [=============>................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8405\n",
      "2881/5349 [===============>..............] - ETA: 1s - loss: 0.4381 - accuracy: 0.8406\n",
      "3088/5349 [================>.............] - ETA: 1s - loss: 0.4384 - accuracy: 0.8404\n",
      "3299/5349 [=================>............] - ETA: 0s - loss: 0.4383 - accuracy: 0.8405\n",
      "3605/5349 [===================>..........] - ETA: 0s - loss: 0.4379 - accuracy: 0.8407\n",
      "3810/5349 [====================>.........] - ETA: 0s - loss: 0.4382 - accuracy: 0.8406\n",
      "4025/5349 [=====================>........] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "4226/5349 [======================>.......] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "4438/5349 [=======================>......] - ETA: 0s - loss: 0.4384 - accuracy: 0.8405\n",
      "4642/5349 [=========================>....] - ETA: 0s - loss: 0.4385 - accuracy: 0.8404\n",
      "4946/5349 [==========================>...] - ETA: 0s - loss: 0.4381 - accuracy: 0.8406\n",
      "5142/5349 [===========================>..] - ETA: 0s - loss: 0.4383 - accuracy: 0.8405\n",
      "5344/5349 [============================>.] - ETA: 0s - loss: 0.4380 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 696us/step - loss: 0.4381 - accuracy: 0.8406 - val_loss: 0.4381 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 5/20\n",
      "  55/5349 [..............................] - ETA: 4s - loss: 0.4266 - accuracy: 0.8475 \n",
      " 241/5349 [>.............................] - ETA: 3s - loss: 0.4363 - accuracy: 0.8417\n",
      " 430/5349 [=>............................] - ETA: 2s - loss: 0.4360 - accuracy: 0.8418\n",
      " 588/5349 [==>...........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8422\n",
      " 905/5349 [====>.........................] - ETA: 2s - loss: 0.4365 - accuracy: 0.8415\n",
      "1109/5349 [=====>........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8416\n",
      "1316/5349 [======>.......................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8415\n",
      "1515/5349 [=======>......................] - ETA: 2s - loss: 0.4362 - accuracy: 0.8417\n",
      "1723/5349 [========>.....................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8419\n",
      "1927/5349 [=========>....................] - ETA: 1s - loss: 0.4357 - accuracy: 0.8420\n",
      "2137/5349 [==========>...................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8418\n",
      "2341/5349 [============>.................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8420\n",
      "2446/5349 [============>.................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8418\n",
      "2649/5349 [=============>................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8417\n",
      "2857/5349 [===============>..............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8416\n",
      "3069/5349 [================>.............] - ETA: 1s - loss: 0.4364 - accuracy: 0.8415\n",
      "3274/5349 [=================>............] - ETA: 1s - loss: 0.4366 - accuracy: 0.8414\n",
      "3482/5349 [==================>...........] - ETA: 0s - loss: 0.4372 - accuracy: 0.8411\n",
      "3664/5349 [===================>..........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8411\n",
      "3873/5349 [====================>.........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8409\n",
      "4069/5349 [=====================>........] - ETA: 0s - loss: 0.4374 - accuracy: 0.8409\n",
      "4278/5349 [======================>.......] - ETA: 0s - loss: 0.4377 - accuracy: 0.8408\n",
      "4473/5349 [========================>.....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8408\n",
      "4565/5349 [========================>.....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8408\n",
      "4763/5349 [=========================>....] - ETA: 0s - loss: 0.4376 - accuracy: 0.8408\n",
      "4940/5349 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8407\n",
      "5145/5349 [===========================>..] - ETA: 0s - loss: 0.4380 - accuracy: 0.8406\n",
      "5312/5349 [============================>.] - ETA: 0s - loss: 0.4379 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 689us/step - loss: 0.4379 - accuracy: 0.8406 - val_loss: 0.4379 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 6/20\n",
      " 106/5349 [..............................] - ETA: 2s - loss: 0.4424 - accuracy: 0.8378\n",
      " 418/5349 [=>............................] - ETA: 2s - loss: 0.4368 - accuracy: 0.8412\n",
      " 626/5349 [==>...........................] - ETA: 2s - loss: 0.4382 - accuracy: 0.8404\n",
      " 828/5349 [===>..........................] - ETA: 2s - loss: 0.4377 - accuracy: 0.8407\n",
      "1038/5349 [====>.........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8415\n",
      "1212/5349 [=====>........................] - ETA: 2s - loss: 0.4366 - accuracy: 0.8413\n",
      "1421/5349 [======>.......................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8410\n",
      "1627/5349 [========>.....................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8411\n",
      "1839/5349 [=========>....................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8410\n",
      "2039/5349 [==========>...................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8409\n",
      "2250/5349 [===========>..................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8403\n",
      "2453/5349 [============>.................] - ETA: 1s - loss: 0.4387 - accuracy: 0.8400\n",
      "2667/5349 [=============>................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8401\n",
      "2971/5349 [===============>..............] - ETA: 1s - loss: 0.4387 - accuracy: 0.8400\n",
      "3183/5349 [================>.............] - ETA: 1s - loss: 0.4380 - accuracy: 0.8404\n",
      "3377/5349 [=================>............] - ETA: 0s - loss: 0.4378 - accuracy: 0.8406\n",
      "3590/5349 [===================>..........] - ETA: 0s - loss: 0.4380 - accuracy: 0.8404\n",
      "3778/5349 [====================>.........] - ETA: 0s - loss: 0.4382 - accuracy: 0.8403\n",
      "3992/5349 [=====================>........] - ETA: 0s - loss: 0.4380 - accuracy: 0.8404\n",
      "4180/5349 [======================>.......] - ETA: 0s - loss: 0.4380 - accuracy: 0.8404\n",
      "4387/5349 [=======================>......] - ETA: 0s - loss: 0.4378 - accuracy: 0.8405\n",
      "4596/5349 [========================>.....] - ETA: 0s - loss: 0.4381 - accuracy: 0.8404\n",
      "4892/5349 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8405\n",
      "5096/5349 [===========================>..] - ETA: 0s - loss: 0.4377 - accuracy: 0.8406\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 670us/step - loss: 0.4377 - accuracy: 0.8406 - val_loss: 0.4377 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 7/20\n",
      "  99/5349 [..............................] - ETA: 2s - loss: 0.4510 - accuracy: 0.8325\n",
      " 306/5349 [>.............................] - ETA: 2s - loss: 0.4376 - accuracy: 0.8406\n",
      " 518/5349 [=>............................] - ETA: 2s - loss: 0.4373 - accuracy: 0.8408\n",
      " 726/5349 [===>..........................] - ETA: 2s - loss: 0.4398 - accuracy: 0.8392\n",
      " 937/5349 [====>.........................] - ETA: 2s - loss: 0.4387 - accuracy: 0.8400\n",
      "1139/5349 [=====>........................] - ETA: 2s - loss: 0.4382 - accuracy: 0.8403\n",
      "1351/5349 [======>.......................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8407\n",
      "1536/5349 [=======>......................] - ETA: 1s - loss: 0.4373 - accuracy: 0.8408\n",
      "1749/5349 [========>.....................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8407\n",
      "1853/5349 [=========>....................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8406\n",
      "2064/5349 [==========>...................] - ETA: 1s - loss: 0.4380 - accuracy: 0.8403\n",
      "2273/5349 [===========>..................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8401\n",
      "2472/5349 [============>.................] - ETA: 1s - loss: 0.4387 - accuracy: 0.8399\n",
      "2686/5349 [==============>...............] - ETA: 1s - loss: 0.4381 - accuracy: 0.8403\n",
      "2887/5349 [===============>..............] - ETA: 1s - loss: 0.4380 - accuracy: 0.8403\n",
      "3101/5349 [================>.............] - ETA: 1s - loss: 0.4375 - accuracy: 0.8406\n",
      "3299/5349 [=================>............] - ETA: 0s - loss: 0.4376 - accuracy: 0.8406\n",
      "3514/5349 [==================>...........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8406\n",
      "3616/5349 [===================>..........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8406\n",
      "3799/5349 [====================>.........] - ETA: 0s - loss: 0.4374 - accuracy: 0.8407\n",
      "3970/5349 [=====================>........] - ETA: 0s - loss: 0.4377 - accuracy: 0.8405\n",
      "4109/5349 [======================>.......] - ETA: 0s - loss: 0.4379 - accuracy: 0.8404\n",
      "4287/5349 [=======================>......] - ETA: 0s - loss: 0.4376 - accuracy: 0.8405\n",
      "4458/5349 [========================>.....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8405\n",
      "4605/5349 [========================>.....] - ETA: 0s - loss: 0.4378 - accuracy: 0.8404\n",
      "4687/5349 [=========================>....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8405\n",
      "4862/5349 [==========================>...] - ETA: 0s - loss: 0.4375 - accuracy: 0.8406\n",
      "5042/5349 [===========================>..] - ETA: 0s - loss: 0.4375 - accuracy: 0.8406\n",
      "5213/5349 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8406\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 739us/step - loss: 0.4375 - accuracy: 0.8406 - val_loss: 0.4375 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.4220 - accuracy: 0.8500\n",
      " 204/5349 [>.............................] - ETA: 2s - loss: 0.4379 - accuracy: 0.8403\n",
      " 403/5349 [=>............................] - ETA: 2s - loss: 0.4378 - accuracy: 0.8403\n",
      " 497/5349 [=>............................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8422\n",
      " 679/5349 [==>...........................] - ETA: 2s - loss: 0.4361 - accuracy: 0.8414\n",
      " 886/5349 [===>..........................] - ETA: 2s - loss: 0.4379 - accuracy: 0.8403\n",
      "1055/5349 [====>.........................] - ETA: 2s - loss: 0.4374 - accuracy: 0.8406\n",
      "1248/5349 [=====>........................] - ETA: 2s - loss: 0.4369 - accuracy: 0.8409\n",
      "1445/5349 [=======>......................] - ETA: 2s - loss: 0.4366 - accuracy: 0.8411\n",
      "1655/5349 [========>.....................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8407\n",
      "1853/5349 [=========>....................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8407\n",
      "2162/5349 [===========>..................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8407\n",
      "2357/5349 [============>.................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8409\n",
      "2567/5349 [=============>................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8409\n",
      "2764/5349 [==============>...............] - ETA: 1s - loss: 0.4372 - accuracy: 0.8407\n",
      "2968/5349 [===============>..............] - ETA: 1s - loss: 0.4371 - accuracy: 0.8407\n",
      "3158/5349 [================>.............] - ETA: 1s - loss: 0.4368 - accuracy: 0.8409\n",
      "3329/5349 [=================>............] - ETA: 1s - loss: 0.4369 - accuracy: 0.8409\n",
      "3485/5349 [==================>...........] - ETA: 0s - loss: 0.4368 - accuracy: 0.8409\n",
      "3796/5349 [====================>.........] - ETA: 0s - loss: 0.4368 - accuracy: 0.8409\n",
      "3997/5349 [=====================>........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8410\n",
      "4197/5349 [======================>.......] - ETA: 0s - loss: 0.4368 - accuracy: 0.8409\n",
      "4394/5349 [=======================>......] - ETA: 0s - loss: 0.4369 - accuracy: 0.8408\n",
      "4596/5349 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8408\n",
      "4798/5349 [=========================>....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8408\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.4371 - accuracy: 0.8407\n",
      "5199/5349 [============================>.] - ETA: 0s - loss: 0.4370 - accuracy: 0.8408\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.4371 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 692us/step - loss: 0.4372 - accuracy: 0.8406 - val_loss: 0.4373 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.4382 - accuracy: 0.8400\n",
      " 211/5349 [>.............................] - ETA: 2s - loss: 0.4414 - accuracy: 0.8380\n",
      " 521/5349 [=>............................] - ETA: 2s - loss: 0.4382 - accuracy: 0.8400\n",
      " 721/5349 [===>..........................] - ETA: 2s - loss: 0.4394 - accuracy: 0.8392\n",
      " 928/5349 [====>.........................] - ETA: 2s - loss: 0.4397 - accuracy: 0.8390\n",
      "1133/5349 [=====>........................] - ETA: 2s - loss: 0.4400 - accuracy: 0.8389\n",
      "1343/5349 [======>.......................] - ETA: 1s - loss: 0.4397 - accuracy: 0.8390\n",
      "1547/5349 [=======>......................] - ETA: 1s - loss: 0.4389 - accuracy: 0.8395\n",
      "1741/5349 [========>.....................] - ETA: 1s - loss: 0.4392 - accuracy: 0.8393\n",
      "1940/5349 [=========>....................] - ETA: 1s - loss: 0.4384 - accuracy: 0.8398\n",
      "2152/5349 [===========>..................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8403\n",
      "2355/5349 [============>.................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8405\n",
      "2555/5349 [=============>................] - ETA: 1s - loss: 0.4376 - accuracy: 0.8403\n",
      "2656/5349 [=============>................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8404\n",
      "2862/5349 [===============>..............] - ETA: 1s - loss: 0.4378 - accuracy: 0.8401\n",
      "3067/5349 [================>.............] - ETA: 1s - loss: 0.4381 - accuracy: 0.8400\n",
      "3274/5349 [=================>............] - ETA: 1s - loss: 0.4383 - accuracy: 0.8398\n",
      "3484/5349 [==================>...........] - ETA: 0s - loss: 0.4382 - accuracy: 0.8399\n",
      "3672/5349 [===================>..........] - ETA: 0s - loss: 0.4377 - accuracy: 0.8402\n",
      "3883/5349 [====================>.........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8403\n",
      "4081/5349 [=====================>........] - ETA: 0s - loss: 0.4371 - accuracy: 0.8405\n",
      "4400/5349 [=======================>......] - ETA: 0s - loss: 0.4374 - accuracy: 0.8404\n",
      "4604/5349 [========================>.....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8404\n",
      "4816/5349 [==========================>...] - ETA: 0s - loss: 0.4373 - accuracy: 0.8404\n",
      "5015/5349 [===========================>..] - ETA: 0s - loss: 0.4373 - accuracy: 0.8405\n",
      "5227/5349 [============================>.] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 683us/step - loss: 0.4370 - accuracy: 0.8406 - val_loss: 0.4370 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 10/20\n",
      " 103/5349 [..............................] - ETA: 2s - loss: 0.4171 - accuracy: 0.8524\n",
      " 317/5349 [>.............................] - ETA: 2s - loss: 0.4294 - accuracy: 0.8450\n",
      " 629/5349 [==>...........................] - ETA: 2s - loss: 0.4325 - accuracy: 0.8432\n",
      " 821/5349 [===>..........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8415\n",
      " 995/5349 [====>.........................] - ETA: 2s - loss: 0.4346 - accuracy: 0.8420\n",
      "1175/5349 [=====>........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8415\n",
      "1384/5349 [======>.......................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8417\n",
      "1573/5349 [=======>......................] - ETA: 1s - loss: 0.4346 - accuracy: 0.8419\n",
      "1772/5349 [========>.....................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8415\n",
      "1968/5349 [==========>...................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8414\n",
      "2036/5349 [==========>...................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8412\n",
      "2193/5349 [===========>..................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8413\n",
      "2307/5349 [===========>..................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8414\n",
      "2465/5349 [============>.................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8415\n",
      "2621/5349 [=============>................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8413\n",
      "2886/5349 [===============>..............] - ETA: 1s - loss: 0.4360 - accuracy: 0.8411\n",
      "3039/5349 [================>.............] - ETA: 1s - loss: 0.4360 - accuracy: 0.8410\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.4363 - accuracy: 0.8409\n",
      "3387/5349 [=================>............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8410\n",
      "3575/5349 [===================>..........] - ETA: 0s - loss: 0.4361 - accuracy: 0.8410\n",
      "3706/5349 [===================>..........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8408\n",
      "3927/5349 [=====================>........] - ETA: 0s - loss: 0.4363 - accuracy: 0.8409\n",
      "4092/5349 [=====================>........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8408\n",
      "4281/5349 [=======================>......] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "4481/5349 [========================>.....] - ETA: 0s - loss: 0.4370 - accuracy: 0.8405\n",
      "4692/5349 [=========================>....] - ETA: 0s - loss: 0.4371 - accuracy: 0.8404\n",
      "4897/5349 [==========================>...] - ETA: 0s - loss: 0.4371 - accuracy: 0.8404\n",
      "5095/5349 [===========================>..] - ETA: 0s - loss: 0.4367 - accuracy: 0.8406\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.4368 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 752us/step - loss: 0.4367 - accuracy: 0.8406 - val_loss: 0.4367 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.5372 - accuracy: 0.7800\n",
      " 193/5349 [>.............................] - ETA: 2s - loss: 0.4315 - accuracy: 0.8436\n",
      " 398/5349 [=>............................] - ETA: 2s - loss: 0.4327 - accuracy: 0.8429\n",
      " 585/5349 [==>...........................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8410\n",
      " 771/5349 [===>..........................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8407\n",
      " 954/5349 [====>.........................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8410\n",
      "1054/5349 [====>.........................] - ETA: 2s - loss: 0.4354 - accuracy: 0.8413\n",
      "1254/5349 [======>.......................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8415\n",
      "1456/5349 [=======>......................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8410\n",
      "1640/5349 [========>.....................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8409\n",
      "1832/5349 [=========>....................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8404\n",
      "1946/5349 [=========>....................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8403\n",
      "2099/5349 [==========>...................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8405\n",
      "2293/5349 [===========>..................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8404\n",
      "2489/5349 [============>.................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8403\n",
      "2591/5349 [=============>................] - ETA: 1s - loss: 0.4372 - accuracy: 0.8402\n",
      "2791/5349 [==============>...............] - ETA: 1s - loss: 0.4373 - accuracy: 0.8401\n",
      "2955/5349 [===============>..............] - ETA: 1s - loss: 0.4370 - accuracy: 0.8403\n",
      "3154/5349 [================>.............] - ETA: 1s - loss: 0.4371 - accuracy: 0.8402\n",
      "3337/5349 [=================>............] - ETA: 1s - loss: 0.4369 - accuracy: 0.8403\n",
      "3524/5349 [==================>...........] - ETA: 0s - loss: 0.4368 - accuracy: 0.8404\n",
      "3808/5349 [====================>.........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8405\n",
      "4017/5349 [=====================>........] - ETA: 0s - loss: 0.4369 - accuracy: 0.8403\n",
      "4220/5349 [======================>.......] - ETA: 0s - loss: 0.4373 - accuracy: 0.8401\n",
      "4402/5349 [=======================>......] - ETA: 0s - loss: 0.4373 - accuracy: 0.8400\n",
      "4607/5349 [========================>.....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8403\n",
      "4802/5349 [=========================>....] - ETA: 0s - loss: 0.4367 - accuracy: 0.8404\n",
      "5004/5349 [===========================>..] - ETA: 0s - loss: 0.4364 - accuracy: 0.8406\n",
      "5200/5349 [============================>.] - ETA: 0s - loss: 0.4363 - accuracy: 0.8406\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.4362 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 721us/step - loss: 0.4363 - accuracy: 0.8406 - val_loss: 0.4363 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.3710 - accuracy: 0.8800\n",
      " 193/5349 [>.............................] - ETA: 2s - loss: 0.4316 - accuracy: 0.8434\n",
      " 378/5349 [=>............................] - ETA: 2s - loss: 0.4328 - accuracy: 0.8426\n",
      " 575/5349 [==>...........................] - ETA: 2s - loss: 0.4327 - accuracy: 0.8427\n",
      " 788/5349 [===>..........................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8416\n",
      " 949/5349 [====>.........................] - ETA: 2s - loss: 0.4346 - accuracy: 0.8415\n",
      "1148/5349 [=====>........................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8408\n",
      "1293/5349 [======>.......................] - ETA: 2s - loss: 0.4361 - accuracy: 0.8406\n",
      "1397/5349 [======>.......................] - ETA: 2s - loss: 0.4360 - accuracy: 0.8407\n",
      "1610/5349 [========>.....................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8403\n",
      "1804/5349 [=========>....................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8407\n",
      "2009/5349 [==========>...................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8406\n",
      "2215/5349 [===========>..................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8402\n",
      "2428/5349 [============>.................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8401\n",
      "2631/5349 [=============>................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8403\n",
      "2844/5349 [==============>...............] - ETA: 1s - loss: 0.4363 - accuracy: 0.8405\n",
      "2924/5349 [===============>..............] - ETA: 1s - loss: 0.4365 - accuracy: 0.8404\n",
      "3130/5349 [================>.............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8405\n",
      "3343/5349 [=================>............] - ETA: 1s - loss: 0.4363 - accuracy: 0.8405\n",
      "3540/5349 [==================>...........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8404\n",
      "3754/5349 [====================>.........] - ETA: 0s - loss: 0.4360 - accuracy: 0.8406\n",
      "3953/5349 [=====================>........] - ETA: 0s - loss: 0.4358 - accuracy: 0.8407\n",
      "4168/5349 [======================>.......] - ETA: 0s - loss: 0.4359 - accuracy: 0.8407\n",
      "4370/5349 [=======================>......] - ETA: 0s - loss: 0.4359 - accuracy: 0.8407\n",
      "4582/5349 [========================>.....] - ETA: 0s - loss: 0.4357 - accuracy: 0.8408\n",
      "4895/5349 [==========================>...] - ETA: 0s - loss: 0.4357 - accuracy: 0.8408\n",
      "5101/5349 [===========================>..] - ETA: 0s - loss: 0.4360 - accuracy: 0.8406\n",
      "5308/5349 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 679us/step - loss: 0.4360 - accuracy: 0.8406 - val_loss: 0.4359 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 13/20\n",
      " 104/5349 [..............................] - ETA: 2s - loss: 0.4225 - accuracy: 0.8487\n",
      " 282/5349 [>.............................] - ETA: 2s - loss: 0.4312 - accuracy: 0.8434\n",
      " 452/5349 [=>............................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8413\n",
      " 541/5349 [==>...........................] - ETA: 2s - loss: 0.4354 - accuracy: 0.8409\n",
      " 711/5349 [==>...........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8409\n",
      " 896/5349 [====>.........................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8409\n",
      "1075/5349 [=====>........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8402\n",
      "1263/5349 [======>.......................] - ETA: 2s - loss: 0.4358 - accuracy: 0.8406\n",
      "1444/5349 [=======>......................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8402\n",
      "1622/5349 [========>.....................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8403\n",
      "1792/5349 [=========>....................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8406\n",
      "1931/5349 [=========>....................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8408\n",
      "2061/5349 [==========>...................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8403\n",
      "2250/5349 [===========>..................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8405\n",
      "2335/5349 [============>.................] - ETA: 1s - loss: 0.4357 - accuracy: 0.8406\n",
      "2510/5349 [=============>................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8405\n",
      "2719/5349 [==============>...............] - ETA: 1s - loss: 0.4358 - accuracy: 0.8405\n",
      "2900/5349 [===============>..............] - ETA: 1s - loss: 0.4357 - accuracy: 0.8406\n",
      "3109/5349 [================>.............] - ETA: 1s - loss: 0.4358 - accuracy: 0.8405\n",
      "3298/5349 [=================>............] - ETA: 1s - loss: 0.4358 - accuracy: 0.8405\n",
      "3496/5349 [==================>...........] - ETA: 1s - loss: 0.4358 - accuracy: 0.8405\n",
      "3700/5349 [===================>..........] - ETA: 0s - loss: 0.4357 - accuracy: 0.8405\n",
      "3808/5349 [====================>.........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8404\n",
      "4018/5349 [=====================>........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8404\n",
      "4221/5349 [======================>.......] - ETA: 0s - loss: 0.4362 - accuracy: 0.8403\n",
      "4422/5349 [=======================>......] - ETA: 0s - loss: 0.4362 - accuracy: 0.8402\n",
      "4629/5349 [========================>.....] - ETA: 0s - loss: 0.4360 - accuracy: 0.8404\n",
      "4844/5349 [==========================>...] - ETA: 0s - loss: 0.4360 - accuracy: 0.8404\n",
      "5046/5349 [===========================>..] - ETA: 0s - loss: 0.4358 - accuracy: 0.8405\n",
      "5258/5349 [============================>.] - ETA: 0s - loss: 0.4357 - accuracy: 0.8405\n",
      "5347/5349 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 721us/step - loss: 0.4355 - accuracy: 0.8406 - val_loss: 0.4354 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.5183 - accuracy: 0.7900\n",
      " 145/5349 [..............................] - ETA: 3s - loss: 0.4362 - accuracy: 0.8401\n",
      " 345/5349 [>.............................] - ETA: 2s - loss: 0.4367 - accuracy: 0.8398\n",
      " 638/5349 [==>...........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8399\n",
      " 848/5349 [===>..........................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8407\n",
      "1022/5349 [====>.........................] - ETA: 2s - loss: 0.4341 - accuracy: 0.8413\n",
      "1208/5349 [=====>........................] - ETA: 2s - loss: 0.4339 - accuracy: 0.8414\n",
      "1398/5349 [======>.......................] - ETA: 2s - loss: 0.4341 - accuracy: 0.8413\n",
      "1593/5349 [=======>......................] - ETA: 2s - loss: 0.4345 - accuracy: 0.8410\n",
      "1768/5349 [========>.....................] - ETA: 1s - loss: 0.4342 - accuracy: 0.8412\n",
      "1967/5349 [==========>...................] - ETA: 1s - loss: 0.4349 - accuracy: 0.8408\n",
      "2274/5349 [===========>..................] - ETA: 1s - loss: 0.4349 - accuracy: 0.8408\n",
      "2469/5349 [============>.................] - ETA: 1s - loss: 0.4346 - accuracy: 0.8409\n",
      "2675/5349 [==============>...............] - ETA: 1s - loss: 0.4347 - accuracy: 0.8409\n",
      "2884/5349 [===============>..............] - ETA: 1s - loss: 0.4343 - accuracy: 0.8412\n",
      "3077/5349 [================>.............] - ETA: 1s - loss: 0.4347 - accuracy: 0.8409\n",
      "3259/5349 [=================>............] - ETA: 1s - loss: 0.4348 - accuracy: 0.8408\n",
      "3450/5349 [==================>...........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8408\n",
      "3752/5349 [====================>.........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8408\n",
      "3955/5349 [=====================>........] - ETA: 0s - loss: 0.4349 - accuracy: 0.8407\n",
      "4159/5349 [======================>.......] - ETA: 0s - loss: 0.4352 - accuracy: 0.8406\n",
      "4364/5349 [=======================>......] - ETA: 0s - loss: 0.4353 - accuracy: 0.8405\n",
      "4550/5349 [========================>.....] - ETA: 0s - loss: 0.4353 - accuracy: 0.8405\n",
      "4756/5349 [=========================>....] - ETA: 0s - loss: 0.4353 - accuracy: 0.8405\n",
      "4950/5349 [==========================>...] - ETA: 0s - loss: 0.4350 - accuracy: 0.8406\n",
      "5153/5349 [===========================>..] - ETA: 0s - loss: 0.4350 - accuracy: 0.8406\n",
      "5254/5349 [============================>.] - ETA: 0s - loss: 0.4352 - accuracy: 0.8405\n",
      "5349/5349 [==============================] - 4s 693us/step - loss: 0.4350 - accuracy: 0.8406 - val_loss: 0.4349 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 15/20\n",
      " 107/5349 [..............................] - ETA: 2s - loss: 0.4308 - accuracy: 0.8430\n",
      " 318/5349 [>.............................] - ETA: 2s - loss: 0.4380 - accuracy: 0.8386\n",
      " 529/5349 [=>............................] - ETA: 2s - loss: 0.4383 - accuracy: 0.8384\n",
      " 708/5349 [==>...........................] - ETA: 2s - loss: 0.4375 - accuracy: 0.8389\n",
      " 920/5349 [====>.........................] - ETA: 2s - loss: 0.4368 - accuracy: 0.8393\n",
      "1127/5349 [=====>........................] - ETA: 2s - loss: 0.4362 - accuracy: 0.8397\n",
      "1445/5349 [=======>......................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8397\n",
      "1651/5349 [========>.....................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8394\n",
      "1860/5349 [=========>....................] - ETA: 1s - loss: 0.4363 - accuracy: 0.8396\n",
      "2057/5349 [==========>...................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8397\n",
      "2267/5349 [===========>..................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8396\n",
      "2473/5349 [============>.................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8396\n",
      "2580/5349 [=============>................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8400\n",
      "2782/5349 [==============>...............] - ETA: 1s - loss: 0.4357 - accuracy: 0.8399\n",
      "2987/5349 [===============>..............] - ETA: 1s - loss: 0.4353 - accuracy: 0.8401\n",
      "3200/5349 [================>.............] - ETA: 1s - loss: 0.4352 - accuracy: 0.8402\n",
      "3406/5349 [==================>...........] - ETA: 0s - loss: 0.4349 - accuracy: 0.8404\n",
      "3585/5349 [===================>..........] - ETA: 0s - loss: 0.4347 - accuracy: 0.8405\n",
      "3745/5349 [====================>.........] - ETA: 0s - loss: 0.4346 - accuracy: 0.8406\n",
      "3932/5349 [=====================>........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8404\n",
      "4137/5349 [======================>.......] - ETA: 0s - loss: 0.4348 - accuracy: 0.8404\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.4351 - accuracy: 0.8402\n",
      "4643/5349 [=========================>....] - ETA: 0s - loss: 0.4347 - accuracy: 0.8405\n",
      "4839/5349 [==========================>...] - ETA: 0s - loss: 0.4345 - accuracy: 0.8406\n",
      "5019/5349 [===========================>..] - ETA: 0s - loss: 0.4345 - accuracy: 0.8406\n",
      "5223/5349 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8406\n",
      "5323/5349 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 714us/step - loss: 0.4344 - accuracy: 0.8406 - val_loss: 0.4342 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 16/20\n",
      "  76/5349 [..............................] - ETA: 7s - loss: 0.4409 - accuracy: 0.8364\n",
      " 189/5349 [>.............................] - ETA: 5s - loss: 0.4405 - accuracy: 0.8367\n",
      " 346/5349 [>.............................] - ETA: 4s - loss: 0.4387 - accuracy: 0.8377\n",
      " 526/5349 [=>............................] - ETA: 3s - loss: 0.4371 - accuracy: 0.8387\n",
      " 711/5349 [==>...........................] - ETA: 3s - loss: 0.4353 - accuracy: 0.8399\n",
      " 909/5349 [====>.........................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8404\n",
      "1090/5349 [=====>........................] - ETA: 2s - loss: 0.4339 - accuracy: 0.8407\n",
      "1302/5349 [======>.......................] - ETA: 2s - loss: 0.4321 - accuracy: 0.8417\n",
      "1505/5349 [=======>......................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8409\n",
      "1715/5349 [========>.....................] - ETA: 2s - loss: 0.4344 - accuracy: 0.8404\n",
      "1821/5349 [=========>....................] - ETA: 2s - loss: 0.4338 - accuracy: 0.8407\n",
      "2023/5349 [==========>...................] - ETA: 1s - loss: 0.4334 - accuracy: 0.8409\n",
      "2233/5349 [===========>..................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8408\n",
      "2439/5349 [============>.................] - ETA: 1s - loss: 0.4334 - accuracy: 0.8410\n",
      "2636/5349 [=============>................] - ETA: 1s - loss: 0.4337 - accuracy: 0.8408\n",
      "2823/5349 [==============>...............] - ETA: 1s - loss: 0.4337 - accuracy: 0.8407\n",
      "3030/5349 [===============>..............] - ETA: 1s - loss: 0.4334 - accuracy: 0.8409\n",
      "3230/5349 [=================>............] - ETA: 1s - loss: 0.4334 - accuracy: 0.8409\n",
      "3442/5349 [==================>...........] - ETA: 1s - loss: 0.4335 - accuracy: 0.8408\n",
      "3642/5349 [===================>..........] - ETA: 0s - loss: 0.4332 - accuracy: 0.8410\n",
      "3746/5349 [====================>.........] - ETA: 0s - loss: 0.4335 - accuracy: 0.8408\n",
      "3952/5349 [=====================>........] - ETA: 0s - loss: 0.4335 - accuracy: 0.8408\n",
      "4131/5349 [======================>.......] - ETA: 0s - loss: 0.4331 - accuracy: 0.8410\n",
      "4342/5349 [=======================>......] - ETA: 0s - loss: 0.4330 - accuracy: 0.8411\n",
      "4539/5349 [========================>.....] - ETA: 0s - loss: 0.4331 - accuracy: 0.8410\n",
      "4847/5349 [==========================>...] - ETA: 0s - loss: 0.4336 - accuracy: 0.8407\n",
      "5051/5349 [===========================>..] - ETA: 0s - loss: 0.4336 - accuracy: 0.8407\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.4337 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 716us/step - loss: 0.4337 - accuracy: 0.8406 - val_loss: 0.4334 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 17/20\n",
      " 104/5349 [..............................] - ETA: 2s - loss: 0.4288 - accuracy: 0.8434\n",
      " 315/5349 [>.............................] - ETA: 2s - loss: 0.4220 - accuracy: 0.8475\n",
      " 528/5349 [=>............................] - ETA: 2s - loss: 0.4282 - accuracy: 0.8437\n",
      " 720/5349 [===>..........................] - ETA: 2s - loss: 0.4315 - accuracy: 0.8417\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.4321 - accuracy: 0.8413\n",
      "1097/5349 [=====>........................] - ETA: 2s - loss: 0.4323 - accuracy: 0.8412\n",
      "1203/5349 [=====>........................] - ETA: 2s - loss: 0.4315 - accuracy: 0.8417\n",
      "1418/5349 [======>.......................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8415\n",
      "1618/5349 [========>.....................] - ETA: 1s - loss: 0.4309 - accuracy: 0.8420\n",
      "1819/5349 [=========>....................] - ETA: 1s - loss: 0.4312 - accuracy: 0.8418\n",
      "2021/5349 [==========>...................] - ETA: 1s - loss: 0.4316 - accuracy: 0.8416\n",
      "2236/5349 [===========>..................] - ETA: 1s - loss: 0.4323 - accuracy: 0.8411\n",
      "2439/5349 [============>.................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8411\n",
      "2646/5349 [=============>................] - ETA: 1s - loss: 0.4328 - accuracy: 0.8408\n",
      "2852/5349 [==============>...............] - ETA: 1s - loss: 0.4328 - accuracy: 0.8408\n",
      "3170/5349 [================>.............] - ETA: 1s - loss: 0.4329 - accuracy: 0.8407\n",
      "3373/5349 [=================>............] - ETA: 0s - loss: 0.4327 - accuracy: 0.8408\n",
      "3567/5349 [===================>..........] - ETA: 0s - loss: 0.4326 - accuracy: 0.8409\n",
      "3762/5349 [====================>.........] - ETA: 0s - loss: 0.4327 - accuracy: 0.8408\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.4322 - accuracy: 0.8411\n",
      "4152/5349 [======================>.......] - ETA: 0s - loss: 0.4321 - accuracy: 0.8411\n",
      "4351/5349 [=======================>......] - ETA: 0s - loss: 0.4323 - accuracy: 0.8410\n",
      "4551/5349 [========================>.....] - ETA: 0s - loss: 0.4327 - accuracy: 0.8407\n",
      "4745/5349 [=========================>....] - ETA: 0s - loss: 0.4328 - accuracy: 0.8407\n",
      "4952/5349 [==========================>...] - ETA: 0s - loss: 0.4327 - accuracy: 0.8407\n",
      "5163/5349 [===========================>..] - ETA: 0s - loss: 0.4327 - accuracy: 0.8407\n",
      "5269/5349 [============================>.] - ETA: 0s - loss: 0.4327 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 672us/step - loss: 0.4328 - accuracy: 0.8406 - val_loss: 0.4324 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 18/20\n",
      "  96/5349 [..............................] - ETA: 2s - loss: 0.4379 - accuracy: 0.8372\n",
      " 301/5349 [>.............................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8389\n",
      " 622/5349 [==>...........................] - ETA: 2s - loss: 0.4326 - accuracy: 0.8404\n",
      " 820/5349 [===>..........................] - ETA: 2s - loss: 0.4319 - accuracy: 0.8408\n",
      "1030/5349 [====>.........................] - ETA: 2s - loss: 0.4326 - accuracy: 0.8404\n",
      "1231/5349 [=====>........................] - ETA: 2s - loss: 0.4331 - accuracy: 0.8401\n",
      "1436/5349 [=======>......................] - ETA: 1s - loss: 0.4321 - accuracy: 0.8406\n",
      "1601/5349 [=======>......................] - ETA: 1s - loss: 0.4315 - accuracy: 0.8410\n",
      "1807/5349 [=========>....................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8409\n",
      "2014/5349 [==========>...................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8409\n",
      "2330/5349 [============>.................] - ETA: 1s - loss: 0.4323 - accuracy: 0.8405\n",
      "2523/5349 [=============>................] - ETA: 1s - loss: 0.4329 - accuracy: 0.8401\n",
      "2734/5349 [==============>...............] - ETA: 1s - loss: 0.4327 - accuracy: 0.8402\n",
      "2941/5349 [===============>..............] - ETA: 1s - loss: 0.4323 - accuracy: 0.8404\n",
      "3155/5349 [================>.............] - ETA: 1s - loss: 0.4326 - accuracy: 0.8402\n",
      "3357/5349 [=================>............] - ETA: 0s - loss: 0.4325 - accuracy: 0.8403\n",
      "3565/5349 [==================>...........] - ETA: 0s - loss: 0.4326 - accuracy: 0.8402\n",
      "3766/5349 [====================>.........] - ETA: 0s - loss: 0.4324 - accuracy: 0.8403\n",
      "3955/5349 [=====================>........] - ETA: 0s - loss: 0.4322 - accuracy: 0.8404\n",
      "4105/5349 [======================>.......] - ETA: 0s - loss: 0.4320 - accuracy: 0.8405\n",
      "4184/5349 [======================>.......] - ETA: 0s - loss: 0.4321 - accuracy: 0.8405\n",
      "4341/5349 [=======================>......] - ETA: 0s - loss: 0.4319 - accuracy: 0.8406\n",
      "4514/5349 [========================>.....] - ETA: 0s - loss: 0.4318 - accuracy: 0.8406\n",
      "4687/5349 [=========================>....] - ETA: 0s - loss: 0.4319 - accuracy: 0.8405\n",
      "4842/5349 [==========================>...] - ETA: 0s - loss: 0.4320 - accuracy: 0.8405\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.4317 - accuracy: 0.8406\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 730us/step - loss: 0.4317 - accuracy: 0.8406 - val_loss: 0.4312 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.3338 - accuracy: 0.9000\n",
      " 204/5349 [>.............................] - ETA: 2s - loss: 0.4284 - accuracy: 0.8423\n",
      " 404/5349 [=>............................] - ETA: 2s - loss: 0.4322 - accuracy: 0.8399\n",
      " 600/5349 [==>...........................] - ETA: 2s - loss: 0.4312 - accuracy: 0.8405\n",
      " 704/5349 [==>...........................] - ETA: 2s - loss: 0.4314 - accuracy: 0.8404\n",
      " 909/5349 [====>.........................] - ETA: 2s - loss: 0.4335 - accuracy: 0.8391\n",
      "1111/5349 [=====>........................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8387\n",
      "1321/5349 [======>.......................] - ETA: 1s - loss: 0.4329 - accuracy: 0.8394\n",
      "1495/5349 [=======>......................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8397\n",
      "1699/5349 [========>.....................] - ETA: 1s - loss: 0.4320 - accuracy: 0.8399\n",
      "1899/5349 [=========>....................] - ETA: 1s - loss: 0.4322 - accuracy: 0.8398\n",
      "2112/5349 [==========>...................] - ETA: 1s - loss: 0.4326 - accuracy: 0.8395\n",
      "2316/5349 [===========>..................] - ETA: 1s - loss: 0.4322 - accuracy: 0.8397\n",
      "2525/5349 [=============>................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8400\n",
      "2626/5349 [=============>................] - ETA: 1s - loss: 0.4316 - accuracy: 0.8401\n",
      "2832/5349 [==============>...............] - ETA: 1s - loss: 0.4316 - accuracy: 0.8400\n",
      "3042/5349 [================>.............] - ETA: 1s - loss: 0.4309 - accuracy: 0.8405\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.4305 - accuracy: 0.8407\n",
      "3446/5349 [==================>...........] - ETA: 0s - loss: 0.4305 - accuracy: 0.8407\n",
      "3644/5349 [===================>..........] - ETA: 0s - loss: 0.4306 - accuracy: 0.8406\n",
      "3818/5349 [====================>.........] - ETA: 0s - loss: 0.4304 - accuracy: 0.8407\n",
      "3973/5349 [=====================>........] - ETA: 0s - loss: 0.4304 - accuracy: 0.8407\n",
      "4184/5349 [======================>.......] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4387/5349 [=======================>......] - ETA: 0s - loss: 0.4301 - accuracy: 0.8408\n",
      "4588/5349 [========================>.....] - ETA: 0s - loss: 0.4301 - accuracy: 0.8409\n",
      "4792/5349 [=========================>....] - ETA: 0s - loss: 0.4299 - accuracy: 0.8409\n",
      "5106/5349 [===========================>..] - ETA: 0s - loss: 0.4300 - accuracy: 0.8409\n",
      "5311/5349 [============================>.] - ETA: 0s - loss: 0.4303 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 678us/step - loss: 0.4303 - accuracy: 0.8406 - val_loss: 0.4297 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5627)\u001B[0m Epoch 20/20\n",
      " 106/5349 [..............................] - ETA: 2s - loss: 0.4332 - accuracy: 0.8384\n",
      " 316/5349 [>.............................] - ETA: 2s - loss: 0.4289 - accuracy: 0.8410\n",
      " 527/5349 [=>............................] - ETA: 2s - loss: 0.4277 - accuracy: 0.8417\n",
      " 729/5349 [===>..........................] - ETA: 2s - loss: 0.4281 - accuracy: 0.8414\n",
      " 943/5349 [====>.........................] - ETA: 2s - loss: 0.4290 - accuracy: 0.8408\n",
      "1153/5349 [=====>........................] - ETA: 2s - loss: 0.4303 - accuracy: 0.8400\n",
      "1228/5349 [=====>........................] - ETA: 2s - loss: 0.4302 - accuracy: 0.8401\n",
      "1399/5349 [======>.......................] - ETA: 1s - loss: 0.4300 - accuracy: 0.8402\n",
      "1585/5349 [=======>......................] - ETA: 1s - loss: 0.4293 - accuracy: 0.8406\n",
      "1800/5349 [=========>....................] - ETA: 1s - loss: 0.4286 - accuracy: 0.8410\n",
      "1999/5349 [==========>...................] - ETA: 1s - loss: 0.4286 - accuracy: 0.8410\n",
      "2212/5349 [===========>..................] - ETA: 1s - loss: 0.4285 - accuracy: 0.8410\n",
      "2412/5349 [============>.................] - ETA: 1s - loss: 0.4285 - accuracy: 0.8410\n",
      "2625/5349 [=============>................] - ETA: 1s - loss: 0.4280 - accuracy: 0.8413\n",
      "2935/5349 [===============>..............] - ETA: 1s - loss: 0.4278 - accuracy: 0.8414\n",
      "3126/5349 [================>.............] - ETA: 1s - loss: 0.4278 - accuracy: 0.8414\n",
      "3330/5349 [=================>............] - ETA: 1s - loss: 0.4278 - accuracy: 0.8414\n",
      "3534/5349 [==================>...........] - ETA: 0s - loss: 0.4283 - accuracy: 0.8410\n",
      "3737/5349 [===================>..........] - ETA: 0s - loss: 0.4283 - accuracy: 0.8410\n",
      "3947/5349 [=====================>........] - ETA: 0s - loss: 0.4284 - accuracy: 0.8409\n",
      "4154/5349 [======================>.......] - ETA: 0s - loss: 0.4287 - accuracy: 0.8407\n",
      "4370/5349 [=======================>......] - ETA: 0s - loss: 0.4286 - accuracy: 0.8407\n",
      "4548/5349 [========================>.....] - ETA: 0s - loss: 0.4286 - accuracy: 0.8407\n",
      "4757/5349 [=========================>....] - ETA: 0s - loss: 0.4284 - accuracy: 0.8408\n",
      "5066/5349 [===========================>..] - ETA: 0s - loss: 0.4286 - accuracy: 0.8406\n",
      "5275/5349 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8407\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 1/20\n",
      "  52/5349 [..............................] - ETA: 5s - loss: 0.5622 - accuracy: 0.7967   \n",
      " 166/5349 [..............................] - ETA: 4s - loss: 0.3855 - accuracy: 0.8657\n",
      " 287/5349 [>.............................] - ETA: 4s - loss: 0.3129 - accuracy: 0.8821\n",
      " 406/5349 [=>............................] - ETA: 4s - loss: 0.2755 - accuracy: 0.8900\n",
      " 529/5349 [=>............................] - ETA: 4s - loss: 0.2537 - accuracy: 0.8940\n",
      " 648/5349 [==>...........................] - ETA: 4s - loss: 0.2385 - accuracy: 0.8971\n",
      " 766/5349 [===>..........................] - ETA: 3s - loss: 0.2281 - accuracy: 0.8988\n",
      " 884/5349 [===>..........................] - ETA: 3s - loss: 0.2190 - accuracy: 0.9011\n",
      "1005/5349 [====>.........................] - ETA: 3s - loss: 0.2119 - accuracy: 0.9027\n",
      "1124/5349 [=====>........................] - ETA: 3s - loss: 0.2066 - accuracy: 0.9037\n",
      "1248/5349 [=====>........................] - ETA: 3s - loss: 0.2018 - accuracy: 0.9050\n",
      "1426/5349 [======>.......................] - ETA: 3s - loss: 0.1963 - accuracy: 0.9063\n",
      "1548/5349 [=======>......................] - ETA: 3s - loss: 0.1927 - accuracy: 0.9075\n",
      "1664/5349 [========>.....................] - ETA: 3s - loss: 0.1903 - accuracy: 0.9079\n",
      "1788/5349 [=========>....................] - ETA: 3s - loss: 0.1877 - accuracy: 0.9087\n",
      "1893/5349 [=========>....................] - ETA: 2s - loss: 0.1858 - accuracy: 0.9092\n",
      "2015/5349 [==========>...................] - ETA: 2s - loss: 0.1839 - accuracy: 0.9097\n",
      "2117/5349 [==========>...................] - ETA: 2s - loss: 0.1824 - accuracy: 0.9101\n",
      "2256/5349 [===========>..................] - ETA: 2s - loss: 0.1807 - accuracy: 0.9106\n",
      "2354/5349 [============>.................] - ETA: 2s - loss: 0.1794 - accuracy: 0.9110\n",
      "2447/5349 [============>.................] - ETA: 2s - loss: 0.1783 - accuracy: 0.9113\n",
      "2533/5349 [=============>................] - ETA: 2s - loss: 0.1774 - accuracy: 0.9115\n",
      "2633/5349 [=============>................] - ETA: 2s - loss: 0.1766 - accuracy: 0.9116\n",
      "2729/5349 [==============>...............] - ETA: 2s - loss: 0.1759 - accuracy: 0.9116\n",
      "2868/5349 [===============>..............] - ETA: 2s - loss: 0.1750 - accuracy: 0.9116\n",
      "2968/5349 [===============>..............] - ETA: 2s - loss: 0.1741 - accuracy: 0.9120\n",
      "3034/5349 [================>.............] - ETA: 2s - loss: 0.1737 - accuracy: 0.9121\n",
      "3116/5349 [================>.............] - ETA: 2s - loss: 0.1730 - accuracy: 0.9122\n",
      "3206/5349 [================>.............] - ETA: 2s - loss: 0.1725 - accuracy: 0.9122\n",
      "3353/5349 [=================>............] - ETA: 1s - loss: 0.1715 - accuracy: 0.9125\n",
      "3471/5349 [==================>...........] - ETA: 1s - loss: 0.1708 - accuracy: 0.9126\n",
      "3589/5349 [===================>..........] - ETA: 1s - loss: 0.1701 - accuracy: 0.9128\n",
      "3704/5349 [===================>..........] - ETA: 1s - loss: 0.1695 - accuracy: 0.9129\n",
      "3821/5349 [====================>.........] - ETA: 1s - loss: 0.1690 - accuracy: 0.9130\n",
      "3935/5349 [=====================>........] - ETA: 1s - loss: 0.1685 - accuracy: 0.9132\n",
      "4045/5349 [=====================>........] - ETA: 1s - loss: 0.1681 - accuracy: 0.9132\n",
      "4160/5349 [======================>.......] - ETA: 1s - loss: 0.1675 - accuracy: 0.9133\n",
      "4274/5349 [======================>.......] - ETA: 1s - loss: 0.1670 - accuracy: 0.9135\n",
      "4392/5349 [=======================>......] - ETA: 0s - loss: 0.1665 - accuracy: 0.9136\n",
      "4504/5349 [========================>.....] - ETA: 0s - loss: 0.1661 - accuracy: 0.9137\n",
      "4684/5349 [=========================>....] - ETA: 0s - loss: 0.1655 - accuracy: 0.9137\n",
      "4806/5349 [=========================>....] - ETA: 0s - loss: 0.1650 - accuracy: 0.9139\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.1647 - accuracy: 0.9140\n",
      "5028/5349 [===========================>..] - ETA: 0s - loss: 0.1642 - accuracy: 0.9142\n",
      "5148/5349 [===========================>..] - ETA: 0s - loss: 0.1638 - accuracy: 0.9142\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9143\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1632 - accuracy: 0.9144\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1631 - accuracy: 0.9144 - val_loss: 0.1463 - val_accuracy: 0.9211\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 2/20\n",
      "  61/5349 [..............................] - ETA: 4s - loss: 0.1481 - accuracy: 0.9182\n",
      " 181/5349 [>.............................] - ETA: 4s - loss: 0.1458 - accuracy: 0.9209\n",
      " 302/5349 [>.............................] - ETA: 4s - loss: 0.1444 - accuracy: 0.9210\n",
      " 412/5349 [=>............................] - ETA: 4s - loss: 0.1434 - accuracy: 0.9212\n",
      " 531/5349 [=>............................] - ETA: 4s - loss: 0.1437 - accuracy: 0.9211\n",
      " 633/5349 [==>...........................] - ETA: 4s - loss: 0.1443 - accuracy: 0.9211\n",
      " 743/5349 [===>..........................] - ETA: 4s - loss: 0.1443 - accuracy: 0.9213\n",
      " 923/5349 [====>.........................] - ETA: 3s - loss: 0.1442 - accuracy: 0.9215\n",
      "1047/5349 [====>.........................] - ETA: 3s - loss: 0.1440 - accuracy: 0.9219\n",
      "1157/5349 [=====>........................] - ETA: 3s - loss: 0.1439 - accuracy: 0.9219\n",
      "1276/5349 [======>.......................] - ETA: 3s - loss: 0.1439 - accuracy: 0.9219\n",
      "1389/5349 [======>.......................] - ETA: 3s - loss: 0.1438 - accuracy: 0.9219\n",
      "1508/5349 [=======>......................] - ETA: 3s - loss: 0.1433 - accuracy: 0.9224\n",
      "1685/5349 [========>.....................] - ETA: 3s - loss: 0.1435 - accuracy: 0.9223\n",
      "1810/5349 [=========>....................] - ETA: 3s - loss: 0.1435 - accuracy: 0.9223\n",
      "1916/5349 [=========>....................] - ETA: 2s - loss: 0.1435 - accuracy: 0.9223\n",
      "2038/5349 [==========>...................] - ETA: 2s - loss: 0.1433 - accuracy: 0.9226\n",
      "2150/5349 [===========>..................] - ETA: 2s - loss: 0.1432 - accuracy: 0.9226\n",
      "2269/5349 [===========>..................] - ETA: 2s - loss: 0.1430 - accuracy: 0.9227\n",
      "2383/5349 [============>.................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9230\n",
      "2507/5349 [=============>................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9230\n",
      "2683/5349 [==============>...............] - ETA: 2s - loss: 0.1422 - accuracy: 0.9232\n",
      "2805/5349 [==============>...............] - ETA: 2s - loss: 0.1419 - accuracy: 0.9235\n",
      "2921/5349 [===============>..............] - ETA: 2s - loss: 0.1418 - accuracy: 0.9235\n",
      "3044/5349 [================>.............] - ETA: 1s - loss: 0.1417 - accuracy: 0.9235\n",
      "3160/5349 [================>.............] - ETA: 1s - loss: 0.1415 - accuracy: 0.9237\n",
      "3273/5349 [=================>............] - ETA: 1s - loss: 0.1413 - accuracy: 0.9237\n",
      "3394/5349 [==================>...........] - ETA: 1s - loss: 0.1411 - accuracy: 0.9239\n",
      "3513/5349 [==================>...........] - ETA: 1s - loss: 0.1409 - accuracy: 0.9239\n",
      "3619/5349 [===================>..........] - ETA: 1s - loss: 0.1408 - accuracy: 0.9241\n",
      "3739/5349 [===================>..........] - ETA: 1s - loss: 0.1406 - accuracy: 0.9242\n",
      "3857/5349 [====================>.........] - ETA: 1s - loss: 0.1404 - accuracy: 0.9243\n",
      "3918/5349 [====================>.........] - ETA: 1s - loss: 0.1403 - accuracy: 0.9243\n",
      "4038/5349 [=====================>........] - ETA: 1s - loss: 0.1402 - accuracy: 0.9244\n",
      "4156/5349 [======================>.......] - ETA: 1s - loss: 0.1399 - accuracy: 0.9246\n",
      "4276/5349 [======================>.......] - ETA: 0s - loss: 0.1398 - accuracy: 0.9246\n",
      "4397/5349 [=======================>......] - ETA: 0s - loss: 0.1396 - accuracy: 0.9248\n",
      "4519/5349 [========================>.....] - ETA: 0s - loss: 0.1393 - accuracy: 0.9249\n",
      "4636/5349 [=========================>....] - ETA: 0s - loss: 0.1391 - accuracy: 0.9251\n",
      "4758/5349 [=========================>....] - ETA: 0s - loss: 0.1390 - accuracy: 0.9251\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.1389 - accuracy: 0.9251\n",
      "5001/5349 [===========================>..] - ETA: 0s - loss: 0.1388 - accuracy: 0.9252\n",
      "5053/5349 [===========================>..] - ETA: 0s - loss: 0.1387 - accuracy: 0.9252\n",
      "5169/5349 [===========================>..] - ETA: 0s - loss: 0.1386 - accuracy: 0.9252\n",
      "5286/5349 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.9253\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.9253\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1384 - accuracy: 0.9253 - val_loss: 0.1321 - val_accuracy: 0.9290\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.0704 - accuracy: 0.9600\n",
      " 122/5349 [..............................] - ETA: 4s - loss: 0.1327 - accuracy: 0.9275\n",
      " 232/5349 [>.............................] - ETA: 4s - loss: 0.1328 - accuracy: 0.9281\n",
      " 344/5349 [>.............................] - ETA: 4s - loss: 0.1304 - accuracy: 0.9292\n",
      " 455/5349 [=>............................] - ETA: 4s - loss: 0.1299 - accuracy: 0.9294\n",
      " 560/5349 [==>...........................] - ETA: 4s - loss: 0.1300 - accuracy: 0.9298\n",
      " 635/5349 [==>...........................] - ETA: 4s - loss: 0.1304 - accuracy: 0.9296\n",
      " 670/5349 [==>...........................] - ETA: 4s - loss: 0.1304 - accuracy: 0.9295\n",
      " 761/5349 [===>..........................] - ETA: 4s - loss: 0.1308 - accuracy: 0.9292\n",
      " 853/5349 [===>..........................] - ETA: 4s - loss: 0.1310 - accuracy: 0.9292\n",
      " 943/5349 [====>.........................] - ETA: 4s - loss: 0.1304 - accuracy: 0.9296\n",
      "1037/5349 [====>.........................] - ETA: 4s - loss: 0.1305 - accuracy: 0.9295\n",
      "1133/5349 [=====>........................] - ETA: 4s - loss: 0.1304 - accuracy: 0.9296\n",
      "1219/5349 [=====>........................] - ETA: 4s - loss: 0.1302 - accuracy: 0.9297\n",
      "1366/5349 [======>.......................] - ETA: 4s - loss: 0.1299 - accuracy: 0.9303\n",
      "1467/5349 [=======>......................] - ETA: 4s - loss: 0.1297 - accuracy: 0.9304\n",
      "1542/5349 [=======>......................] - ETA: 3s - loss: 0.1297 - accuracy: 0.9304\n",
      "1611/5349 [========>.....................] - ETA: 3s - loss: 0.1296 - accuracy: 0.9303\n",
      "1712/5349 [========>.....................] - ETA: 3s - loss: 0.1297 - accuracy: 0.9303\n",
      "1804/5349 [=========>....................] - ETA: 3s - loss: 0.1294 - accuracy: 0.9305\n",
      "1955/5349 [=========>....................] - ETA: 3s - loss: 0.1291 - accuracy: 0.9306\n",
      "2072/5349 [==========>...................] - ETA: 3s - loss: 0.1291 - accuracy: 0.9308\n",
      "2181/5349 [===========>..................] - ETA: 3s - loss: 0.1291 - accuracy: 0.9308\n",
      "2295/5349 [===========>..................] - ETA: 3s - loss: 0.1290 - accuracy: 0.9307\n",
      "2408/5349 [============>.................] - ETA: 3s - loss: 0.1290 - accuracy: 0.9307\n",
      "2522/5349 [=============>................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9306\n",
      "2640/5349 [=============>................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9305\n",
      "2806/5349 [==============>...............] - ETA: 2s - loss: 0.1290 - accuracy: 0.9306\n",
      "2920/5349 [===============>..............] - ETA: 2s - loss: 0.1291 - accuracy: 0.9306\n",
      "3037/5349 [================>.............] - ETA: 2s - loss: 0.1288 - accuracy: 0.9307\n",
      "3155/5349 [================>.............] - ETA: 2s - loss: 0.1286 - accuracy: 0.9308\n",
      "3272/5349 [=================>............] - ETA: 2s - loss: 0.1287 - accuracy: 0.9309\n",
      "3387/5349 [=================>............] - ETA: 1s - loss: 0.1285 - accuracy: 0.9311\n",
      "3496/5349 [==================>...........] - ETA: 1s - loss: 0.1284 - accuracy: 0.9311\n",
      "3603/5349 [===================>..........] - ETA: 1s - loss: 0.1284 - accuracy: 0.9310\n",
      "3706/5349 [===================>..........] - ETA: 1s - loss: 0.1284 - accuracy: 0.9311\n",
      "3814/5349 [====================>.........] - ETA: 1s - loss: 0.1282 - accuracy: 0.9312\n",
      "3985/5349 [=====================>........] - ETA: 1s - loss: 0.1282 - accuracy: 0.9312\n",
      "4082/5349 [=====================>........] - ETA: 1s - loss: 0.1282 - accuracy: 0.9312\n",
      "4178/5349 [======================>.......] - ETA: 1s - loss: 0.1282 - accuracy: 0.9312\n",
      "4287/5349 [=======================>......] - ETA: 1s - loss: 0.1282 - accuracy: 0.9312\n",
      "4389/5349 [=======================>......] - ETA: 0s - loss: 0.1281 - accuracy: 0.9312\n",
      "4507/5349 [========================>.....] - ETA: 0s - loss: 0.1280 - accuracy: 0.9312\n",
      "4620/5349 [========================>.....] - ETA: 0s - loss: 0.1281 - accuracy: 0.9311\n",
      "4767/5349 [=========================>....] - ETA: 0s - loss: 0.1282 - accuracy: 0.9311\n",
      "4865/5349 [==========================>...] - ETA: 0s - loss: 0.1281 - accuracy: 0.9312\n",
      "4981/5349 [==========================>...] - ETA: 0s - loss: 0.1280 - accuracy: 0.9312\n",
      "5092/5349 [===========================>..] - ETA: 0s - loss: 0.1280 - accuracy: 0.9312\n",
      "5196/5349 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.9312\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1279 - accuracy: 0.9312\n",
      "5347/5349 [============================>.] - ETA: 0s - loss: 0.1279 - accuracy: 0.9312\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1279 - accuracy: 0.9312 - val_loss: 0.1250 - val_accuracy: 0.9327\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1299 - accuracy: 0.9100\n",
      " 113/5349 [..............................] - ETA: 4s - loss: 0.1218 - accuracy: 0.9328\n",
      " 231/5349 [>.............................] - ETA: 4s - loss: 0.1232 - accuracy: 0.9325\n",
      " 340/5349 [>.............................] - ETA: 4s - loss: 0.1221 - accuracy: 0.9342\n",
      " 461/5349 [=>............................] - ETA: 4s - loss: 0.1235 - accuracy: 0.9334\n",
      " 574/5349 [==>...........................] - ETA: 4s - loss: 0.1243 - accuracy: 0.9326\n",
      " 696/5349 [==>...........................] - ETA: 4s - loss: 0.1240 - accuracy: 0.9326\n",
      " 758/5349 [===>..........................] - ETA: 3s - loss: 0.1235 - accuracy: 0.9329\n",
      " 874/5349 [===>..........................] - ETA: 3s - loss: 0.1237 - accuracy: 0.9330\n",
      " 996/5349 [====>.........................] - ETA: 3s - loss: 0.1240 - accuracy: 0.9328\n",
      "1113/5349 [=====>........................] - ETA: 3s - loss: 0.1236 - accuracy: 0.9333\n",
      "1235/5349 [=====>........................] - ETA: 3s - loss: 0.1233 - accuracy: 0.9337\n",
      "1348/5349 [======>.......................] - ETA: 3s - loss: 0.1234 - accuracy: 0.9337\n",
      "1468/5349 [=======>......................] - ETA: 3s - loss: 0.1234 - accuracy: 0.9336\n",
      "1583/5349 [=======>......................] - ETA: 3s - loss: 0.1233 - accuracy: 0.9336\n",
      "1706/5349 [========>.....................] - ETA: 3s - loss: 0.1231 - accuracy: 0.9336\n",
      "1826/5349 [=========>....................] - ETA: 3s - loss: 0.1232 - accuracy: 0.9336\n",
      "1948/5349 [=========>....................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9334\n",
      "2112/5349 [==========>...................] - ETA: 2s - loss: 0.1237 - accuracy: 0.9332\n",
      "2234/5349 [===========>..................] - ETA: 2s - loss: 0.1237 - accuracy: 0.9332\n",
      "2341/5349 [============>.................] - ETA: 2s - loss: 0.1235 - accuracy: 0.9333\n",
      "2465/5349 [============>.................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9333\n",
      "2580/5349 [=============>................] - ETA: 2s - loss: 0.1235 - accuracy: 0.9331\n",
      "2703/5349 [==============>...............] - ETA: 2s - loss: 0.1237 - accuracy: 0.9331\n",
      "2821/5349 [==============>...............] - ETA: 2s - loss: 0.1235 - accuracy: 0.9332\n",
      "2946/5349 [===============>..............] - ETA: 2s - loss: 0.1235 - accuracy: 0.9332\n",
      "3066/5349 [================>.............] - ETA: 1s - loss: 0.1233 - accuracy: 0.9333\n",
      "3187/5349 [================>.............] - ETA: 1s - loss: 0.1235 - accuracy: 0.9333\n",
      "3302/5349 [=================>............] - ETA: 1s - loss: 0.1237 - accuracy: 0.9330\n",
      "3425/5349 [==================>...........] - ETA: 1s - loss: 0.1235 - accuracy: 0.9331\n",
      "3484/5349 [==================>...........] - ETA: 1s - loss: 0.1235 - accuracy: 0.9331\n",
      "3602/5349 [===================>..........] - ETA: 1s - loss: 0.1236 - accuracy: 0.9330\n",
      "3724/5349 [===================>..........] - ETA: 1s - loss: 0.1234 - accuracy: 0.9331\n",
      "3839/5349 [====================>.........] - ETA: 1s - loss: 0.1233 - accuracy: 0.9333\n",
      "3963/5349 [=====================>........] - ETA: 1s - loss: 0.1233 - accuracy: 0.9334\n",
      "4072/5349 [=====================>........] - ETA: 1s - loss: 0.1234 - accuracy: 0.9333\n",
      "4196/5349 [======================>.......] - ETA: 0s - loss: 0.1233 - accuracy: 0.9333\n",
      "4308/5349 [=======================>......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9333\n",
      "4488/5349 [========================>.....] - ETA: 0s - loss: 0.1234 - accuracy: 0.9334\n",
      "4601/5349 [========================>.....] - ETA: 0s - loss: 0.1233 - accuracy: 0.9334\n",
      "4723/5349 [=========================>....] - ETA: 0s - loss: 0.1234 - accuracy: 0.9334\n",
      "4841/5349 [==========================>...] - ETA: 0s - loss: 0.1234 - accuracy: 0.9334\n",
      "4956/5349 [==========================>...] - ETA: 0s - loss: 0.1235 - accuracy: 0.9334\n",
      "5064/5349 [===========================>..] - ETA: 0s - loss: 0.1233 - accuracy: 0.9335\n",
      "5184/5349 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9334\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9334\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1234 - accuracy: 0.9335 - val_loss: 0.1221 - val_accuracy: 0.9350\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 8s - loss: 0.0976 - accuracy: 0.9500\n",
      "  81/5349 [..............................] - ETA: 6s - loss: 0.1197 - accuracy: 0.9353\n",
      " 169/5349 [..............................] - ETA: 6s - loss: 0.1203 - accuracy: 0.9350\n",
      " 224/5349 [>.............................] - ETA: 7s - loss: 0.1220 - accuracy: 0.9337\n",
      " 311/5349 [>.............................] - ETA: 6s - loss: 0.1220 - accuracy: 0.9341\n",
      " 401/5349 [=>............................] - ETA: 6s - loss: 0.1218 - accuracy: 0.9350\n",
      " 499/5349 [=>............................] - ETA: 5s - loss: 0.1217 - accuracy: 0.9346\n",
      " 602/5349 [==>...........................] - ETA: 5s - loss: 0.1212 - accuracy: 0.9351\n",
      " 663/5349 [==>...........................] - ETA: 5s - loss: 0.1213 - accuracy: 0.9349\n",
      " 784/5349 [===>..........................] - ETA: 5s - loss: 0.1211 - accuracy: 0.9348\n",
      " 899/5349 [====>.........................] - ETA: 4s - loss: 0.1217 - accuracy: 0.9342\n",
      "1017/5349 [====>.........................] - ETA: 4s - loss: 0.1219 - accuracy: 0.9340\n",
      "1130/5349 [=====>........................] - ETA: 4s - loss: 0.1222 - accuracy: 0.9337\n",
      "1250/5349 [======>.......................] - ETA: 4s - loss: 0.1220 - accuracy: 0.9341\n",
      "1369/5349 [======>.......................] - ETA: 3s - loss: 0.1215 - accuracy: 0.9342\n",
      "1489/5349 [=======>......................] - ETA: 3s - loss: 0.1221 - accuracy: 0.9340\n",
      "1660/5349 [========>.....................] - ETA: 3s - loss: 0.1219 - accuracy: 0.9340\n",
      "1782/5349 [========>.....................] - ETA: 3s - loss: 0.1220 - accuracy: 0.9340\n",
      "1899/5349 [=========>....................] - ETA: 3s - loss: 0.1218 - accuracy: 0.9340\n",
      "2019/5349 [==========>...................] - ETA: 3s - loss: 0.1216 - accuracy: 0.9341\n",
      "2137/5349 [==========>...................] - ETA: 3s - loss: 0.1219 - accuracy: 0.9338\n",
      "2251/5349 [===========>..................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9339\n",
      "2355/5349 [============>.................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9339\n",
      "2474/5349 [============>.................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9340\n",
      "2590/5349 [=============>................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9339\n",
      "2710/5349 [==============>...............] - ETA: 2s - loss: 0.1218 - accuracy: 0.9340\n",
      "2883/5349 [===============>..............] - ETA: 2s - loss: 0.1217 - accuracy: 0.9341\n",
      "3004/5349 [===============>..............] - ETA: 2s - loss: 0.1216 - accuracy: 0.9342\n",
      "3122/5349 [================>.............] - ETA: 2s - loss: 0.1216 - accuracy: 0.9342\n",
      "3242/5349 [=================>............] - ETA: 1s - loss: 0.1215 - accuracy: 0.9343\n",
      "3349/5349 [=================>............] - ETA: 1s - loss: 0.1213 - accuracy: 0.9344\n",
      "3436/5349 [==================>...........] - ETA: 1s - loss: 0.1214 - accuracy: 0.9344\n",
      "3531/5349 [==================>...........] - ETA: 1s - loss: 0.1214 - accuracy: 0.9343\n",
      "3644/5349 [===================>..........] - ETA: 1s - loss: 0.1214 - accuracy: 0.9344\n",
      "3808/5349 [====================>.........] - ETA: 1s - loss: 0.1214 - accuracy: 0.9344\n",
      "3920/5349 [====================>.........] - ETA: 1s - loss: 0.1214 - accuracy: 0.9344\n",
      "4036/5349 [=====================>........] - ETA: 1s - loss: 0.1213 - accuracy: 0.9345\n",
      "4156/5349 [======================>.......] - ETA: 1s - loss: 0.1213 - accuracy: 0.9344\n",
      "4263/5349 [======================>.......] - ETA: 1s - loss: 0.1211 - accuracy: 0.9345\n",
      "4378/5349 [=======================>......] - ETA: 0s - loss: 0.1211 - accuracy: 0.9345\n",
      "4425/5349 [=======================>......] - ETA: 0s - loss: 0.1212 - accuracy: 0.9344\n",
      "4543/5349 [========================>.....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9346\n",
      "4666/5349 [=========================>....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9346\n",
      "4782/5349 [=========================>....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9346\n",
      "4890/5349 [==========================>...] - ETA: 0s - loss: 0.1209 - accuracy: 0.9346\n",
      "4989/5349 [==========================>...] - ETA: 0s - loss: 0.1209 - accuracy: 0.9347\n",
      "5103/5349 [===========================>..] - ETA: 0s - loss: 0.1208 - accuracy: 0.9347\n",
      "5221/5349 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9347\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9346\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1208 - accuracy: 0.9346 - val_loss: 0.1243 - val_accuracy: 0.9329\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 6/20\n",
      "  62/5349 [..............................] - ETA: 4s - loss: 0.1192 - accuracy: 0.9339\n",
      " 186/5349 [>.............................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9347\n",
      " 308/5349 [>.............................] - ETA: 4s - loss: 0.1192 - accuracy: 0.9344\n",
      " 424/5349 [=>............................] - ETA: 4s - loss: 0.1199 - accuracy: 0.9351\n",
      " 535/5349 [==>...........................] - ETA: 4s - loss: 0.1199 - accuracy: 0.9352\n",
      " 651/5349 [==>...........................] - ETA: 4s - loss: 0.1197 - accuracy: 0.9349\n",
      " 712/5349 [==>...........................] - ETA: 3s - loss: 0.1198 - accuracy: 0.9348\n",
      " 831/5349 [===>..........................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9351\n",
      " 947/5349 [====>.........................] - ETA: 3s - loss: 0.1192 - accuracy: 0.9348\n",
      "1070/5349 [=====>........................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9350\n",
      "1173/5349 [=====>........................] - ETA: 3s - loss: 0.1188 - accuracy: 0.9351\n",
      "1293/5349 [======>.......................] - ETA: 3s - loss: 0.1189 - accuracy: 0.9351\n",
      "1412/5349 [======>.......................] - ETA: 3s - loss: 0.1188 - accuracy: 0.9352\n",
      "1535/5349 [=======>......................] - ETA: 3s - loss: 0.1188 - accuracy: 0.9354\n",
      "1652/5349 [========>.....................] - ETA: 3s - loss: 0.1187 - accuracy: 0.9354\n",
      "1776/5349 [========>.....................] - ETA: 3s - loss: 0.1186 - accuracy: 0.9355\n",
      "1952/5349 [=========>....................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9356\n",
      "2072/5349 [==========>...................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9357\n",
      "2181/5349 [===========>..................] - ETA: 2s - loss: 0.1187 - accuracy: 0.9356\n",
      "2286/5349 [===========>..................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9354\n",
      "2402/5349 [============>.................] - ETA: 2s - loss: 0.1190 - accuracy: 0.9353\n",
      "2523/5349 [=============>................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9352\n",
      "2639/5349 [=============>................] - ETA: 2s - loss: 0.1190 - accuracy: 0.9353\n",
      "2760/5349 [==============>...............] - ETA: 2s - loss: 0.1191 - accuracy: 0.9354\n",
      "2864/5349 [===============>..............] - ETA: 2s - loss: 0.1192 - accuracy: 0.9353\n",
      "3045/5349 [================>.............] - ETA: 1s - loss: 0.1193 - accuracy: 0.9353\n",
      "3158/5349 [================>.............] - ETA: 1s - loss: 0.1193 - accuracy: 0.9353\n",
      "3281/5349 [=================>............] - ETA: 1s - loss: 0.1194 - accuracy: 0.9354\n",
      "3400/5349 [==================>...........] - ETA: 1s - loss: 0.1192 - accuracy: 0.9355\n",
      "3517/5349 [==================>...........] - ETA: 1s - loss: 0.1193 - accuracy: 0.9354\n",
      "3634/5349 [===================>..........] - ETA: 1s - loss: 0.1193 - accuracy: 0.9353\n",
      "3756/5349 [====================>.........] - ETA: 1s - loss: 0.1193 - accuracy: 0.9354\n",
      "3873/5349 [====================>.........] - ETA: 1s - loss: 0.1192 - accuracy: 0.9354\n",
      "3995/5349 [=====================>........] - ETA: 1s - loss: 0.1193 - accuracy: 0.9353\n",
      "4114/5349 [======================>.......] - ETA: 1s - loss: 0.1192 - accuracy: 0.9354\n",
      "4171/5349 [======================>.......] - ETA: 1s - loss: 0.1193 - accuracy: 0.9353\n",
      "4264/5349 [======================>.......] - ETA: 0s - loss: 0.1192 - accuracy: 0.9354\n",
      "4357/5349 [=======================>......] - ETA: 0s - loss: 0.1191 - accuracy: 0.9354\n",
      "4461/5349 [========================>.....] - ETA: 0s - loss: 0.1191 - accuracy: 0.9354\n",
      "4551/5349 [========================>.....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9355\n",
      "4645/5349 [=========================>....] - ETA: 0s - loss: 0.1189 - accuracy: 0.9354\n",
      "4743/5349 [=========================>....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9355\n",
      "4847/5349 [==========================>...] - ETA: 0s - loss: 0.1189 - accuracy: 0.9355\n",
      "4945/5349 [==========================>...] - ETA: 0s - loss: 0.1189 - accuracy: 0.9354\n",
      "5075/5349 [===========================>..] - ETA: 0s - loss: 0.1188 - accuracy: 0.9354\n",
      "5128/5349 [===========================>..] - ETA: 0s - loss: 0.1190 - accuracy: 0.9354\n",
      "5220/5349 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.9354\n",
      "5318/5349 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.9354\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1189 - accuracy: 0.9354 - val_loss: 0.1176 - val_accuracy: 0.9370\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 7/20\n",
      "  59/5349 [..............................] - ETA: 4s - loss: 0.1189 - accuracy: 0.9349\n",
      " 180/5349 [>.............................] - ETA: 4s - loss: 0.1186 - accuracy: 0.9360\n",
      " 301/5349 [>.............................] - ETA: 4s - loss: 0.1188 - accuracy: 0.9353\n",
      " 415/5349 [=>............................] - ETA: 4s - loss: 0.1176 - accuracy: 0.9362\n",
      " 537/5349 [==>...........................] - ETA: 4s - loss: 0.1185 - accuracy: 0.9352\n",
      " 639/5349 [==>...........................] - ETA: 4s - loss: 0.1181 - accuracy: 0.9354\n",
      " 699/5349 [==>...........................] - ETA: 4s - loss: 0.1183 - accuracy: 0.9352\n",
      " 821/5349 [===>..........................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9355\n",
      " 942/5349 [====>.........................] - ETA: 3s - loss: 0.1176 - accuracy: 0.9358\n",
      "1057/5349 [====>.........................] - ETA: 3s - loss: 0.1175 - accuracy: 0.9361\n",
      "1174/5349 [=====>........................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9360\n",
      "1294/5349 [======>.......................] - ETA: 3s - loss: 0.1176 - accuracy: 0.9361\n",
      "1411/5349 [======>.......................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9359\n",
      "1531/5349 [=======>......................] - ETA: 3s - loss: 0.1176 - accuracy: 0.9360\n",
      "1644/5349 [========>.....................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9360\n",
      "1736/5349 [========>.....................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9359\n",
      "1835/5349 [=========>....................] - ETA: 3s - loss: 0.1179 - accuracy: 0.9359\n",
      "1895/5349 [=========>....................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9360\n",
      "2016/5349 [==========>...................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9362\n",
      "2128/5349 [==========>...................] - ETA: 2s - loss: 0.1177 - accuracy: 0.9363\n",
      "2242/5349 [===========>..................] - ETA: 2s - loss: 0.1177 - accuracy: 0.9364\n",
      "2356/5349 [============>.................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9365\n",
      "2473/5349 [============>.................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9364\n",
      "2592/5349 [=============>................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9363\n",
      "2705/5349 [==============>...............] - ETA: 2s - loss: 0.1174 - accuracy: 0.9363\n",
      "2870/5349 [===============>..............] - ETA: 2s - loss: 0.1175 - accuracy: 0.9361\n",
      "2989/5349 [===============>..............] - ETA: 2s - loss: 0.1174 - accuracy: 0.9362\n",
      "3102/5349 [================>.............] - ETA: 1s - loss: 0.1175 - accuracy: 0.9363\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1176 - accuracy: 0.9362\n",
      "3333/5349 [=================>............] - ETA: 1s - loss: 0.1175 - accuracy: 0.9363\n",
      "3451/5349 [==================>...........] - ETA: 1s - loss: 0.1175 - accuracy: 0.9363\n",
      "3570/5349 [===================>..........] - ETA: 1s - loss: 0.1175 - accuracy: 0.9364\n",
      "3678/5349 [===================>..........] - ETA: 1s - loss: 0.1176 - accuracy: 0.9362\n",
      "3797/5349 [====================>.........] - ETA: 1s - loss: 0.1176 - accuracy: 0.9362\n",
      "3912/5349 [====================>.........] - ETA: 1s - loss: 0.1177 - accuracy: 0.9362\n",
      "4083/5349 [=====================>........] - ETA: 1s - loss: 0.1177 - accuracy: 0.9361\n",
      "4201/5349 [======================>.......] - ETA: 1s - loss: 0.1178 - accuracy: 0.9361\n",
      "4313/5349 [=======================>......] - ETA: 0s - loss: 0.1177 - accuracy: 0.9361\n",
      "4426/5349 [=======================>......] - ETA: 0s - loss: 0.1177 - accuracy: 0.9361\n",
      "4533/5349 [========================>.....] - ETA: 0s - loss: 0.1177 - accuracy: 0.9361\n",
      "4647/5349 [=========================>....] - ETA: 0s - loss: 0.1178 - accuracy: 0.9360\n",
      "4754/5349 [=========================>....] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "4874/5349 [==========================>...] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "4990/5349 [==========================>...] - ETA: 0s - loss: 0.1178 - accuracy: 0.9361\n",
      "5163/5349 [===========================>..] - ETA: 0s - loss: 0.1177 - accuracy: 0.9361\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9360\n",
      "5328/5349 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9360\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1177 - accuracy: 0.9360 - val_loss: 0.1220 - val_accuracy: 0.9330\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1464 - accuracy: 0.9100\n",
      " 123/5349 [..............................] - ETA: 4s - loss: 0.1203 - accuracy: 0.9345\n",
      " 245/5349 [>.............................] - ETA: 4s - loss: 0.1189 - accuracy: 0.9358\n",
      " 363/5349 [=>............................] - ETA: 4s - loss: 0.1183 - accuracy: 0.9365\n",
      " 484/5349 [=>............................] - ETA: 4s - loss: 0.1176 - accuracy: 0.9360\n",
      " 601/5349 [==>...........................] - ETA: 3s - loss: 0.1166 - accuracy: 0.9369\n",
      " 725/5349 [===>..........................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9371\n",
      " 837/5349 [===>..........................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9371\n",
      " 958/5349 [====>.........................] - ETA: 3s - loss: 0.1161 - accuracy: 0.9370\n",
      "1077/5349 [=====>........................] - ETA: 3s - loss: 0.1165 - accuracy: 0.9367\n",
      "1239/5349 [=====>........................] - ETA: 3s - loss: 0.1162 - accuracy: 0.9370\n",
      "1360/5349 [======>.......................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9370\n",
      "1475/5349 [=======>......................] - ETA: 3s - loss: 0.1165 - accuracy: 0.9367\n",
      "1593/5349 [=======>......................] - ETA: 3s - loss: 0.1166 - accuracy: 0.9368\n",
      "1711/5349 [========>.....................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9366\n",
      "1829/5349 [=========>....................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9363\n",
      "1947/5349 [=========>....................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9359\n",
      "2052/5349 [==========>...................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9361\n",
      "2170/5349 [===========>..................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9361\n",
      "2289/5349 [===========>..................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9363\n",
      "2408/5349 [============>.................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9364\n",
      "2467/5349 [============>.................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9366\n",
      "2583/5349 [=============>................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9366\n",
      "2673/5349 [=============>................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9367\n",
      "2767/5349 [==============>...............] - ETA: 2s - loss: 0.1163 - accuracy: 0.9366\n",
      "2854/5349 [===============>..............] - ETA: 2s - loss: 0.1163 - accuracy: 0.9366\n",
      "2952/5349 [===============>..............] - ETA: 2s - loss: 0.1162 - accuracy: 0.9366\n",
      "3038/5349 [================>.............] - ETA: 2s - loss: 0.1161 - accuracy: 0.9366\n",
      "3137/5349 [================>.............] - ETA: 1s - loss: 0.1161 - accuracy: 0.9367\n",
      "3285/5349 [=================>............] - ETA: 1s - loss: 0.1162 - accuracy: 0.9367\n",
      "3384/5349 [=================>............] - ETA: 1s - loss: 0.1162 - accuracy: 0.9367\n",
      "3457/5349 [==================>...........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9366\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9366\n",
      "3631/5349 [===================>..........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9365\n",
      "3729/5349 [===================>..........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9365\n",
      "3846/5349 [====================>.........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9365\n",
      "4021/5349 [=====================>........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9364\n",
      "4135/5349 [======================>.......] - ETA: 1s - loss: 0.1163 - accuracy: 0.9364\n",
      "4250/5349 [======================>.......] - ETA: 1s - loss: 0.1164 - accuracy: 0.9365\n",
      "4358/5349 [=======================>......] - ETA: 0s - loss: 0.1165 - accuracy: 0.9364\n",
      "4475/5349 [========================>.....] - ETA: 0s - loss: 0.1164 - accuracy: 0.9365\n",
      "4592/5349 [========================>.....] - ETA: 0s - loss: 0.1164 - accuracy: 0.9365\n",
      "4709/5349 [=========================>....] - ETA: 0s - loss: 0.1163 - accuracy: 0.9366\n",
      "4825/5349 [==========================>...] - ETA: 0s - loss: 0.1163 - accuracy: 0.9367\n",
      "4942/5349 [==========================>...] - ETA: 0s - loss: 0.1164 - accuracy: 0.9366\n",
      "5059/5349 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.9366\n",
      "5165/5349 [===========================>..] - ETA: 0s - loss: 0.1165 - accuracy: 0.9365\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9365\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1166 - accuracy: 0.9365 - val_loss: 0.1213 - val_accuracy: 0.9344\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.0995 - accuracy: 0.9500\n",
      " 121/5349 [..............................] - ETA: 4s - loss: 0.1166 - accuracy: 0.9357\n",
      " 235/5349 [>.............................] - ETA: 4s - loss: 0.1143 - accuracy: 0.9356\n",
      " 354/5349 [>.............................] - ETA: 4s - loss: 0.1141 - accuracy: 0.9372\n",
      " 461/5349 [=>............................] - ETA: 4s - loss: 0.1140 - accuracy: 0.9378\n",
      " 581/5349 [==>...........................] - ETA: 4s - loss: 0.1144 - accuracy: 0.9375\n",
      " 760/5349 [===>..........................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9374\n",
      " 880/5349 [===>..........................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9377\n",
      " 993/5349 [====>.........................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9377\n",
      "1108/5349 [=====>........................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9374\n",
      "1213/5349 [=====>........................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9373\n",
      "1310/5349 [======>.......................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9374\n",
      "1366/5349 [======>.......................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9375\n",
      "1474/5349 [=======>......................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9373\n",
      "1585/5349 [=======>......................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9372\n",
      "1690/5349 [========>.....................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9371\n",
      "1801/5349 [=========>....................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9371\n",
      "1914/5349 [=========>....................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9371\n",
      "2022/5349 [==========>...................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9369\n",
      "2118/5349 [==========>...................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9369\n",
      "2229/5349 [===========>..................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9370\n",
      "2401/5349 [============>.................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9368\n",
      "2518/5349 [=============>................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9366\n",
      "2628/5349 [=============>................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9367\n",
      "2743/5349 [==============>...............] - ETA: 2s - loss: 0.1162 - accuracy: 0.9366\n",
      "2862/5349 [===============>..............] - ETA: 2s - loss: 0.1163 - accuracy: 0.9365\n",
      "2971/5349 [===============>..............] - ETA: 2s - loss: 0.1163 - accuracy: 0.9364\n",
      "3091/5349 [================>.............] - ETA: 2s - loss: 0.1162 - accuracy: 0.9365\n",
      "3262/5349 [=================>............] - ETA: 1s - loss: 0.1159 - accuracy: 0.9367\n",
      "3380/5349 [=================>............] - ETA: 1s - loss: 0.1160 - accuracy: 0.9368\n",
      "3499/5349 [==================>...........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9369\n",
      "3615/5349 [===================>..........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9368\n",
      "3721/5349 [===================>..........] - ETA: 1s - loss: 0.1157 - accuracy: 0.9369\n",
      "3823/5349 [====================>.........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9369\n",
      "3939/5349 [=====================>........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9368\n",
      "4056/5349 [=====================>........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9368\n",
      "4175/5349 [======================>.......] - ETA: 1s - loss: 0.1158 - accuracy: 0.9367\n",
      "4293/5349 [=======================>......] - ETA: 0s - loss: 0.1158 - accuracy: 0.9367\n",
      "4405/5349 [=======================>......] - ETA: 0s - loss: 0.1158 - accuracy: 0.9367\n",
      "4521/5349 [========================>.....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9366\n",
      "4577/5349 [========================>.....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9366\n",
      "4691/5349 [=========================>....] - ETA: 0s - loss: 0.1159 - accuracy: 0.9366\n",
      "4804/5349 [=========================>....] - ETA: 0s - loss: 0.1159 - accuracy: 0.9366\n",
      "4920/5349 [==========================>...] - ETA: 0s - loss: 0.1158 - accuracy: 0.9366\n",
      "5031/5349 [===========================>..] - ETA: 0s - loss: 0.1157 - accuracy: 0.9366\n",
      "5148/5349 [===========================>..] - ETA: 0s - loss: 0.1159 - accuracy: 0.9366\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9366\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1158 - accuracy: 0.9366 - val_loss: 0.1310 - val_accuracy: 0.9277\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1141 - accuracy: 0.9200\n",
      " 122/5349 [..............................] - ETA: 4s - loss: 0.1161 - accuracy: 0.9372\n",
      " 239/5349 [>.............................] - ETA: 4s - loss: 0.1168 - accuracy: 0.9372\n",
      " 358/5349 [=>............................] - ETA: 4s - loss: 0.1169 - accuracy: 0.9357\n",
      " 541/5349 [==>...........................] - ETA: 4s - loss: 0.1174 - accuracy: 0.9357\n",
      " 660/5349 [==>...........................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9358\n",
      " 780/5349 [===>..........................] - ETA: 3s - loss: 0.1173 - accuracy: 0.9361\n",
      " 872/5349 [===>..........................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9362\n",
      " 969/5349 [====>.........................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9362\n",
      "1060/5349 [====>.........................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9364\n",
      "1161/5349 [=====>........................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9363\n",
      "1194/5349 [=====>........................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9363\n",
      "1262/5349 [======>.......................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9364\n",
      "1343/5349 [======>.......................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9361\n",
      "1413/5349 [======>.......................] - ETA: 3s - loss: 0.1171 - accuracy: 0.9359\n",
      "1518/5349 [=======>......................] - ETA: 3s - loss: 0.1169 - accuracy: 0.9361\n",
      "1607/5349 [========>.....................] - ETA: 3s - loss: 0.1169 - accuracy: 0.9360\n",
      "1695/5349 [========>.....................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9361\n",
      "1803/5349 [=========>....................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9361\n",
      "1907/5349 [=========>....................] - ETA: 3s - loss: 0.1166 - accuracy: 0.9361\n",
      "2007/5349 [==========>...................] - ETA: 3s - loss: 0.1165 - accuracy: 0.9363\n",
      "2117/5349 [==========>...................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9364\n",
      "2232/5349 [===========>..................] - ETA: 3s - loss: 0.1160 - accuracy: 0.9365\n",
      "2353/5349 [============>.................] - ETA: 3s - loss: 0.1160 - accuracy: 0.9364\n",
      "2468/5349 [============>.................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9363\n",
      "2586/5349 [=============>................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9363\n",
      "2699/5349 [==============>...............] - ETA: 2s - loss: 0.1161 - accuracy: 0.9363\n",
      "2879/5349 [===============>..............] - ETA: 2s - loss: 0.1159 - accuracy: 0.9366\n",
      "2995/5349 [===============>..............] - ETA: 2s - loss: 0.1159 - accuracy: 0.9365\n",
      "3117/5349 [================>.............] - ETA: 2s - loss: 0.1157 - accuracy: 0.9368\n",
      "3230/5349 [=================>............] - ETA: 2s - loss: 0.1157 - accuracy: 0.9368\n",
      "3350/5349 [=================>............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9369\n",
      "3466/5349 [==================>...........] - ETA: 1s - loss: 0.1154 - accuracy: 0.9370\n",
      "3588/5349 [===================>..........] - ETA: 1s - loss: 0.1154 - accuracy: 0.9370\n",
      "3704/5349 [===================>..........] - ETA: 1s - loss: 0.1154 - accuracy: 0.9370\n",
      "3823/5349 [====================>.........] - ETA: 1s - loss: 0.1155 - accuracy: 0.9370\n",
      "3936/5349 [=====================>........] - ETA: 1s - loss: 0.1155 - accuracy: 0.9369\n",
      "4056/5349 [=====================>........] - ETA: 1s - loss: 0.1155 - accuracy: 0.9369\n",
      "4117/5349 [======================>.......] - ETA: 1s - loss: 0.1155 - accuracy: 0.9368\n",
      "4235/5349 [======================>.......] - ETA: 1s - loss: 0.1155 - accuracy: 0.9369\n",
      "4356/5349 [=======================>......] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "4469/5349 [========================>.....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9369\n",
      "4592/5349 [========================>.....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "4695/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "4793/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "4896/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "5013/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "5126/5349 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9371\n",
      "5240/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9370\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1153 - accuracy: 0.9370 - val_loss: 0.1132 - val_accuracy: 0.9382\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1346 - accuracy: 0.9000\n",
      " 123/5349 [..............................] - ETA: 4s - loss: 0.1111 - accuracy: 0.9421\n",
      " 246/5349 [>.............................] - ETA: 4s - loss: 0.1156 - accuracy: 0.9378\n",
      " 360/5349 [=>............................] - ETA: 4s - loss: 0.1151 - accuracy: 0.9379\n",
      " 483/5349 [=>............................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9380\n",
      " 597/5349 [==>...........................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9375\n",
      " 720/5349 [===>..........................] - ETA: 3s - loss: 0.1161 - accuracy: 0.9367\n",
      " 837/5349 [===>..........................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9372\n",
      " 959/5349 [====>.........................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9369\n",
      "1078/5349 [=====>........................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9367\n",
      "1202/5349 [=====>........................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9371\n",
      "1319/5349 [======>.......................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9372\n",
      "1378/5349 [======>.......................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9374\n",
      "1495/5349 [=======>......................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9372\n",
      "1616/5349 [========>.....................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9374\n",
      "1738/5349 [========>.....................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9377\n",
      "1840/5349 [=========>....................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9377\n",
      "1962/5349 [==========>...................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9374\n",
      "2070/5349 [==========>...................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9375\n",
      "2193/5349 [===========>..................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9373\n",
      "2309/5349 [===========>..................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9371\n",
      "2433/5349 [============>.................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9372\n",
      "2607/5349 [=============>................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9373\n",
      "2729/5349 [==============>...............] - ETA: 2s - loss: 0.1148 - accuracy: 0.9375\n",
      "2845/5349 [==============>...............] - ETA: 2s - loss: 0.1148 - accuracy: 0.9375\n",
      "2967/5349 [===============>..............] - ETA: 2s - loss: 0.1146 - accuracy: 0.9376\n",
      "3085/5349 [================>.............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9376\n",
      "3202/5349 [================>.............] - ETA: 1s - loss: 0.1146 - accuracy: 0.9376\n",
      "3315/5349 [=================>............] - ETA: 1s - loss: 0.1147 - accuracy: 0.9375\n",
      "3438/5349 [==================>...........] - ETA: 1s - loss: 0.1147 - accuracy: 0.9375\n",
      "3605/5349 [===================>..........] - ETA: 1s - loss: 0.1147 - accuracy: 0.9375\n",
      "3724/5349 [===================>..........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9375\n",
      "3837/5349 [====================>.........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9375\n",
      "3961/5349 [=====================>........] - ETA: 1s - loss: 0.1144 - accuracy: 0.9376\n",
      "4076/5349 [=====================>........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9375\n",
      "4194/5349 [======================>.......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9375\n",
      "4309/5349 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9375\n",
      "4429/5349 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9375\n",
      "4610/5349 [========================>.....] - ETA: 0s - loss: 0.1145 - accuracy: 0.9375\n",
      "4734/5349 [=========================>....] - ETA: 0s - loss: 0.1145 - accuracy: 0.9376\n",
      "4854/5349 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9377\n",
      "4974/5349 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9377\n",
      "5083/5349 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9377\n",
      "5205/5349 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9377\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.9377\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1143 - accuracy: 0.9377 - val_loss: 0.2750 - val_accuracy: 0.9065\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 12/20\n",
      "  34/5349 [..............................] - ETA: 8s - loss: 0.1133 - accuracy: 0.9388 \n",
      "  86/5349 [..............................] - ETA: 9s - loss: 0.1112 - accuracy: 0.9407 \n",
      " 179/5349 [>.............................] - ETA: 7s - loss: 0.1122 - accuracy: 0.9392\n",
      " 259/5349 [>.............................] - ETA: 7s - loss: 0.1136 - accuracy: 0.9373\n",
      " 357/5349 [=>............................] - ETA: 6s - loss: 0.1126 - accuracy: 0.9384\n",
      " 472/5349 [=>............................] - ETA: 5s - loss: 0.1126 - accuracy: 0.9393\n",
      " 594/5349 [==>...........................] - ETA: 5s - loss: 0.1124 - accuracy: 0.9389\n",
      " 708/5349 [==>...........................] - ETA: 5s - loss: 0.1121 - accuracy: 0.9388\n",
      " 888/5349 [===>..........................] - ETA: 4s - loss: 0.1128 - accuracy: 0.9385\n",
      "1008/5349 [====>.........................] - ETA: 4s - loss: 0.1131 - accuracy: 0.9380\n",
      "1128/5349 [=====>........................] - ETA: 4s - loss: 0.1133 - accuracy: 0.9377\n",
      "1236/5349 [=====>........................] - ETA: 4s - loss: 0.1138 - accuracy: 0.9374\n",
      "1358/5349 [======>.......................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9376\n",
      "1475/5349 [=======>......................] - ETA: 3s - loss: 0.1141 - accuracy: 0.9375\n",
      "1595/5349 [=======>......................] - ETA: 3s - loss: 0.1141 - accuracy: 0.9375\n",
      "1705/5349 [========>.....................] - ETA: 3s - loss: 0.1140 - accuracy: 0.9377\n",
      "1885/5349 [=========>....................] - ETA: 3s - loss: 0.1143 - accuracy: 0.9375\n",
      "2005/5349 [==========>...................] - ETA: 3s - loss: 0.1140 - accuracy: 0.9375\n",
      "2127/5349 [==========>...................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9377\n",
      "2237/5349 [===========>..................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9375\n",
      "2359/5349 [============>.................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9376\n",
      "2478/5349 [============>.................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9376\n",
      "2599/5349 [=============>................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9376\n",
      "2717/5349 [==============>...............] - ETA: 2s - loss: 0.1140 - accuracy: 0.9376\n",
      "2832/5349 [==============>...............] - ETA: 2s - loss: 0.1140 - accuracy: 0.9377\n",
      "2886/5349 [===============>..............] - ETA: 2s - loss: 0.1141 - accuracy: 0.9375\n",
      "2985/5349 [===============>..............] - ETA: 2s - loss: 0.1141 - accuracy: 0.9375\n",
      "3107/5349 [================>.............] - ETA: 2s - loss: 0.1141 - accuracy: 0.9376\n",
      "3225/5349 [=================>............] - ETA: 1s - loss: 0.1140 - accuracy: 0.9376\n",
      "3339/5349 [=================>............] - ETA: 1s - loss: 0.1139 - accuracy: 0.9377\n",
      "3457/5349 [==================>...........] - ETA: 1s - loss: 0.1140 - accuracy: 0.9376\n",
      "3576/5349 [===================>..........] - ETA: 1s - loss: 0.1140 - accuracy: 0.9377\n",
      "3689/5349 [===================>..........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9377\n",
      "3810/5349 [====================>.........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9377\n",
      "3924/5349 [=====================>........] - ETA: 1s - loss: 0.1140 - accuracy: 0.9377\n",
      "4046/5349 [=====================>........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9376\n",
      "4159/5349 [======================>.......] - ETA: 1s - loss: 0.1141 - accuracy: 0.9377\n",
      "4338/5349 [=======================>......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9377\n",
      "4446/5349 [=======================>......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9377\n",
      "4564/5349 [========================>.....] - ETA: 0s - loss: 0.1141 - accuracy: 0.9376\n",
      "4681/5349 [=========================>....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9376\n",
      "4802/5349 [=========================>....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9376\n",
      "4917/5349 [==========================>...] - ETA: 0s - loss: 0.1141 - accuracy: 0.9376\n",
      "5040/5349 [===========================>..] - ETA: 0s - loss: 0.1140 - accuracy: 0.9376\n",
      "5151/5349 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.9376\n",
      "5269/5349 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9376\n",
      "5327/5349 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9376\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1139 - accuracy: 0.9376 - val_loss: 0.1177 - val_accuracy: 0.9359\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1033 - accuracy: 0.9500\n",
      " 118/5349 [..............................] - ETA: 4s - loss: 0.1178 - accuracy: 0.9349\n",
      " 180/5349 [>.............................] - ETA: 4s - loss: 0.1177 - accuracy: 0.9352\n",
      " 292/5349 [>.............................] - ETA: 4s - loss: 0.1166 - accuracy: 0.9367\n",
      " 399/5349 [=>............................] - ETA: 4s - loss: 0.1159 - accuracy: 0.9369\n",
      " 522/5349 [=>............................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9378\n",
      " 618/5349 [==>...........................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9375\n",
      " 739/5349 [===>..........................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9378\n",
      " 852/5349 [===>..........................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9375\n",
      " 975/5349 [====>.........................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9375\n",
      "1152/5349 [=====>........................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9375\n",
      "1270/5349 [======>.......................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9375\n",
      "1383/5349 [======>.......................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9375\n",
      "1502/5349 [=======>......................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9373\n",
      "1617/5349 [========>.....................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9376\n",
      "1737/5349 [========>.....................] - ETA: 3s - loss: 0.1146 - accuracy: 0.9378\n",
      "1854/5349 [=========>....................] - ETA: 3s - loss: 0.1143 - accuracy: 0.9380\n",
      "1976/5349 [==========>...................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9381\n",
      "2079/5349 [==========>...................] - ETA: 2s - loss: 0.1141 - accuracy: 0.9382\n",
      "2202/5349 [===========>..................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9384\n",
      "2263/5349 [===========>..................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9383\n",
      "2383/5349 [============>.................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9383\n",
      "2505/5349 [=============>................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9383\n",
      "2612/5349 [=============>................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9382\n",
      "2733/5349 [==============>...............] - ETA: 2s - loss: 0.1139 - accuracy: 0.9381\n",
      "2847/5349 [==============>...............] - ETA: 2s - loss: 0.1139 - accuracy: 0.9380\n",
      "2969/5349 [===============>..............] - ETA: 2s - loss: 0.1139 - accuracy: 0.9379\n",
      "3089/5349 [================>.............] - ETA: 1s - loss: 0.1138 - accuracy: 0.9380\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.1138 - accuracy: 0.9381\n",
      "3321/5349 [=================>............] - ETA: 1s - loss: 0.1137 - accuracy: 0.9382\n",
      "3443/5349 [==================>...........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9381\n",
      "3492/5349 [==================>...........] - ETA: 1s - loss: 0.1139 - accuracy: 0.9380\n",
      "3611/5349 [===================>..........] - ETA: 1s - loss: 0.1138 - accuracy: 0.9380\n",
      "3731/5349 [===================>..........] - ETA: 1s - loss: 0.1138 - accuracy: 0.9381\n",
      "3847/5349 [====================>.........] - ETA: 1s - loss: 0.1138 - accuracy: 0.9381\n",
      "3970/5349 [=====================>........] - ETA: 1s - loss: 0.1138 - accuracy: 0.9381\n",
      "4078/5349 [=====================>........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9382\n",
      "4169/5349 [======================>.......] - ETA: 1s - loss: 0.1138 - accuracy: 0.9381\n",
      "4255/5349 [======================>.......] - ETA: 0s - loss: 0.1137 - accuracy: 0.9382\n",
      "4349/5349 [=======================>......] - ETA: 0s - loss: 0.1138 - accuracy: 0.9381\n",
      "4451/5349 [=======================>......] - ETA: 0s - loss: 0.1139 - accuracy: 0.9382\n",
      "4552/5349 [========================>.....] - ETA: 0s - loss: 0.1139 - accuracy: 0.9381\n",
      "4684/5349 [=========================>....] - ETA: 0s - loss: 0.1139 - accuracy: 0.9381\n",
      "4782/5349 [=========================>....] - ETA: 0s - loss: 0.1138 - accuracy: 0.9382\n",
      "4879/5349 [==========================>...] - ETA: 0s - loss: 0.1138 - accuracy: 0.9382\n",
      "4984/5349 [==========================>...] - ETA: 0s - loss: 0.1137 - accuracy: 0.9383\n",
      "5067/5349 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9383\n",
      "5130/5349 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9383\n",
      "5204/5349 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9383\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9383\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9383\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1136 - accuracy: 0.9382 - val_loss: 0.1191 - val_accuracy: 0.9352\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 10s - loss: 0.1125 - accuracy: 0.9400\n",
      " 168/5349 [..............................] - ETA: 4s - loss: 0.1172 - accuracy: 0.9354\n",
      " 289/5349 [>.............................] - ETA: 4s - loss: 0.1161 - accuracy: 0.9360\n",
      " 399/5349 [=>............................] - ETA: 4s - loss: 0.1164 - accuracy: 0.9362\n",
      " 520/5349 [=>............................] - ETA: 4s - loss: 0.1166 - accuracy: 0.9354\n",
      " 635/5349 [==>...........................] - ETA: 4s - loss: 0.1157 - accuracy: 0.9359\n",
      " 755/5349 [===>..........................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9363\n",
      " 870/5349 [===>..........................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9368\n",
      " 984/5349 [====>.........................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9374\n",
      "1089/5349 [=====>........................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9371\n",
      "1270/5349 [======>.......................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9374\n",
      "1376/5349 [======>.......................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9376\n",
      "1494/5349 [=======>......................] - ETA: 3s - loss: 0.1139 - accuracy: 0.9378\n",
      "1604/5349 [=======>......................] - ETA: 3s - loss: 0.1140 - accuracy: 0.9377\n",
      "1720/5349 [========>.....................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9376\n",
      "1835/5349 [=========>....................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9376\n",
      "1927/5349 [=========>....................] - ETA: 3s - loss: 0.1141 - accuracy: 0.9376\n",
      "2024/5349 [==========>...................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9377\n",
      "2103/5349 [==========>...................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9377\n",
      "2215/5349 [===========>..................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9376\n",
      "2273/5349 [===========>..................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9377\n",
      "2391/5349 [============>.................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9377\n",
      "2508/5349 [=============>................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9378\n",
      "2609/5349 [=============>................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9380\n",
      "2717/5349 [==============>...............] - ETA: 2s - loss: 0.1135 - accuracy: 0.9380\n",
      "2835/5349 [==============>...............] - ETA: 2s - loss: 0.1135 - accuracy: 0.9380\n",
      "2943/5349 [===============>..............] - ETA: 2s - loss: 0.1136 - accuracy: 0.9380\n",
      "3053/5349 [================>.............] - ETA: 2s - loss: 0.1136 - accuracy: 0.9380\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1136 - accuracy: 0.9380\n",
      "3329/5349 [=================>............] - ETA: 1s - loss: 0.1136 - accuracy: 0.9380\n",
      "3432/5349 [==================>...........] - ETA: 1s - loss: 0.1137 - accuracy: 0.9380\n",
      "3544/5349 [==================>...........] - ETA: 1s - loss: 0.1136 - accuracy: 0.9381\n",
      "3645/5349 [===================>..........] - ETA: 1s - loss: 0.1135 - accuracy: 0.9381\n",
      "3739/5349 [===================>..........] - ETA: 1s - loss: 0.1134 - accuracy: 0.9382\n",
      "3852/5349 [====================>.........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9382\n",
      "3962/5349 [=====================>........] - ETA: 1s - loss: 0.1134 - accuracy: 0.9382\n",
      "4071/5349 [=====================>........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9381\n",
      "4224/5349 [======================>.......] - ETA: 1s - loss: 0.1134 - accuracy: 0.9381\n",
      "4338/5349 [=======================>......] - ETA: 0s - loss: 0.1133 - accuracy: 0.9383\n",
      "4454/5349 [=======================>......] - ETA: 0s - loss: 0.1132 - accuracy: 0.9383\n",
      "4565/5349 [========================>.....] - ETA: 0s - loss: 0.1133 - accuracy: 0.9383\n",
      "4685/5349 [=========================>....] - ETA: 0s - loss: 0.1133 - accuracy: 0.9382\n",
      "4807/5349 [=========================>....] - ETA: 0s - loss: 0.1133 - accuracy: 0.9383\n",
      "4918/5349 [==========================>...] - ETA: 0s - loss: 0.1133 - accuracy: 0.9383\n",
      "5086/5349 [===========================>..] - ETA: 0s - loss: 0.1132 - accuracy: 0.9384\n",
      "5188/5349 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9384\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9385\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1131 - accuracy: 0.9385 - val_loss: 0.1111 - val_accuracy: 0.9383\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 15/20\n",
      "  60/5349 [..............................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9380\n",
      " 243/5349 [>.............................] - ETA: 4s - loss: 0.1100 - accuracy: 0.9391\n",
      " 366/5349 [=>............................] - ETA: 4s - loss: 0.1108 - accuracy: 0.9388\n",
      " 473/5349 [=>............................] - ETA: 4s - loss: 0.1115 - accuracy: 0.9381\n",
      " 594/5349 [==>...........................] - ETA: 4s - loss: 0.1117 - accuracy: 0.9383\n",
      " 699/5349 [==>...........................] - ETA: 4s - loss: 0.1114 - accuracy: 0.9388\n",
      " 821/5349 [===>..........................] - ETA: 3s - loss: 0.1108 - accuracy: 0.9392\n",
      " 934/5349 [====>.........................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9391\n",
      "1058/5349 [====>.........................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9387\n",
      "1177/5349 [=====>........................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9384\n",
      "1293/5349 [======>.......................] - ETA: 3s - loss: 0.1115 - accuracy: 0.9385\n",
      "1414/5349 [======>.......................] - ETA: 3s - loss: 0.1118 - accuracy: 0.9385\n",
      "1600/5349 [=======>......................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9385\n",
      "1715/5349 [========>.....................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9385\n",
      "1828/5349 [=========>....................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9384\n",
      "1945/5349 [=========>....................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9384\n",
      "2063/5349 [==========>...................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9384\n",
      "2177/5349 [===========>..................] - ETA: 2s - loss: 0.1124 - accuracy: 0.9385\n",
      "2296/5349 [===========>..................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9385\n",
      "2401/5349 [============>.................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9387\n",
      "2524/5349 [=============>................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9387\n",
      "2641/5349 [=============>................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9388\n",
      "2701/5349 [==============>...............] - ETA: 2s - loss: 0.1123 - accuracy: 0.9387\n",
      "2824/5349 [==============>...............] - ETA: 2s - loss: 0.1126 - accuracy: 0.9385\n",
      "2937/5349 [===============>..............] - ETA: 2s - loss: 0.1124 - accuracy: 0.9387\n",
      "3040/5349 [================>.............] - ETA: 1s - loss: 0.1125 - accuracy: 0.9386\n",
      "3112/5349 [================>.............] - ETA: 1s - loss: 0.1125 - accuracy: 0.9386\n",
      "3194/5349 [================>.............] - ETA: 1s - loss: 0.1126 - accuracy: 0.9386\n",
      "3273/5349 [=================>............] - ETA: 1s - loss: 0.1128 - accuracy: 0.9385\n",
      "3405/5349 [==================>...........] - ETA: 1s - loss: 0.1126 - accuracy: 0.9387\n",
      "3498/5349 [==================>...........] - ETA: 1s - loss: 0.1128 - accuracy: 0.9386\n",
      "3602/5349 [===================>..........] - ETA: 1s - loss: 0.1127 - accuracy: 0.9387\n",
      "3699/5349 [===================>..........] - ETA: 1s - loss: 0.1127 - accuracy: 0.9387\n",
      "3803/5349 [====================>.........] - ETA: 1s - loss: 0.1128 - accuracy: 0.9385\n",
      "3886/5349 [====================>.........] - ETA: 1s - loss: 0.1128 - accuracy: 0.9385\n",
      "3952/5349 [=====================>........] - ETA: 1s - loss: 0.1129 - accuracy: 0.9385\n",
      "4027/5349 [=====================>........] - ETA: 1s - loss: 0.1130 - accuracy: 0.9385\n",
      "4081/5349 [=====================>........] - ETA: 1s - loss: 0.1129 - accuracy: 0.9385\n",
      "4180/5349 [======================>.......] - ETA: 1s - loss: 0.1129 - accuracy: 0.9385\n",
      "4276/5349 [======================>.......] - ETA: 1s - loss: 0.1128 - accuracy: 0.9386\n",
      "4394/5349 [=======================>......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9384\n",
      "4512/5349 [========================>.....] - ETA: 0s - loss: 0.1130 - accuracy: 0.9385\n",
      "4634/5349 [========================>.....] - ETA: 0s - loss: 0.1130 - accuracy: 0.9385\n",
      "4750/5349 [=========================>....] - ETA: 0s - loss: 0.1129 - accuracy: 0.9385\n",
      "4872/5349 [==========================>...] - ETA: 0s - loss: 0.1128 - accuracy: 0.9385\n",
      "5044/5349 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9385\n",
      "5165/5349 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9385\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9385\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9385\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1128 - accuracy: 0.9385 - val_loss: 0.1320 - val_accuracy: 0.9383\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 16/20\n",
      "  61/5349 [..............................] - ETA: 4s - loss: 0.1099 - accuracy: 0.9421\n",
      " 239/5349 [>.............................] - ETA: 4s - loss: 0.1094 - accuracy: 0.9411\n",
      " 355/5349 [>.............................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9404\n",
      " 472/5349 [=>............................] - ETA: 4s - loss: 0.1115 - accuracy: 0.9397\n",
      " 594/5349 [==>...........................] - ETA: 4s - loss: 0.1119 - accuracy: 0.9394\n",
      " 674/5349 [==>...........................] - ETA: 4s - loss: 0.1118 - accuracy: 0.9396\n",
      " 795/5349 [===>..........................] - ETA: 4s - loss: 0.1112 - accuracy: 0.9397\n",
      " 907/5349 [====>.........................] - ETA: 3s - loss: 0.1118 - accuracy: 0.9391\n",
      "1026/5349 [====>.........................] - ETA: 3s - loss: 0.1115 - accuracy: 0.9391\n",
      "1119/5349 [=====>........................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9393\n",
      "1238/5349 [=====>........................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9393\n",
      "1349/5349 [======>.......................] - ETA: 3s - loss: 0.1116 - accuracy: 0.9393\n",
      "1467/5349 [=======>......................] - ETA: 3s - loss: 0.1117 - accuracy: 0.9392\n",
      "1582/5349 [=======>......................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9392\n",
      "1644/5349 [========>.....................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9391\n",
      "1767/5349 [========>.....................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9391\n",
      "1880/5349 [=========>....................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9392\n",
      "2001/5349 [==========>...................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9391\n",
      "2115/5349 [==========>...................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9391\n",
      "2237/5349 [===========>..................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9391\n",
      "2351/5349 [============>.................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9391\n",
      "2471/5349 [============>.................] - ETA: 2s - loss: 0.1126 - accuracy: 0.9391\n",
      "2591/5349 [=============>................] - ETA: 2s - loss: 0.1124 - accuracy: 0.9391\n",
      "2714/5349 [==============>...............] - ETA: 2s - loss: 0.1124 - accuracy: 0.9392\n",
      "2830/5349 [==============>...............] - ETA: 2s - loss: 0.1123 - accuracy: 0.9392\n",
      "2953/5349 [===============>..............] - ETA: 2s - loss: 0.1123 - accuracy: 0.9393\n",
      "3008/5349 [===============>..............] - ETA: 2s - loss: 0.1122 - accuracy: 0.9393\n",
      "3127/5349 [================>.............] - ETA: 1s - loss: 0.1121 - accuracy: 0.9393\n",
      "3247/5349 [=================>............] - ETA: 1s - loss: 0.1121 - accuracy: 0.9393\n",
      "3364/5349 [=================>............] - ETA: 1s - loss: 0.1122 - accuracy: 0.9392\n",
      "3487/5349 [==================>...........] - ETA: 1s - loss: 0.1121 - accuracy: 0.9393\n",
      "3601/5349 [===================>..........] - ETA: 1s - loss: 0.1120 - accuracy: 0.9394\n",
      "3723/5349 [===================>..........] - ETA: 1s - loss: 0.1119 - accuracy: 0.9393\n",
      "3804/5349 [====================>.........] - ETA: 1s - loss: 0.1119 - accuracy: 0.9393\n",
      "3915/5349 [====================>.........] - ETA: 1s - loss: 0.1120 - accuracy: 0.9393\n",
      "4032/5349 [=====================>........] - ETA: 1s - loss: 0.1121 - accuracy: 0.9392\n",
      "4154/5349 [======================>.......] - ETA: 1s - loss: 0.1121 - accuracy: 0.9392\n",
      "4334/5349 [=======================>......] - ETA: 0s - loss: 0.1121 - accuracy: 0.9392\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.1122 - accuracy: 0.9391\n",
      "4565/5349 [========================>.....] - ETA: 0s - loss: 0.1122 - accuracy: 0.9390\n",
      "4689/5349 [=========================>....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9389\n",
      "4795/5349 [=========================>....] - ETA: 0s - loss: 0.1125 - accuracy: 0.9388\n",
      "4919/5349 [==========================>...] - ETA: 0s - loss: 0.1125 - accuracy: 0.9388\n",
      "5035/5349 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.9388\n",
      "5152/5349 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.9388\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9388\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9389\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1124 - accuracy: 0.9389 - val_loss: 0.1213 - val_accuracy: 0.9393\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1160 - accuracy: 0.9300\n",
      " 120/5349 [..............................] - ETA: 4s - loss: 0.1084 - accuracy: 0.9402\n",
      " 240/5349 [>.............................] - ETA: 4s - loss: 0.1090 - accuracy: 0.9406\n",
      " 356/5349 [>.............................] - ETA: 4s - loss: 0.1099 - accuracy: 0.9408\n",
      " 478/5349 [=>............................] - ETA: 4s - loss: 0.1112 - accuracy: 0.9404\n",
      " 655/5349 [==>...........................] - ETA: 3s - loss: 0.1116 - accuracy: 0.9399\n",
      " 776/5349 [===>..........................] - ETA: 3s - loss: 0.1125 - accuracy: 0.9391\n",
      " 894/5349 [====>.........................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9391\n",
      "1017/5349 [====>.........................] - ETA: 3s - loss: 0.1123 - accuracy: 0.9391\n",
      "1129/5349 [=====>........................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9396\n",
      "1248/5349 [=====>........................] - ETA: 3s - loss: 0.1118 - accuracy: 0.9396\n",
      "1366/5349 [======>.......................] - ETA: 3s - loss: 0.1117 - accuracy: 0.9396\n",
      "1489/5349 [=======>......................] - ETA: 3s - loss: 0.1120 - accuracy: 0.9393\n",
      "1607/5349 [========>.....................] - ETA: 3s - loss: 0.1121 - accuracy: 0.9394\n",
      "1722/5349 [========>.....................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9394\n",
      "1798/5349 [=========>....................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9394\n",
      "1945/5349 [=========>....................] - ETA: 3s - loss: 0.1117 - accuracy: 0.9394\n",
      "2044/5349 [==========>...................] - ETA: 2s - loss: 0.1120 - accuracy: 0.9391\n",
      "2143/5349 [===========>..................] - ETA: 2s - loss: 0.1119 - accuracy: 0.9392\n",
      "2231/5349 [===========>..................] - ETA: 2s - loss: 0.1120 - accuracy: 0.9391\n",
      "2328/5349 [============>.................] - ETA: 2s - loss: 0.1118 - accuracy: 0.9393\n",
      "2424/5349 [============>.................] - ETA: 2s - loss: 0.1117 - accuracy: 0.9394\n",
      "2520/5349 [=============>................] - ETA: 2s - loss: 0.1115 - accuracy: 0.9395\n",
      "2622/5349 [=============>................] - ETA: 2s - loss: 0.1113 - accuracy: 0.9397\n",
      "2671/5349 [=============>................] - ETA: 2s - loss: 0.1112 - accuracy: 0.9397\n",
      "2728/5349 [==============>...............] - ETA: 2s - loss: 0.1111 - accuracy: 0.9399\n",
      "2811/5349 [==============>...............] - ETA: 2s - loss: 0.1111 - accuracy: 0.9399\n",
      "2896/5349 [===============>..............] - ETA: 2s - loss: 0.1112 - accuracy: 0.9398\n",
      "2983/5349 [===============>..............] - ETA: 2s - loss: 0.1115 - accuracy: 0.9396\n",
      "3106/5349 [================>.............] - ETA: 2s - loss: 0.1115 - accuracy: 0.9396\n",
      "3208/5349 [================>.............] - ETA: 2s - loss: 0.1115 - accuracy: 0.9395\n",
      "3381/5349 [=================>............] - ETA: 1s - loss: 0.1116 - accuracy: 0.9395\n",
      "3500/5349 [==================>...........] - ETA: 1s - loss: 0.1116 - accuracy: 0.9394\n",
      "3620/5349 [===================>..........] - ETA: 1s - loss: 0.1116 - accuracy: 0.9395\n",
      "3736/5349 [===================>..........] - ETA: 1s - loss: 0.1116 - accuracy: 0.9393\n",
      "3851/5349 [====================>.........] - ETA: 1s - loss: 0.1117 - accuracy: 0.9392\n",
      "3966/5349 [=====================>........] - ETA: 1s - loss: 0.1118 - accuracy: 0.9393\n",
      "4085/5349 [=====================>........] - ETA: 1s - loss: 0.1119 - accuracy: 0.9392\n",
      "4196/5349 [======================>.......] - ETA: 1s - loss: 0.1120 - accuracy: 0.9391\n",
      "4315/5349 [=======================>......] - ETA: 0s - loss: 0.1120 - accuracy: 0.9390\n",
      "4366/5349 [=======================>......] - ETA: 0s - loss: 0.1121 - accuracy: 0.9390\n",
      "4481/5349 [========================>.....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9389\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9389\n",
      "4707/5349 [=========================>....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9390\n",
      "4827/5349 [==========================>...] - ETA: 0s - loss: 0.1119 - accuracy: 0.9390\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.1120 - accuracy: 0.9390\n",
      "5050/5349 [===========================>..] - ETA: 0s - loss: 0.1120 - accuracy: 0.9390\n",
      "5160/5349 [===========================>..] - ETA: 0s - loss: 0.1120 - accuracy: 0.9390\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.9390\n",
      "5332/5349 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9390\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1119 - accuracy: 0.9391 - val_loss: 0.1199 - val_accuracy: 0.9353\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 18/20\n",
      "  58/5349 [..............................] - ETA: 4s - loss: 0.1122 - accuracy: 0.9386 \n",
      " 174/5349 [..............................] - ETA: 4s - loss: 0.1072 - accuracy: 0.9421\n",
      " 295/5349 [>.............................] - ETA: 4s - loss: 0.1081 - accuracy: 0.9415\n",
      " 402/5349 [=>............................] - ETA: 4s - loss: 0.1092 - accuracy: 0.9412\n",
      " 524/5349 [=>............................] - ETA: 4s - loss: 0.1095 - accuracy: 0.9410\n",
      " 628/5349 [==>...........................] - ETA: 4s - loss: 0.1100 - accuracy: 0.9409\n",
      " 745/5349 [===>..........................] - ETA: 4s - loss: 0.1101 - accuracy: 0.9408\n",
      " 926/5349 [====>.........................] - ETA: 3s - loss: 0.1107 - accuracy: 0.9403\n",
      "1049/5349 [====>.........................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9400\n",
      "1159/5349 [=====>........................] - ETA: 3s - loss: 0.1114 - accuracy: 0.9396\n",
      "1275/5349 [======>.......................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9395\n",
      "1387/5349 [======>.......................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9397\n",
      "1507/5349 [=======>......................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9397\n",
      "1618/5349 [========>.....................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9398\n",
      "1737/5349 [========>.....................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9397\n",
      "1850/5349 [=========>....................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9397\n",
      "1972/5349 [==========>...................] - ETA: 2s - loss: 0.1112 - accuracy: 0.9396\n",
      "2151/5349 [===========>..................] - ETA: 2s - loss: 0.1113 - accuracy: 0.9395\n",
      "2273/5349 [===========>..................] - ETA: 2s - loss: 0.1116 - accuracy: 0.9394\n",
      "2383/5349 [============>.................] - ETA: 2s - loss: 0.1117 - accuracy: 0.9393\n",
      "2503/5349 [=============>................] - ETA: 2s - loss: 0.1117 - accuracy: 0.9394\n",
      "2621/5349 [=============>................] - ETA: 2s - loss: 0.1119 - accuracy: 0.9394\n",
      "2745/5349 [==============>...............] - ETA: 2s - loss: 0.1118 - accuracy: 0.9394\n",
      "2864/5349 [===============>..............] - ETA: 2s - loss: 0.1117 - accuracy: 0.9395\n",
      "2988/5349 [===============>..............] - ETA: 2s - loss: 0.1116 - accuracy: 0.9395\n",
      "3100/5349 [================>.............] - ETA: 1s - loss: 0.1117 - accuracy: 0.9395\n",
      "3263/5349 [=================>............] - ETA: 1s - loss: 0.1115 - accuracy: 0.9396\n",
      "3372/5349 [=================>............] - ETA: 1s - loss: 0.1115 - accuracy: 0.9396\n",
      "3493/5349 [==================>...........] - ETA: 1s - loss: 0.1115 - accuracy: 0.9396\n",
      "3598/5349 [===================>..........] - ETA: 1s - loss: 0.1116 - accuracy: 0.9396\n",
      "3717/5349 [===================>..........] - ETA: 1s - loss: 0.1115 - accuracy: 0.9396\n",
      "3837/5349 [====================>.........] - ETA: 1s - loss: 0.1114 - accuracy: 0.9397\n",
      "3957/5349 [=====================>........] - ETA: 1s - loss: 0.1113 - accuracy: 0.9397\n",
      "4076/5349 [=====================>........] - ETA: 1s - loss: 0.1113 - accuracy: 0.9397\n",
      "4192/5349 [======================>.......] - ETA: 1s - loss: 0.1113 - accuracy: 0.9397\n",
      "4370/5349 [=======================>......] - ETA: 0s - loss: 0.1115 - accuracy: 0.9396\n",
      "4485/5349 [========================>.....] - ETA: 0s - loss: 0.1114 - accuracy: 0.9396\n",
      "4602/5349 [========================>.....] - ETA: 0s - loss: 0.1114 - accuracy: 0.9396\n",
      "4717/5349 [=========================>....] - ETA: 0s - loss: 0.1113 - accuracy: 0.9397\n",
      "4829/5349 [==========================>...] - ETA: 0s - loss: 0.1114 - accuracy: 0.9396\n",
      "4943/5349 [==========================>...] - ETA: 0s - loss: 0.1113 - accuracy: 0.9397\n",
      "5120/5349 [===========================>..] - ETA: 0s - loss: 0.1115 - accuracy: 0.9396\n",
      "5237/5349 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9396\n",
      "5339/5349 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9396\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1114 - accuracy: 0.9396 - val_loss: 0.1089 - val_accuracy: 0.9394\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 19/20\n",
      "  60/5349 [..............................] - ETA: 4s - loss: 0.1068 - accuracy: 0.9463\n",
      " 179/5349 [>.............................] - ETA: 4s - loss: 0.1117 - accuracy: 0.9404\n",
      " 291/5349 [>.............................] - ETA: 4s - loss: 0.1114 - accuracy: 0.9403\n",
      " 407/5349 [=>............................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9414\n",
      " 514/5349 [=>............................] - ETA: 4s - loss: 0.1103 - accuracy: 0.9414\n",
      " 590/5349 [==>...........................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9412\n",
      " 689/5349 [==>...........................] - ETA: 4s - loss: 0.1106 - accuracy: 0.9410\n",
      " 780/5349 [===>..........................] - ETA: 4s - loss: 0.1105 - accuracy: 0.9409\n",
      " 827/5349 [===>..........................] - ETA: 4s - loss: 0.1104 - accuracy: 0.9410\n",
      " 920/5349 [====>.........................] - ETA: 4s - loss: 0.1103 - accuracy: 0.9410\n",
      "1010/5349 [====>.........................] - ETA: 4s - loss: 0.1104 - accuracy: 0.9408\n",
      "1107/5349 [=====>........................] - ETA: 4s - loss: 0.1108 - accuracy: 0.9405\n",
      "1192/5349 [=====>........................] - ETA: 4s - loss: 0.1103 - accuracy: 0.9409\n",
      "1345/5349 [======>.......................] - ETA: 4s - loss: 0.1107 - accuracy: 0.9407\n",
      "1442/5349 [=======>......................] - ETA: 3s - loss: 0.1108 - accuracy: 0.9407\n",
      "1505/5349 [=======>......................] - ETA: 4s - loss: 0.1108 - accuracy: 0.9406\n",
      "1590/5349 [=======>......................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9406\n",
      "1690/5349 [========>.....................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9407\n",
      "1790/5349 [=========>....................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9405\n",
      "1910/5349 [=========>....................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9405\n",
      "2022/5349 [==========>...................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9405\n",
      "2079/5349 [==========>...................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9406\n",
      "2200/5349 [===========>..................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9407\n",
      "2304/5349 [===========>..................] - ETA: 3s - loss: 0.1108 - accuracy: 0.9404\n",
      "2402/5349 [============>.................] - ETA: 2s - loss: 0.1109 - accuracy: 0.9403\n",
      "2506/5349 [=============>................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9401\n",
      "2617/5349 [=============>................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9401\n",
      "2729/5349 [==============>...............] - ETA: 2s - loss: 0.1112 - accuracy: 0.9401\n",
      "2843/5349 [==============>...............] - ETA: 2s - loss: 0.1112 - accuracy: 0.9401\n",
      "2901/5349 [===============>..............] - ETA: 2s - loss: 0.1112 - accuracy: 0.9401\n",
      "3010/5349 [===============>..............] - ETA: 2s - loss: 0.1110 - accuracy: 0.9401\n",
      "3128/5349 [================>.............] - ETA: 2s - loss: 0.1110 - accuracy: 0.9402\n",
      "3231/5349 [=================>............] - ETA: 2s - loss: 0.1110 - accuracy: 0.9401\n",
      "3343/5349 [=================>............] - ETA: 1s - loss: 0.1110 - accuracy: 0.9401\n",
      "3458/5349 [==================>...........] - ETA: 1s - loss: 0.1109 - accuracy: 0.9402\n",
      "3576/5349 [===================>..........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9400\n",
      "3748/5349 [====================>.........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9399\n",
      "3864/5349 [====================>.........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9399\n",
      "3981/5349 [=====================>........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9401\n",
      "4088/5349 [=====================>........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9401\n",
      "4207/5349 [======================>.......] - ETA: 1s - loss: 0.1111 - accuracy: 0.9400\n",
      "4320/5349 [=======================>......] - ETA: 0s - loss: 0.1111 - accuracy: 0.9400\n",
      "4437/5349 [=======================>......] - ETA: 0s - loss: 0.1112 - accuracy: 0.9399\n",
      "4554/5349 [========================>.....] - ETA: 0s - loss: 0.1113 - accuracy: 0.9399\n",
      "4672/5349 [=========================>....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9400\n",
      "4813/5349 [=========================>....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9401\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.1112 - accuracy: 0.9401\n",
      "5032/5349 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9402\n",
      "5143/5349 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9403\n",
      "5256/5349 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9403\n",
      "5312/5349 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9403\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1110 - accuracy: 0.9403 - val_loss: 0.1091 - val_accuracy: 0.9394\n",
      "\u001B[36m(train_DNN pid=5641)\u001B[0m Epoch 20/20\n",
      "  62/5349 [..............................] - ETA: 4s - loss: 0.1051 - accuracy: 0.9437\n",
      " 182/5349 [>.............................] - ETA: 4s - loss: 0.1098 - accuracy: 0.9401\n",
      " 302/5349 [>.............................] - ETA: 4s - loss: 0.1093 - accuracy: 0.9410\n",
      " 407/5349 [=>............................] - ETA: 4s - loss: 0.1106 - accuracy: 0.9401\n",
      " 469/5349 [=>............................] - ETA: 4s - loss: 0.1108 - accuracy: 0.9397\n",
      " 586/5349 [==>...........................] - ETA: 4s - loss: 0.1112 - accuracy: 0.9389\n",
      " 691/5349 [==>...........................] - ETA: 4s - loss: 0.1118 - accuracy: 0.9390\n",
      " 811/5349 [===>..........................] - ETA: 3s - loss: 0.1114 - accuracy: 0.9397\n",
      " 928/5349 [====>.........................] - ETA: 3s - loss: 0.1107 - accuracy: 0.9401\n",
      "1050/5349 [====>.........................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9402\n",
      "1168/5349 [=====>........................] - ETA: 3s - loss: 0.1107 - accuracy: 0.9404\n",
      "1289/5349 [======>.......................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9402\n",
      "1409/5349 [======>.......................] - ETA: 3s - loss: 0.1111 - accuracy: 0.9404\n",
      "1524/5349 [=======>......................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9404\n",
      "1644/5349 [========>.....................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9404\n",
      "1703/5349 [========>.....................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9405\n",
      "1823/5349 [=========>....................] - ETA: 3s - loss: 0.1106 - accuracy: 0.9408\n",
      "1932/5349 [=========>....................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9408\n",
      "2043/5349 [==========>...................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9406\n",
      "2161/5349 [===========>..................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9406\n",
      "2285/5349 [===========>..................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9406\n",
      "2401/5349 [============>.................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9407\n",
      "2524/5349 [=============>................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9408\n",
      "2644/5349 [=============>................] - ETA: 2s - loss: 0.1107 - accuracy: 0.9407\n",
      "2767/5349 [==============>...............] - ETA: 2s - loss: 0.1107 - accuracy: 0.9407\n",
      "2876/5349 [===============>..............] - ETA: 2s - loss: 0.1107 - accuracy: 0.9408\n",
      "2992/5349 [===============>..............] - ETA: 2s - loss: 0.1107 - accuracy: 0.9408\n",
      "3110/5349 [================>.............] - ETA: 1s - loss: 0.1107 - accuracy: 0.9409\n",
      "3233/5349 [=================>............] - ETA: 1s - loss: 0.1106 - accuracy: 0.9410\n",
      "3294/5349 [=================>............] - ETA: 1s - loss: 0.1105 - accuracy: 0.9410\n",
      "3411/5349 [==================>...........] - ETA: 1s - loss: 0.1103 - accuracy: 0.9412\n",
      "3535/5349 [==================>...........] - ETA: 1s - loss: 0.1104 - accuracy: 0.9411\n",
      "3640/5349 [===================>..........] - ETA: 1s - loss: 0.1104 - accuracy: 0.9410\n",
      "3761/5349 [====================>.........] - ETA: 1s - loss: 0.1103 - accuracy: 0.9411\n",
      "3873/5349 [====================>.........] - ETA: 1s - loss: 0.1105 - accuracy: 0.9410\n",
      "3997/5349 [=====================>........] - ETA: 1s - loss: 0.1105 - accuracy: 0.9409\n",
      "4112/5349 [======================>.......] - ETA: 1s - loss: 0.1104 - accuracy: 0.9411\n",
      "4230/5349 [======================>.......] - ETA: 0s - loss: 0.1103 - accuracy: 0.9411\n",
      "4345/5349 [=======================>......] - ETA: 0s - loss: 0.1103 - accuracy: 0.9411\n",
      "4526/5349 [========================>.....] - ETA: 0s - loss: 0.1102 - accuracy: 0.9411\n",
      "4645/5349 [=========================>....] - ETA: 0s - loss: 0.1102 - accuracy: 0.9412\n",
      "4764/5349 [=========================>....] - ETA: 0s - loss: 0.1103 - accuracy: 0.9411\n",
      "4878/5349 [==========================>...] - ETA: 0s - loss: 0.1103 - accuracy: 0.9412\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1103 - accuracy: 0.9412\n",
      "5116/5349 [===========================>..] - ETA: 0s - loss: 0.1102 - accuracy: 0.9411\n",
      "5237/5349 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9411\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9412\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1101 - accuracy: 0.9412 - val_loss: 0.1073 - val_accuracy: 0.9409\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 23:46 - loss: 1.0396 - accuracy: 0.1500\n",
      " 160/5349 [..............................] - ETA: 3s - loss: 0.5330 - accuracy: 0.7177\n",
      " 326/5349 [>.............................] - ETA: 3s - loss: 0.4287 - accuracy: 0.7787\n",
      " 474/5349 [=>............................] - ETA: 3s - loss: 0.3695 - accuracy: 0.8055\n",
      " 644/5349 [==>...........................] - ETA: 2s - loss: 0.3232 - accuracy: 0.8335\n",
      " 806/5349 [===>..........................] - ETA: 2s - loss: 0.2944 - accuracy: 0.8496\n",
      " 973/5349 [====>.........................] - ETA: 2s - loss: 0.2739 - accuracy: 0.8604\n",
      "1139/5349 [=====>........................] - ETA: 2s - loss: 0.2586 - accuracy: 0.8683\n",
      "1311/5349 [======>.......................] - ETA: 2s - loss: 0.2463 - accuracy: 0.8746\n",
      "1477/5349 [=======>......................] - ETA: 2s - loss: 0.2370 - accuracy: 0.8790\n",
      "1730/5349 [========>.....................] - ETA: 2s - loss: 0.2255 - accuracy: 0.8851\n",
      "1897/5349 [=========>....................] - ETA: 2s - loss: 0.2201 - accuracy: 0.8877\n",
      "2070/5349 [==========>...................] - ETA: 1s - loss: 0.2150 - accuracy: 0.8902\n",
      "2236/5349 [===========>..................] - ETA: 1s - loss: 0.2107 - accuracy: 0.8923\n",
      "2390/5349 [============>.................] - ETA: 1s - loss: 0.2075 - accuracy: 0.8937\n",
      "2506/5349 [=============>................] - ETA: 1s - loss: 0.2049 - accuracy: 0.8949\n",
      "2641/5349 [=============>................] - ETA: 1s - loss: 0.2025 - accuracy: 0.8960\n",
      "2768/5349 [==============>...............] - ETA: 1s - loss: 0.2004 - accuracy: 0.8969\n",
      "2973/5349 [===============>..............] - ETA: 1s - loss: 0.1974 - accuracy: 0.8983\n",
      "3107/5349 [================>.............] - ETA: 1s - loss: 0.1955 - accuracy: 0.8992\n",
      "3251/5349 [=================>............] - ETA: 1s - loss: 0.1937 - accuracy: 0.8999\n",
      "3396/5349 [==================>...........] - ETA: 1s - loss: 0.1921 - accuracy: 0.9007\n",
      "3540/5349 [==================>...........] - ETA: 1s - loss: 0.1904 - accuracy: 0.9013\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.1896 - accuracy: 0.9018\n",
      "3740/5349 [===================>..........] - ETA: 1s - loss: 0.1883 - accuracy: 0.9023\n",
      "3805/5349 [====================>.........] - ETA: 1s - loss: 0.1877 - accuracy: 0.9026\n",
      "3945/5349 [=====================>........] - ETA: 0s - loss: 0.1865 - accuracy: 0.9030\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.1852 - accuracy: 0.9036\n",
      "4249/5349 [======================>.......] - ETA: 0s - loss: 0.1840 - accuracy: 0.9041\n",
      "4421/5349 [=======================>......] - ETA: 0s - loss: 0.1828 - accuracy: 0.9046\n",
      "4570/5349 [========================>.....] - ETA: 0s - loss: 0.1817 - accuracy: 0.9051\n",
      "4742/5349 [=========================>....] - ETA: 0s - loss: 0.1806 - accuracy: 0.9057\n",
      "4906/5349 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.9060\n",
      "5069/5349 [===========================>..] - ETA: 0s - loss: 0.1786 - accuracy: 0.9064\n",
      "5147/5349 [===========================>..] - ETA: 0s - loss: 0.1781 - accuracy: 0.9067\n",
      "5308/5349 [============================>.] - ETA: 0s - loss: 0.1773 - accuracy: 0.9070\n",
      "5349/5349 [==============================] - 5s 862us/step - loss: 0.1770 - accuracy: 0.9071 - val_loss: 0.1482 - val_accuracy: 0.9208\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 2/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.1396 - accuracy: 0.9239\n",
      " 253/5349 [>.............................] - ETA: 3s - loss: 0.1476 - accuracy: 0.9197\n",
      " 426/5349 [=>............................] - ETA: 2s - loss: 0.1477 - accuracy: 0.9204\n",
      " 594/5349 [==>...........................] - ETA: 2s - loss: 0.1473 - accuracy: 0.9204\n",
      " 731/5349 [===>..........................] - ETA: 2s - loss: 0.1472 - accuracy: 0.9207\n",
      " 885/5349 [===>..........................] - ETA: 2s - loss: 0.1471 - accuracy: 0.9210\n",
      "1054/5349 [====>.........................] - ETA: 2s - loss: 0.1471 - accuracy: 0.9210\n",
      "1216/5349 [=====>........................] - ETA: 2s - loss: 0.1466 - accuracy: 0.9215\n",
      "1298/5349 [======>.......................] - ETA: 2s - loss: 0.1471 - accuracy: 0.9212\n",
      "1466/5349 [=======>......................] - ETA: 2s - loss: 0.1474 - accuracy: 0.9209\n",
      "1619/5349 [========>.....................] - ETA: 2s - loss: 0.1476 - accuracy: 0.9206\n",
      "1788/5349 [=========>....................] - ETA: 2s - loss: 0.1476 - accuracy: 0.9206\n",
      "1953/5349 [=========>....................] - ETA: 2s - loss: 0.1477 - accuracy: 0.9206\n",
      "2125/5349 [==========>...................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9208\n",
      "2284/5349 [===========>..................] - ETA: 1s - loss: 0.1474 - accuracy: 0.9210\n",
      "2524/5349 [=============>................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9209\n",
      "2686/5349 [==============>...............] - ETA: 1s - loss: 0.1477 - accuracy: 0.9208\n",
      "2853/5349 [===============>..............] - ETA: 1s - loss: 0.1477 - accuracy: 0.9208\n",
      "3023/5349 [===============>..............] - ETA: 1s - loss: 0.1475 - accuracy: 0.9210\n",
      "3185/5349 [================>.............] - ETA: 1s - loss: 0.1474 - accuracy: 0.9210\n",
      "3348/5349 [=================>............] - ETA: 1s - loss: 0.1474 - accuracy: 0.9210\n",
      "3503/5349 [==================>...........] - ETA: 1s - loss: 0.1472 - accuracy: 0.9211\n",
      "3633/5349 [===================>..........] - ETA: 1s - loss: 0.1470 - accuracy: 0.9212\n",
      "3786/5349 [====================>.........] - ETA: 0s - loss: 0.1470 - accuracy: 0.9211\n",
      "3932/5349 [=====================>........] - ETA: 0s - loss: 0.1469 - accuracy: 0.9211\n",
      "4014/5349 [=====================>........] - ETA: 0s - loss: 0.1467 - accuracy: 0.9211\n",
      "4180/5349 [======================>.......] - ETA: 0s - loss: 0.1466 - accuracy: 0.9212\n",
      "4340/5349 [=======================>......] - ETA: 0s - loss: 0.1466 - accuracy: 0.9212\n",
      "4500/5349 [========================>.....] - ETA: 0s - loss: 0.1465 - accuracy: 0.9213\n",
      "4659/5349 [=========================>....] - ETA: 0s - loss: 0.1464 - accuracy: 0.9213\n",
      "4817/5349 [==========================>...] - ETA: 0s - loss: 0.1463 - accuracy: 0.9214\n",
      "4964/5349 [==========================>...] - ETA: 0s - loss: 0.1463 - accuracy: 0.9213\n",
      "5135/5349 [===========================>..] - ETA: 0s - loss: 0.1463 - accuracy: 0.9213\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.9214\n",
      "5349/5349 [==============================] - 4s 794us/step - loss: 0.1461 - accuracy: 0.9215 - val_loss: 0.1422 - val_accuracy: 0.9251\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1202 - accuracy: 0.9400\n",
      " 257/5349 [>.............................] - ETA: 2s - loss: 0.1431 - accuracy: 0.9241\n",
      " 421/5349 [=>............................] - ETA: 2s - loss: 0.1425 - accuracy: 0.9246\n",
      " 585/5349 [==>...........................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9248\n",
      " 756/5349 [===>..........................] - ETA: 2s - loss: 0.1427 - accuracy: 0.9244\n",
      " 920/5349 [====>.........................] - ETA: 2s - loss: 0.1431 - accuracy: 0.9244\n",
      "1089/5349 [=====>........................] - ETA: 2s - loss: 0.1428 - accuracy: 0.9242\n",
      "1250/5349 [======>.......................] - ETA: 2s - loss: 0.1433 - accuracy: 0.9240\n",
      "1421/5349 [======>.......................] - ETA: 2s - loss: 0.1432 - accuracy: 0.9241\n",
      "1574/5349 [=======>......................] - ETA: 2s - loss: 0.1432 - accuracy: 0.9240\n",
      "1740/5349 [========>.....................] - ETA: 2s - loss: 0.1430 - accuracy: 0.9241\n",
      "1986/5349 [==========>...................] - ETA: 2s - loss: 0.1428 - accuracy: 0.9239\n",
      "2153/5349 [===========>..................] - ETA: 1s - loss: 0.1427 - accuracy: 0.9239\n",
      "2292/5349 [===========>..................] - ETA: 1s - loss: 0.1426 - accuracy: 0.9239\n",
      "2447/5349 [============>.................] - ETA: 1s - loss: 0.1425 - accuracy: 0.9241\n",
      "2600/5349 [=============>................] - ETA: 1s - loss: 0.1424 - accuracy: 0.9242\n",
      "2773/5349 [==============>...............] - ETA: 1s - loss: 0.1421 - accuracy: 0.9242\n",
      "2934/5349 [===============>..............] - ETA: 1s - loss: 0.1421 - accuracy: 0.9243\n",
      "3106/5349 [================>.............] - ETA: 1s - loss: 0.1420 - accuracy: 0.9244\n",
      "3255/5349 [=================>............] - ETA: 1s - loss: 0.1417 - accuracy: 0.9247\n",
      "3418/5349 [==================>...........] - ETA: 1s - loss: 0.1414 - accuracy: 0.9248\n",
      "3498/5349 [==================>...........] - ETA: 1s - loss: 0.1414 - accuracy: 0.9248\n",
      "3660/5349 [===================>..........] - ETA: 1s - loss: 0.1413 - accuracy: 0.9249\n",
      "3829/5349 [====================>.........] - ETA: 0s - loss: 0.1411 - accuracy: 0.9251\n",
      "3972/5349 [=====================>........] - ETA: 0s - loss: 0.1411 - accuracy: 0.9250\n",
      "4141/5349 [======================>.......] - ETA: 0s - loss: 0.1410 - accuracy: 0.9250\n",
      "4302/5349 [=======================>......] - ETA: 0s - loss: 0.1408 - accuracy: 0.9252\n",
      "4463/5349 [========================>.....] - ETA: 0s - loss: 0.1408 - accuracy: 0.9253\n",
      "4581/5349 [========================>.....] - ETA: 0s - loss: 0.1408 - accuracy: 0.9253\n",
      "4785/5349 [=========================>....] - ETA: 0s - loss: 0.1408 - accuracy: 0.9253\n",
      "4928/5349 [==========================>...] - ETA: 0s - loss: 0.1408 - accuracy: 0.9252\n",
      "5065/5349 [===========================>..] - ETA: 0s - loss: 0.1407 - accuracy: 0.9253\n",
      "5196/5349 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9254\n",
      "5344/5349 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9254\n",
      "5349/5349 [==============================] - 5s 844us/step - loss: 0.1406 - accuracy: 0.9254 - val_loss: 0.1384 - val_accuracy: 0.9285\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 4/20\n",
      "  47/5349 [..............................] - ETA: 5s - loss: 0.1464 - accuracy: 0.9177\n",
      " 214/5349 [>.............................] - ETA: 3s - loss: 0.1374 - accuracy: 0.9267\n",
      " 299/5349 [>.............................] - ETA: 3s - loss: 0.1377 - accuracy: 0.9267\n",
      " 466/5349 [=>............................] - ETA: 3s - loss: 0.1384 - accuracy: 0.9272\n",
      " 625/5349 [==>...........................] - ETA: 3s - loss: 0.1383 - accuracy: 0.9274\n",
      " 793/5349 [===>..........................] - ETA: 2s - loss: 0.1381 - accuracy: 0.9280\n",
      " 940/5349 [====>.........................] - ETA: 2s - loss: 0.1379 - accuracy: 0.9280\n",
      "1107/5349 [=====>........................] - ETA: 2s - loss: 0.1381 - accuracy: 0.9279\n",
      "1260/5349 [======>.......................] - ETA: 2s - loss: 0.1382 - accuracy: 0.9276\n",
      "1427/5349 [=======>......................] - ETA: 2s - loss: 0.1377 - accuracy: 0.9280\n",
      "1589/5349 [=======>......................] - ETA: 2s - loss: 0.1377 - accuracy: 0.9282\n",
      "1748/5349 [========>.....................] - ETA: 2s - loss: 0.1371 - accuracy: 0.9286\n",
      "1980/5349 [==========>...................] - ETA: 2s - loss: 0.1375 - accuracy: 0.9283\n",
      "2146/5349 [===========>..................] - ETA: 2s - loss: 0.1378 - accuracy: 0.9280\n",
      "2304/5349 [===========>..................] - ETA: 1s - loss: 0.1377 - accuracy: 0.9278\n",
      "2471/5349 [============>.................] - ETA: 1s - loss: 0.1373 - accuracy: 0.9281\n",
      "2619/5349 [=============>................] - ETA: 1s - loss: 0.1371 - accuracy: 0.9281\n",
      "2779/5349 [==============>...............] - ETA: 1s - loss: 0.1371 - accuracy: 0.9281\n",
      "2939/5349 [===============>..............] - ETA: 1s - loss: 0.1370 - accuracy: 0.9281\n",
      "3107/5349 [================>.............] - ETA: 1s - loss: 0.1370 - accuracy: 0.9280\n",
      "3269/5349 [=================>............] - ETA: 1s - loss: 0.1367 - accuracy: 0.9282\n",
      "3438/5349 [==================>...........] - ETA: 1s - loss: 0.1366 - accuracy: 0.9283\n",
      "3541/5349 [==================>...........] - ETA: 1s - loss: 0.1366 - accuracy: 0.9283\n",
      "3705/5349 [===================>..........] - ETA: 1s - loss: 0.1365 - accuracy: 0.9283\n",
      "3859/5349 [====================>.........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9284\n",
      "3941/5349 [=====================>........] - ETA: 0s - loss: 0.1363 - accuracy: 0.9284\n",
      "4112/5349 [======================>.......] - ETA: 0s - loss: 0.1362 - accuracy: 0.9285\n",
      "4262/5349 [======================>.......] - ETA: 0s - loss: 0.1361 - accuracy: 0.9285\n",
      "4423/5349 [=======================>......] - ETA: 0s - loss: 0.1361 - accuracy: 0.9285\n",
      "4586/5349 [========================>.....] - ETA: 0s - loss: 0.1361 - accuracy: 0.9285\n",
      "4758/5349 [=========================>....] - ETA: 0s - loss: 0.1361 - accuracy: 0.9285\n",
      "4904/5349 [==========================>...] - ETA: 0s - loss: 0.1361 - accuracy: 0.9286\n",
      "5077/5349 [===========================>..] - ETA: 0s - loss: 0.1362 - accuracy: 0.9285\n",
      "5233/5349 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9285\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9285\n",
      "5349/5349 [==============================] - 4s 801us/step - loss: 0.1361 - accuracy: 0.9285 - val_loss: 0.1326 - val_accuracy: 0.9306\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1235 - accuracy: 0.9400\n",
      " 168/5349 [..............................] - ETA: 3s - loss: 0.1379 - accuracy: 0.9240\n",
      " 340/5349 [>.............................] - ETA: 2s - loss: 0.1341 - accuracy: 0.9286\n",
      " 502/5349 [=>............................] - ETA: 2s - loss: 0.1340 - accuracy: 0.9283\n",
      " 673/5349 [==>...........................] - ETA: 2s - loss: 0.1331 - accuracy: 0.9290\n",
      " 832/5349 [===>..........................] - ETA: 2s - loss: 0.1332 - accuracy: 0.9288\n",
      "1085/5349 [=====>........................] - ETA: 2s - loss: 0.1328 - accuracy: 0.9294\n",
      "1225/5349 [=====>........................] - ETA: 2s - loss: 0.1332 - accuracy: 0.9292\n",
      "1382/5349 [======>.......................] - ETA: 2s - loss: 0.1332 - accuracy: 0.9294\n",
      "1546/5349 [=======>......................] - ETA: 2s - loss: 0.1334 - accuracy: 0.9292\n",
      "1703/5349 [========>.....................] - ETA: 2s - loss: 0.1334 - accuracy: 0.9292\n",
      "1882/5349 [=========>....................] - ETA: 2s - loss: 0.1335 - accuracy: 0.9293\n",
      "1885/5349 [=========>....................] - ETA: 2s - loss: 0.1335 - accuracy: 0.9292\n",
      "1959/5349 [=========>....................] - ETA: 2s - loss: 0.1335 - accuracy: 0.9293\n",
      "2088/5349 [==========>...................] - ETA: 2s - loss: 0.1333 - accuracy: 0.9296\n",
      "2153/5349 [===========>..................] - ETA: 2s - loss: 0.1333 - accuracy: 0.9296\n",
      "2320/5349 [============>.................] - ETA: 2s - loss: 0.1334 - accuracy: 0.9295\n",
      "2484/5349 [============>.................] - ETA: 2s - loss: 0.1333 - accuracy: 0.9296\n",
      "2650/5349 [=============>................] - ETA: 1s - loss: 0.1330 - accuracy: 0.9299\n",
      "2804/5349 [==============>...............] - ETA: 1s - loss: 0.1332 - accuracy: 0.9298\n",
      "2968/5349 [===============>..............] - ETA: 1s - loss: 0.1332 - accuracy: 0.9298\n",
      "3130/5349 [================>.............] - ETA: 1s - loss: 0.1332 - accuracy: 0.9300\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.1332 - accuracy: 0.9300\n",
      "3320/5349 [=================>............] - ETA: 1s - loss: 0.1330 - accuracy: 0.9301\n",
      "3469/5349 [==================>...........] - ETA: 1s - loss: 0.1330 - accuracy: 0.9302\n",
      "3629/5349 [===================>..........] - ETA: 1s - loss: 0.1330 - accuracy: 0.9303\n",
      "3782/5349 [====================>.........] - ETA: 1s - loss: 0.1331 - accuracy: 0.9302\n",
      "3929/5349 [=====================>........] - ETA: 0s - loss: 0.1331 - accuracy: 0.9302\n",
      "4085/5349 [=====================>........] - ETA: 0s - loss: 0.1331 - accuracy: 0.9302\n",
      "4244/5349 [======================>.......] - ETA: 0s - loss: 0.1330 - accuracy: 0.9303\n",
      "4401/5349 [=======================>......] - ETA: 0s - loss: 0.1330 - accuracy: 0.9303\n",
      "4626/5349 [========================>.....] - ETA: 0s - loss: 0.1330 - accuracy: 0.9304\n",
      "4770/5349 [=========================>....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9304\n",
      "4921/5349 [==========================>...] - ETA: 0s - loss: 0.1329 - accuracy: 0.9304\n",
      "5063/5349 [===========================>..] - ETA: 0s - loss: 0.1327 - accuracy: 0.9305\n",
      "5204/5349 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9306\n",
      "5275/5349 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 0.9306\n",
      "5349/5349 [==============================] - 5s 864us/step - loss: 0.1324 - accuracy: 0.9306 - val_loss: 0.1290 - val_accuracy: 0.9331\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 6/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1288 - accuracy: 0.9338\n",
      " 254/5349 [>.............................] - ETA: 3s - loss: 0.1315 - accuracy: 0.9317\n",
      " 394/5349 [=>............................] - ETA: 3s - loss: 0.1309 - accuracy: 0.9313\n",
      " 521/5349 [=>............................] - ETA: 3s - loss: 0.1304 - accuracy: 0.9314\n",
      " 653/5349 [==>...........................] - ETA: 3s - loss: 0.1298 - accuracy: 0.9321\n",
      " 776/5349 [===>..........................] - ETA: 3s - loss: 0.1294 - accuracy: 0.9326\n",
      " 914/5349 [====>.........................] - ETA: 3s - loss: 0.1292 - accuracy: 0.9323\n",
      "1051/5349 [====>.........................] - ETA: 3s - loss: 0.1294 - accuracy: 0.9320\n",
      "1255/5349 [======>.......................] - ETA: 2s - loss: 0.1289 - accuracy: 0.9322\n",
      "1386/5349 [======>.......................] - ETA: 2s - loss: 0.1293 - accuracy: 0.9319\n",
      "1530/5349 [=======>......................] - ETA: 2s - loss: 0.1294 - accuracy: 0.9318\n",
      "1629/5349 [========>.....................] - ETA: 2s - loss: 0.1294 - accuracy: 0.9319\n",
      "1718/5349 [========>.....................] - ETA: 2s - loss: 0.1298 - accuracy: 0.9315\n",
      "1794/5349 [=========>....................] - ETA: 2s - loss: 0.1299 - accuracy: 0.9315\n",
      "1963/5349 [==========>...................] - ETA: 2s - loss: 0.1300 - accuracy: 0.9317\n",
      "2081/5349 [==========>...................] - ETA: 2s - loss: 0.1301 - accuracy: 0.9316\n",
      "2237/5349 [===========>..................] - ETA: 2s - loss: 0.1300 - accuracy: 0.9317\n",
      "2403/5349 [============>.................] - ETA: 2s - loss: 0.1300 - accuracy: 0.9319\n",
      "2555/5349 [=============>................] - ETA: 2s - loss: 0.1301 - accuracy: 0.9319\n",
      "2701/5349 [==============>...............] - ETA: 2s - loss: 0.1300 - accuracy: 0.9319\n",
      "2765/5349 [==============>...............] - ETA: 1s - loss: 0.1301 - accuracy: 0.9320\n",
      "2926/5349 [===============>..............] - ETA: 1s - loss: 0.1301 - accuracy: 0.9318\n",
      "3089/5349 [================>.............] - ETA: 1s - loss: 0.1301 - accuracy: 0.9318\n",
      "3249/5349 [=================>............] - ETA: 1s - loss: 0.1301 - accuracy: 0.9318\n",
      "3407/5349 [==================>...........] - ETA: 1s - loss: 0.1301 - accuracy: 0.9319\n",
      "3570/5349 [===================>..........] - ETA: 1s - loss: 0.1301 - accuracy: 0.9319\n",
      "3727/5349 [===================>..........] - ETA: 1s - loss: 0.1301 - accuracy: 0.9319\n",
      "3791/5349 [====================>.........] - ETA: 1s - loss: 0.1300 - accuracy: 0.9319\n",
      "3955/5349 [=====================>........] - ETA: 1s - loss: 0.1300 - accuracy: 0.9319\n",
      "4114/5349 [======================>.......] - ETA: 0s - loss: 0.1300 - accuracy: 0.9320\n",
      "4269/5349 [======================>.......] - ETA: 0s - loss: 0.1299 - accuracy: 0.9320\n",
      "4422/5349 [=======================>......] - ETA: 0s - loss: 0.1298 - accuracy: 0.9320\n",
      "4584/5349 [========================>.....] - ETA: 0s - loss: 0.1297 - accuracy: 0.9321\n",
      "4745/5349 [=========================>....] - ETA: 0s - loss: 0.1299 - accuracy: 0.9321\n",
      "4974/5349 [==========================>...] - ETA: 0s - loss: 0.1298 - accuracy: 0.9322\n",
      "5136/5349 [===========================>..] - ETA: 0s - loss: 0.1297 - accuracy: 0.9321\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9321\n",
      "5349/5349 [==============================] - 5s 891us/step - loss: 0.1297 - accuracy: 0.9321 - val_loss: 0.1265 - val_accuracy: 0.9348\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0663 - accuracy: 0.9700\n",
      " 158/5349 [..............................] - ETA: 3s - loss: 0.1267 - accuracy: 0.9327\n",
      " 404/5349 [=>............................] - ETA: 3s - loss: 0.1260 - accuracy: 0.9342\n",
      " 555/5349 [==>...........................] - ETA: 3s - loss: 0.1262 - accuracy: 0.9339\n",
      " 725/5349 [===>..........................] - ETA: 2s - loss: 0.1262 - accuracy: 0.9339\n",
      " 878/5349 [===>..........................] - ETA: 2s - loss: 0.1264 - accuracy: 0.9340\n",
      "1048/5349 [====>.........................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9336\n",
      "1211/5349 [=====>........................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9336\n",
      "1384/5349 [======>.......................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9336\n",
      "1463/5349 [=======>......................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9336\n",
      "1622/5349 [========>.....................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9337\n",
      "1793/5349 [=========>....................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9338\n",
      "1956/5349 [=========>....................] - ETA: 2s - loss: 0.1272 - accuracy: 0.9338\n",
      "2124/5349 [==========>...................] - ETA: 1s - loss: 0.1273 - accuracy: 0.9339\n",
      "2289/5349 [===========>..................] - ETA: 1s - loss: 0.1276 - accuracy: 0.9338\n",
      "2450/5349 [============>.................] - ETA: 1s - loss: 0.1277 - accuracy: 0.9336\n",
      "2619/5349 [=============>................] - ETA: 1s - loss: 0.1277 - accuracy: 0.9336\n",
      "2784/5349 [==============>...............] - ETA: 1s - loss: 0.1276 - accuracy: 0.9335\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1278 - accuracy: 0.9334\n",
      "3122/5349 [================>.............] - ETA: 1s - loss: 0.1278 - accuracy: 0.9334\n",
      "3289/5349 [=================>............] - ETA: 1s - loss: 0.1277 - accuracy: 0.9336\n",
      "3461/5349 [==================>...........] - ETA: 1s - loss: 0.1277 - accuracy: 0.9335\n",
      "3605/5349 [===================>..........] - ETA: 1s - loss: 0.1276 - accuracy: 0.9336\n",
      "3861/5349 [====================>.........] - ETA: 0s - loss: 0.1274 - accuracy: 0.9338\n",
      "4027/5349 [=====================>........] - ETA: 0s - loss: 0.1274 - accuracy: 0.9338\n",
      "4196/5349 [======================>.......] - ETA: 0s - loss: 0.1272 - accuracy: 0.9339\n",
      "4362/5349 [=======================>......] - ETA: 0s - loss: 0.1273 - accuracy: 0.9338\n",
      "4531/5349 [========================>.....] - ETA: 0s - loss: 0.1273 - accuracy: 0.9338\n",
      "4681/5349 [=========================>....] - ETA: 0s - loss: 0.1272 - accuracy: 0.9339\n",
      "4838/5349 [==========================>...] - ETA: 0s - loss: 0.1274 - accuracy: 0.9337\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1274 - accuracy: 0.9337\n",
      "5250/5349 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 0.9337\n",
      "5332/5349 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 0.9336\n",
      "5349/5349 [==============================] - 4s 779us/step - loss: 0.1274 - accuracy: 0.9336 - val_loss: 0.1250 - val_accuracy: 0.9352\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1172 - accuracy: 0.9300\n",
      " 168/5349 [..............................] - ETA: 3s - loss: 0.1255 - accuracy: 0.9320\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1263 - accuracy: 0.9322\n",
      " 475/5349 [=>............................] - ETA: 3s - loss: 0.1259 - accuracy: 0.9328\n",
      " 648/5349 [==>...........................] - ETA: 2s - loss: 0.1257 - accuracy: 0.9334\n",
      " 806/5349 [===>..........................] - ETA: 2s - loss: 0.1265 - accuracy: 0.9333\n",
      " 977/5349 [====>.........................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9333\n",
      "1141/5349 [=====>........................] - ETA: 2s - loss: 0.1268 - accuracy: 0.9334\n",
      "1312/5349 [======>.......................] - ETA: 2s - loss: 0.1265 - accuracy: 0.9337\n",
      "1394/5349 [======>.......................] - ETA: 2s - loss: 0.1266 - accuracy: 0.9335\n",
      "1561/5349 [=======>......................] - ETA: 2s - loss: 0.1263 - accuracy: 0.9338\n",
      "1730/5349 [========>.....................] - ETA: 2s - loss: 0.1261 - accuracy: 0.9341\n",
      "1896/5349 [=========>....................] - ETA: 2s - loss: 0.1261 - accuracy: 0.9342\n",
      "2067/5349 [==========>...................] - ETA: 2s - loss: 0.1264 - accuracy: 0.9341\n",
      "2233/5349 [===========>..................] - ETA: 1s - loss: 0.1263 - accuracy: 0.9340\n",
      "2404/5349 [============>.................] - ETA: 1s - loss: 0.1263 - accuracy: 0.9340\n",
      "2560/5349 [=============>................] - ETA: 1s - loss: 0.1262 - accuracy: 0.9340\n",
      "2735/5349 [==============>...............] - ETA: 1s - loss: 0.1260 - accuracy: 0.9342\n",
      "2968/5349 [===============>..............] - ETA: 1s - loss: 0.1257 - accuracy: 0.9343\n",
      "3087/5349 [================>.............] - ETA: 1s - loss: 0.1257 - accuracy: 0.9344\n",
      "3215/5349 [=================>............] - ETA: 1s - loss: 0.1255 - accuracy: 0.9345\n",
      "3346/5349 [=================>............] - ETA: 1s - loss: 0.1255 - accuracy: 0.9346\n",
      "3471/5349 [==================>...........] - ETA: 1s - loss: 0.1253 - accuracy: 0.9347\n",
      "3598/5349 [===================>..........] - ETA: 1s - loss: 0.1253 - accuracy: 0.9346\n",
      "3712/5349 [===================>..........] - ETA: 1s - loss: 0.1253 - accuracy: 0.9346\n",
      "3845/5349 [====================>.........] - ETA: 0s - loss: 0.1252 - accuracy: 0.9346\n",
      "4046/5349 [=====================>........] - ETA: 0s - loss: 0.1254 - accuracy: 0.9345\n",
      "4160/5349 [======================>.......] - ETA: 0s - loss: 0.1256 - accuracy: 0.9344\n",
      "4256/5349 [======================>.......] - ETA: 0s - loss: 0.1255 - accuracy: 0.9344\n",
      "4338/5349 [=======================>......] - ETA: 0s - loss: 0.1255 - accuracy: 0.9343\n",
      "4520/5349 [========================>.....] - ETA: 0s - loss: 0.1254 - accuracy: 0.9344\n",
      "4651/5349 [=========================>....] - ETA: 0s - loss: 0.1253 - accuracy: 0.9345\n",
      "4800/5349 [=========================>....] - ETA: 0s - loss: 0.1252 - accuracy: 0.9345\n",
      "4944/5349 [==========================>...] - ETA: 0s - loss: 0.1251 - accuracy: 0.9346\n",
      "5083/5349 [===========================>..] - ETA: 0s - loss: 0.1251 - accuracy: 0.9346\n",
      "5242/5349 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9346\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9346\n",
      "5349/5349 [==============================] - 5s 858us/step - loss: 0.1251 - accuracy: 0.9346 - val_loss: 0.1273 - val_accuracy: 0.9277\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.2076 - accuracy: 0.8500\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1297 - accuracy: 0.9317\n",
      " 340/5349 [>.............................] - ETA: 2s - loss: 0.1269 - accuracy: 0.9329\n",
      " 501/5349 [=>............................] - ETA: 2s - loss: 0.1254 - accuracy: 0.9340\n",
      " 747/5349 [===>..........................] - ETA: 2s - loss: 0.1239 - accuracy: 0.9349\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.1237 - accuracy: 0.9351\n",
      "1081/5349 [=====>........................] - ETA: 2s - loss: 0.1239 - accuracy: 0.9353\n",
      "1225/5349 [=====>........................] - ETA: 2s - loss: 0.1242 - accuracy: 0.9350\n",
      "1391/5349 [======>.......................] - ETA: 2s - loss: 0.1239 - accuracy: 0.9352\n",
      "1549/5349 [=======>......................] - ETA: 2s - loss: 0.1237 - accuracy: 0.9349\n",
      "1709/5349 [========>.....................] - ETA: 2s - loss: 0.1234 - accuracy: 0.9352\n",
      "1830/5349 [=========>....................] - ETA: 2s - loss: 0.1233 - accuracy: 0.9353\n",
      "1991/5349 [==========>...................] - ETA: 2s - loss: 0.1231 - accuracy: 0.9353\n",
      "2069/5349 [==========>...................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9354\n",
      "2227/5349 [===========>..................] - ETA: 1s - loss: 0.1232 - accuracy: 0.9354\n",
      "2379/5349 [============>.................] - ETA: 1s - loss: 0.1233 - accuracy: 0.9354\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.1235 - accuracy: 0.9354\n",
      "2701/5349 [==============>...............] - ETA: 1s - loss: 0.1234 - accuracy: 0.9354\n",
      "2853/5349 [===============>..............] - ETA: 1s - loss: 0.1233 - accuracy: 0.9355\n",
      "3013/5349 [===============>..............] - ETA: 1s - loss: 0.1236 - accuracy: 0.9354\n",
      "3246/5349 [=================>............] - ETA: 1s - loss: 0.1235 - accuracy: 0.9355\n",
      "3415/5349 [==================>...........] - ETA: 1s - loss: 0.1233 - accuracy: 0.9357\n",
      "3548/5349 [==================>...........] - ETA: 1s - loss: 0.1232 - accuracy: 0.9358\n",
      "3720/5349 [===================>..........] - ETA: 1s - loss: 0.1233 - accuracy: 0.9356\n",
      "3964/5349 [=====================>........] - ETA: 0s - loss: 0.1233 - accuracy: 0.9356\n",
      "4130/5349 [======================>.......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9356\n",
      "4296/5349 [=======================>......] - ETA: 0s - loss: 0.1234 - accuracy: 0.9355\n",
      "4464/5349 [========================>.....] - ETA: 0s - loss: 0.1233 - accuracy: 0.9356\n",
      "4616/5349 [========================>.....] - ETA: 0s - loss: 0.1235 - accuracy: 0.9355\n",
      "4771/5349 [=========================>....] - ETA: 0s - loss: 0.1234 - accuracy: 0.9356\n",
      "5017/5349 [===========================>..] - ETA: 0s - loss: 0.1231 - accuracy: 0.9358\n",
      "5185/5349 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9358\n",
      "5348/5349 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9357\n",
      "5349/5349 [==============================] - 4s 795us/step - loss: 0.1232 - accuracy: 0.9357 - val_loss: 0.1200 - val_accuracy: 0.9379\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 10/20\n",
      "  86/5349 [..............................] - ETA: 3s - loss: 0.1220 - accuracy: 0.9355\n",
      " 249/5349 [>.............................] - ETA: 3s - loss: 0.1204 - accuracy: 0.9364\n",
      " 412/5349 [=>............................] - ETA: 3s - loss: 0.1209 - accuracy: 0.9372\n",
      " 576/5349 [==>...........................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9368\n",
      " 744/5349 [===>..........................] - ETA: 2s - loss: 0.1211 - accuracy: 0.9369\n",
      " 910/5349 [====>.........................] - ETA: 2s - loss: 0.1211 - accuracy: 0.9369\n",
      "1081/5349 [=====>........................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9367\n",
      "1239/5349 [=====>........................] - ETA: 2s - loss: 0.1221 - accuracy: 0.9363\n",
      "1323/5349 [======>.......................] - ETA: 2s - loss: 0.1226 - accuracy: 0.9359\n",
      "1493/5349 [=======>......................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9357\n",
      "1658/5349 [========>.....................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9359\n",
      "1830/5349 [=========>....................] - ETA: 2s - loss: 0.1229 - accuracy: 0.9359\n",
      "1993/5349 [==========>...................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9361\n",
      "2159/5349 [===========>..................] - ETA: 1s - loss: 0.1226 - accuracy: 0.9362\n",
      "2322/5349 [============>.................] - ETA: 1s - loss: 0.1228 - accuracy: 0.9360\n",
      "2493/5349 [============>.................] - ETA: 1s - loss: 0.1228 - accuracy: 0.9359\n",
      "2643/5349 [=============>................] - ETA: 1s - loss: 0.1226 - accuracy: 0.9360\n",
      "2815/5349 [==============>...............] - ETA: 1s - loss: 0.1224 - accuracy: 0.9361\n",
      "2896/5349 [===============>..............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9360\n",
      "3062/5349 [================>.............] - ETA: 1s - loss: 0.1224 - accuracy: 0.9360\n",
      "3234/5349 [=================>............] - ETA: 1s - loss: 0.1225 - accuracy: 0.9360\n",
      "3393/5349 [==================>...........] - ETA: 1s - loss: 0.1222 - accuracy: 0.9362\n",
      "3566/5349 [===================>..........] - ETA: 1s - loss: 0.1219 - accuracy: 0.9363\n",
      "3726/5349 [===================>..........] - ETA: 0s - loss: 0.1220 - accuracy: 0.9362\n",
      "3898/5349 [====================>.........] - ETA: 0s - loss: 0.1218 - accuracy: 0.9364\n",
      "4063/5349 [=====================>........] - ETA: 0s - loss: 0.1217 - accuracy: 0.9364\n",
      "4235/5349 [======================>.......] - ETA: 0s - loss: 0.1217 - accuracy: 0.9365\n",
      "4483/5349 [========================>.....] - ETA: 0s - loss: 0.1218 - accuracy: 0.9363\n",
      "4650/5349 [=========================>....] - ETA: 0s - loss: 0.1217 - accuracy: 0.9364\n",
      "4816/5349 [==========================>...] - ETA: 0s - loss: 0.1217 - accuracy: 0.9364\n",
      "4985/5349 [==========================>...] - ETA: 0s - loss: 0.1216 - accuracy: 0.9365\n",
      "5138/5349 [===========================>..] - ETA: 0s - loss: 0.1215 - accuracy: 0.9366\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9366\n",
      "5349/5349 [==============================] - 4s 822us/step - loss: 0.1215 - accuracy: 0.9366 - val_loss: 0.1185 - val_accuracy: 0.9396\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 9s - loss: 0.1233 - accuracy: 0.9200\n",
      " 101/5349 [..............................] - ETA: 5s - loss: 0.1145 - accuracy: 0.9399\n",
      " 210/5349 [>.............................] - ETA: 4s - loss: 0.1172 - accuracy: 0.9377\n",
      " 339/5349 [>.............................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9375\n",
      " 506/5349 [=>............................] - ETA: 3s - loss: 0.1190 - accuracy: 0.9379\n",
      " 592/5349 [==>...........................] - ETA: 3s - loss: 0.1196 - accuracy: 0.9378\n",
      " 759/5349 [===>..........................] - ETA: 3s - loss: 0.1191 - accuracy: 0.9384\n",
      " 930/5349 [====>.........................] - ETA: 3s - loss: 0.1198 - accuracy: 0.9385\n",
      "1094/5349 [=====>........................] - ETA: 2s - loss: 0.1197 - accuracy: 0.9386\n",
      "1262/5349 [======>.......................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9385\n",
      "1405/5349 [======>.......................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9383\n",
      "1577/5349 [=======>......................] - ETA: 2s - loss: 0.1200 - accuracy: 0.9382\n",
      "1740/5349 [========>.....................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9381\n",
      "1911/5349 [=========>....................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9380\n",
      "2072/5349 [==========>...................] - ETA: 2s - loss: 0.1204 - accuracy: 0.9379\n",
      "2240/5349 [===========>..................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9379\n",
      "2488/5349 [============>.................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9379\n",
      "2657/5349 [=============>................] - ETA: 1s - loss: 0.1198 - accuracy: 0.9381\n",
      "2823/5349 [==============>...............] - ETA: 1s - loss: 0.1198 - accuracy: 0.9382\n",
      "2985/5349 [===============>..............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9379\n",
      "3141/5349 [================>.............] - ETA: 1s - loss: 0.1202 - accuracy: 0.9378\n",
      "3311/5349 [=================>............] - ETA: 1s - loss: 0.1204 - accuracy: 0.9376\n",
      "3472/5349 [==================>...........] - ETA: 1s - loss: 0.1203 - accuracy: 0.9376\n",
      "3641/5349 [===================>..........] - ETA: 1s - loss: 0.1203 - accuracy: 0.9376\n",
      "3712/5349 [===================>..........] - ETA: 1s - loss: 0.1204 - accuracy: 0.9375\n",
      "3872/5349 [====================>.........] - ETA: 0s - loss: 0.1204 - accuracy: 0.9374\n",
      "4039/5349 [=====================>........] - ETA: 0s - loss: 0.1203 - accuracy: 0.9374\n",
      "4196/5349 [======================>.......] - ETA: 0s - loss: 0.1202 - accuracy: 0.9374\n",
      "4323/5349 [=======================>......] - ETA: 0s - loss: 0.1201 - accuracy: 0.9374\n",
      "4471/5349 [========================>.....] - ETA: 0s - loss: 0.1201 - accuracy: 0.9374\n",
      "4637/5349 [=========================>....] - ETA: 0s - loss: 0.1202 - accuracy: 0.9373\n",
      "4797/5349 [=========================>....] - ETA: 0s - loss: 0.1200 - accuracy: 0.9374\n",
      "4967/5349 [==========================>...] - ETA: 0s - loss: 0.1200 - accuracy: 0.9373\n",
      "5218/5349 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9373\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9373\n",
      "5349/5349 [==============================] - 4s 813us/step - loss: 0.1201 - accuracy: 0.9374 - val_loss: 0.1181 - val_accuracy: 0.9390\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 14s - loss: 0.0922 - accuracy: 0.9700\n",
      " 123/5349 [..............................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9381\n",
      " 291/5349 [>.............................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9404\n",
      " 454/5349 [=>............................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9389\n",
      " 624/5349 [==>...........................] - ETA: 3s - loss: 0.1188 - accuracy: 0.9386\n",
      " 776/5349 [===>..........................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9388\n",
      "1017/5349 [====>.........................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9385\n",
      "1188/5349 [=====>........................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9385\n",
      "1360/5349 [======>.......................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9382\n",
      "1523/5349 [=======>......................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9377\n",
      "1692/5349 [========>.....................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9378\n",
      "1859/5349 [=========>....................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9378\n",
      "2035/5349 [==========>...................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9379\n",
      "2203/5349 [===========>..................] - ETA: 1s - loss: 0.1185 - accuracy: 0.9380\n",
      "2374/5349 [============>.................] - ETA: 1s - loss: 0.1185 - accuracy: 0.9379\n",
      "2514/5349 [=============>................] - ETA: 1s - loss: 0.1182 - accuracy: 0.9381\n",
      "2683/5349 [==============>...............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9382\n",
      "2828/5349 [==============>...............] - ETA: 1s - loss: 0.1184 - accuracy: 0.9380\n",
      "3081/5349 [================>.............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9378\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.1190 - accuracy: 0.9374\n",
      "3404/5349 [==================>...........] - ETA: 1s - loss: 0.1191 - accuracy: 0.9373\n",
      "3573/5349 [===================>..........] - ETA: 1s - loss: 0.1190 - accuracy: 0.9373\n",
      "3743/5349 [===================>..........] - ETA: 0s - loss: 0.1192 - accuracy: 0.9373\n",
      "3907/5349 [====================>.........] - ETA: 0s - loss: 0.1192 - accuracy: 0.9373\n",
      "4078/5349 [=====================>........] - ETA: 0s - loss: 0.1192 - accuracy: 0.9373\n",
      "4232/5349 [======================>.......] - ETA: 0s - loss: 0.1192 - accuracy: 0.9374\n",
      "4404/5349 [=======================>......] - ETA: 0s - loss: 0.1191 - accuracy: 0.9374\n",
      "4570/5349 [========================>.....] - ETA: 0s - loss: 0.1191 - accuracy: 0.9375\n",
      "4829/5349 [==========================>...] - ETA: 0s - loss: 0.1192 - accuracy: 0.9374\n",
      "4972/5349 [==========================>...] - ETA: 0s - loss: 0.1191 - accuracy: 0.9374\n",
      "5143/5349 [===========================>..] - ETA: 0s - loss: 0.1191 - accuracy: 0.9375\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.1190 - accuracy: 0.9375\n",
      "5349/5349 [==============================] - 4s 780us/step - loss: 0.1190 - accuracy: 0.9375 - val_loss: 0.1156 - val_accuracy: 0.9403\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0832 - accuracy: 0.9700\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9410\n",
      " 256/5349 [>.............................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9416\n",
      " 416/5349 [=>............................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9407\n",
      " 559/5349 [==>...........................] - ETA: 3s - loss: 0.1169 - accuracy: 0.9403\n",
      " 713/5349 [==>...........................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9401\n",
      " 856/5349 [===>..........................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9392\n",
      "1015/5349 [====>.........................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9386\n",
      "1153/5349 [=====>........................] - ETA: 2s - loss: 0.1183 - accuracy: 0.9384\n",
      "1366/5349 [======>.......................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9380\n",
      "1494/5349 [=======>......................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9383\n",
      "1630/5349 [========>.....................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9383\n",
      "1747/5349 [========>.....................] - ETA: 2s - loss: 0.1187 - accuracy: 0.9383\n",
      "1880/5349 [=========>....................] - ETA: 2s - loss: 0.1187 - accuracy: 0.9381\n",
      "2007/5349 [==========>...................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9382\n",
      "2197/5349 [===========>..................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9382\n",
      "2338/5349 [============>.................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9382\n",
      "2465/5349 [============>.................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9382\n",
      "2597/5349 [=============>................] - ETA: 1s - loss: 0.1188 - accuracy: 0.9383\n",
      "2711/5349 [==============>...............] - ETA: 1s - loss: 0.1189 - accuracy: 0.9382\n",
      "2843/5349 [==============>...............] - ETA: 1s - loss: 0.1187 - accuracy: 0.9382\n",
      "2978/5349 [===============>..............] - ETA: 1s - loss: 0.1187 - accuracy: 0.9381\n",
      "3125/5349 [================>.............] - ETA: 1s - loss: 0.1185 - accuracy: 0.9381\n",
      "3271/5349 [=================>............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9378\n",
      "3425/5349 [==================>...........] - ETA: 1s - loss: 0.1186 - accuracy: 0.9378\n",
      "3589/5349 [===================>..........] - ETA: 1s - loss: 0.1185 - accuracy: 0.9379\n",
      "3673/5349 [===================>..........] - ETA: 1s - loss: 0.1184 - accuracy: 0.9379\n",
      "3834/5349 [====================>.........] - ETA: 1s - loss: 0.1186 - accuracy: 0.9377\n",
      "4004/5349 [=====================>........] - ETA: 0s - loss: 0.1184 - accuracy: 0.9378\n",
      "4169/5349 [======================>.......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9377\n",
      "4330/5349 [=======================>......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9378\n",
      "4480/5349 [========================>.....] - ETA: 0s - loss: 0.1183 - accuracy: 0.9379\n",
      "4646/5349 [=========================>....] - ETA: 0s - loss: 0.1183 - accuracy: 0.9379\n",
      "4887/5349 [==========================>...] - ETA: 0s - loss: 0.1183 - accuracy: 0.9378\n",
      "5046/5349 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 0.9379\n",
      "5207/5349 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9380\n",
      "5278/5349 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9380\n",
      "5349/5349 [==============================] - 5s 865us/step - loss: 0.1182 - accuracy: 0.9381 - val_loss: 0.1161 - val_accuracy: 0.9385\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 14/20\n",
      "  85/5349 [..............................] - ETA: 3s - loss: 0.1237 - accuracy: 0.9334\n",
      " 254/5349 [>.............................] - ETA: 3s - loss: 0.1203 - accuracy: 0.9346\n",
      " 386/5349 [=>............................] - ETA: 3s - loss: 0.1181 - accuracy: 0.9371\n",
      " 546/5349 [==>...........................] - ETA: 3s - loss: 0.1182 - accuracy: 0.9369\n",
      " 711/5349 [==>...........................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9366\n",
      " 874/5349 [===>..........................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9369\n",
      "1044/5349 [====>.........................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9369\n",
      "1206/5349 [=====>........................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9370\n",
      "1456/5349 [=======>......................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9370\n",
      "1619/5349 [========>.....................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9370\n",
      "1793/5349 [=========>....................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9371\n",
      "1933/5349 [=========>....................] - ETA: 2s - loss: 0.1180 - accuracy: 0.9373\n",
      "2104/5349 [==========>...................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9374\n",
      "2259/5349 [===========>..................] - ETA: 1s - loss: 0.1177 - accuracy: 0.9376\n",
      "2421/5349 [============>.................] - ETA: 1s - loss: 0.1178 - accuracy: 0.9377\n",
      "2588/5349 [=============>................] - ETA: 1s - loss: 0.1180 - accuracy: 0.9376\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.1179 - accuracy: 0.9376\n",
      "2995/5349 [===============>..............] - ETA: 1s - loss: 0.1178 - accuracy: 0.9377\n",
      "3157/5349 [================>.............] - ETA: 1s - loss: 0.1178 - accuracy: 0.9377\n",
      "3325/5349 [=================>............] - ETA: 1s - loss: 0.1175 - accuracy: 0.9379\n",
      "3487/5349 [==================>...........] - ETA: 1s - loss: 0.1176 - accuracy: 0.9378\n",
      "3650/5349 [===================>..........] - ETA: 1s - loss: 0.1174 - accuracy: 0.9379\n",
      "3816/5349 [====================>.........] - ETA: 0s - loss: 0.1175 - accuracy: 0.9379\n",
      "4052/5349 [=====================>........] - ETA: 0s - loss: 0.1174 - accuracy: 0.9379\n",
      "4212/5349 [======================>.......] - ETA: 0s - loss: 0.1172 - accuracy: 0.9380\n",
      "4376/5349 [=======================>......] - ETA: 0s - loss: 0.1171 - accuracy: 0.9381\n",
      "4539/5349 [========================>.....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9381\n",
      "4697/5349 [=========================>....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9381\n",
      "4861/5349 [==========================>...] - ETA: 0s - loss: 0.1172 - accuracy: 0.9382\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.1174 - accuracy: 0.9382\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9381\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9382\n",
      "5349/5349 [==============================] - 4s 789us/step - loss: 0.1174 - accuracy: 0.9382 - val_loss: 0.1149 - val_accuracy: 0.9396\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1128 - accuracy: 0.9300\n",
      " 172/5349 [..............................] - ETA: 3s - loss: 0.1128 - accuracy: 0.9410\n",
      " 344/5349 [>.............................] - ETA: 2s - loss: 0.1141 - accuracy: 0.9402\n",
      " 504/5349 [=>............................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9394\n",
      " 677/5349 [==>...........................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9388\n",
      " 842/5349 [===>..........................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9391\n",
      "1015/5349 [====>.........................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9386\n",
      "1170/5349 [=====>........................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9388\n",
      "1340/5349 [======>.......................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9384\n",
      "1504/5349 [=======>......................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9385\n",
      "1673/5349 [========>.....................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9386\n",
      "1910/5349 [=========>....................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9389\n",
      "2077/5349 [==========>...................] - ETA: 1s - loss: 0.1161 - accuracy: 0.9390\n",
      "2242/5349 [===========>..................] - ETA: 1s - loss: 0.1159 - accuracy: 0.9392\n",
      "2410/5349 [============>.................] - ETA: 1s - loss: 0.1160 - accuracy: 0.9392\n",
      "2571/5349 [=============>................] - ETA: 1s - loss: 0.1161 - accuracy: 0.9390\n",
      "2742/5349 [==============>...............] - ETA: 1s - loss: 0.1161 - accuracy: 0.9389\n",
      "2902/5349 [===============>..............] - ETA: 1s - loss: 0.1162 - accuracy: 0.9388\n",
      "3073/5349 [================>.............] - ETA: 1s - loss: 0.1161 - accuracy: 0.9390\n",
      "3233/5349 [=================>............] - ETA: 1s - loss: 0.1161 - accuracy: 0.9390\n",
      "3472/5349 [==================>...........] - ETA: 1s - loss: 0.1162 - accuracy: 0.9389\n",
      "3631/5349 [===================>..........] - ETA: 1s - loss: 0.1163 - accuracy: 0.9389\n",
      "3801/5349 [====================>.........] - ETA: 0s - loss: 0.1162 - accuracy: 0.9390\n",
      "3929/5349 [=====================>........] - ETA: 0s - loss: 0.1163 - accuracy: 0.9390\n",
      "4051/5349 [=====================>........] - ETA: 0s - loss: 0.1165 - accuracy: 0.9389\n",
      "4188/5349 [======================>.......] - ETA: 0s - loss: 0.1165 - accuracy: 0.9390\n",
      "4308/5349 [=======================>......] - ETA: 0s - loss: 0.1165 - accuracy: 0.9390\n",
      "4494/5349 [========================>.....] - ETA: 0s - loss: 0.1166 - accuracy: 0.9389\n",
      "4629/5349 [========================>.....] - ETA: 0s - loss: 0.1166 - accuracy: 0.9388\n",
      "4758/5349 [=========================>....] - ETA: 0s - loss: 0.1165 - accuracy: 0.9389\n",
      "4809/5349 [=========================>....] - ETA: 0s - loss: 0.1165 - accuracy: 0.9389\n",
      "4906/5349 [==========================>...] - ETA: 0s - loss: 0.1165 - accuracy: 0.9389\n",
      "5009/5349 [===========================>..] - ETA: 0s - loss: 0.1166 - accuracy: 0.9388\n",
      "5095/5349 [===========================>..] - ETA: 0s - loss: 0.1166 - accuracy: 0.9388\n",
      "5222/5349 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9387\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9386\n",
      "5349/5349 [==============================] - 5s 866us/step - loss: 0.1166 - accuracy: 0.9387 - val_loss: 0.1142 - val_accuracy: 0.9394\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 16/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9393\n",
      " 253/5349 [>.............................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9386\n",
      " 425/5349 [=>............................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9394\n",
      " 585/5349 [==>...........................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9393\n",
      " 752/5349 [===>..........................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9390\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9387\n",
      "1077/5349 [=====>........................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9384\n",
      "1240/5349 [=====>........................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9384\n",
      "1493/5349 [=======>......................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9378\n",
      "1655/5349 [========>.....................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9380\n",
      "1822/5349 [=========>....................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9380\n",
      "1982/5349 [==========>...................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9382\n",
      "2136/5349 [==========>...................] - ETA: 1s - loss: 0.1174 - accuracy: 0.9381\n",
      "2281/5349 [===========>..................] - ETA: 1s - loss: 0.1171 - accuracy: 0.9384\n",
      "2453/5349 [============>.................] - ETA: 1s - loss: 0.1172 - accuracy: 0.9381\n",
      "2617/5349 [=============>................] - ETA: 1s - loss: 0.1171 - accuracy: 0.9382\n",
      "2877/5349 [===============>..............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9381\n",
      "3037/5349 [================>.............] - ETA: 1s - loss: 0.1169 - accuracy: 0.9382\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.1170 - accuracy: 0.9381\n",
      "3367/5349 [=================>............] - ETA: 1s - loss: 0.1166 - accuracy: 0.9384\n",
      "3534/5349 [==================>...........] - ETA: 1s - loss: 0.1165 - accuracy: 0.9384\n",
      "3699/5349 [===================>..........] - ETA: 1s - loss: 0.1165 - accuracy: 0.9385\n",
      "3857/5349 [====================>.........] - ETA: 0s - loss: 0.1165 - accuracy: 0.9385\n",
      "4019/5349 [=====================>........] - ETA: 0s - loss: 0.1164 - accuracy: 0.9385\n",
      "4257/5349 [======================>.......] - ETA: 0s - loss: 0.1162 - accuracy: 0.9385\n",
      "4406/5349 [=======================>......] - ETA: 0s - loss: 0.1161 - accuracy: 0.9385\n",
      "4576/5349 [========================>.....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9385\n",
      "4734/5349 [=========================>....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9385\n",
      "4903/5349 [==========================>...] - ETA: 0s - loss: 0.1161 - accuracy: 0.9385\n",
      "5041/5349 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9386\n",
      "5192/5349 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9385\n",
      "5338/5349 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9385\n",
      "5349/5349 [==============================] - 4s 786us/step - loss: 0.1161 - accuracy: 0.9385 - val_loss: 0.1133 - val_accuracy: 0.9411\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0789 - accuracy: 0.9700\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9405\n",
      " 322/5349 [>.............................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9387\n",
      " 468/5349 [=>............................] - ETA: 3s - loss: 0.1143 - accuracy: 0.9400\n",
      " 627/5349 [==>...........................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9403\n",
      " 767/5349 [===>..........................] - ETA: 3s - loss: 0.1140 - accuracy: 0.9401\n",
      " 929/5349 [====>.........................] - ETA: 2s - loss: 0.1141 - accuracy: 0.9399\n",
      "1066/5349 [====>.........................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9399\n",
      "1229/5349 [=====>........................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9398\n",
      "1379/5349 [======>.......................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9393\n",
      "1543/5349 [=======>......................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9395\n",
      "1685/5349 [========>.....................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9397\n",
      "1840/5349 [=========>....................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9393\n",
      "2000/5349 [==========>...................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9393\n",
      "2162/5349 [===========>..................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9392\n",
      "2237/5349 [===========>..................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9392\n",
      "2403/5349 [============>.................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9392\n",
      "2575/5349 [=============>................] - ETA: 1s - loss: 0.1156 - accuracy: 0.9391\n",
      "2739/5349 [==============>...............] - ETA: 1s - loss: 0.1157 - accuracy: 0.9389\n",
      "2911/5349 [===============>..............] - ETA: 1s - loss: 0.1160 - accuracy: 0.9388\n",
      "3068/5349 [================>.............] - ETA: 1s - loss: 0.1160 - accuracy: 0.9389\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.1159 - accuracy: 0.9388\n",
      "3390/5349 [==================>...........] - ETA: 1s - loss: 0.1159 - accuracy: 0.9388\n",
      "3562/5349 [==================>...........] - ETA: 1s - loss: 0.1160 - accuracy: 0.9386\n",
      "3806/5349 [====================>.........] - ETA: 0s - loss: 0.1159 - accuracy: 0.9386\n",
      "3978/5349 [=====================>........] - ETA: 0s - loss: 0.1159 - accuracy: 0.9387\n",
      "4146/5349 [======================>.......] - ETA: 0s - loss: 0.1160 - accuracy: 0.9385\n",
      "4317/5349 [=======================>......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9386\n",
      "4482/5349 [========================>.....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9387\n",
      "4653/5349 [=========================>....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9388\n",
      "4815/5349 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.9388\n",
      "4981/5349 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.9388\n",
      "5139/5349 [===========================>..] - ETA: 0s - loss: 0.1157 - accuracy: 0.9388\n",
      "5284/5349 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9388\n",
      "5349/5349 [==============================] - 4s 813us/step - loss: 0.1155 - accuracy: 0.9389 - val_loss: 0.1130 - val_accuracy: 0.9413\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 18/20\n",
      "  45/5349 [..............................] - ETA: 6s - loss: 0.1179 - accuracy: 0.9396\n",
      " 165/5349 [..............................] - ETA: 4s - loss: 0.1146 - accuracy: 0.9378\n",
      " 313/5349 [>.............................] - ETA: 4s - loss: 0.1154 - accuracy: 0.9383\n",
      " 419/5349 [=>............................] - ETA: 4s - loss: 0.1158 - accuracy: 0.9380\n",
      " 613/5349 [==>...........................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9381\n",
      " 686/5349 [==>...........................] - ETA: 4s - loss: 0.1160 - accuracy: 0.9385\n",
      " 805/5349 [===>..........................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9386\n",
      " 935/5349 [====>.........................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9385\n",
      "1076/5349 [=====>........................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9384\n",
      "1238/5349 [=====>........................] - ETA: 3s - loss: 0.1163 - accuracy: 0.9386\n",
      "1407/5349 [======>.......................] - ETA: 3s - loss: 0.1155 - accuracy: 0.9389\n",
      "1560/5349 [=======>......................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9393\n",
      "1814/5349 [=========>....................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9392\n",
      "1971/5349 [==========>...................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9392\n",
      "2140/5349 [===========>..................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9395\n",
      "2297/5349 [===========>..................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9394\n",
      "2460/5349 [============>.................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9396\n",
      "2612/5349 [=============>................] - ETA: 1s - loss: 0.1149 - accuracy: 0.9395\n",
      "2774/5349 [==============>...............] - ETA: 1s - loss: 0.1148 - accuracy: 0.9396\n",
      "2932/5349 [===============>..............] - ETA: 1s - loss: 0.1148 - accuracy: 0.9396\n",
      "3173/5349 [================>.............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9395\n",
      "3340/5349 [=================>............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9394\n",
      "3506/5349 [==================>...........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9392\n",
      "3652/5349 [===================>..........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9393\n",
      "3820/5349 [====================>.........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9394\n",
      "3979/5349 [=====================>........] - ETA: 0s - loss: 0.1150 - accuracy: 0.9394\n",
      "4148/5349 [======================>.......] - ETA: 0s - loss: 0.1150 - accuracy: 0.9394\n",
      "4305/5349 [=======================>......] - ETA: 0s - loss: 0.1149 - accuracy: 0.9394\n",
      "4476/5349 [========================>.....] - ETA: 0s - loss: 0.1148 - accuracy: 0.9394\n",
      "4558/5349 [========================>.....] - ETA: 0s - loss: 0.1147 - accuracy: 0.9394\n",
      "4721/5349 [=========================>....] - ETA: 0s - loss: 0.1146 - accuracy: 0.9395\n",
      "4893/5349 [==========================>...] - ETA: 0s - loss: 0.1147 - accuracy: 0.9395\n",
      "5058/5349 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.9394\n",
      "5176/5349 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9395\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9396\n",
      "5349/5349 [==============================] - 5s 852us/step - loss: 0.1146 - accuracy: 0.9396 - val_loss: 0.1125 - val_accuracy: 0.9397\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 19/20\n",
      " 170/5349 [..............................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9400\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9388\n",
      " 511/5349 [=>............................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9390\n",
      " 673/5349 [==>...........................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9394\n",
      " 846/5349 [===>..........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9390\n",
      "1011/5349 [====>.........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9390\n",
      "1174/5349 [=====>........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9388\n",
      "1336/5349 [======>.......................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9390\n",
      "1507/5349 [=======>......................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9393\n",
      "1669/5349 [========>.....................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9394\n",
      "1840/5349 [=========>....................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9394\n",
      "2002/5349 [==========>...................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9392\n",
      "2251/5349 [===========>..................] - ETA: 1s - loss: 0.1147 - accuracy: 0.9393\n",
      "2412/5349 [============>.................] - ETA: 1s - loss: 0.1146 - accuracy: 0.9393\n",
      "2583/5349 [=============>................] - ETA: 1s - loss: 0.1145 - accuracy: 0.9394\n",
      "2725/5349 [==============>...............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9395\n",
      "2896/5349 [===============>..............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9396\n",
      "3056/5349 [================>.............] - ETA: 1s - loss: 0.1143 - accuracy: 0.9397\n",
      "3226/5349 [=================>............] - ETA: 1s - loss: 0.1142 - accuracy: 0.9398\n",
      "3392/5349 [==================>...........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9397\n",
      "3522/5349 [==================>...........] - ETA: 1s - loss: 0.1144 - accuracy: 0.9395\n",
      "3679/5349 [===================>..........] - ETA: 1s - loss: 0.1143 - accuracy: 0.9396\n",
      "3850/5349 [====================>.........] - ETA: 0s - loss: 0.1142 - accuracy: 0.9396\n",
      "4015/5349 [=====================>........] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.1143 - accuracy: 0.9395\n",
      "4259/5349 [======================>.......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "4421/5349 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "4591/5349 [========================>.....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "4754/5349 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9396\n",
      "4926/5349 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "5071/5349 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "5239/5349 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9395\n",
      "5318/5349 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.9396\n",
      "5349/5349 [==============================] - 4s 782us/step - loss: 0.1143 - accuracy: 0.9395 - val_loss: 0.1129 - val_accuracy: 0.9367\n",
      "\u001B[36m(train_DNN pid=5662)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1174 - accuracy: 0.9600\n",
      " 168/5349 [..............................] - ETA: 3s - loss: 0.1134 - accuracy: 0.9390\n",
      " 339/5349 [>.............................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9392\n",
      " 497/5349 [=>............................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9392\n",
      " 747/5349 [===>..........................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9392\n",
      " 902/5349 [====>.........................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9391\n",
      "1070/5349 [=====>........................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9392\n",
      "1234/5349 [=====>........................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9389\n",
      "1391/5349 [======>.......................] - ETA: 2s - loss: 0.1146 - accuracy: 0.9391\n",
      "1537/5349 [=======>......................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9395\n",
      "1703/5349 [========>.....................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9392\n",
      "1934/5349 [=========>....................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9393\n",
      "2105/5349 [==========>...................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9394\n",
      "2229/5349 [===========>..................] - ETA: 1s - loss: 0.1140 - accuracy: 0.9396\n",
      "2328/5349 [============>.................] - ETA: 1s - loss: 0.1139 - accuracy: 0.9397\n",
      "2456/5349 [============>.................] - ETA: 1s - loss: 0.1141 - accuracy: 0.9396\n",
      "2590/5349 [=============>................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9394\n",
      "2717/5349 [==============>...............] - ETA: 1s - loss: 0.1142 - accuracy: 0.9395\n",
      "2922/5349 [===============>..............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9395\n",
      "3055/5349 [================>.............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9395\n",
      "3190/5349 [================>.............] - ETA: 1s - loss: 0.1140 - accuracy: 0.9396\n",
      "3294/5349 [=================>............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9395\n",
      "3436/5349 [==================>...........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9395\n",
      "3531/5349 [==================>...........] - ETA: 1s - loss: 0.1140 - accuracy: 0.9396\n",
      "3564/5349 [==================>...........] - ETA: 1s - loss: 0.1140 - accuracy: 0.9397\n",
      "3674/5349 [===================>..........] - ETA: 1s - loss: 0.1139 - accuracy: 0.9398\n",
      "3797/5349 [====================>.........] - ETA: 1s - loss: 0.1138 - accuracy: 0.9398\n",
      "3920/5349 [====================>.........] - ETA: 1s - loss: 0.1138 - accuracy: 0.9399\n",
      "4075/5349 [=====================>........] - ETA: 0s - loss: 0.1138 - accuracy: 0.9399\n",
      "4230/5349 [======================>.......] - ETA: 0s - loss: 0.1138 - accuracy: 0.9399\n",
      "4384/5349 [=======================>......] - ETA: 0s - loss: 0.1139 - accuracy: 0.9400\n",
      "4542/5349 [========================>.....] - ETA: 0s - loss: 0.1140 - accuracy: 0.9399\n",
      "4684/5349 [=========================>....] - ETA: 0s - loss: 0.1140 - accuracy: 0.9399\n",
      "4928/5349 [==========================>...] - ETA: 0s - loss: 0.1138 - accuracy: 0.9399\n",
      "5085/5349 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9400\n",
      "5254/5349 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9399\n",
      "5333/5349 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.9399\n",
      "5349/5349 [==============================] - 5s 869us/step - loss: 0.1137 - accuracy: 0.9399 - val_loss: 0.1111 - val_accuracy: 0.9429\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 27:22 - loss: 0.5752 - accuracy: 0.8300\n",
      " 111/5349 [..............................] - ETA: 4s - loss: 0.3338 - accuracy: 0.8458\n",
      " 274/5349 [>.............................] - ETA: 3s - loss: 0.2517 - accuracy: 0.8792\n",
      " 429/5349 [=>............................] - ETA: 3s - loss: 0.2247 - accuracy: 0.8901\n",
      " 606/5349 [==>...........................] - ETA: 3s - loss: 0.2086 - accuracy: 0.8951\n",
      " 760/5349 [===>..........................] - ETA: 3s - loss: 0.1998 - accuracy: 0.8991\n",
      " 934/5349 [====>.........................] - ETA: 2s - loss: 0.1928 - accuracy: 0.9022\n",
      "1104/5349 [=====>........................] - ETA: 2s - loss: 0.1873 - accuracy: 0.9046\n",
      "1374/5349 [======>.......................] - ETA: 2s - loss: 0.1815 - accuracy: 0.9071\n",
      "1549/5349 [=======>......................] - ETA: 2s - loss: 0.1791 - accuracy: 0.9078\n",
      "1732/5349 [========>.....................] - ETA: 2s - loss: 0.1765 - accuracy: 0.9088\n",
      "1910/5349 [=========>....................] - ETA: 2s - loss: 0.1741 - accuracy: 0.9099\n",
      "2089/5349 [==========>...................] - ETA: 1s - loss: 0.1720 - accuracy: 0.9107\n",
      "2262/5349 [===========>..................] - ETA: 1s - loss: 0.1707 - accuracy: 0.9111\n",
      "2447/5349 [============>.................] - ETA: 1s - loss: 0.1693 - accuracy: 0.9117\n",
      "2626/5349 [=============>................] - ETA: 1s - loss: 0.1678 - accuracy: 0.9122\n",
      "2808/5349 [==============>...............] - ETA: 1s - loss: 0.1671 - accuracy: 0.9122\n",
      "2887/5349 [===============>..............] - ETA: 1s - loss: 0.1667 - accuracy: 0.9123\n",
      "3063/5349 [================>.............] - ETA: 1s - loss: 0.1658 - accuracy: 0.9127\n",
      "3246/5349 [=================>............] - ETA: 1s - loss: 0.1649 - accuracy: 0.9131\n",
      "3421/5349 [==================>...........] - ETA: 1s - loss: 0.1639 - accuracy: 0.9136\n",
      "3609/5349 [===================>..........] - ETA: 1s - loss: 0.1630 - accuracy: 0.9139\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.1623 - accuracy: 0.9142\n",
      "3960/5349 [=====================>........] - ETA: 0s - loss: 0.1616 - accuracy: 0.9145\n",
      "4140/5349 [======================>.......] - ETA: 0s - loss: 0.1608 - accuracy: 0.9149\n",
      "4324/5349 [=======================>......] - ETA: 0s - loss: 0.1605 - accuracy: 0.9148\n",
      "4416/5349 [=======================>......] - ETA: 0s - loss: 0.1603 - accuracy: 0.9149\n",
      "4566/5349 [========================>.....] - ETA: 0s - loss: 0.1598 - accuracy: 0.9152\n",
      "4746/5349 [=========================>....] - ETA: 0s - loss: 0.1594 - accuracy: 0.9153\n",
      "4919/5349 [==========================>...] - ETA: 0s - loss: 0.1590 - accuracy: 0.9155\n",
      "5104/5349 [===========================>..] - ETA: 0s - loss: 0.1587 - accuracy: 0.9156\n",
      "5261/5349 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9156\n",
      "5349/5349 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9157\n",
      "5349/5349 [==============================] - 5s 784us/step - loss: 0.1582 - accuracy: 0.9157 - val_loss: 0.1444 - val_accuracy: 0.9208\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 2/20\n",
      "  88/5349 [..............................] - ETA: 3s - loss: 0.1467 - accuracy: 0.9212\n",
      " 261/5349 [>.............................] - ETA: 2s - loss: 0.1454 - accuracy: 0.9201\n",
      " 446/5349 [=>............................] - ETA: 2s - loss: 0.1456 - accuracy: 0.9212\n",
      " 619/5349 [==>...........................] - ETA: 2s - loss: 0.1455 - accuracy: 0.9213\n",
      " 805/5349 [===>..........................] - ETA: 2s - loss: 0.1451 - accuracy: 0.9210\n",
      " 983/5349 [====>.........................] - ETA: 2s - loss: 0.1456 - accuracy: 0.9205\n",
      "1167/5349 [=====>........................] - ETA: 2s - loss: 0.1459 - accuracy: 0.9204\n",
      "1343/5349 [======>.......................] - ETA: 2s - loss: 0.1453 - accuracy: 0.9205\n",
      "1611/5349 [========>.....................] - ETA: 2s - loss: 0.1445 - accuracy: 0.9213\n",
      "1787/5349 [=========>....................] - ETA: 2s - loss: 0.1441 - accuracy: 0.9216\n",
      "1965/5349 [==========>...................] - ETA: 1s - loss: 0.1440 - accuracy: 0.9217\n",
      "2137/5349 [==========>...................] - ETA: 1s - loss: 0.1437 - accuracy: 0.9220\n",
      "2320/5349 [============>.................] - ETA: 1s - loss: 0.1437 - accuracy: 0.9220\n",
      "2495/5349 [============>.................] - ETA: 1s - loss: 0.1436 - accuracy: 0.9221\n",
      "2677/5349 [==============>...............] - ETA: 1s - loss: 0.1436 - accuracy: 0.9219\n",
      "2847/5349 [==============>...............] - ETA: 1s - loss: 0.1433 - accuracy: 0.9220\n",
      "3096/5349 [================>.............] - ETA: 1s - loss: 0.1432 - accuracy: 0.9222\n",
      "3273/5349 [=================>............] - ETA: 1s - loss: 0.1429 - accuracy: 0.9225\n",
      "3460/5349 [==================>...........] - ETA: 1s - loss: 0.1429 - accuracy: 0.9224\n",
      "3639/5349 [===================>..........] - ETA: 0s - loss: 0.1430 - accuracy: 0.9225\n",
      "3819/5349 [====================>.........] - ETA: 0s - loss: 0.1431 - accuracy: 0.9225\n",
      "3999/5349 [=====================>........] - ETA: 0s - loss: 0.1431 - accuracy: 0.9225\n",
      "4183/5349 [======================>.......] - ETA: 0s - loss: 0.1430 - accuracy: 0.9225\n",
      "4342/5349 [=======================>......] - ETA: 0s - loss: 0.1429 - accuracy: 0.9225\n",
      "4528/5349 [========================>.....] - ETA: 0s - loss: 0.1429 - accuracy: 0.9225\n",
      "4787/5349 [=========================>....] - ETA: 0s - loss: 0.1427 - accuracy: 0.9227\n",
      "4947/5349 [==========================>...] - ETA: 0s - loss: 0.1428 - accuracy: 0.9226\n",
      "5093/5349 [===========================>..] - ETA: 0s - loss: 0.1426 - accuracy: 0.9228\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.1424 - accuracy: 0.9230\n",
      "5349/5349 [==============================] - 4s 736us/step - loss: 0.1423 - accuracy: 0.9230 - val_loss: 0.1386 - val_accuracy: 0.9272\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1601 - accuracy: 0.9100\n",
      " 182/5349 [>.............................] - ETA: 2s - loss: 0.1402 - accuracy: 0.9260\n",
      " 265/5349 [>.............................] - ETA: 2s - loss: 0.1406 - accuracy: 0.9250\n",
      " 441/5349 [=>............................] - ETA: 2s - loss: 0.1401 - accuracy: 0.9249\n",
      " 603/5349 [==>...........................] - ETA: 2s - loss: 0.1393 - accuracy: 0.9248\n",
      " 787/5349 [===>..........................] - ETA: 2s - loss: 0.1390 - accuracy: 0.9251\n",
      " 965/5349 [====>.........................] - ETA: 2s - loss: 0.1390 - accuracy: 0.9251\n",
      "1149/5349 [=====>........................] - ETA: 2s - loss: 0.1393 - accuracy: 0.9246\n",
      "1324/5349 [======>.......................] - ETA: 2s - loss: 0.1391 - accuracy: 0.9250\n",
      "1415/5349 [======>.......................] - ETA: 2s - loss: 0.1390 - accuracy: 0.9250\n",
      "1596/5349 [=======>......................] - ETA: 2s - loss: 0.1388 - accuracy: 0.9252\n",
      "1773/5349 [========>.....................] - ETA: 2s - loss: 0.1386 - accuracy: 0.9254\n",
      "1956/5349 [=========>....................] - ETA: 1s - loss: 0.1385 - accuracy: 0.9254\n",
      "2113/5349 [==========>...................] - ETA: 1s - loss: 0.1383 - accuracy: 0.9257\n",
      "2239/5349 [===========>..................] - ETA: 1s - loss: 0.1382 - accuracy: 0.9257\n",
      "2440/5349 [============>.................] - ETA: 1s - loss: 0.1382 - accuracy: 0.9258\n",
      "2586/5349 [=============>................] - ETA: 1s - loss: 0.1380 - accuracy: 0.9260\n",
      "2723/5349 [==============>...............] - ETA: 1s - loss: 0.1378 - accuracy: 0.9260\n",
      "2835/5349 [==============>...............] - ETA: 1s - loss: 0.1377 - accuracy: 0.9261\n",
      "2932/5349 [===============>..............] - ETA: 1s - loss: 0.1377 - accuracy: 0.9261\n",
      "3073/5349 [================>.............] - ETA: 1s - loss: 0.1375 - accuracy: 0.9262\n",
      "3204/5349 [================>.............] - ETA: 1s - loss: 0.1376 - accuracy: 0.9262\n",
      "3413/5349 [==================>...........] - ETA: 1s - loss: 0.1373 - accuracy: 0.9265\n",
      "3501/5349 [==================>...........] - ETA: 1s - loss: 0.1372 - accuracy: 0.9265\n",
      "3594/5349 [===================>..........] - ETA: 1s - loss: 0.1371 - accuracy: 0.9266\n",
      "3701/5349 [===================>..........] - ETA: 1s - loss: 0.1371 - accuracy: 0.9265\n",
      "3836/5349 [====================>.........] - ETA: 1s - loss: 0.1371 - accuracy: 0.9264\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.1369 - accuracy: 0.9267\n",
      "4243/5349 [======================>.......] - ETA: 0s - loss: 0.1368 - accuracy: 0.9267\n",
      "4416/5349 [=======================>......] - ETA: 0s - loss: 0.1368 - accuracy: 0.9267\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.1368 - accuracy: 0.9267\n",
      "4730/5349 [=========================>....] - ETA: 0s - loss: 0.1366 - accuracy: 0.9269\n",
      "4888/5349 [==========================>...] - ETA: 0s - loss: 0.1367 - accuracy: 0.9267\n",
      "5046/5349 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.9268\n",
      "5228/5349 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9268\n",
      "5312/5349 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9267\n",
      "5349/5349 [==============================] - 5s 847us/step - loss: 0.1366 - accuracy: 0.9267 - val_loss: 0.1384 - val_accuracy: 0.9247\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1122 - accuracy: 0.9500\n",
      " 159/5349 [..............................] - ETA: 3s - loss: 0.1321 - accuracy: 0.9276\n",
      " 160/5349 [..............................] - ETA: 6s - loss: 0.1322 - accuracy: 0.9276\n",
      " 299/5349 [>.............................] - ETA: 5s - loss: 0.1309 - accuracy: 0.9299\n",
      " 461/5349 [=>............................] - ETA: 4s - loss: 0.1336 - accuracy: 0.9281\n",
      " 605/5349 [==>...........................] - ETA: 3s - loss: 0.1335 - accuracy: 0.9281\n",
      " 751/5349 [===>..........................] - ETA: 3s - loss: 0.1332 - accuracy: 0.9277\n",
      " 978/5349 [====>.........................] - ETA: 3s - loss: 0.1333 - accuracy: 0.9280\n",
      "1088/5349 [=====>........................] - ETA: 3s - loss: 0.1333 - accuracy: 0.9284\n",
      "1202/5349 [=====>........................] - ETA: 3s - loss: 0.1334 - accuracy: 0.9282\n",
      "1322/5349 [======>.......................] - ETA: 3s - loss: 0.1336 - accuracy: 0.9281\n",
      "1489/5349 [=======>......................] - ETA: 3s - loss: 0.1331 - accuracy: 0.9283\n",
      "1660/5349 [========>.....................] - ETA: 2s - loss: 0.1332 - accuracy: 0.9282\n",
      "1837/5349 [=========>....................] - ETA: 2s - loss: 0.1331 - accuracy: 0.9282\n",
      "2009/5349 [==========>...................] - ETA: 2s - loss: 0.1329 - accuracy: 0.9284\n",
      "2255/5349 [===========>..................] - ETA: 2s - loss: 0.1326 - accuracy: 0.9285\n",
      "2410/5349 [============>.................] - ETA: 2s - loss: 0.1328 - accuracy: 0.9284\n",
      "2586/5349 [=============>................] - ETA: 1s - loss: 0.1326 - accuracy: 0.9286\n",
      "2759/5349 [==============>...............] - ETA: 1s - loss: 0.1326 - accuracy: 0.9286\n",
      "2931/5349 [===============>..............] - ETA: 1s - loss: 0.1327 - accuracy: 0.9287\n",
      "3179/5349 [================>.............] - ETA: 1s - loss: 0.1327 - accuracy: 0.9286\n",
      "3355/5349 [=================>............] - ETA: 1s - loss: 0.1325 - accuracy: 0.9288\n",
      "3522/5349 [==================>...........] - ETA: 1s - loss: 0.1322 - accuracy: 0.9290\n",
      "3701/5349 [===================>..........] - ETA: 1s - loss: 0.1322 - accuracy: 0.9292\n",
      "3852/5349 [====================>.........] - ETA: 1s - loss: 0.1318 - accuracy: 0.9295\n",
      "4010/5349 [=====================>........] - ETA: 0s - loss: 0.1317 - accuracy: 0.9296\n",
      "4262/5349 [======================>.......] - ETA: 0s - loss: 0.1318 - accuracy: 0.9297\n",
      "4437/5349 [=======================>......] - ETA: 0s - loss: 0.1317 - accuracy: 0.9297\n",
      "4607/5349 [========================>.....] - ETA: 0s - loss: 0.1316 - accuracy: 0.9298\n",
      "4781/5349 [=========================>....] - ETA: 0s - loss: 0.1317 - accuracy: 0.9297\n",
      "4946/5349 [==========================>...] - ETA: 0s - loss: 0.1316 - accuracy: 0.9298\n",
      "5116/5349 [===========================>..] - ETA: 0s - loss: 0.1315 - accuracy: 0.9298\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.1314 - accuracy: 0.9300\n",
      "5349/5349 [==============================] - 4s 814us/step - loss: 0.1314 - accuracy: 0.9300 - val_loss: 0.1308 - val_accuracy: 0.9289\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 5/20\n",
      "  93/5349 [..............................] - ETA: 2s - loss: 0.1287 - accuracy: 0.9300\n",
      " 240/5349 [>.............................] - ETA: 3s - loss: 0.1282 - accuracy: 0.9318\n",
      " 409/5349 [=>............................] - ETA: 3s - loss: 0.1301 - accuracy: 0.9303\n",
      " 572/5349 [==>...........................] - ETA: 2s - loss: 0.1289 - accuracy: 0.9310\n",
      " 755/5349 [===>..........................] - ETA: 2s - loss: 0.1295 - accuracy: 0.9309\n",
      " 917/5349 [====>.........................] - ETA: 2s - loss: 0.1294 - accuracy: 0.9315\n",
      "1101/5349 [=====>........................] - ETA: 2s - loss: 0.1296 - accuracy: 0.9313\n",
      "1191/5349 [=====>........................] - ETA: 2s - loss: 0.1296 - accuracy: 0.9311\n",
      "1370/5349 [======>.......................] - ETA: 2s - loss: 0.1292 - accuracy: 0.9312\n",
      "1549/5349 [=======>......................] - ETA: 2s - loss: 0.1293 - accuracy: 0.9311\n",
      "1727/5349 [========>.....................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9312\n",
      "1911/5349 [=========>....................] - ETA: 1s - loss: 0.1287 - accuracy: 0.9316\n",
      "2076/5349 [==========>...................] - ETA: 1s - loss: 0.1283 - accuracy: 0.9319\n",
      "2254/5349 [===========>..................] - ETA: 1s - loss: 0.1286 - accuracy: 0.9317\n",
      "2421/5349 [============>.................] - ETA: 1s - loss: 0.1285 - accuracy: 0.9318\n",
      "2667/5349 [=============>................] - ETA: 1s - loss: 0.1284 - accuracy: 0.9317\n",
      "2850/5349 [==============>...............] - ETA: 1s - loss: 0.1282 - accuracy: 0.9319\n",
      "3027/5349 [===============>..............] - ETA: 1s - loss: 0.1282 - accuracy: 0.9319\n",
      "3201/5349 [================>.............] - ETA: 1s - loss: 0.1281 - accuracy: 0.9320\n",
      "3381/5349 [=================>............] - ETA: 1s - loss: 0.1279 - accuracy: 0.9322\n",
      "3560/5349 [==================>...........] - ETA: 1s - loss: 0.1279 - accuracy: 0.9322\n",
      "3737/5349 [===================>..........] - ETA: 0s - loss: 0.1281 - accuracy: 0.9320\n",
      "3898/5349 [====================>.........] - ETA: 0s - loss: 0.1281 - accuracy: 0.9320\n",
      "4070/5349 [=====================>........] - ETA: 0s - loss: 0.1280 - accuracy: 0.9320\n",
      "4159/5349 [======================>.......] - ETA: 0s - loss: 0.1281 - accuracy: 0.9318\n",
      "4337/5349 [=======================>......] - ETA: 0s - loss: 0.1279 - accuracy: 0.9320\n",
      "4513/5349 [========================>.....] - ETA: 0s - loss: 0.1278 - accuracy: 0.9320\n",
      "4692/5349 [=========================>....] - ETA: 0s - loss: 0.1279 - accuracy: 0.9319\n",
      "4872/5349 [==========================>...] - ETA: 0s - loss: 0.1276 - accuracy: 0.9320\n",
      "5049/5349 [===========================>..] - ETA: 0s - loss: 0.1276 - accuracy: 0.9319\n",
      "5211/5349 [============================>.] - ETA: 0s - loss: 0.1275 - accuracy: 0.9319\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.1275 - accuracy: 0.9320\n",
      "5349/5349 [==============================] - 4s 773us/step - loss: 0.1274 - accuracy: 0.9320 - val_loss: 0.1259 - val_accuracy: 0.9338\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 6/20\n",
      "  74/5349 [..............................] - ETA: 3s - loss: 0.1344 - accuracy: 0.9276\n",
      " 152/5349 [..............................] - ETA: 5s - loss: 0.1348 - accuracy: 0.9284\n",
      " 364/5349 [=>............................] - ETA: 4s - loss: 0.1286 - accuracy: 0.9320\n",
      " 493/5349 [=>............................] - ETA: 3s - loss: 0.1286 - accuracy: 0.9321\n",
      " 661/5349 [==>...........................] - ETA: 3s - loss: 0.1273 - accuracy: 0.9328\n",
      " 840/5349 [===>..........................] - ETA: 3s - loss: 0.1266 - accuracy: 0.9332\n",
      "1024/5349 [====>.........................] - ETA: 2s - loss: 0.1264 - accuracy: 0.9334\n",
      "1185/5349 [=====>........................] - ETA: 2s - loss: 0.1271 - accuracy: 0.9326\n",
      "1369/5349 [======>.......................] - ETA: 2s - loss: 0.1263 - accuracy: 0.9331\n",
      "1523/5349 [=======>......................] - ETA: 2s - loss: 0.1254 - accuracy: 0.9334\n",
      "1707/5349 [========>.....................] - ETA: 2s - loss: 0.1252 - accuracy: 0.9337\n",
      "1970/5349 [==========>...................] - ETA: 2s - loss: 0.1250 - accuracy: 0.9340\n",
      "2154/5349 [===========>..................] - ETA: 2s - loss: 0.1252 - accuracy: 0.9337\n",
      "2328/5349 [============>.................] - ETA: 1s - loss: 0.1250 - accuracy: 0.9337\n",
      "2509/5349 [=============>................] - ETA: 1s - loss: 0.1248 - accuracy: 0.9338\n",
      "2684/5349 [==============>...............] - ETA: 1s - loss: 0.1251 - accuracy: 0.9335\n",
      "2864/5349 [===============>..............] - ETA: 1s - loss: 0.1253 - accuracy: 0.9335\n",
      "3040/5349 [================>.............] - ETA: 1s - loss: 0.1251 - accuracy: 0.9336\n",
      "3226/5349 [=================>............] - ETA: 1s - loss: 0.1250 - accuracy: 0.9336\n",
      "3404/5349 [==================>...........] - ETA: 1s - loss: 0.1250 - accuracy: 0.9335\n",
      "3562/5349 [==================>...........] - ETA: 1s - loss: 0.1248 - accuracy: 0.9335\n",
      "3722/5349 [===================>..........] - ETA: 0s - loss: 0.1247 - accuracy: 0.9335\n",
      "3989/5349 [=====================>........] - ETA: 0s - loss: 0.1246 - accuracy: 0.9336\n",
      "4160/5349 [======================>.......] - ETA: 0s - loss: 0.1247 - accuracy: 0.9334\n",
      "4320/5349 [=======================>......] - ETA: 0s - loss: 0.1246 - accuracy: 0.9335\n",
      "4489/5349 [========================>.....] - ETA: 0s - loss: 0.1246 - accuracy: 0.9336\n",
      "4652/5349 [=========================>....] - ETA: 0s - loss: 0.1244 - accuracy: 0.9337\n",
      "4813/5349 [=========================>....] - ETA: 0s - loss: 0.1243 - accuracy: 0.9339\n",
      "4984/5349 [==========================>...] - ETA: 0s - loss: 0.1243 - accuracy: 0.9340\n",
      "5171/5349 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9340\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9339\n",
      "5349/5349 [==============================] - 4s 785us/step - loss: 0.1242 - accuracy: 0.9340 - val_loss: 0.1201 - val_accuracy: 0.9364\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1552 - accuracy: 0.9200\n",
      " 180/5349 [>.............................] - ETA: 2s - loss: 0.1245 - accuracy: 0.9327\n",
      " 437/5349 [=>............................] - ETA: 2s - loss: 0.1228 - accuracy: 0.9337\n",
      " 617/5349 [==>...........................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9336\n",
      " 803/5349 [===>..........................] - ETA: 2s - loss: 0.1233 - accuracy: 0.9336\n",
      " 975/5349 [====>.........................] - ETA: 2s - loss: 0.1232 - accuracy: 0.9336\n",
      "1157/5349 [=====>........................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9341\n",
      "1329/5349 [======>.......................] - ETA: 2s - loss: 0.1228 - accuracy: 0.9345\n",
      "1512/5349 [=======>......................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9341\n",
      "1686/5349 [========>.....................] - ETA: 2s - loss: 0.1227 - accuracy: 0.9345\n",
      "1870/5349 [=========>....................] - ETA: 1s - loss: 0.1224 - accuracy: 0.9347\n",
      "2037/5349 [==========>...................] - ETA: 1s - loss: 0.1228 - accuracy: 0.9343\n",
      "2314/5349 [===========>..................] - ETA: 1s - loss: 0.1231 - accuracy: 0.9343\n",
      "2486/5349 [============>.................] - ETA: 1s - loss: 0.1229 - accuracy: 0.9344\n",
      "2670/5349 [=============>................] - ETA: 1s - loss: 0.1229 - accuracy: 0.9344\n",
      "2836/5349 [==============>...............] - ETA: 1s - loss: 0.1229 - accuracy: 0.9344\n",
      "3021/5349 [===============>..............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9345\n",
      "3179/5349 [================>.............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9346\n",
      "3363/5349 [=================>............] - ETA: 1s - loss: 0.1223 - accuracy: 0.9346\n",
      "3543/5349 [==================>...........] - ETA: 1s - loss: 0.1222 - accuracy: 0.9346\n",
      "3713/5349 [===================>..........] - ETA: 0s - loss: 0.1221 - accuracy: 0.9348\n",
      "3882/5349 [====================>.........] - ETA: 0s - loss: 0.1220 - accuracy: 0.9349\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.1220 - accuracy: 0.9348\n",
      "4159/5349 [======================>.......] - ETA: 0s - loss: 0.1220 - accuracy: 0.9348\n",
      "4337/5349 [=======================>......] - ETA: 0s - loss: 0.1218 - accuracy: 0.9350\n",
      "4520/5349 [========================>.....] - ETA: 0s - loss: 0.1217 - accuracy: 0.9350\n",
      "4698/5349 [=========================>....] - ETA: 0s - loss: 0.1217 - accuracy: 0.9350\n",
      "4885/5349 [==========================>...] - ETA: 0s - loss: 0.1218 - accuracy: 0.9349\n",
      "5064/5349 [===========================>..] - ETA: 0s - loss: 0.1218 - accuracy: 0.9349\n",
      "5222/5349 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9349\n",
      "5302/5349 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9349\n",
      "5349/5349 [==============================] - 4s 745us/step - loss: 0.1216 - accuracy: 0.9349 - val_loss: 0.1196 - val_accuracy: 0.9362\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 8/20\n",
      "  80/5349 [..............................] - ETA: 3s - loss: 0.1230 - accuracy: 0.9330\n",
      " 192/5349 [>.............................] - ETA: 4s - loss: 0.1222 - accuracy: 0.9351\n",
      " 360/5349 [=>............................] - ETA: 3s - loss: 0.1211 - accuracy: 0.9349\n",
      " 528/5349 [=>............................] - ETA: 3s - loss: 0.1207 - accuracy: 0.9351\n",
      " 701/5349 [==>...........................] - ETA: 2s - loss: 0.1213 - accuracy: 0.9346\n",
      " 950/5349 [====>.........................] - ETA: 2s - loss: 0.1208 - accuracy: 0.9348\n",
      "1125/5349 [=====>........................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9356\n",
      "1299/5349 [======>.......................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9357\n",
      "1473/5349 [=======>......................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9357\n",
      "1627/5349 [========>.....................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9358\n",
      "1792/5349 [=========>....................] - ETA: 2s - loss: 0.1208 - accuracy: 0.9353\n",
      "1964/5349 [==========>...................] - ETA: 2s - loss: 0.1206 - accuracy: 0.9356\n",
      "2146/5349 [===========>..................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9360\n",
      "2226/5349 [===========>..................] - ETA: 1s - loss: 0.1201 - accuracy: 0.9358\n",
      "2391/5349 [============>.................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9361\n",
      "2539/5349 [=============>................] - ETA: 1s - loss: 0.1198 - accuracy: 0.9361\n",
      "2641/5349 [=============>................] - ETA: 1s - loss: 0.1198 - accuracy: 0.9362\n",
      "2769/5349 [==============>...............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9361\n",
      "2895/5349 [===============>..............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9360\n",
      "3012/5349 [===============>..............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9361\n",
      "3149/5349 [================>.............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9361\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9362\n",
      "3430/5349 [==================>...........] - ETA: 1s - loss: 0.1199 - accuracy: 0.9363\n",
      "3506/5349 [==================>...........] - ETA: 1s - loss: 0.1199 - accuracy: 0.9363\n",
      "3626/5349 [===================>..........] - ETA: 1s - loss: 0.1198 - accuracy: 0.9363\n",
      "3739/5349 [===================>..........] - ETA: 1s - loss: 0.1197 - accuracy: 0.9363\n",
      "3853/5349 [====================>.........] - ETA: 1s - loss: 0.1196 - accuracy: 0.9363\n",
      "3944/5349 [=====================>........] - ETA: 0s - loss: 0.1197 - accuracy: 0.9362\n",
      "4067/5349 [=====================>........] - ETA: 0s - loss: 0.1197 - accuracy: 0.9362\n",
      "4285/5349 [=======================>......] - ETA: 0s - loss: 0.1197 - accuracy: 0.9362\n",
      "4427/5349 [=======================>......] - ETA: 0s - loss: 0.1197 - accuracy: 0.9362\n",
      "4598/5349 [========================>.....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9361\n",
      "4785/5349 [=========================>....] - ETA: 0s - loss: 0.1198 - accuracy: 0.9360\n",
      "4959/5349 [==========================>...] - ETA: 0s - loss: 0.1197 - accuracy: 0.9361\n",
      "5139/5349 [===========================>..] - ETA: 0s - loss: 0.1197 - accuracy: 0.9361\n",
      "5305/5349 [============================>.] - ETA: 0s - loss: 0.1197 - accuracy: 0.9361\n",
      "5349/5349 [==============================] - 5s 843us/step - loss: 0.1197 - accuracy: 0.9361 - val_loss: 0.1210 - val_accuracy: 0.9362\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1193 - accuracy: 0.9200\n",
      " 180/5349 [>.............................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9368\n",
      " 360/5349 [=>............................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9376\n",
      " 534/5349 [=>............................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9368\n",
      " 718/5349 [===>..........................] - ETA: 2s - loss: 0.1190 - accuracy: 0.9372\n",
      " 898/5349 [====>.........................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9370\n",
      "1081/5349 [=====>........................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9371\n",
      "1255/5349 [======>.......................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9370\n",
      "1346/5349 [======>.......................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9369\n",
      "1521/5349 [=======>......................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9364\n",
      "1697/5349 [========>.....................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9362\n",
      "1846/5349 [=========>....................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9360\n",
      "1953/5349 [=========>....................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9360\n",
      "2125/5349 [==========>...................] - ETA: 1s - loss: 0.1191 - accuracy: 0.9361\n",
      "2290/5349 [===========>..................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9359\n",
      "2451/5349 [============>.................] - ETA: 1s - loss: 0.1190 - accuracy: 0.9361\n",
      "2590/5349 [=============>................] - ETA: 1s - loss: 0.1189 - accuracy: 0.9360\n",
      "2766/5349 [==============>...............] - ETA: 1s - loss: 0.1187 - accuracy: 0.9362\n",
      "2934/5349 [===============>..............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9362\n",
      "3082/5349 [================>.............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9361\n",
      "3353/5349 [=================>............] - ETA: 1s - loss: 0.1185 - accuracy: 0.9364\n",
      "3525/5349 [==================>...........] - ETA: 1s - loss: 0.1187 - accuracy: 0.9364\n",
      "3689/5349 [===================>..........] - ETA: 0s - loss: 0.1186 - accuracy: 0.9365\n",
      "3846/5349 [====================>.........] - ETA: 0s - loss: 0.1185 - accuracy: 0.9365\n",
      "3995/5349 [=====================>........] - ETA: 0s - loss: 0.1187 - accuracy: 0.9363\n",
      "4102/5349 [======================>.......] - ETA: 0s - loss: 0.1188 - accuracy: 0.9363\n",
      "4246/5349 [======================>.......] - ETA: 0s - loss: 0.1188 - accuracy: 0.9363\n",
      "4411/5349 [=======================>......] - ETA: 0s - loss: 0.1188 - accuracy: 0.9364\n",
      "4585/5349 [========================>.....] - ETA: 0s - loss: 0.1186 - accuracy: 0.9366\n",
      "4764/5349 [=========================>....] - ETA: 0s - loss: 0.1185 - accuracy: 0.9367\n",
      "4932/5349 [==========================>...] - ETA: 0s - loss: 0.1184 - accuracy: 0.9368\n",
      "5112/5349 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 0.9368\n",
      "5283/5349 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9368\n",
      "5349/5349 [==============================] - 4s 787us/step - loss: 0.1184 - accuracy: 0.9367 - val_loss: 0.1184 - val_accuracy: 0.9372\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 10/20\n",
      " 176/5349 [..............................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9359\n",
      " 350/5349 [>.............................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9364\n",
      " 529/5349 [=>............................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9372\n",
      " 677/5349 [==>...........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9379\n",
      " 846/5349 [===>..........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9379\n",
      " 998/5349 [====>.........................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9379\n",
      "1141/5349 [=====>........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9378\n",
      "1312/5349 [======>.......................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9372\n",
      "1479/5349 [=======>......................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9368\n",
      "1643/5349 [========>.....................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9370\n",
      "1819/5349 [=========>....................] - ETA: 2s - loss: 0.1171 - accuracy: 0.9369\n",
      "2081/5349 [==========>...................] - ETA: 1s - loss: 0.1172 - accuracy: 0.9367\n",
      "2246/5349 [===========>..................] - ETA: 1s - loss: 0.1172 - accuracy: 0.9368\n",
      "2401/5349 [============>.................] - ETA: 1s - loss: 0.1176 - accuracy: 0.9368\n",
      "2568/5349 [=============>................] - ETA: 1s - loss: 0.1174 - accuracy: 0.9369\n",
      "2744/5349 [==============>...............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9370\n",
      "2915/5349 [===============>..............] - ETA: 1s - loss: 0.1172 - accuracy: 0.9370\n",
      "3088/5349 [================>.............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9368\n",
      "3268/5349 [=================>............] - ETA: 1s - loss: 0.1173 - accuracy: 0.9369\n",
      "3512/5349 [==================>...........] - ETA: 1s - loss: 0.1171 - accuracy: 0.9369\n",
      "3668/5349 [===================>..........] - ETA: 1s - loss: 0.1170 - accuracy: 0.9370\n",
      "3845/5349 [====================>.........] - ETA: 0s - loss: 0.1170 - accuracy: 0.9370\n",
      "4023/5349 [=====================>........] - ETA: 0s - loss: 0.1170 - accuracy: 0.9371\n",
      "4198/5349 [======================>.......] - ETA: 0s - loss: 0.1168 - accuracy: 0.9373\n",
      "4376/5349 [=======================>......] - ETA: 0s - loss: 0.1168 - accuracy: 0.9373\n",
      "4557/5349 [========================>.....] - ETA: 0s - loss: 0.1168 - accuracy: 0.9372\n",
      "4734/5349 [=========================>....] - ETA: 0s - loss: 0.1169 - accuracy: 0.9371\n",
      "4810/5349 [=========================>....] - ETA: 0s - loss: 0.1169 - accuracy: 0.9371\n",
      "4990/5349 [==========================>...] - ETA: 0s - loss: 0.1170 - accuracy: 0.9371\n",
      "5166/5349 [===========================>..] - ETA: 0s - loss: 0.1170 - accuracy: 0.9372\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9371\n",
      "5349/5349 [==============================] - 4s 761us/step - loss: 0.1170 - accuracy: 0.9371 - val_loss: 0.1148 - val_accuracy: 0.9394\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.0934 - accuracy: 0.9500\n",
      "  98/5349 [..............................] - ETA: 5s - loss: 0.1160 - accuracy: 0.9374\n",
      " 135/5349 [..............................] - ETA: 6s - loss: 0.1152 - accuracy: 0.9380\n",
      " 260/5349 [>.............................] - ETA: 5s - loss: 0.1171 - accuracy: 0.9376\n",
      " 384/5349 [=>............................] - ETA: 4s - loss: 0.1171 - accuracy: 0.9383\n",
      " 517/5349 [=>............................] - ETA: 4s - loss: 0.1170 - accuracy: 0.9386\n",
      " 662/5349 [==>...........................] - ETA: 3s - loss: 0.1167 - accuracy: 0.9388\n",
      " 818/5349 [===>..........................] - ETA: 3s - loss: 0.1164 - accuracy: 0.9392\n",
      " 950/5349 [====>.........................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9393\n",
      "1097/5349 [=====>........................] - ETA: 3s - loss: 0.1162 - accuracy: 0.9386\n",
      "1160/5349 [=====>........................] - ETA: 3s - loss: 0.1162 - accuracy: 0.9383\n",
      "1231/5349 [=====>........................] - ETA: 3s - loss: 0.1165 - accuracy: 0.9381\n",
      "1371/5349 [======>.......................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9387\n",
      "1512/5349 [=======>......................] - ETA: 3s - loss: 0.1160 - accuracy: 0.9385\n",
      "1671/5349 [========>.....................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9383\n",
      "1834/5349 [=========>....................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9381\n",
      "2013/5349 [==========>...................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9379\n",
      "2183/5349 [===========>..................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9378\n",
      "2435/5349 [============>.................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9377\n",
      "2619/5349 [=============>................] - ETA: 1s - loss: 0.1165 - accuracy: 0.9378\n",
      "2795/5349 [==============>...............] - ETA: 1s - loss: 0.1166 - accuracy: 0.9377\n",
      "2965/5349 [===============>..............] - ETA: 1s - loss: 0.1163 - accuracy: 0.9379\n",
      "3139/5349 [================>.............] - ETA: 1s - loss: 0.1162 - accuracy: 0.9380\n",
      "3316/5349 [=================>............] - ETA: 1s - loss: 0.1161 - accuracy: 0.9381\n",
      "3491/5349 [==================>...........] - ETA: 1s - loss: 0.1160 - accuracy: 0.9382\n",
      "3653/5349 [===================>..........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9383\n",
      "3816/5349 [====================>.........] - ETA: 1s - loss: 0.1158 - accuracy: 0.9381\n",
      "4068/5349 [=====================>........] - ETA: 0s - loss: 0.1158 - accuracy: 0.9382\n",
      "4242/5349 [======================>.......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9382\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9380\n",
      "4585/5349 [========================>.....] - ETA: 0s - loss: 0.1160 - accuracy: 0.9379\n",
      "4753/5349 [=========================>....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9380\n",
      "4899/5349 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.9380\n",
      "5065/5349 [===========================>..] - ETA: 0s - loss: 0.1156 - accuracy: 0.9381\n",
      "5242/5349 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9381\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9380\n",
      "5349/5349 [==============================] - 4s 832us/step - loss: 0.1156 - accuracy: 0.9380 - val_loss: 0.1123 - val_accuracy: 0.9398\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 12/20\n",
      "  93/5349 [..............................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9356\n",
      " 253/5349 [>.............................] - ETA: 3s - loss: 0.1162 - accuracy: 0.9372\n",
      " 429/5349 [=>............................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9383\n",
      " 584/5349 [==>...........................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9378\n",
      " 759/5349 [===>..........................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9376\n",
      " 884/5349 [===>..........................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9378\n",
      "1042/5349 [====>.........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9374\n",
      "1204/5349 [=====>........................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9376\n",
      "1368/5349 [======>.......................] - ETA: 2s - loss: 0.1146 - accuracy: 0.9382\n",
      "1534/5349 [=======>......................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9382\n",
      "1702/5349 [========>.....................] - ETA: 2s - loss: 0.1146 - accuracy: 0.9382\n",
      "1866/5349 [=========>....................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9380\n",
      "2038/5349 [==========>...................] - ETA: 2s - loss: 0.1146 - accuracy: 0.9383\n",
      "2298/5349 [===========>..................] - ETA: 1s - loss: 0.1148 - accuracy: 0.9382\n",
      "2478/5349 [============>.................] - ETA: 1s - loss: 0.1147 - accuracy: 0.9383\n",
      "2647/5349 [=============>................] - ETA: 1s - loss: 0.1147 - accuracy: 0.9383\n",
      "2824/5349 [==============>...............] - ETA: 1s - loss: 0.1148 - accuracy: 0.9384\n",
      "3004/5349 [===============>..............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9384\n",
      "3169/5349 [================>.............] - ETA: 1s - loss: 0.1150 - accuracy: 0.9384\n",
      "3301/5349 [=================>............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9384\n",
      "3473/5349 [==================>...........] - ETA: 1s - loss: 0.1150 - accuracy: 0.9384\n",
      "3643/5349 [===================>..........] - ETA: 1s - loss: 0.1149 - accuracy: 0.9384\n",
      "3819/5349 [====================>.........] - ETA: 0s - loss: 0.1147 - accuracy: 0.9385\n",
      "3989/5349 [=====================>........] - ETA: 0s - loss: 0.1148 - accuracy: 0.9384\n",
      "4075/5349 [=====================>........] - ETA: 0s - loss: 0.1146 - accuracy: 0.9385\n",
      "4249/5349 [======================>.......] - ETA: 0s - loss: 0.1147 - accuracy: 0.9384\n",
      "4404/5349 [=======================>......] - ETA: 0s - loss: 0.1147 - accuracy: 0.9383\n",
      "4583/5349 [========================>.....] - ETA: 0s - loss: 0.1146 - accuracy: 0.9383\n",
      "4759/5349 [=========================>....] - ETA: 0s - loss: 0.1146 - accuracy: 0.9385\n",
      "4921/5349 [==========================>...] - ETA: 0s - loss: 0.1148 - accuracy: 0.9383\n",
      "5055/5349 [===========================>..] - ETA: 0s - loss: 0.1148 - accuracy: 0.9383\n",
      "5222/5349 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9384\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9383\n",
      "5349/5349 [==============================] - 4s 769us/step - loss: 0.1148 - accuracy: 0.9383 - val_loss: 0.1122 - val_accuracy: 0.9417\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1310 - accuracy: 0.9300\n",
      " 181/5349 [>.............................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9403\n",
      " 351/5349 [>.............................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9395\n",
      " 488/5349 [=>............................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9398\n",
      " 745/5349 [===>..........................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9393\n",
      " 908/5349 [====>.........................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9392\n",
      "1095/5349 [=====>........................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9393\n",
      "1272/5349 [======>.......................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9394\n",
      "1457/5349 [=======>......................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9392\n",
      "1633/5349 [========>.....................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9388\n",
      "1814/5349 [=========>....................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9389\n",
      "1992/5349 [==========>...................] - ETA: 1s - loss: 0.1142 - accuracy: 0.9391\n",
      "2179/5349 [===========>..................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9389\n",
      "2337/5349 [============>.................] - ETA: 1s - loss: 0.1145 - accuracy: 0.9388\n",
      "2483/5349 [============>.................] - ETA: 1s - loss: 0.1142 - accuracy: 0.9391\n",
      "2642/5349 [=============>................] - ETA: 1s - loss: 0.1141 - accuracy: 0.9392\n",
      "2913/5349 [===============>..............] - ETA: 1s - loss: 0.1140 - accuracy: 0.9392\n",
      "3090/5349 [================>.............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9391\n",
      "3276/5349 [=================>............] - ETA: 1s - loss: 0.1143 - accuracy: 0.9390\n",
      "3423/5349 [==================>...........] - ETA: 1s - loss: 0.1144 - accuracy: 0.9390\n",
      "3569/5349 [===================>..........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9390\n",
      "3711/5349 [===================>..........] - ETA: 0s - loss: 0.1141 - accuracy: 0.9390\n",
      "3866/5349 [====================>.........] - ETA: 0s - loss: 0.1140 - accuracy: 0.9391\n",
      "4005/5349 [=====================>........] - ETA: 0s - loss: 0.1141 - accuracy: 0.9390\n",
      "4160/5349 [======================>.......] - ETA: 0s - loss: 0.1140 - accuracy: 0.9392\n",
      "4379/5349 [=======================>......] - ETA: 0s - loss: 0.1140 - accuracy: 0.9392\n",
      "4537/5349 [========================>.....] - ETA: 0s - loss: 0.1140 - accuracy: 0.9391\n",
      "4671/5349 [=========================>....] - ETA: 0s - loss: 0.1139 - accuracy: 0.9391\n",
      "4773/5349 [=========================>....] - ETA: 0s - loss: 0.1138 - accuracy: 0.9392\n",
      "4918/5349 [==========================>...] - ETA: 0s - loss: 0.1138 - accuracy: 0.9392\n",
      "5041/5349 [===========================>..] - ETA: 0s - loss: 0.1138 - accuracy: 0.9390\n",
      "5206/5349 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9390\n",
      "5289/5349 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.9390\n",
      "5349/5349 [==============================] - 4s 797us/step - loss: 0.1138 - accuracy: 0.9390 - val_loss: 0.1104 - val_accuracy: 0.9428\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 14/20\n",
      "  89/5349 [..............................] - ETA: 3s - loss: 0.1070 - accuracy: 0.9456\n",
      " 277/5349 [>.............................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9410\n",
      " 459/5349 [=>............................] - ETA: 2s - loss: 0.1113 - accuracy: 0.9410\n",
      " 630/5349 [==>...........................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9404\n",
      " 806/5349 [===>..........................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9394\n",
      " 985/5349 [====>.........................] - ETA: 2s - loss: 0.1128 - accuracy: 0.9392\n",
      "1173/5349 [=====>........................] - ETA: 2s - loss: 0.1124 - accuracy: 0.9395\n",
      "1352/5349 [======>.......................] - ETA: 2s - loss: 0.1124 - accuracy: 0.9392\n",
      "1531/5349 [=======>......................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9398\n",
      "1804/5349 [=========>....................] - ETA: 1s - loss: 0.1119 - accuracy: 0.9402\n",
      "1989/5349 [==========>...................] - ETA: 1s - loss: 0.1122 - accuracy: 0.9399\n",
      "2171/5349 [===========>..................] - ETA: 1s - loss: 0.1119 - accuracy: 0.9403\n",
      "2352/5349 [============>.................] - ETA: 1s - loss: 0.1121 - accuracy: 0.9399\n",
      "2473/5349 [============>.................] - ETA: 1s - loss: 0.1124 - accuracy: 0.9397\n",
      "2648/5349 [=============>................] - ETA: 1s - loss: 0.1126 - accuracy: 0.9395\n",
      "2828/5349 [==============>...............] - ETA: 1s - loss: 0.1128 - accuracy: 0.9393\n",
      "3014/5349 [===============>..............] - ETA: 1s - loss: 0.1125 - accuracy: 0.9395\n",
      "3184/5349 [================>.............] - ETA: 1s - loss: 0.1126 - accuracy: 0.9396\n",
      "3368/5349 [=================>............] - ETA: 1s - loss: 0.1128 - accuracy: 0.9394\n",
      "3548/5349 [==================>...........] - ETA: 1s - loss: 0.1128 - accuracy: 0.9393\n",
      "3733/5349 [===================>..........] - ETA: 0s - loss: 0.1129 - accuracy: 0.9392\n",
      "3912/5349 [====================>.........] - ETA: 0s - loss: 0.1128 - accuracy: 0.9392\n",
      "4095/5349 [=====================>........] - ETA: 0s - loss: 0.1128 - accuracy: 0.9393\n",
      "4273/5349 [======================>.......] - ETA: 0s - loss: 0.1129 - accuracy: 0.9392\n",
      "4457/5349 [=======================>......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9392\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.1130 - accuracy: 0.9391\n",
      "4915/5349 [==========================>...] - ETA: 0s - loss: 0.1129 - accuracy: 0.9393\n",
      "5076/5349 [===========================>..] - ETA: 0s - loss: 0.1130 - accuracy: 0.9392\n",
      "5261/5349 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9392\n",
      "5348/5349 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9392\n",
      "5349/5349 [==============================] - 4s 728us/step - loss: 0.1129 - accuracy: 0.9392 - val_loss: 0.1179 - val_accuracy: 0.9249\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1475 - accuracy: 0.9400\n",
      " 179/5349 [>.............................] - ETA: 2s - loss: 0.1117 - accuracy: 0.9417\n",
      " 365/5349 [=>............................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9384\n",
      " 640/5349 [==>...........................] - ETA: 2s - loss: 0.1120 - accuracy: 0.9398\n",
      " 820/5349 [===>..........................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9392\n",
      " 997/5349 [====>.........................] - ETA: 2s - loss: 0.1121 - accuracy: 0.9396\n",
      "1179/5349 [=====>........................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9397\n",
      "1345/5349 [======>.......................] - ETA: 2s - loss: 0.1119 - accuracy: 0.9399\n",
      "1530/5349 [=======>......................] - ETA: 2s - loss: 0.1118 - accuracy: 0.9400\n",
      "1690/5349 [========>.....................] - ETA: 2s - loss: 0.1116 - accuracy: 0.9403\n",
      "1874/5349 [=========>....................] - ETA: 1s - loss: 0.1119 - accuracy: 0.9399\n",
      "2057/5349 [==========>...................] - ETA: 1s - loss: 0.1122 - accuracy: 0.9395\n",
      "2241/5349 [===========>..................] - ETA: 1s - loss: 0.1124 - accuracy: 0.9396\n",
      "2416/5349 [============>.................] - ETA: 1s - loss: 0.1123 - accuracy: 0.9398\n",
      "2589/5349 [=============>................] - ETA: 1s - loss: 0.1123 - accuracy: 0.9398\n",
      "2761/5349 [==============>...............] - ETA: 1s - loss: 0.1120 - accuracy: 0.9400\n",
      "2946/5349 [===============>..............] - ETA: 1s - loss: 0.1119 - accuracy: 0.9398\n",
      "3038/5349 [================>.............] - ETA: 1s - loss: 0.1120 - accuracy: 0.9398\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1120 - accuracy: 0.9398\n",
      "3405/5349 [==================>...........] - ETA: 1s - loss: 0.1121 - accuracy: 0.9399\n",
      "3577/5349 [===================>..........] - ETA: 0s - loss: 0.1122 - accuracy: 0.9398\n",
      "3752/5349 [====================>.........] - ETA: 0s - loss: 0.1123 - accuracy: 0.9398\n",
      "3930/5349 [=====================>........] - ETA: 0s - loss: 0.1123 - accuracy: 0.9397\n",
      "4111/5349 [======================>.......] - ETA: 0s - loss: 0.1125 - accuracy: 0.9395\n",
      "4272/5349 [======================>.......] - ETA: 0s - loss: 0.1124 - accuracy: 0.9395\n",
      "4453/5349 [=======================>......] - ETA: 0s - loss: 0.1123 - accuracy: 0.9396\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9396\n",
      "4820/5349 [==========================>...] - ETA: 0s - loss: 0.1121 - accuracy: 0.9397\n",
      "5090/5349 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.9395\n",
      "5271/5349 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.9394\n",
      "5349/5349 [==============================] - 4s 732us/step - loss: 0.1123 - accuracy: 0.9395 - val_loss: 0.1100 - val_accuracy: 0.9432\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 16/20\n",
      "  59/5349 [..............................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9336\n",
      " 219/5349 [>.............................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9388\n",
      " 378/5349 [=>............................] - ETA: 3s - loss: 0.1130 - accuracy: 0.9378\n",
      " 601/5349 [==>...........................] - ETA: 3s - loss: 0.1128 - accuracy: 0.9379\n",
      " 762/5349 [===>..........................] - ETA: 3s - loss: 0.1135 - accuracy: 0.9375\n",
      " 900/5349 [====>.........................] - ETA: 2s - loss: 0.1132 - accuracy: 0.9380\n",
      "1057/5349 [====>.........................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9384\n",
      "1146/5349 [=====>........................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9384\n",
      "1285/5349 [======>.......................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9387\n",
      "1437/5349 [=======>......................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9387\n",
      "1569/5349 [=======>......................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9388\n",
      "1658/5349 [========>.....................] - ETA: 2s - loss: 0.1128 - accuracy: 0.9388\n",
      "1840/5349 [=========>....................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9389\n",
      "1998/5349 [==========>...................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9388\n",
      "2171/5349 [===========>..................] - ETA: 2s - loss: 0.1129 - accuracy: 0.9388\n",
      "2354/5349 [============>.................] - ETA: 1s - loss: 0.1127 - accuracy: 0.9390\n",
      "2531/5349 [=============>................] - ETA: 1s - loss: 0.1125 - accuracy: 0.9390\n",
      "2714/5349 [==============>...............] - ETA: 1s - loss: 0.1121 - accuracy: 0.9392\n",
      "2894/5349 [===============>..............] - ETA: 1s - loss: 0.1120 - accuracy: 0.9393\n",
      "3079/5349 [================>.............] - ETA: 1s - loss: 0.1119 - accuracy: 0.9394\n",
      "3240/5349 [=================>............] - ETA: 1s - loss: 0.1120 - accuracy: 0.9393\n",
      "3423/5349 [==================>...........] - ETA: 1s - loss: 0.1116 - accuracy: 0.9397\n",
      "3599/5349 [===================>..........] - ETA: 1s - loss: 0.1115 - accuracy: 0.9397\n",
      "3878/5349 [====================>.........] - ETA: 0s - loss: 0.1119 - accuracy: 0.9394\n",
      "4052/5349 [=====================>........] - ETA: 0s - loss: 0.1119 - accuracy: 0.9394\n",
      "4232/5349 [======================>.......] - ETA: 0s - loss: 0.1121 - accuracy: 0.9394\n",
      "4412/5349 [=======================>......] - ETA: 0s - loss: 0.1119 - accuracy: 0.9395\n",
      "4599/5349 [========================>.....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9395\n",
      "4779/5349 [=========================>....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9396\n",
      "4961/5349 [==========================>...] - ETA: 0s - loss: 0.1119 - accuracy: 0.9395\n",
      "5132/5349 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.9396\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9396\n",
      "5349/5349 [==============================] - 4s 775us/step - loss: 0.1118 - accuracy: 0.9396 - val_loss: 0.1085 - val_accuracy: 0.9440\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 17/20\n",
      "  91/5349 [..............................] - ETA: 2s - loss: 0.1081 - accuracy: 0.9427\n",
      " 275/5349 [>.............................] - ETA: 2s - loss: 0.1083 - accuracy: 0.9425\n",
      " 462/5349 [=>............................] - ETA: 2s - loss: 0.1095 - accuracy: 0.9417\n",
      " 642/5349 [==>...........................] - ETA: 2s - loss: 0.1095 - accuracy: 0.9422\n",
      " 819/5349 [===>..........................] - ETA: 2s - loss: 0.1096 - accuracy: 0.9419\n",
      " 992/5349 [====>.........................] - ETA: 2s - loss: 0.1098 - accuracy: 0.9414\n",
      "1170/5349 [=====>........................] - ETA: 2s - loss: 0.1101 - accuracy: 0.9409\n",
      "1347/5349 [======>.......................] - ETA: 2s - loss: 0.1102 - accuracy: 0.9405\n",
      "1533/5349 [=======>......................] - ETA: 2s - loss: 0.1100 - accuracy: 0.9404\n",
      "1624/5349 [========>.....................] - ETA: 2s - loss: 0.1100 - accuracy: 0.9403\n",
      "1798/5349 [=========>....................] - ETA: 1s - loss: 0.1103 - accuracy: 0.9401\n",
      "1983/5349 [==========>...................] - ETA: 1s - loss: 0.1104 - accuracy: 0.9402\n",
      "2166/5349 [===========>..................] - ETA: 1s - loss: 0.1105 - accuracy: 0.9403\n",
      "2352/5349 [============>.................] - ETA: 1s - loss: 0.1103 - accuracy: 0.9406\n",
      "2534/5349 [=============>................] - ETA: 1s - loss: 0.1105 - accuracy: 0.9403\n",
      "2713/5349 [==============>...............] - ETA: 1s - loss: 0.1105 - accuracy: 0.9403\n",
      "2864/5349 [===============>..............] - ETA: 1s - loss: 0.1106 - accuracy: 0.9402\n",
      "3044/5349 [================>.............] - ETA: 1s - loss: 0.1108 - accuracy: 0.9401\n",
      "3223/5349 [=================>............] - ETA: 1s - loss: 0.1107 - accuracy: 0.9402\n",
      "3398/5349 [==================>...........] - ETA: 1s - loss: 0.1110 - accuracy: 0.9401\n",
      "3572/5349 [===================>..........] - ETA: 1s - loss: 0.1109 - accuracy: 0.9401\n",
      "3841/5349 [====================>.........] - ETA: 0s - loss: 0.1108 - accuracy: 0.9401\n",
      "4027/5349 [=====================>........] - ETA: 0s - loss: 0.1108 - accuracy: 0.9402\n",
      "4190/5349 [======================>.......] - ETA: 0s - loss: 0.1108 - accuracy: 0.9402\n",
      "4369/5349 [=======================>......] - ETA: 0s - loss: 0.1107 - accuracy: 0.9403\n",
      "4537/5349 [========================>.....] - ETA: 0s - loss: 0.1107 - accuracy: 0.9404\n",
      "4719/5349 [=========================>....] - ETA: 0s - loss: 0.1107 - accuracy: 0.9404\n",
      "4895/5349 [==========================>...] - ETA: 0s - loss: 0.1108 - accuracy: 0.9404\n",
      "5075/5349 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9402\n",
      "5251/5349 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9402\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9403\n",
      "5349/5349 [==============================] - 4s 733us/step - loss: 0.1110 - accuracy: 0.9403 - val_loss: 0.1092 - val_accuracy: 0.9382\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1223 - accuracy: 0.9300\n",
      " 182/5349 [>.............................] - ETA: 2s - loss: 0.1092 - accuracy: 0.9399\n",
      " 365/5349 [=>............................] - ETA: 2s - loss: 0.1090 - accuracy: 0.9410\n",
      " 546/5349 [==>...........................] - ETA: 2s - loss: 0.1101 - accuracy: 0.9410\n",
      " 728/5349 [===>..........................] - ETA: 2s - loss: 0.1106 - accuracy: 0.9399\n",
      " 908/5349 [====>.........................] - ETA: 2s - loss: 0.1104 - accuracy: 0.9406\n",
      "1092/5349 [=====>........................] - ETA: 2s - loss: 0.1109 - accuracy: 0.9404\n",
      "1270/5349 [======>.......................] - ETA: 2s - loss: 0.1108 - accuracy: 0.9406\n",
      "1457/5349 [=======>......................] - ETA: 2s - loss: 0.1109 - accuracy: 0.9402\n",
      "1550/5349 [=======>......................] - ETA: 2s - loss: 0.1110 - accuracy: 0.9400\n",
      "1728/5349 [========>.....................] - ETA: 2s - loss: 0.1112 - accuracy: 0.9399\n",
      "1915/5349 [=========>....................] - ETA: 1s - loss: 0.1111 - accuracy: 0.9401\n",
      "2072/5349 [==========>...................] - ETA: 1s - loss: 0.1109 - accuracy: 0.9401\n",
      "2260/5349 [===========>..................] - ETA: 1s - loss: 0.1107 - accuracy: 0.9404\n",
      "2440/5349 [============>.................] - ETA: 1s - loss: 0.1107 - accuracy: 0.9404\n",
      "2625/5349 [=============>................] - ETA: 1s - loss: 0.1108 - accuracy: 0.9405\n",
      "2802/5349 [==============>...............] - ETA: 1s - loss: 0.1108 - accuracy: 0.9404\n",
      "2965/5349 [===============>..............] - ETA: 1s - loss: 0.1108 - accuracy: 0.9405\n",
      "3097/5349 [================>.............] - ETA: 1s - loss: 0.1107 - accuracy: 0.9406\n",
      "3171/5349 [================>.............] - ETA: 1s - loss: 0.1107 - accuracy: 0.9406\n",
      "3322/5349 [=================>............] - ETA: 1s - loss: 0.1107 - accuracy: 0.9405\n",
      "3465/5349 [==================>...........] - ETA: 1s - loss: 0.1108 - accuracy: 0.9404\n",
      "3608/5349 [===================>..........] - ETA: 1s - loss: 0.1107 - accuracy: 0.9405\n",
      "3755/5349 [====================>.........] - ETA: 0s - loss: 0.1105 - accuracy: 0.9406\n",
      "3872/5349 [====================>.........] - ETA: 0s - loss: 0.1105 - accuracy: 0.9406\n",
      "3977/5349 [=====================>........] - ETA: 0s - loss: 0.1106 - accuracy: 0.9404\n",
      "4117/5349 [======================>.......] - ETA: 0s - loss: 0.1106 - accuracy: 0.9404\n",
      "4228/5349 [======================>.......] - ETA: 0s - loss: 0.1106 - accuracy: 0.9404\n",
      "4291/5349 [=======================>......] - ETA: 0s - loss: 0.1106 - accuracy: 0.9403\n",
      "4368/5349 [=======================>......] - ETA: 0s - loss: 0.1107 - accuracy: 0.9403\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.1105 - accuracy: 0.9404\n",
      "4612/5349 [========================>.....] - ETA: 0s - loss: 0.1105 - accuracy: 0.9405\n",
      "4688/5349 [=========================>....] - ETA: 0s - loss: 0.1105 - accuracy: 0.9405\n",
      "4841/5349 [==========================>...] - ETA: 0s - loss: 0.1106 - accuracy: 0.9405\n",
      "5016/5349 [===========================>..] - ETA: 0s - loss: 0.1105 - accuracy: 0.9405\n",
      "5203/5349 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 0.9405\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9404\n",
      "5349/5349 [==============================] - 4s 812us/step - loss: 0.1107 - accuracy: 0.9404 - val_loss: 0.1083 - val_accuracy: 0.9429\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1097 - accuracy: 0.9300\n",
      " 184/5349 [>.............................] - ETA: 2s - loss: 0.1054 - accuracy: 0.9418\n",
      " 366/5349 [=>............................] - ETA: 2s - loss: 0.1072 - accuracy: 0.9417\n",
      " 528/5349 [=>............................] - ETA: 2s - loss: 0.1088 - accuracy: 0.9413\n",
      " 711/5349 [==>...........................] - ETA: 2s - loss: 0.1093 - accuracy: 0.9409\n",
      " 890/5349 [===>..........................] - ETA: 2s - loss: 0.1102 - accuracy: 0.9406\n",
      "1074/5349 [=====>........................] - ETA: 2s - loss: 0.1105 - accuracy: 0.9400\n",
      "1343/5349 [======>.......................] - ETA: 2s - loss: 0.1101 - accuracy: 0.9405\n",
      "1528/5349 [=======>......................] - ETA: 2s - loss: 0.1099 - accuracy: 0.9405\n",
      "1705/5349 [========>.....................] - ETA: 2s - loss: 0.1100 - accuracy: 0.9406\n",
      "1892/5349 [=========>....................] - ETA: 1s - loss: 0.1100 - accuracy: 0.9406\n",
      "2067/5349 [==========>...................] - ETA: 1s - loss: 0.1101 - accuracy: 0.9406\n",
      "2185/5349 [===========>..................] - ETA: 1s - loss: 0.1101 - accuracy: 0.9406\n",
      "2359/5349 [============>.................] - ETA: 1s - loss: 0.1102 - accuracy: 0.9406\n",
      "2542/5349 [=============>................] - ETA: 1s - loss: 0.1101 - accuracy: 0.9406\n",
      "2775/5349 [==============>...............] - ETA: 1s - loss: 0.1101 - accuracy: 0.9405\n",
      "2951/5349 [===============>..............] - ETA: 1s - loss: 0.1100 - accuracy: 0.9406\n",
      "3112/5349 [================>.............] - ETA: 1s - loss: 0.1102 - accuracy: 0.9404\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1102 - accuracy: 0.9404\n",
      "3455/5349 [==================>...........] - ETA: 1s - loss: 0.1102 - accuracy: 0.9405\n",
      "3618/5349 [===================>..........] - ETA: 1s - loss: 0.1102 - accuracy: 0.9405\n",
      "3789/5349 [====================>.........] - ETA: 0s - loss: 0.1102 - accuracy: 0.9405\n",
      "3971/5349 [=====================>........] - ETA: 0s - loss: 0.1101 - accuracy: 0.9405\n",
      "4149/5349 [======================>.......] - ETA: 0s - loss: 0.1102 - accuracy: 0.9405\n",
      "4335/5349 [=======================>......] - ETA: 0s - loss: 0.1101 - accuracy: 0.9405\n",
      "4516/5349 [========================>.....] - ETA: 0s - loss: 0.1102 - accuracy: 0.9405\n",
      "4699/5349 [=========================>....] - ETA: 0s - loss: 0.1101 - accuracy: 0.9406\n",
      "4880/5349 [==========================>...] - ETA: 0s - loss: 0.1101 - accuracy: 0.9406\n",
      "4973/5349 [==========================>...] - ETA: 0s - loss: 0.1101 - accuracy: 0.9406\n",
      "5160/5349 [===========================>..] - ETA: 0s - loss: 0.1102 - accuracy: 0.9405\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9406\n",
      "5349/5349 [==============================] - 4s 741us/step - loss: 0.1101 - accuracy: 0.9406 - val_loss: 0.1080 - val_accuracy: 0.9414\n",
      "\u001B[36m(train_DNN pid=5684)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0906 - accuracy: 0.9700\n",
      " 179/5349 [>.............................] - ETA: 2s - loss: 0.1086 - accuracy: 0.9415\n",
      " 361/5349 [=>............................] - ETA: 2s - loss: 0.1106 - accuracy: 0.9407\n",
      " 540/5349 [==>...........................] - ETA: 2s - loss: 0.1091 - accuracy: 0.9423\n",
      " 721/5349 [===>..........................] - ETA: 2s - loss: 0.1092 - accuracy: 0.9416\n",
      " 988/5349 [====>.........................] - ETA: 2s - loss: 0.1089 - accuracy: 0.9418\n",
      "1136/5349 [=====>........................] - ETA: 2s - loss: 0.1092 - accuracy: 0.9412\n",
      "1310/5349 [======>.......................] - ETA: 2s - loss: 0.1088 - accuracy: 0.9412\n",
      "1495/5349 [=======>......................] - ETA: 2s - loss: 0.1088 - accuracy: 0.9413\n",
      "1677/5349 [========>.....................] - ETA: 2s - loss: 0.1091 - accuracy: 0.9411\n",
      "1861/5349 [=========>....................] - ETA: 1s - loss: 0.1086 - accuracy: 0.9414\n",
      "2025/5349 [==========>...................] - ETA: 1s - loss: 0.1089 - accuracy: 0.9414\n",
      "2209/5349 [===========>..................] - ETA: 1s - loss: 0.1089 - accuracy: 0.9412\n",
      "2390/5349 [============>.................] - ETA: 1s - loss: 0.1090 - accuracy: 0.9412\n",
      "2572/5349 [=============>................] - ETA: 1s - loss: 0.1093 - accuracy: 0.9413\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.1093 - accuracy: 0.9414\n",
      "2846/5349 [==============>...............] - ETA: 1s - loss: 0.1095 - accuracy: 0.9412\n",
      "3030/5349 [===============>..............] - ETA: 1s - loss: 0.1096 - accuracy: 0.9411\n",
      "3210/5349 [=================>............] - ETA: 1s - loss: 0.1096 - accuracy: 0.9410\n",
      "3396/5349 [==================>...........] - ETA: 1s - loss: 0.1097 - accuracy: 0.9409\n",
      "3575/5349 [===================>..........] - ETA: 0s - loss: 0.1098 - accuracy: 0.9408\n",
      "3760/5349 [====================>.........] - ETA: 0s - loss: 0.1101 - accuracy: 0.9406\n",
      "3941/5349 [=====================>........] - ETA: 0s - loss: 0.1102 - accuracy: 0.9406\n",
      "4124/5349 [======================>.......] - ETA: 0s - loss: 0.1102 - accuracy: 0.9405\n",
      "4303/5349 [=======================>......] - ETA: 0s - loss: 0.1101 - accuracy: 0.9406\n",
      "4490/5349 [========================>.....] - ETA: 0s - loss: 0.1099 - accuracy: 0.9408\n",
      "4656/5349 [=========================>....] - ETA: 0s - loss: 0.1099 - accuracy: 0.9407\n",
      "4842/5349 [==========================>...] - ETA: 0s - loss: 0.1098 - accuracy: 0.9408\n",
      "5099/5349 [===========================>..] - ETA: 0s - loss: 0.1098 - accuracy: 0.9409\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9408\n",
      "5349/5349 [==============================] - 4s 735us/step - loss: 0.1098 - accuracy: 0.9408 - val_loss: 0.1080 - val_accuracy: 0.9456\n",
      "\u001B[36m(train_DNN pid=5745)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 23:52 - loss: 1.0790 - accuracy: 0.1400\n",
      " 157/5349 [..............................] - ETA: 3s - loss: 0.4157 - accuracy: 0.7897\n",
      " 391/5349 [=>............................] - ETA: 3s - loss: 0.2859 - accuracy: 0.8533\n",
      " 539/5349 [==>...........................] - ETA: 3s - loss: 0.2548 - accuracy: 0.8691\n",
      " 690/5349 [==>...........................] - ETA: 3s - loss: 0.2359 - accuracy: 0.8785\n",
      " 834/5349 [===>..........................] - ETA: 2s - loss: 0.2232 - accuracy: 0.8851\n",
      " 987/5349 [====>.........................] - ETA: 2s - loss: 0.2137 - accuracy: 0.8894\n",
      "1127/5349 [=====>........................] - ETA: 2s - loss: 0.2068 - accuracy: 0.8926\n",
      "1280/5349 [======>.......................] - ETA: 2s - loss: 0.2012 - accuracy: 0.8955\n",
      "1425/5349 [======>.......................] - ETA: 2s - loss: 0.1969 - accuracy: 0.8973\n",
      "1580/5349 [=======>......................] - ETA: 2s - loss: 0.1928 - accuracy: 0.8993\n",
      "1722/5349 [========>.....................] - ETA: 2s - loss: 0.1897 - accuracy: 0.9005\n",
      "1874/5349 [=========>....................] - ETA: 2s - loss: 0.1865 - accuracy: 0.9022\n",
      "1949/5349 [=========>....................] - ETA: 2s - loss: 0.1852 - accuracy: 0.9029\n",
      "2081/5349 [==========>...................] - ETA: 2s - loss: 0.1833 - accuracy: 0.9037\n",
      "2227/5349 [===========>..................] - ETA: 2s - loss: 0.1810 - accuracy: 0.9050\n",
      "2367/5349 [============>.................] - ETA: 2s - loss: 0.1790 - accuracy: 0.9059\n",
      "2524/5349 [=============>................] - ETA: 1s - loss: 0.1771 - accuracy: 0.9068\n",
      "2672/5349 [=============>................] - ETA: 1s - loss: 0.1758 - accuracy: 0.9073\n",
      "2825/5349 [==============>...............] - ETA: 1s - loss: 0.1744 - accuracy: 0.9079\n",
      "2967/5349 [===============>..............] - ETA: 1s - loss: 0.1733 - accuracy: 0.9084\n",
      "3114/5349 [================>.............] - ETA: 1s - loss: 0.1724 - accuracy: 0.9088\n",
      "3261/5349 [=================>............] - ETA: 1s - loss: 0.1712 - accuracy: 0.9092\n",
      "3408/5349 [==================>...........] - ETA: 1s - loss: 0.1704 - accuracy: 0.9095\n",
      "3470/5349 [==================>...........] - ETA: 1s - loss: 0.1700 - accuracy: 0.9097\n",
      "3604/5349 [===================>..........] - ETA: 1s - loss: 0.1692 - accuracy: 0.9101\n",
      "3756/5349 [====================>.........] - ETA: 1s - loss: 0.1683 - accuracy: 0.9105\n",
      "3881/5349 [====================>.........] - ETA: 1s - loss: 0.1676 - accuracy: 0.9107\n",
      "3985/5349 [=====================>........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9109\n",
      "4095/5349 [=====================>........] - ETA: 0s - loss: 0.1666 - accuracy: 0.9112\n",
      "4216/5349 [======================>.......] - ETA: 0s - loss: 0.1660 - accuracy: 0.9114\n",
      "4338/5349 [=======================>......] - ETA: 0s - loss: 0.1656 - accuracy: 0.9116\n",
      "4504/5349 [========================>.....] - ETA: 0s - loss: 0.1649 - accuracy: 0.9119\n",
      "4608/5349 [========================>.....] - ETA: 0s - loss: 0.1645 - accuracy: 0.9122\n",
      "4686/5349 [=========================>....] - ETA: 0s - loss: 0.1642 - accuracy: 0.9123\n",
      "4786/5349 [=========================>....] - ETA: 0s - loss: 0.1638 - accuracy: 0.9125\n",
      "4878/5349 [==========================>...] - ETA: 0s - loss: 0.1634 - accuracy: 0.9127\n",
      "4980/5349 [==========================>...] - ETA: 0s - loss: 0.1629 - accuracy: 0.9130\n",
      "5031/5349 [===========================>..] - ETA: 0s - loss: 0.1627 - accuracy: 0.9131\n",
      "5093/5349 [===========================>..] - ETA: 0s - loss: 0.1625 - accuracy: 0.9132\n",
      "5185/5349 [============================>.] - ETA: 0s - loss: 0.1622 - accuracy: 0.9132\n",
      "5246/5349 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9133\n",
      "5347/5349 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9135\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1617 - accuracy: 0.9135 - val_loss: 0.1434 - val_accuracy: 0.9221\n",
      "\u001B[36m(train_DNN pid=5745)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1306 - accuracy: 0.9400\n",
      " 150/5349 [..............................] - ETA: 3s - loss: 0.1403 - accuracy: 0.9244\n",
      " 303/5349 [>.............................] - ETA: 3s - loss: 0.1430 - accuracy: 0.9231\n",
      " 445/5349 [=>............................] - ETA: 3s - loss: 0.1438 - accuracy: 0.9222\n",
      " 601/5349 [==>...........................] - ETA: 3s - loss: 0.1435 - accuracy: 0.9217\n",
      " 749/5349 [===>..........................] - ETA: 3s - loss: 0.1436 - accuracy: 0.9216\n",
      " 903/5349 [====>.........................] - ETA: 2s - loss: 0.1437 - accuracy: 0.9215\n",
      "1050/5349 [====>.........................] - ETA: 2s - loss: 0.1440 - accuracy: 0.9213\n",
      "1200/5349 [=====>........................] - ETA: 2s - loss: 0.1439 - accuracy: 0.9215\n",
      "1334/5349 [======>.......................] - ETA: 2s - loss: 0.1440 - accuracy: 0.9214\n",
      "1486/5349 [=======>......................] - ETA: 2s - loss: 0.1434 - accuracy: 0.9217\n",
      "1636/5349 [========>.....................] - ETA: 2s - loss: 0.1429 - accuracy: 0.9221\n",
      "1778/5349 [========>.....................] - ETA: 2s - loss: 0.1430 - accuracy: 0.9218\n",
      "1969/5349 [==========>...................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9224\n",
      "2121/5349 [==========>...................] - ETA: 2s - loss: 0.1427 - accuracy: 0.9223\n",
      "2243/5349 [===========>..................] - ETA: 2s - loss: 0.1427 - accuracy: 0.9223\n",
      "2370/5349 [============>.................] - ETA: 2s - loss: 0.1426 - accuracy: 0.9222\n",
      "2510/5349 [=============>................] - ETA: 1s - loss: 0.1427 - accuracy: 0.9222\n",
      "2660/5349 [=============>................] - ETA: 1s - loss: 0.1425 - accuracy: 0.9224\n",
      "2803/5349 [==============>...............] - ETA: 1s - loss: 0.1423 - accuracy: 0.9224\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1424 - accuracy: 0.9223\n",
      "3023/5349 [===============>..............] - ETA: 1s - loss: 0.1423 - accuracy: 0.9224\n",
      "3167/5349 [================>.............] - ETA: 1s - loss: 0.1420 - accuracy: 0.9225\n",
      "3315/5349 [=================>............] - ETA: 1s - loss: 0.1419 - accuracy: 0.9226\n",
      "3450/5349 [==================>...........] - ETA: 1s - loss: 0.1418 - accuracy: 0.9227\n",
      "3597/5349 [===================>..........] - ETA: 1s - loss: 0.1420 - accuracy: 0.9223\n",
      "3741/5349 [===================>..........] - ETA: 1s - loss: 0.1420 - accuracy: 0.9224\n",
      "3888/5349 [====================>.........] - ETA: 1s - loss: 0.1419 - accuracy: 0.9225\n",
      "4024/5349 [=====================>........] - ETA: 0s - loss: 0.1418 - accuracy: 0.9225\n",
      "4178/5349 [======================>.......] - ETA: 0s - loss: 0.1417 - accuracy: 0.9227\n",
      "4323/5349 [=======================>......] - ETA: 0s - loss: 0.1416 - accuracy: 0.9228\n",
      "4467/5349 [========================>.....] - ETA: 0s - loss: 0.1417 - accuracy: 0.9227\n",
      "4615/5349 [========================>.....] - ETA: 0s - loss: 0.1417 - accuracy: 0.9228\n",
      "4691/5349 [=========================>....] - ETA: 0s - loss: 0.1415 - accuracy: 0.9229\n",
      "4847/5349 [==========================>...] - ETA: 0s - loss: 0.1415 - accuracy: 0.9230\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1414 - accuracy: 0.9232\n",
      "5151/5349 [===========================>..] - ETA: 0s - loss: 0.1412 - accuracy: 0.9233\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9234\n",
      "5349/5349 [==============================] - 5s 867us/step - loss: 0.1410 - accuracy: 0.9235 - val_loss: 0.1371 - val_accuracy: 0.9269\n",
      "\u001B[36m(train_DNN pid=5745)\u001B[0m Epoch 3/20\n",
      "  76/5349 [..............................] - ETA: 3s - loss: 0.1392 - accuracy: 0.9214\n",
      " 229/5349 [>.............................] - ETA: 3s - loss: 0.1396 - accuracy: 0.9242\n",
      " 360/5349 [=>............................] - ETA: 3s - loss: 0.1399 - accuracy: 0.9242\n",
      " 509/5349 [=>............................] - ETA: 3s - loss: 0.1392 - accuracy: 0.9254\n",
      " 663/5349 [==>...........................] - ETA: 3s - loss: 0.1387 - accuracy: 0.9262\n",
      " 891/5349 [===>..........................] - ETA: 3s - loss: 0.1383 - accuracy: 0.9261\n",
      "1044/5349 [====>.........................] - ETA: 2s - loss: 0.1379 - accuracy: 0.9260\n",
      "1194/5349 [=====>........................] - ETA: 2s - loss: 0.1381 - accuracy: 0.9258\n",
      "1350/5349 [======>.......................] - ETA: 2s - loss: 0.1381 - accuracy: 0.9256\n",
      "1498/5349 [=======>......................] - ETA: 2s - loss: 0.1377 - accuracy: 0.9259\n",
      "1653/5349 [========>.....................] - ETA: 2s - loss: 0.1371 - accuracy: 0.9262\n",
      "1798/5349 [=========>....................] - ETA: 2s - loss: 0.1370 - accuracy: 0.9262\n",
      "1952/5349 [=========>....................] - ETA: 2s - loss: 0.1367 - accuracy: 0.9264\n",
      "2088/5349 [==========>...................] - ETA: 2s - loss: 0.1367 - accuracy: 0.9266\n",
      "2244/5349 [===========>..................] - ETA: 2s - loss: 0.1365 - accuracy: 0.9266\n",
      "2317/5349 [===========>..................] - ETA: 2s - loss: 0.1368 - accuracy: 0.9265\n",
      "2461/5349 [============>.................] - ETA: 1s - loss: 0.1368 - accuracy: 0.9264\n",
      "2615/5349 [=============>................] - ETA: 1s - loss: 0.1364 - accuracy: 0.9267\n",
      "2764/5349 [==============>...............] - ETA: 1s - loss: 0.1360 - accuracy: 0.9272\n",
      "2918/5349 [===============>..............] - ETA: 1s - loss: 0.1361 - accuracy: 0.9270\n",
      "3064/5349 [================>.............] - ETA: 1s - loss: 0.1360 - accuracy: 0.9270\n",
      "3214/5349 [=================>............] - ETA: 1s - loss: 0.1360 - accuracy: 0.9269\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1359 - accuracy: 0.9271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-27 11:46:29,952\tERROR tune_controller.py:1331 -- Trial task failed for trial train_DNN_906fd_00014\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(InvalidArgumentError): \u001B[36mray::ImplicitFunc.train()\u001B[39m (pid=5745, ip=127.0.0.1, actor_id=18b4dacd66055c2d061a3ef401000000, repr=train_DNN)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/finnbeckmann/uni/DLLabs/lab2/utilities.py\", line 154, in train_DNN\n",
      "    model.fit(X_train, y_train,\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node gradient_tape/binary_crossentropy/logistic_loss/mul/Reshape defined at (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "\n",
      "  File \"/Users/finnbeckmann/uni/DLLabs/lab2/utilities.py\", line 154, in train_DNN\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1151, in train_step\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/optimizers/legacy/optimizer_v2.py\", line 591, in minimize\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/optimizers/legacy/optimizer_v2.py\", line 649, in _compute_gradients\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/optimizers/legacy/optimizer_v2.py\", line 525, in _get_gradients\n",
      "\n",
      "Input to reshape is a tensor with 1 values, but the requested shape has 100\n",
      "\t [[{{node gradient_tape/binary_crossentropy/logistic_loss/mul/Reshape}}]] [Op:__inference_train_function_874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 1/20\n",
      "  96/5349 [..............................] - ETA: 2s - loss: 0.8770 - accuracy: 0.1590   \n",
      " 329/5349 [>.............................] - ETA: 2s - loss: 0.7241 - accuracy: 0.4882\n",
      " 566/5349 [==>...........................] - ETA: 2s - loss: 0.6405 - accuracy: 0.6355\n",
      " 796/5349 [===>..........................] - ETA: 2s - loss: 0.5913 - accuracy: 0.6957\n",
      "1030/5349 [====>.........................] - ETA: 1s - loss: 0.5598 - accuracy: 0.7287\n",
      "1262/5349 [======>.......................] - ETA: 1s - loss: 0.5389 - accuracy: 0.7489\n",
      "1482/5349 [=======>......................] - ETA: 1s - loss: 0.5244 - accuracy: 0.7623\n",
      "1602/5349 [=======>......................] - ETA: 1s - loss: 0.5180 - accuracy: 0.7681\n",
      "1809/5349 [=========>....................] - ETA: 1s - loss: 0.5089 - accuracy: 0.7762\n",
      "2041/5349 [==========>...................] - ETA: 1s - loss: 0.4999 - accuracy: 0.7840\n",
      "2263/5349 [===========>..................] - ETA: 1s - loss: 0.4938 - accuracy: 0.7893\n",
      "2505/5349 [=============>................] - ETA: 1s - loss: 0.4877 - accuracy: 0.7945\n",
      "2730/5349 [==============>...............] - ETA: 1s - loss: 0.4831 - accuracy: 0.7984\n",
      "2965/5349 [===============>..............] - ETA: 1s - loss: 0.4791 - accuracy: 0.8018\n",
      "3164/5349 [================>.............] - ETA: 0s - loss: 0.4763 - accuracy: 0.8042\n",
      "3400/5349 [==================>...........] - ETA: 0s - loss: 0.4734 - accuracy: 0.8067\n",
      "3751/5349 [====================>.........] - ETA: 0s - loss: 0.4695 - accuracy: 0.8100\n",
      "3993/5349 [=====================>........] - ETA: 0s - loss: 0.4674 - accuracy: 0.8118\n",
      "4227/5349 [======================>.......] - ETA: 0s - loss: 0.4655 - accuracy: 0.8134\n",
      "4461/5349 [========================>.....] - ETA: 0s - loss: 0.4637 - accuracy: 0.8149\n",
      "4694/5349 [=========================>....] - ETA: 0s - loss: 0.4621 - accuracy: 0.8162\n",
      "4933/5349 [==========================>...] - ETA: 0s - loss: 0.4608 - accuracy: 0.8173\n",
      "5146/5349 [===========================>..] - ETA: 0s - loss: 0.4597 - accuracy: 0.8182\n",
      "5266/5349 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.8188\n",
      "5349/5349 [==============================] - 4s 635us/step - loss: 0.4587 - accuracy: 0.8190 - val_loss: 0.4325 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4168 - accuracy: 0.8500\n",
      " 236/5349 [>.............................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8391\n",
      " 474/5349 [=>............................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8388\n",
      " 706/5349 [==>...........................] - ETA: 1s - loss: 0.4325 - accuracy: 0.8404\n",
      "1008/5349 [====>.........................] - ETA: 1s - loss: 0.4316 - accuracy: 0.8409\n",
      "1174/5349 [=====>........................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8408\n",
      "1370/5349 [======>.......................] - ETA: 1s - loss: 0.4317 - accuracy: 0.8407\n",
      "1554/5349 [=======>......................] - ETA: 1s - loss: 0.4312 - accuracy: 0.8410\n",
      "1724/5349 [========>.....................] - ETA: 1s - loss: 0.4310 - accuracy: 0.8411\n",
      "1920/5349 [=========>....................] - ETA: 1s - loss: 0.4316 - accuracy: 0.8407\n",
      "2107/5349 [==========>...................] - ETA: 1s - loss: 0.4315 - accuracy: 0.8407\n",
      "2296/5349 [===========>..................] - ETA: 1s - loss: 0.4312 - accuracy: 0.8409\n",
      "2401/5349 [============>.................] - ETA: 1s - loss: 0.4314 - accuracy: 0.8407\n",
      "2598/5349 [=============>................] - ETA: 1s - loss: 0.4312 - accuracy: 0.8408\n",
      "2707/5349 [==============>...............] - ETA: 1s - loss: 0.4312 - accuracy: 0.8408\n",
      "2895/5349 [===============>..............] - ETA: 1s - loss: 0.4312 - accuracy: 0.8407\n",
      "3024/5349 [===============>..............] - ETA: 1s - loss: 0.4314 - accuracy: 0.8406\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.4315 - accuracy: 0.8405\n",
      "3428/5349 [==================>...........] - ETA: 1s - loss: 0.4312 - accuracy: 0.8406\n",
      "3664/5349 [===================>..........] - ETA: 0s - loss: 0.4312 - accuracy: 0.8406\n",
      "3890/5349 [====================>.........] - ETA: 0s - loss: 0.4310 - accuracy: 0.8406\n",
      "4127/5349 [======================>.......] - ETA: 0s - loss: 0.4309 - accuracy: 0.8407\n",
      "4233/5349 [======================>.......] - ETA: 0s - loss: 0.4310 - accuracy: 0.8406\n",
      "4446/5349 [=======================>......] - ETA: 0s - loss: 0.4309 - accuracy: 0.8406\n",
      "4682/5349 [=========================>....] - ETA: 0s - loss: 0.4305 - accuracy: 0.8408\n",
      "4913/5349 [==========================>...] - ETA: 0s - loss: 0.4309 - accuracy: 0.8405\n",
      "5148/5349 [===========================>..] - ETA: 0s - loss: 0.4308 - accuracy: 0.8405\n",
      "5260/5349 [============================>.] - ETA: 0s - loss: 0.4306 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 664us/step - loss: 0.4306 - accuracy: 0.8406 - val_loss: 0.4289 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 3/20\n",
      " 117/5349 [..............................] - ETA: 2s - loss: 0.4339 - accuracy: 0.8374\n",
      " 350/5349 [>.............................] - ETA: 2s - loss: 0.4279 - accuracy: 0.8411\n",
      " 585/5349 [==>...........................] - ETA: 2s - loss: 0.4281 - accuracy: 0.8409\n",
      " 813/5349 [===>..........................] - ETA: 1s - loss: 0.4286 - accuracy: 0.8405\n",
      "1047/5349 [====>.........................] - ETA: 1s - loss: 0.4292 - accuracy: 0.8401\n",
      "1381/5349 [======>.......................] - ETA: 1s - loss: 0.4285 - accuracy: 0.8404\n",
      "1563/5349 [=======>......................] - ETA: 1s - loss: 0.4283 - accuracy: 0.8405\n",
      "1764/5349 [========>.....................] - ETA: 1s - loss: 0.4277 - accuracy: 0.8409\n",
      "1997/5349 [==========>...................] - ETA: 1s - loss: 0.4284 - accuracy: 0.8403\n",
      "2210/5349 [===========>..................] - ETA: 1s - loss: 0.4285 - accuracy: 0.8402\n",
      "2443/5349 [============>.................] - ETA: 1s - loss: 0.4290 - accuracy: 0.8398\n",
      "2674/5349 [=============>................] - ETA: 1s - loss: 0.4283 - accuracy: 0.8402\n",
      "2912/5349 [===============>..............] - ETA: 1s - loss: 0.4280 - accuracy: 0.8404\n",
      "3140/5349 [================>.............] - ETA: 0s - loss: 0.4275 - accuracy: 0.8406\n",
      "3369/5349 [=================>............] - ETA: 0s - loss: 0.4278 - accuracy: 0.8404\n",
      "3597/5349 [===================>..........] - ETA: 0s - loss: 0.4272 - accuracy: 0.8407\n",
      "3839/5349 [====================>.........] - ETA: 0s - loss: 0.4266 - accuracy: 0.8410\n",
      "4189/5349 [======================>.......] - ETA: 0s - loss: 0.4267 - accuracy: 0.8408\n",
      "4425/5349 [=======================>......] - ETA: 0s - loss: 0.4268 - accuracy: 0.8407\n",
      "4599/5349 [========================>.....] - ETA: 0s - loss: 0.4266 - accuracy: 0.8408\n",
      "4794/5349 [=========================>....] - ETA: 0s - loss: 0.4265 - accuracy: 0.8408\n",
      "5023/5349 [===========================>..] - ETA: 0s - loss: 0.4266 - accuracy: 0.8406\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 615us/step - loss: 0.4265 - accuracy: 0.8406 - val_loss: 0.4242 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4110 - accuracy: 0.8500\n",
      " 230/5349 [>.............................] - ETA: 2s - loss: 0.4235 - accuracy: 0.8408\n",
      " 468/5349 [=>............................] - ETA: 2s - loss: 0.4208 - accuracy: 0.8425\n",
      " 700/5349 [==>...........................] - ETA: 2s - loss: 0.4213 - accuracy: 0.8421\n",
      " 938/5349 [====>.........................] - ETA: 1s - loss: 0.4230 - accuracy: 0.8410\n",
      "1252/5349 [======>.......................] - ETA: 1s - loss: 0.4227 - accuracy: 0.8410\n",
      "1481/5349 [=======>......................] - ETA: 1s - loss: 0.4229 - accuracy: 0.8408\n",
      "1703/5349 [========>.....................] - ETA: 1s - loss: 0.4226 - accuracy: 0.8409\n",
      "1941/5349 [=========>....................] - ETA: 1s - loss: 0.4220 - accuracy: 0.8412\n",
      "2160/5349 [===========>..................] - ETA: 1s - loss: 0.4218 - accuracy: 0.8413\n",
      "2396/5349 [============>.................] - ETA: 1s - loss: 0.4212 - accuracy: 0.8416\n",
      "2624/5349 [=============>................] - ETA: 1s - loss: 0.4212 - accuracy: 0.8415\n",
      "2858/5349 [===============>..............] - ETA: 1s - loss: 0.4209 - accuracy: 0.8416\n",
      "3091/5349 [================>.............] - ETA: 0s - loss: 0.4215 - accuracy: 0.8411\n",
      "3325/5349 [=================>............] - ETA: 0s - loss: 0.4218 - accuracy: 0.8408\n",
      "3660/5349 [===================>..........] - ETA: 0s - loss: 0.4213 - accuracy: 0.8411\n",
      "3895/5349 [====================>.........] - ETA: 0s - loss: 0.4211 - accuracy: 0.8411\n",
      "4100/5349 [=====================>........] - ETA: 0s - loss: 0.4212 - accuracy: 0.8410\n",
      "4336/5349 [=======================>......] - ETA: 0s - loss: 0.4210 - accuracy: 0.8410\n",
      "4564/5349 [========================>.....] - ETA: 0s - loss: 0.4208 - accuracy: 0.8410\n",
      "4801/5349 [=========================>....] - ETA: 0s - loss: 0.4210 - accuracy: 0.8408\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.4210 - accuracy: 0.8407\n",
      "5259/5349 [============================>.] - ETA: 0s - loss: 0.4208 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 3s 610us/step - loss: 0.4209 - accuracy: 0.8406 - val_loss: 0.4176 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4338 - accuracy: 0.8300\n",
      " 227/5349 [>.............................] - ETA: 2s - loss: 0.4127 - accuracy: 0.8436\n",
      " 457/5349 [=>............................] - ETA: 2s - loss: 0.4159 - accuracy: 0.8414\n",
      " 687/5349 [==>...........................] - ETA: 2s - loss: 0.4169 - accuracy: 0.8406\n",
      " 922/5349 [====>.........................] - ETA: 1s - loss: 0.4170 - accuracy: 0.8405\n",
      "1117/5349 [=====>........................] - ETA: 1s - loss: 0.4168 - accuracy: 0.8405\n",
      "1345/5349 [======>.......................] - ETA: 1s - loss: 0.4173 - accuracy: 0.8400\n",
      "1550/5349 [=======>......................] - ETA: 1s - loss: 0.4164 - accuracy: 0.8405\n",
      "1744/5349 [========>.....................] - ETA: 1s - loss: 0.4154 - accuracy: 0.8411\n",
      "1826/5349 [=========>....................] - ETA: 1s - loss: 0.4159 - accuracy: 0.8407\n",
      "2018/5349 [==========>...................] - ETA: 1s - loss: 0.4160 - accuracy: 0.8405\n",
      "2210/5349 [===========>..................] - ETA: 1s - loss: 0.4158 - accuracy: 0.8406\n",
      "2402/5349 [============>.................] - ETA: 1s - loss: 0.4153 - accuracy: 0.8408\n",
      "2606/5349 [=============>................] - ETA: 1s - loss: 0.4154 - accuracy: 0.8406\n",
      "2798/5349 [==============>...............] - ETA: 1s - loss: 0.4154 - accuracy: 0.8405\n",
      "2998/5349 [===============>..............] - ETA: 1s - loss: 0.4153 - accuracy: 0.8404\n",
      "3175/5349 [================>.............] - ETA: 1s - loss: 0.4151 - accuracy: 0.8405\n",
      "3387/5349 [=================>............] - ETA: 0s - loss: 0.4153 - accuracy: 0.8402\n",
      "3540/5349 [==================>...........] - ETA: 0s - loss: 0.4150 - accuracy: 0.8403\n",
      "3609/5349 [===================>..........] - ETA: 0s - loss: 0.4150 - accuracy: 0.8403\n",
      "3799/5349 [====================>.........] - ETA: 0s - loss: 0.4145 - accuracy: 0.8405\n",
      "3991/5349 [=====================>........] - ETA: 0s - loss: 0.4142 - accuracy: 0.8406\n",
      "4205/5349 [======================>.......] - ETA: 0s - loss: 0.4139 - accuracy: 0.8407\n",
      "4436/5349 [=======================>......] - ETA: 0s - loss: 0.4139 - accuracy: 0.8405\n",
      "4671/5349 [=========================>....] - ETA: 0s - loss: 0.4135 - accuracy: 0.8407\n",
      "4898/5349 [==========================>...] - ETA: 0s - loss: 0.4133 - accuracy: 0.8407\n",
      "5130/5349 [===========================>..] - ETA: 0s - loss: 0.4131 - accuracy: 0.8407\n",
      "5245/5349 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 665us/step - loss: 0.4129 - accuracy: 0.8406 - val_loss: 0.4079 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 6/20\n",
      " 115/5349 [..............................] - ETA: 2s - loss: 0.4039 - accuracy: 0.8430\n",
      " 344/5349 [>.............................] - ETA: 2s - loss: 0.4076 - accuracy: 0.8404\n",
      " 573/5349 [==>...........................] - ETA: 2s - loss: 0.4086 - accuracy: 0.8396\n",
      " 796/5349 [===>..........................] - ETA: 2s - loss: 0.4071 - accuracy: 0.8404\n",
      "1026/5349 [====>.........................] - ETA: 1s - loss: 0.4082 - accuracy: 0.8396\n",
      "1245/5349 [=====>........................] - ETA: 1s - loss: 0.4083 - accuracy: 0.8394\n",
      "1446/5349 [=======>......................] - ETA: 1s - loss: 0.4067 - accuracy: 0.8403\n",
      "1661/5349 [========>.....................] - ETA: 1s - loss: 0.4077 - accuracy: 0.8394\n",
      "1898/5349 [=========>....................] - ETA: 1s - loss: 0.4075 - accuracy: 0.8394\n",
      "2119/5349 [==========>...................] - ETA: 1s - loss: 0.4074 - accuracy: 0.8393\n",
      "2409/5349 [============>.................] - ETA: 1s - loss: 0.4071 - accuracy: 0.8393\n",
      "2612/5349 [=============>................] - ETA: 1s - loss: 0.4063 - accuracy: 0.8396\n",
      "2834/5349 [==============>...............] - ETA: 1s - loss: 0.4061 - accuracy: 0.8396\n",
      "3036/5349 [================>.............] - ETA: 1s - loss: 0.4055 - accuracy: 0.8397\n",
      "3263/5349 [=================>............] - ETA: 0s - loss: 0.4045 - accuracy: 0.8402\n",
      "3482/5349 [==================>...........] - ETA: 0s - loss: 0.4040 - accuracy: 0.8404\n",
      "3716/5349 [===================>..........] - ETA: 0s - loss: 0.4034 - accuracy: 0.8406\n",
      "4054/5349 [=====================>........] - ETA: 0s - loss: 0.4028 - accuracy: 0.8406\n",
      "4280/5349 [=======================>......] - ETA: 0s - loss: 0.4028 - accuracy: 0.8404\n",
      "4507/5349 [========================>.....] - ETA: 0s - loss: 0.4023 - accuracy: 0.8405\n",
      "4745/5349 [=========================>....] - ETA: 0s - loss: 0.4020 - accuracy: 0.8405\n",
      "4974/5349 [==========================>...] - ETA: 0s - loss: 0.4016 - accuracy: 0.8406\n",
      "5176/5349 [============================>.] - ETA: 0s - loss: 0.4012 - accuracy: 0.8406\n",
      "5284/5349 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 3s 624us/step - loss: 0.4009 - accuracy: 0.8406 - val_loss: 0.3933 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 7/20\n",
      " 119/5349 [..............................] - ETA: 2s - loss: 0.3726 - accuracy: 0.8544\n",
      " 353/5349 [>.............................] - ETA: 2s - loss: 0.3865 - accuracy: 0.8450\n",
      " 593/5349 [==>...........................] - ETA: 2s - loss: 0.3884 - accuracy: 0.8434\n",
      " 947/5349 [====>.........................] - ETA: 1s - loss: 0.3903 - accuracy: 0.8416\n",
      "1189/5349 [=====>........................] - ETA: 1s - loss: 0.3902 - accuracy: 0.8414\n",
      "1419/5349 [======>.......................] - ETA: 1s - loss: 0.3892 - accuracy: 0.8418\n",
      "1654/5349 [========>.....................] - ETA: 1s - loss: 0.3883 - accuracy: 0.8421\n",
      "1864/5349 [=========>....................] - ETA: 1s - loss: 0.3883 - accuracy: 0.8418\n",
      "2101/5349 [==========>...................] - ETA: 1s - loss: 0.3883 - accuracy: 0.8415\n",
      "2306/5349 [===========>..................] - ETA: 1s - loss: 0.3878 - accuracy: 0.8415\n",
      "2541/5349 [=============>................] - ETA: 1s - loss: 0.3875 - accuracy: 0.8414\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.3877 - accuracy: 0.8410\n",
      "2978/5349 [===============>..............] - ETA: 1s - loss: 0.3879 - accuracy: 0.8405\n",
      "3202/5349 [================>.............] - ETA: 0s - loss: 0.3876 - accuracy: 0.8404\n",
      "3325/5349 [=================>............] - ETA: 0s - loss: 0.3873 - accuracy: 0.8404\n",
      "3563/5349 [==================>...........] - ETA: 0s - loss: 0.3866 - accuracy: 0.8407\n",
      "3788/5349 [====================>.........] - ETA: 0s - loss: 0.3860 - accuracy: 0.8407\n",
      "4031/5349 [=====================>........] - ETA: 0s - loss: 0.3856 - accuracy: 0.8407\n",
      "4263/5349 [======================>.......] - ETA: 0s - loss: 0.3849 - accuracy: 0.8408\n",
      "4507/5349 [========================>.....] - ETA: 0s - loss: 0.3844 - accuracy: 0.8408\n",
      "4717/5349 [=========================>....] - ETA: 0s - loss: 0.3843 - accuracy: 0.8405\n",
      "4956/5349 [==========================>...] - ETA: 0s - loss: 0.3837 - accuracy: 0.8406\n",
      "5193/5349 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8407\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 605us/step - loss: 0.3828 - accuracy: 0.8406 - val_loss: 0.3711 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2932 - accuracy: 0.9000\n",
      " 230/5349 [>.............................] - ETA: 2s - loss: 0.3677 - accuracy: 0.8423\n",
      " 466/5349 [=>............................] - ETA: 2s - loss: 0.3700 - accuracy: 0.8403\n",
      " 697/5349 [==>...........................] - ETA: 2s - loss: 0.3686 - accuracy: 0.8410\n",
      " 930/5349 [====>.........................] - ETA: 1s - loss: 0.3669 - accuracy: 0.8418\n",
      "1152/5349 [=====>........................] - ETA: 1s - loss: 0.3670 - accuracy: 0.8413\n",
      "1388/5349 [======>.......................] - ETA: 1s - loss: 0.3670 - accuracy: 0.8409\n",
      "1599/5349 [=======>......................] - ETA: 1s - loss: 0.3657 - accuracy: 0.8415\n",
      "1829/5349 [=========>....................] - ETA: 1s - loss: 0.3650 - accuracy: 0.8414\n",
      "2050/5349 [==========>...................] - ETA: 1s - loss: 0.3646 - accuracy: 0.8414\n",
      "2282/5349 [===========>..................] - ETA: 1s - loss: 0.3641 - accuracy: 0.8412\n",
      "2537/5349 [=============>................] - ETA: 1s - loss: 0.3637 - accuracy: 0.8410\n",
      "2695/5349 [==============>...............] - ETA: 1s - loss: 0.3633 - accuracy: 0.8410\n",
      "2885/5349 [===============>..............] - ETA: 1s - loss: 0.3628 - accuracy: 0.8409\n",
      "3059/5349 [================>.............] - ETA: 1s - loss: 0.3626 - accuracy: 0.8406\n",
      "3246/5349 [=================>............] - ETA: 1s - loss: 0.3622 - accuracy: 0.8406\n",
      "3446/5349 [==================>...........] - ETA: 0s - loss: 0.3617 - accuracy: 0.8405\n",
      "3544/5349 [==================>...........] - ETA: 0s - loss: 0.3614 - accuracy: 0.8405\n",
      "3741/5349 [===================>..........] - ETA: 0s - loss: 0.3611 - accuracy: 0.8403\n",
      "3915/5349 [====================>.........] - ETA: 0s - loss: 0.3606 - accuracy: 0.8404\n",
      "4112/5349 [======================>.......] - ETA: 0s - loss: 0.3600 - accuracy: 0.8403\n",
      "4242/5349 [======================>.......] - ETA: 0s - loss: 0.3595 - accuracy: 0.8404\n",
      "4384/5349 [=======================>......] - ETA: 0s - loss: 0.3590 - accuracy: 0.8405\n",
      "4564/5349 [========================>.....] - ETA: 0s - loss: 0.3583 - accuracy: 0.8406\n",
      "4751/5349 [=========================>....] - ETA: 0s - loss: 0.3578 - accuracy: 0.8405\n",
      "5081/5349 [===========================>..] - ETA: 0s - loss: 0.3568 - accuracy: 0.8405\n",
      "5283/5349 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.8405\n",
      "5349/5349 [==============================] - 4s 679us/step - loss: 0.3558 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 9/20\n",
      " 116/5349 [..............................] - ETA: 2s - loss: 0.3343 - accuracy: 0.8444\n",
      " 350/5349 [>.............................] - ETA: 2s - loss: 0.3370 - accuracy: 0.8411\n",
      " 588/5349 [==>...........................] - ETA: 2s - loss: 0.3378 - accuracy: 0.8397\n",
      " 811/5349 [===>..........................] - ETA: 1s - loss: 0.3371 - accuracy: 0.8397\n",
      "1047/5349 [====>.........................] - ETA: 1s - loss: 0.3361 - accuracy: 0.8398\n",
      "1276/5349 [======>.......................] - ETA: 1s - loss: 0.3364 - accuracy: 0.8391\n",
      "1634/5349 [========>.....................] - ETA: 1s - loss: 0.3350 - accuracy: 0.8392\n",
      "1854/5349 [=========>....................] - ETA: 1s - loss: 0.3336 - accuracy: 0.8397\n",
      "2087/5349 [==========>...................] - ETA: 1s - loss: 0.3322 - accuracy: 0.8402\n",
      "2315/5349 [===========>..................] - ETA: 1s - loss: 0.3310 - accuracy: 0.8404\n",
      "2548/5349 [=============>................] - ETA: 1s - loss: 0.3300 - accuracy: 0.8405\n",
      "2754/5349 [==============>...............] - ETA: 1s - loss: 0.3287 - accuracy: 0.8410\n",
      "2968/5349 [===============>..............] - ETA: 1s - loss: 0.3279 - accuracy: 0.8410\n",
      "3135/5349 [================>.............] - ETA: 0s - loss: 0.3273 - accuracy: 0.8410\n",
      "3359/5349 [=================>............] - ETA: 0s - loss: 0.3267 - accuracy: 0.8408\n",
      "3573/5349 [===================>..........] - ETA: 0s - loss: 0.3259 - accuracy: 0.8408\n",
      "3893/5349 [====================>.........] - ETA: 0s - loss: 0.3246 - accuracy: 0.8409\n",
      "4096/5349 [=====================>........] - ETA: 0s - loss: 0.3238 - accuracy: 0.8409\n",
      "4317/5349 [=======================>......] - ETA: 0s - loss: 0.3232 - accuracy: 0.8407\n",
      "4545/5349 [========================>.....] - ETA: 0s - loss: 0.3222 - accuracy: 0.8409\n",
      "4785/5349 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.8406\n",
      "4976/5349 [==========================>...] - ETA: 0s - loss: 0.3207 - accuracy: 0.8407\n",
      "5201/5349 [============================>.] - ETA: 0s - loss: 0.3198 - accuracy: 0.8407\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.3194 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 3s 620us/step - loss: 0.3193 - accuracy: 0.8406 - val_loss: 0.2989 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.2689 - accuracy: 0.8700\n",
      " 237/5349 [>.............................] - ETA: 2s - loss: 0.2941 - accuracy: 0.8442\n",
      " 478/5349 [=>............................] - ETA: 2s - loss: 0.2937 - accuracy: 0.8441\n",
      " 711/5349 [==>...........................] - ETA: 1s - loss: 0.2946 - accuracy: 0.8422\n",
      " 951/5349 [====>.........................] - ETA: 1s - loss: 0.2942 - accuracy: 0.8416\n",
      "1171/5349 [=====>........................] - ETA: 1s - loss: 0.2935 - accuracy: 0.8415\n",
      "1406/5349 [======>.......................] - ETA: 1s - loss: 0.2931 - accuracy: 0.8410\n",
      "1636/5349 [========>.....................] - ETA: 1s - loss: 0.2926 - accuracy: 0.8405\n",
      "1875/5349 [=========>....................] - ETA: 1s - loss: 0.2917 - accuracy: 0.8406\n",
      "1983/5349 [==========>...................] - ETA: 1s - loss: 0.2914 - accuracy: 0.8406\n",
      "2213/5349 [===========>..................] - ETA: 1s - loss: 0.2906 - accuracy: 0.8406\n",
      "2444/5349 [============>.................] - ETA: 1s - loss: 0.2898 - accuracy: 0.8404\n",
      "2673/5349 [=============>................] - ETA: 1s - loss: 0.2890 - accuracy: 0.8402\n",
      "2891/5349 [===============>..............] - ETA: 1s - loss: 0.2882 - accuracy: 0.8401\n",
      "3111/5349 [================>.............] - ETA: 0s - loss: 0.2873 - accuracy: 0.8403\n",
      "3351/5349 [=================>............] - ETA: 0s - loss: 0.2862 - accuracy: 0.8404\n",
      "3578/5349 [===================>..........] - ETA: 0s - loss: 0.2853 - accuracy: 0.8405\n",
      "3818/5349 [====================>.........] - ETA: 0s - loss: 0.2842 - accuracy: 0.8407\n",
      "4050/5349 [=====================>........] - ETA: 0s - loss: 0.2833 - accuracy: 0.8406\n",
      "4289/5349 [=======================>......] - ETA: 0s - loss: 0.2823 - accuracy: 0.8409\n",
      "4630/5349 [========================>.....] - ETA: 0s - loss: 0.2809 - accuracy: 0.8410\n",
      "4868/5349 [==========================>...] - ETA: 0s - loss: 0.2803 - accuracy: 0.8407\n",
      "5080/5349 [===========================>..] - ETA: 0s - loss: 0.2795 - accuracy: 0.8407\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 601us/step - loss: 0.2787 - accuracy: 0.8406 - val_loss: 0.2596 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 2s - loss: 0.2470 - accuracy: 0.8800\n",
      " 120/5349 [..............................] - ETA: 2s - loss: 0.2608 - accuracy: 0.8346\n",
      " 360/5349 [=>............................] - ETA: 2s - loss: 0.2582 - accuracy: 0.8396\n",
      " 598/5349 [==>...........................] - ETA: 1s - loss: 0.2585 - accuracy: 0.8385\n",
      " 815/5349 [===>..........................] - ETA: 1s - loss: 0.2573 - accuracy: 0.8392\n",
      "1052/5349 [====>.........................] - ETA: 1s - loss: 0.2562 - accuracy: 0.8402\n",
      "1276/5349 [======>.......................] - ETA: 1s - loss: 0.2555 - accuracy: 0.8402\n",
      "1512/5349 [=======>......................] - ETA: 1s - loss: 0.2548 - accuracy: 0.8404\n",
      "1711/5349 [========>.....................] - ETA: 1s - loss: 0.2541 - accuracy: 0.8403\n",
      "1944/5349 [=========>....................] - ETA: 1s - loss: 0.2536 - accuracy: 0.8403\n",
      "2172/5349 [===========>..................] - ETA: 1s - loss: 0.2527 - accuracy: 0.8408\n",
      "2384/5349 [============>.................] - ETA: 1s - loss: 0.2521 - accuracy: 0.8415\n",
      "2667/5349 [=============>................] - ETA: 1s - loss: 0.2510 - accuracy: 0.8425\n",
      "2852/5349 [==============>...............] - ETA: 1s - loss: 0.2506 - accuracy: 0.8430\n",
      "3043/5349 [================>.............] - ETA: 1s - loss: 0.2503 - accuracy: 0.8434\n",
      "3223/5349 [=================>............] - ETA: 0s - loss: 0.2498 - accuracy: 0.8439\n",
      "3425/5349 [==================>...........] - ETA: 0s - loss: 0.2493 - accuracy: 0.8446\n",
      "3627/5349 [===================>..........] - ETA: 0s - loss: 0.2487 - accuracy: 0.8453\n",
      "3819/5349 [====================>.........] - ETA: 0s - loss: 0.2482 - accuracy: 0.8457\n",
      "4016/5349 [=====================>........] - ETA: 0s - loss: 0.2478 - accuracy: 0.8462\n",
      "4136/5349 [======================>.......] - ETA: 0s - loss: 0.2475 - accuracy: 0.8464\n",
      "4200/5349 [======================>.......] - ETA: 0s - loss: 0.2474 - accuracy: 0.8466\n",
      "4391/5349 [=======================>......] - ETA: 0s - loss: 0.2467 - accuracy: 0.8471\n",
      "4595/5349 [========================>.....] - ETA: 0s - loss: 0.2461 - accuracy: 0.8476\n",
      "4789/5349 [=========================>....] - ETA: 0s - loss: 0.2457 - accuracy: 0.8479\n",
      "5020/5349 [===========================>..] - ETA: 0s - loss: 0.2450 - accuracy: 0.8484\n",
      "5246/5349 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.8489\n",
      "5349/5349 [==============================] - 4s 661us/step - loss: 0.2442 - accuracy: 0.8490 - val_loss: 0.2308 - val_accuracy: 0.8570\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 12/20\n",
      " 113/5349 [..............................] - ETA: 2s - loss: 0.2329 - accuracy: 0.8573\n",
      " 346/5349 [>.............................] - ETA: 2s - loss: 0.2333 - accuracy: 0.8544\n",
      " 583/5349 [==>...........................] - ETA: 2s - loss: 0.2317 - accuracy: 0.8554\n",
      " 807/5349 [===>..........................] - ETA: 1s - loss: 0.2298 - accuracy: 0.8578\n",
      "1046/5349 [====>.........................] - ETA: 1s - loss: 0.2295 - accuracy: 0.8574\n",
      "1162/5349 [=====>........................] - ETA: 1s - loss: 0.2293 - accuracy: 0.8574\n",
      "1372/5349 [======>.......................] - ETA: 1s - loss: 0.2283 - accuracy: 0.8585\n",
      "1612/5349 [========>.....................] - ETA: 1s - loss: 0.2283 - accuracy: 0.8582\n",
      "1831/5349 [=========>....................] - ETA: 1s - loss: 0.2273 - accuracy: 0.8590\n",
      "2071/5349 [==========>...................] - ETA: 1s - loss: 0.2267 - accuracy: 0.8597\n",
      "2297/5349 [===========>..................] - ETA: 1s - loss: 0.2264 - accuracy: 0.8603\n",
      "2494/5349 [============>.................] - ETA: 1s - loss: 0.2261 - accuracy: 0.8606\n",
      "2720/5349 [==============>...............] - ETA: 1s - loss: 0.2257 - accuracy: 0.8613\n",
      "2945/5349 [===============>..............] - ETA: 1s - loss: 0.2254 - accuracy: 0.8618\n",
      "3149/5349 [================>.............] - ETA: 0s - loss: 0.2250 - accuracy: 0.8623\n",
      "3385/5349 [=================>............] - ETA: 0s - loss: 0.2245 - accuracy: 0.8628\n",
      "3612/5349 [===================>..........] - ETA: 0s - loss: 0.2243 - accuracy: 0.8631\n",
      "3951/5349 [=====================>........] - ETA: 0s - loss: 0.2238 - accuracy: 0.8635\n",
      "4169/5349 [======================>.......] - ETA: 0s - loss: 0.2232 - accuracy: 0.8641\n",
      "4407/5349 [=======================>......] - ETA: 0s - loss: 0.2229 - accuracy: 0.8647\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.2225 - accuracy: 0.8650\n",
      "4867/5349 [==========================>...] - ETA: 0s - loss: 0.2223 - accuracy: 0.8654\n",
      "5067/5349 [===========================>..] - ETA: 0s - loss: 0.2219 - accuracy: 0.8659\n",
      "5282/5349 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.8665\n",
      "5349/5349 [==============================] - 3s 616us/step - loss: 0.2213 - accuracy: 0.8666 - val_loss: 0.2133 - val_accuracy: 0.8782\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.2082 - accuracy: 0.8700\n",
      " 238/5349 [>.............................] - ETA: 2s - loss: 0.2137 - accuracy: 0.8764\n",
      " 475/5349 [=>............................] - ETA: 2s - loss: 0.2120 - accuracy: 0.8789\n",
      " 701/5349 [==>...........................] - ETA: 1s - loss: 0.2118 - accuracy: 0.8798\n",
      " 940/5349 [====>.........................] - ETA: 1s - loss: 0.2111 - accuracy: 0.8815\n",
      "1159/5349 [=====>........................] - ETA: 1s - loss: 0.2115 - accuracy: 0.8819\n",
      "1391/5349 [======>.......................] - ETA: 1s - loss: 0.2118 - accuracy: 0.8824\n",
      "1738/5349 [========>.....................] - ETA: 1s - loss: 0.2115 - accuracy: 0.8836\n",
      "1977/5349 [==========>...................] - ETA: 1s - loss: 0.2112 - accuracy: 0.8844\n",
      "2181/5349 [===========>..................] - ETA: 1s - loss: 0.2109 - accuracy: 0.8848\n",
      "2414/5349 [============>.................] - ETA: 1s - loss: 0.2107 - accuracy: 0.8849\n",
      "2618/5349 [=============>................] - ETA: 1s - loss: 0.2106 - accuracy: 0.8851\n",
      "2855/5349 [===============>..............] - ETA: 1s - loss: 0.2105 - accuracy: 0.8853\n",
      "3073/5349 [================>.............] - ETA: 1s - loss: 0.2099 - accuracy: 0.8860\n",
      "3309/5349 [=================>............] - ETA: 0s - loss: 0.2097 - accuracy: 0.8862\n",
      "3653/5349 [===================>..........] - ETA: 0s - loss: 0.2093 - accuracy: 0.8869\n",
      "3896/5349 [====================>.........] - ETA: 0s - loss: 0.2092 - accuracy: 0.8870\n",
      "4129/5349 [======================>.......] - ETA: 0s - loss: 0.2088 - accuracy: 0.8875\n",
      "4365/5349 [=======================>......] - ETA: 0s - loss: 0.2087 - accuracy: 0.8878\n",
      "4586/5349 [========================>.....] - ETA: 0s - loss: 0.2085 - accuracy: 0.8881\n",
      "4826/5349 [==========================>...] - ETA: 0s - loss: 0.2082 - accuracy: 0.8884\n",
      "5040/5349 [===========================>..] - ETA: 0s - loss: 0.2079 - accuracy: 0.8886\n",
      "5275/5349 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.8887\n",
      "5349/5349 [==============================] - 3s 603us/step - loss: 0.2078 - accuracy: 0.8887 - val_loss: 0.2031 - val_accuracy: 0.8945\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1851 - accuracy: 0.8700\n",
      " 121/5349 [..............................] - ETA: 2s - loss: 0.2063 - accuracy: 0.8917\n",
      " 360/5349 [=>............................] - ETA: 2s - loss: 0.2057 - accuracy: 0.8921\n",
      " 600/5349 [==>...........................] - ETA: 1s - loss: 0.2047 - accuracy: 0.8939\n",
      " 817/5349 [===>..........................] - ETA: 1s - loss: 0.2040 - accuracy: 0.8956\n",
      "1056/5349 [====>.........................] - ETA: 1s - loss: 0.2037 - accuracy: 0.8970\n",
      "1283/5349 [======>.......................] - ETA: 1s - loss: 0.2031 - accuracy: 0.8980\n",
      "1524/5349 [=======>......................] - ETA: 1s - loss: 0.2031 - accuracy: 0.8982\n",
      "1755/5349 [========>.....................] - ETA: 1s - loss: 0.2036 - accuracy: 0.8979\n",
      "1958/5349 [=========>....................] - ETA: 1s - loss: 0.2034 - accuracy: 0.8980\n",
      "2129/5349 [==========>...................] - ETA: 1s - loss: 0.2032 - accuracy: 0.8981\n",
      "2222/5349 [===========>..................] - ETA: 1s - loss: 0.2030 - accuracy: 0.8982\n",
      "2410/5349 [============>.................] - ETA: 1s - loss: 0.2029 - accuracy: 0.8982\n",
      "2596/5349 [=============>................] - ETA: 1s - loss: 0.2028 - accuracy: 0.8982\n",
      "2801/5349 [==============>...............] - ETA: 1s - loss: 0.2026 - accuracy: 0.8985\n",
      "2994/5349 [===============>..............] - ETA: 1s - loss: 0.2024 - accuracy: 0.8986\n",
      "3203/5349 [================>.............] - ETA: 1s - loss: 0.2023 - accuracy: 0.8986\n",
      "3380/5349 [=================>............] - ETA: 0s - loss: 0.2019 - accuracy: 0.8988\n",
      "3568/5349 [===================>..........] - ETA: 0s - loss: 0.2016 - accuracy: 0.8989\n",
      "3652/5349 [===================>..........] - ETA: 0s - loss: 0.2015 - accuracy: 0.8990\n",
      "3829/5349 [====================>.........] - ETA: 0s - loss: 0.2012 - accuracy: 0.8992\n",
      "3942/5349 [=====================>........] - ETA: 0s - loss: 0.2010 - accuracy: 0.8993\n",
      "4138/5349 [======================>.......] - ETA: 0s - loss: 0.2009 - accuracy: 0.8994\n",
      "4325/5349 [=======================>......] - ETA: 0s - loss: 0.2007 - accuracy: 0.8995\n",
      "4493/5349 [========================>.....] - ETA: 0s - loss: 0.2006 - accuracy: 0.8997\n",
      "4713/5349 [=========================>....] - ETA: 0s - loss: 0.2004 - accuracy: 0.8998\n",
      "4830/5349 [==========================>...] - ETA: 0s - loss: 0.2003 - accuracy: 0.8999\n",
      "5057/5349 [===========================>..] - ETA: 0s - loss: 0.2000 - accuracy: 0.9000\n",
      "5290/5349 [============================>.] - ETA: 0s - loss: 0.1999 - accuracy: 0.9001\n",
      "5349/5349 [==============================] - 4s 667us/step - loss: 0.1999 - accuracy: 0.9001 - val_loss: 0.1969 - val_accuracy: 0.9020\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 15/20\n",
      " 118/5349 [..............................] - ETA: 2s - loss: 0.1963 - accuracy: 0.9021\n",
      " 351/5349 [>.............................] - ETA: 2s - loss: 0.1974 - accuracy: 0.9020\n",
      " 587/5349 [==>...........................] - ETA: 2s - loss: 0.1964 - accuracy: 0.9026\n",
      " 812/5349 [===>..........................] - ETA: 1s - loss: 0.1961 - accuracy: 0.9023\n",
      "1046/5349 [====>.........................] - ETA: 1s - loss: 0.1965 - accuracy: 0.9024\n",
      "1164/5349 [=====>........................] - ETA: 1s - loss: 0.1964 - accuracy: 0.9021\n",
      "1384/5349 [======>.......................] - ETA: 1s - loss: 0.1958 - accuracy: 0.9025\n",
      "1620/5349 [========>.....................] - ETA: 1s - loss: 0.1958 - accuracy: 0.9021\n",
      "1843/5349 [=========>....................] - ETA: 1s - loss: 0.1959 - accuracy: 0.9019\n",
      "2079/5349 [==========>...................] - ETA: 1s - loss: 0.1953 - accuracy: 0.9021\n",
      "2239/5349 [===========>..................] - ETA: 1s - loss: 0.1953 - accuracy: 0.9020\n",
      "2455/5349 [============>.................] - ETA: 1s - loss: 0.1952 - accuracy: 0.9022\n",
      "2686/5349 [==============>...............] - ETA: 1s - loss: 0.1951 - accuracy: 0.9023\n",
      "2916/5349 [===============>..............] - ETA: 1s - loss: 0.1950 - accuracy: 0.9023\n",
      "3146/5349 [================>.............] - ETA: 0s - loss: 0.1949 - accuracy: 0.9025\n",
      "3498/5349 [==================>...........] - ETA: 0s - loss: 0.1951 - accuracy: 0.9023\n",
      "3719/5349 [===================>..........] - ETA: 0s - loss: 0.1952 - accuracy: 0.9021\n",
      "3937/5349 [=====================>........] - ETA: 0s - loss: 0.1950 - accuracy: 0.9021\n",
      "4157/5349 [======================>.......] - ETA: 0s - loss: 0.1951 - accuracy: 0.9019\n",
      "4396/5349 [=======================>......] - ETA: 0s - loss: 0.1952 - accuracy: 0.9019\n",
      "4627/5349 [========================>.....] - ETA: 0s - loss: 0.1951 - accuracy: 0.9019\n",
      "4861/5349 [==========================>...] - ETA: 0s - loss: 0.1949 - accuracy: 0.9021\n",
      "5064/5349 [===========================>..] - ETA: 0s - loss: 0.1948 - accuracy: 0.9022\n",
      "5284/5349 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9021\n",
      "5349/5349 [==============================] - 3s 612us/step - loss: 0.1948 - accuracy: 0.9021 - val_loss: 0.1927 - val_accuracy: 0.9024\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1864 - accuracy: 0.9000\n",
      " 234/5349 [>.............................] - ETA: 2s - loss: 0.1937 - accuracy: 0.9008\n",
      " 355/5349 [>.............................] - ETA: 2s - loss: 0.1933 - accuracy: 0.9011\n",
      " 589/5349 [==>...........................] - ETA: 2s - loss: 0.1932 - accuracy: 0.9013\n",
      " 815/5349 [===>..........................] - ETA: 1s - loss: 0.1930 - accuracy: 0.9020\n",
      "1056/5349 [====>.........................] - ETA: 1s - loss: 0.1934 - accuracy: 0.9016\n",
      "1261/5349 [======>.......................] - ETA: 1s - loss: 0.1928 - accuracy: 0.9020\n",
      "1495/5349 [=======>......................] - ETA: 1s - loss: 0.1929 - accuracy: 0.9017\n",
      "1725/5349 [========>.....................] - ETA: 1s - loss: 0.1932 - accuracy: 0.9013\n",
      "1952/5349 [=========>....................] - ETA: 1s - loss: 0.1931 - accuracy: 0.9012\n",
      "2183/5349 [===========>..................] - ETA: 1s - loss: 0.1927 - accuracy: 0.9018\n",
      "2418/5349 [============>.................] - ETA: 1s - loss: 0.1926 - accuracy: 0.9017\n",
      "2645/5349 [=============>................] - ETA: 1s - loss: 0.1927 - accuracy: 0.9016\n",
      "3002/5349 [===============>..............] - ETA: 1s - loss: 0.1928 - accuracy: 0.9016\n",
      "3233/5349 [=================>............] - ETA: 0s - loss: 0.1925 - accuracy: 0.9017\n",
      "3463/5349 [==================>...........] - ETA: 0s - loss: 0.1922 - accuracy: 0.9019\n",
      "3688/5349 [===================>..........] - ETA: 0s - loss: 0.1919 - accuracy: 0.9020\n",
      "3923/5349 [=====================>........] - ETA: 0s - loss: 0.1919 - accuracy: 0.9022\n",
      "4138/5349 [======================>.......] - ETA: 0s - loss: 0.1916 - accuracy: 0.9024\n",
      "4377/5349 [=======================>......] - ETA: 0s - loss: 0.1914 - accuracy: 0.9024\n",
      "4602/5349 [========================>.....] - ETA: 0s - loss: 0.1913 - accuracy: 0.9025\n",
      "4841/5349 [==========================>...] - ETA: 0s - loss: 0.1913 - accuracy: 0.9024\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.1913 - accuracy: 0.9023\n",
      "5313/5349 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9023\n",
      "5349/5349 [==============================] - 3s 600us/step - loss: 0.1913 - accuracy: 0.9023 - val_loss: 0.1897 - val_accuracy: 0.9027\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 17/20\n",
      " 118/5349 [..............................] - ETA: 2s - loss: 0.1874 - accuracy: 0.9022\n",
      " 359/5349 [=>............................] - ETA: 2s - loss: 0.1893 - accuracy: 0.9025\n",
      " 597/5349 [==>...........................] - ETA: 2s - loss: 0.1909 - accuracy: 0.9008\n",
      " 820/5349 [===>..........................] - ETA: 1s - loss: 0.1912 - accuracy: 0.9011\n",
      "1170/5349 [=====>........................] - ETA: 1s - loss: 0.1907 - accuracy: 0.9019\n",
      "1401/5349 [======>.......................] - ETA: 1s - loss: 0.1905 - accuracy: 0.9020\n",
      "1619/5349 [========>.....................] - ETA: 1s - loss: 0.1909 - accuracy: 0.9016\n",
      "1788/5349 [=========>....................] - ETA: 1s - loss: 0.1908 - accuracy: 0.9015\n",
      "1976/5349 [==========>...................] - ETA: 1s - loss: 0.1905 - accuracy: 0.9019\n",
      "2163/5349 [===========>..................] - ETA: 1s - loss: 0.1901 - accuracy: 0.9021\n",
      "2344/5349 [============>.................] - ETA: 1s - loss: 0.1900 - accuracy: 0.9022\n",
      "2527/5349 [=============>................] - ETA: 1s - loss: 0.1900 - accuracy: 0.9021\n",
      "2629/5349 [=============>................] - ETA: 1s - loss: 0.1898 - accuracy: 0.9022\n",
      "2818/5349 [==============>...............] - ETA: 1s - loss: 0.1898 - accuracy: 0.9022\n",
      "3020/5349 [===============>..............] - ETA: 1s - loss: 0.1894 - accuracy: 0.9024\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1893 - accuracy: 0.9024\n",
      "3363/5349 [=================>............] - ETA: 0s - loss: 0.1893 - accuracy: 0.9024\n",
      "3516/5349 [==================>...........] - ETA: 0s - loss: 0.1891 - accuracy: 0.9026\n",
      "3682/5349 [===================>..........] - ETA: 0s - loss: 0.1889 - accuracy: 0.9027\n",
      "3986/5349 [=====================>........] - ETA: 0s - loss: 0.1887 - accuracy: 0.9027\n",
      "4224/5349 [======================>.......] - ETA: 0s - loss: 0.1888 - accuracy: 0.9026\n",
      "4407/5349 [=======================>......] - ETA: 0s - loss: 0.1889 - accuracy: 0.9024\n",
      "4555/5349 [========================>.....] - ETA: 0s - loss: 0.1889 - accuracy: 0.9024\n",
      "4734/5349 [=========================>....] - ETA: 0s - loss: 0.1887 - accuracy: 0.9026\n",
      "4909/5349 [==========================>...] - ETA: 0s - loss: 0.1887 - accuracy: 0.9026\n",
      "5129/5349 [===========================>..] - ETA: 0s - loss: 0.1887 - accuracy: 0.9026\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9026\n",
      "5349/5349 [==============================] - 4s 687us/step - loss: 0.1886 - accuracy: 0.9026 - val_loss: 0.1874 - val_accuracy: 0.9029\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2113 - accuracy: 0.8900\n",
      " 232/5349 [>.............................] - ETA: 2s - loss: 0.1845 - accuracy: 0.9043\n",
      " 467/5349 [=>............................] - ETA: 2s - loss: 0.1862 - accuracy: 0.9031\n",
      " 694/5349 [==>...........................] - ETA: 2s - loss: 0.1865 - accuracy: 0.9032\n",
      " 929/5349 [====>.........................] - ETA: 1s - loss: 0.1857 - accuracy: 0.9038\n",
      "1156/5349 [=====>........................] - ETA: 1s - loss: 0.1865 - accuracy: 0.9028\n",
      "1392/5349 [======>.......................] - ETA: 1s - loss: 0.1867 - accuracy: 0.9027\n",
      "1563/5349 [=======>......................] - ETA: 1s - loss: 0.1870 - accuracy: 0.9025\n",
      "1797/5349 [=========>....................] - ETA: 1s - loss: 0.1871 - accuracy: 0.9027\n",
      "2021/5349 [==========>...................] - ETA: 1s - loss: 0.1871 - accuracy: 0.9026\n",
      "2369/5349 [============>.................] - ETA: 1s - loss: 0.1872 - accuracy: 0.9022\n",
      "2590/5349 [=============>................] - ETA: 1s - loss: 0.1874 - accuracy: 0.9022\n",
      "2824/5349 [==============>...............] - ETA: 1s - loss: 0.1873 - accuracy: 0.9022\n",
      "3050/5349 [================>.............] - ETA: 1s - loss: 0.1874 - accuracy: 0.9023\n",
      "3284/5349 [=================>............] - ETA: 0s - loss: 0.1870 - accuracy: 0.9027\n",
      "3497/5349 [==================>...........] - ETA: 0s - loss: 0.1869 - accuracy: 0.9027\n",
      "3719/5349 [===================>..........] - ETA: 0s - loss: 0.1867 - accuracy: 0.9026\n",
      "3945/5349 [=====================>........] - ETA: 0s - loss: 0.1867 - accuracy: 0.9026\n",
      "4177/5349 [======================>.......] - ETA: 0s - loss: 0.1868 - accuracy: 0.9026\n",
      "4384/5349 [=======================>......] - ETA: 0s - loss: 0.1869 - accuracy: 0.9026\n",
      "4618/5349 [========================>.....] - ETA: 0s - loss: 0.1867 - accuracy: 0.9026\n",
      "4955/5349 [==========================>...] - ETA: 0s - loss: 0.1868 - accuracy: 0.9025\n",
      "5175/5349 [============================>.] - ETA: 0s - loss: 0.1867 - accuracy: 0.9026\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9027\n",
      "5349/5349 [==============================] - 3s 612us/step - loss: 0.1865 - accuracy: 0.9027 - val_loss: 0.1854 - val_accuracy: 0.9031\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 19/20\n",
      " 119/5349 [..............................] - ETA: 2s - loss: 0.1820 - accuracy: 0.9054\n",
      " 357/5349 [=>............................] - ETA: 2s - loss: 0.1831 - accuracy: 0.9055\n",
      " 595/5349 [==>...........................] - ETA: 2s - loss: 0.1835 - accuracy: 0.9052\n",
      " 822/5349 [===>..........................] - ETA: 1s - loss: 0.1836 - accuracy: 0.9052\n",
      "1161/5349 [=====>........................] - ETA: 1s - loss: 0.1840 - accuracy: 0.9043\n",
      "1363/5349 [======>.......................] - ETA: 1s - loss: 0.1840 - accuracy: 0.9042\n",
      "1571/5349 [=======>......................] - ETA: 1s - loss: 0.1847 - accuracy: 0.9037\n",
      "1804/5349 [=========>....................] - ETA: 1s - loss: 0.1850 - accuracy: 0.9033\n",
      "2034/5349 [==========>...................] - ETA: 1s - loss: 0.1853 - accuracy: 0.9031\n",
      "2262/5349 [===========>..................] - ETA: 1s - loss: 0.1854 - accuracy: 0.9029\n",
      "2500/5349 [=============>................] - ETA: 1s - loss: 0.1855 - accuracy: 0.9028\n",
      "2727/5349 [==============>...............] - ETA: 1s - loss: 0.1854 - accuracy: 0.9027\n",
      "2968/5349 [===============>..............] - ETA: 1s - loss: 0.1856 - accuracy: 0.9026\n",
      "3194/5349 [================>.............] - ETA: 0s - loss: 0.1855 - accuracy: 0.9026\n",
      "3433/5349 [==================>...........] - ETA: 0s - loss: 0.1855 - accuracy: 0.9026\n",
      "3548/5349 [==================>...........] - ETA: 0s - loss: 0.1854 - accuracy: 0.9026\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.1853 - accuracy: 0.9027\n",
      "4017/5349 [=====================>........] - ETA: 0s - loss: 0.1853 - accuracy: 0.9028\n",
      "4229/5349 [======================>.......] - ETA: 0s - loss: 0.1853 - accuracy: 0.9027\n",
      "4460/5349 [========================>.....] - ETA: 0s - loss: 0.1851 - accuracy: 0.9028\n",
      "4690/5349 [=========================>....] - ETA: 0s - loss: 0.1850 - accuracy: 0.9029\n",
      "4928/5349 [==========================>...] - ETA: 0s - loss: 0.1848 - accuracy: 0.9030\n",
      "5158/5349 [===========================>..] - ETA: 0s - loss: 0.1847 - accuracy: 0.9031\n",
      "5277/5349 [============================>.] - ETA: 0s - loss: 0.1847 - accuracy: 0.9032\n",
      "5349/5349 [==============================] - 3s 605us/step - loss: 0.1847 - accuracy: 0.9031 - val_loss: 0.1838 - val_accuracy: 0.9035\n",
      "\u001B[36m(train_DNN pid=5750)\u001B[0m Epoch 20/20\n",
      " 118/5349 [..............................] - ETA: 2s - loss: 0.1897 - accuracy: 0.9002\n",
      " 237/5349 [>.............................] - ETA: 2s - loss: 0.1880 - accuracy: 0.9014\n",
      " 466/5349 [=>............................] - ETA: 2s - loss: 0.1850 - accuracy: 0.9027\n",
      " 702/5349 [==>...........................] - ETA: 1s - loss: 0.1849 - accuracy: 0.9030\n",
      " 928/5349 [====>.........................] - ETA: 1s - loss: 0.1844 - accuracy: 0.9033\n",
      "1133/5349 [=====>........................] - ETA: 1s - loss: 0.1840 - accuracy: 0.9036\n",
      "1295/5349 [======>.......................] - ETA: 1s - loss: 0.1835 - accuracy: 0.9039\n",
      "1484/5349 [=======>......................] - ETA: 1s - loss: 0.1834 - accuracy: 0.9041\n",
      "1658/5349 [========>.....................] - ETA: 1s - loss: 0.1839 - accuracy: 0.9037\n",
      "1837/5349 [=========>....................] - ETA: 1s - loss: 0.1838 - accuracy: 0.9035\n",
      "2027/5349 [==========>...................] - ETA: 1s - loss: 0.1833 - accuracy: 0.9040\n",
      "2130/5349 [==========>...................] - ETA: 1s - loss: 0.1832 - accuracy: 0.9040\n",
      "2316/5349 [===========>..................] - ETA: 1s - loss: 0.1830 - accuracy: 0.9040\n",
      "2486/5349 [============>.................] - ETA: 1s - loss: 0.1831 - accuracy: 0.9040\n",
      "2684/5349 [==============>...............] - ETA: 1s - loss: 0.1832 - accuracy: 0.9040\n",
      "2838/5349 [==============>...............] - ETA: 1s - loss: 0.1832 - accuracy: 0.9041\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1832 - accuracy: 0.9042\n",
      "3131/5349 [================>.............] - ETA: 1s - loss: 0.1832 - accuracy: 0.9041\n",
      "3315/5349 [=================>............] - ETA: 1s - loss: 0.1833 - accuracy: 0.9039\n",
      "3509/5349 [==================>...........] - ETA: 0s - loss: 0.1834 - accuracy: 0.9038\n",
      "3729/5349 [===================>..........] - ETA: 0s - loss: 0.1834 - accuracy: 0.9038\n",
      "4065/5349 [=====================>........] - ETA: 0s - loss: 0.1833 - accuracy: 0.9037\n",
      "4292/5349 [=======================>......] - ETA: 0s - loss: 0.1833 - accuracy: 0.9037\n",
      "4512/5349 [========================>.....] - ETA: 0s - loss: 0.1834 - accuracy: 0.9038\n",
      "4728/5349 [=========================>....] - ETA: 0s - loss: 0.1833 - accuracy: 0.9038\n",
      "4943/5349 [==========================>...] - ETA: 0s - loss: 0.1832 - accuracy: 0.9039\n",
      "5163/5349 [===========================>..] - ETA: 0s - loss: 0.1831 - accuracy: 0.9039\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9039\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 30:57 - loss: 0.8136 - accuracy: 0.1100\n",
      "  97/5349 [..............................] - ETA: 5s - loss: 0.4799 - accuracy: 0.8179\n",
      " 223/5349 [>.............................] - ETA: 4s - loss: 0.3627 - accuracy: 0.8717\n",
      " 379/5349 [=>............................] - ETA: 4s - loss: 0.3030 - accuracy: 0.8857\n",
      " 545/5349 [==>...........................] - ETA: 3s - loss: 0.2698 - accuracy: 0.8917\n",
      " 702/5349 [==>...........................] - ETA: 3s - loss: 0.2505 - accuracy: 0.8953\n",
      " 781/5349 [===>..........................] - ETA: 3s - loss: 0.2432 - accuracy: 0.8967\n",
      " 948/5349 [====>.........................] - ETA: 3s - loss: 0.2314 - accuracy: 0.8988\n",
      "1109/5349 [=====>........................] - ETA: 2s - loss: 0.2231 - accuracy: 0.9000\n",
      "1278/5349 [======>.......................] - ETA: 2s - loss: 0.2159 - accuracy: 0.9014\n",
      "1438/5349 [=======>......................] - ETA: 2s - loss: 0.2108 - accuracy: 0.9021\n",
      "1598/5349 [=======>......................] - ETA: 2s - loss: 0.2063 - accuracy: 0.9030\n",
      "1761/5349 [========>.....................] - ETA: 2s - loss: 0.2018 - accuracy: 0.9045\n",
      "1929/5349 [=========>....................] - ETA: 2s - loss: 0.1983 - accuracy: 0.9052\n",
      "2076/5349 [==========>...................] - ETA: 2s - loss: 0.1956 - accuracy: 0.9060\n",
      "2245/5349 [===========>..................] - ETA: 2s - loss: 0.1931 - accuracy: 0.9066\n",
      "2402/5349 [============>.................] - ETA: 1s - loss: 0.1909 - accuracy: 0.9069\n",
      "2571/5349 [=============>................] - ETA: 1s - loss: 0.1889 - accuracy: 0.9073\n",
      "2656/5349 [=============>................] - ETA: 1s - loss: 0.1878 - accuracy: 0.9076\n",
      "2818/5349 [==============>...............] - ETA: 1s - loss: 0.1860 - accuracy: 0.9080\n",
      "2987/5349 [===============>..............] - ETA: 1s - loss: 0.1845 - accuracy: 0.9085\n",
      "3143/5349 [================>.............] - ETA: 1s - loss: 0.1829 - accuracy: 0.9090\n",
      "3311/5349 [=================>............] - ETA: 1s - loss: 0.1817 - accuracy: 0.9092\n",
      "3473/5349 [==================>...........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9095\n",
      "3645/5349 [===================>..........] - ETA: 1s - loss: 0.1792 - accuracy: 0.9098\n",
      "3806/5349 [====================>.........] - ETA: 0s - loss: 0.1783 - accuracy: 0.9100\n",
      "3964/5349 [=====================>........] - ETA: 0s - loss: 0.1774 - accuracy: 0.9102\n",
      "4090/5349 [=====================>........] - ETA: 0s - loss: 0.1767 - accuracy: 0.9104\n",
      "4220/5349 [======================>.......] - ETA: 0s - loss: 0.1760 - accuracy: 0.9106\n",
      "4366/5349 [=======================>......] - ETA: 0s - loss: 0.1750 - accuracy: 0.9110\n",
      "4451/5349 [=======================>......] - ETA: 0s - loss: 0.1746 - accuracy: 0.9112\n",
      "4618/5349 [========================>.....] - ETA: 0s - loss: 0.1739 - accuracy: 0.9113\n",
      "4779/5349 [=========================>....] - ETA: 0s - loss: 0.1732 - accuracy: 0.9115\n",
      "4943/5349 [==========================>...] - ETA: 0s - loss: 0.1725 - accuracy: 0.9117\n",
      "5100/5349 [===========================>..] - ETA: 0s - loss: 0.1719 - accuracy: 0.9119\n",
      "5255/5349 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9121\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9121\n",
      "5349/5349 [==============================] - 5s 866us/step - loss: 0.1709 - accuracy: 0.9121 - val_loss: 0.1485 - val_accuracy: 0.9208\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1575 - accuracy: 0.9000\n",
      " 139/5349 [..............................] - ETA: 3s - loss: 0.1439 - accuracy: 0.9226\n",
      " 277/5349 [>.............................] - ETA: 3s - loss: 0.1471 - accuracy: 0.9201\n",
      " 419/5349 [=>............................] - ETA: 3s - loss: 0.1488 - accuracy: 0.9192\n",
      " 575/5349 [==>...........................] - ETA: 3s - loss: 0.1487 - accuracy: 0.9194\n",
      " 817/5349 [===>..........................] - ETA: 3s - loss: 0.1490 - accuracy: 0.9194\n",
      " 983/5349 [====>.........................] - ETA: 2s - loss: 0.1488 - accuracy: 0.9194\n",
      "1147/5349 [=====>........................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9187\n",
      "1310/5349 [======>.......................] - ETA: 2s - loss: 0.1492 - accuracy: 0.9189\n",
      "1465/5349 [=======>......................] - ETA: 2s - loss: 0.1489 - accuracy: 0.9192\n",
      "1609/5349 [========>.....................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9194\n",
      "1762/5349 [========>.....................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9193\n",
      "1907/5349 [=========>....................] - ETA: 2s - loss: 0.1487 - accuracy: 0.9190\n",
      "2064/5349 [==========>...................] - ETA: 2s - loss: 0.1482 - accuracy: 0.9194\n",
      "2217/5349 [===========>..................] - ETA: 2s - loss: 0.1481 - accuracy: 0.9194\n",
      "2377/5349 [============>.................] - ETA: 1s - loss: 0.1482 - accuracy: 0.9192\n",
      "2510/5349 [=============>................] - ETA: 1s - loss: 0.1483 - accuracy: 0.9193\n",
      "2744/5349 [==============>...............] - ETA: 1s - loss: 0.1479 - accuracy: 0.9195\n",
      "2899/5349 [===============>..............] - ETA: 1s - loss: 0.1481 - accuracy: 0.9193\n",
      "3055/5349 [================>.............] - ETA: 1s - loss: 0.1481 - accuracy: 0.9193\n",
      "3218/5349 [=================>............] - ETA: 1s - loss: 0.1478 - accuracy: 0.9195\n",
      "3382/5349 [=================>............] - ETA: 1s - loss: 0.1476 - accuracy: 0.9196\n",
      "3541/5349 [==================>...........] - ETA: 1s - loss: 0.1476 - accuracy: 0.9195\n",
      "3687/5349 [===================>..........] - ETA: 1s - loss: 0.1476 - accuracy: 0.9196\n",
      "3845/5349 [====================>.........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9196\n",
      "4000/5349 [=====================>........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9197\n",
      "4167/5349 [======================>.......] - ETA: 0s - loss: 0.1472 - accuracy: 0.9198\n",
      "4416/5349 [=======================>......] - ETA: 0s - loss: 0.1468 - accuracy: 0.9201\n",
      "4574/5349 [========================>.....] - ETA: 0s - loss: 0.1467 - accuracy: 0.9201\n",
      "4736/5349 [=========================>....] - ETA: 0s - loss: 0.1464 - accuracy: 0.9202\n",
      "4885/5349 [==========================>...] - ETA: 0s - loss: 0.1464 - accuracy: 0.9202\n",
      "5041/5349 [===========================>..] - ETA: 0s - loss: 0.1463 - accuracy: 0.9203\n",
      "5199/5349 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9204\n",
      "5276/5349 [============================>.] - ETA: 0s - loss: 0.1461 - accuracy: 0.9204\n",
      "5349/5349 [==============================] - 4s 817us/step - loss: 0.1460 - accuracy: 0.9205 - val_loss: 0.1401 - val_accuracy: 0.9253\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 3/20\n",
      "  80/5349 [..............................] - ETA: 3s - loss: 0.1489 - accuracy: 0.9155\n",
      " 244/5349 [>.............................] - ETA: 3s - loss: 0.1433 - accuracy: 0.9204\n",
      " 412/5349 [=>............................] - ETA: 3s - loss: 0.1433 - accuracy: 0.9206\n",
      " 576/5349 [==>...........................] - ETA: 2s - loss: 0.1420 - accuracy: 0.9220\n",
      " 741/5349 [===>..........................] - ETA: 2s - loss: 0.1413 - accuracy: 0.9229\n",
      " 875/5349 [===>..........................] - ETA: 2s - loss: 0.1405 - accuracy: 0.9239\n",
      "1034/5349 [====>.........................] - ETA: 2s - loss: 0.1411 - accuracy: 0.9236\n",
      "1142/5349 [=====>........................] - ETA: 2s - loss: 0.1408 - accuracy: 0.9240\n",
      "1245/5349 [=====>........................] - ETA: 2s - loss: 0.1404 - accuracy: 0.9242\n",
      "1357/5349 [======>.......................] - ETA: 2s - loss: 0.1403 - accuracy: 0.9244\n",
      "1468/5349 [=======>......................] - ETA: 2s - loss: 0.1405 - accuracy: 0.9242\n",
      "1598/5349 [=======>......................] - ETA: 2s - loss: 0.1403 - accuracy: 0.9240\n",
      "1736/5349 [========>.....................] - ETA: 2s - loss: 0.1404 - accuracy: 0.9240\n",
      "1874/5349 [=========>....................] - ETA: 2s - loss: 0.1400 - accuracy: 0.9244\n",
      "2039/5349 [==========>...................] - ETA: 2s - loss: 0.1397 - accuracy: 0.9246\n",
      "2141/5349 [===========>..................] - ETA: 2s - loss: 0.1398 - accuracy: 0.9244\n",
      "2279/5349 [===========>..................] - ETA: 2s - loss: 0.1396 - accuracy: 0.9245\n",
      "2401/5349 [============>.................] - ETA: 2s - loss: 0.1396 - accuracy: 0.9246\n",
      "2562/5349 [=============>................] - ETA: 2s - loss: 0.1392 - accuracy: 0.9249\n",
      "2721/5349 [==============>...............] - ETA: 1s - loss: 0.1392 - accuracy: 0.9248\n",
      "2881/5349 [===============>..............] - ETA: 1s - loss: 0.1388 - accuracy: 0.9250\n",
      "3041/5349 [================>.............] - ETA: 1s - loss: 0.1386 - accuracy: 0.9250\n",
      "3291/5349 [=================>............] - ETA: 1s - loss: 0.1384 - accuracy: 0.9252\n",
      "3451/5349 [==================>...........] - ETA: 1s - loss: 0.1382 - accuracy: 0.9253\n",
      "3617/5349 [===================>..........] - ETA: 1s - loss: 0.1379 - accuracy: 0.9255\n",
      "3774/5349 [====================>.........] - ETA: 1s - loss: 0.1379 - accuracy: 0.9255\n",
      "3943/5349 [=====================>........] - ETA: 1s - loss: 0.1378 - accuracy: 0.9255\n",
      "4103/5349 [======================>.......] - ETA: 0s - loss: 0.1377 - accuracy: 0.9256\n",
      "4267/5349 [======================>.......] - ETA: 0s - loss: 0.1377 - accuracy: 0.9257\n",
      "4426/5349 [=======================>......] - ETA: 0s - loss: 0.1375 - accuracy: 0.9258\n",
      "4592/5349 [========================>.....] - ETA: 0s - loss: 0.1376 - accuracy: 0.9258\n",
      "4743/5349 [=========================>....] - ETA: 0s - loss: 0.1373 - accuracy: 0.9260\n",
      "4911/5349 [==========================>...] - ETA: 0s - loss: 0.1372 - accuracy: 0.9261\n",
      "4992/5349 [==========================>...] - ETA: 0s - loss: 0.1372 - accuracy: 0.9261\n",
      "5151/5349 [===========================>..] - ETA: 0s - loss: 0.1370 - accuracy: 0.9262\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9263\n",
      "5349/5349 [==============================] - 5s 872us/step - loss: 0.1368 - accuracy: 0.9263 - val_loss: 0.1314 - val_accuracy: 0.9289\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1986 - accuracy: 0.8900\n",
      " 230/5349 [>.............................] - ETA: 3s - loss: 0.1304 - accuracy: 0.9307\n",
      " 378/5349 [=>............................] - ETA: 3s - loss: 0.1315 - accuracy: 0.9307\n",
      " 534/5349 [=>............................] - ETA: 3s - loss: 0.1313 - accuracy: 0.9306\n",
      " 702/5349 [==>...........................] - ETA: 2s - loss: 0.1313 - accuracy: 0.9301\n",
      " 855/5349 [===>..........................] - ETA: 2s - loss: 0.1309 - accuracy: 0.9301\n",
      "1019/5349 [====>.........................] - ETA: 2s - loss: 0.1311 - accuracy: 0.9301\n",
      "1177/5349 [=====>........................] - ETA: 2s - loss: 0.1313 - accuracy: 0.9300\n",
      "1346/5349 [======>.......................] - ETA: 2s - loss: 0.1314 - accuracy: 0.9297\n",
      "1492/5349 [=======>......................] - ETA: 2s - loss: 0.1314 - accuracy: 0.9295\n",
      "1737/5349 [========>.....................] - ETA: 2s - loss: 0.1310 - accuracy: 0.9292\n",
      "1904/5349 [=========>....................] - ETA: 2s - loss: 0.1309 - accuracy: 0.9293\n",
      "2060/5349 [==========>...................] - ETA: 2s - loss: 0.1308 - accuracy: 0.9295\n",
      "2227/5349 [===========>..................] - ETA: 1s - loss: 0.1305 - accuracy: 0.9298\n",
      "2393/5349 [============>.................] - ETA: 1s - loss: 0.1306 - accuracy: 0.9298\n",
      "2556/5349 [=============>................] - ETA: 1s - loss: 0.1308 - accuracy: 0.9295\n",
      "2725/5349 [==============>...............] - ETA: 1s - loss: 0.1304 - accuracy: 0.9298\n",
      "2889/5349 [===============>..............] - ETA: 1s - loss: 0.1303 - accuracy: 0.9299\n",
      "3057/5349 [================>.............] - ETA: 1s - loss: 0.1303 - accuracy: 0.9299\n",
      "3197/5349 [================>.............] - ETA: 1s - loss: 0.1302 - accuracy: 0.9299\n",
      "3360/5349 [=================>............] - ETA: 1s - loss: 0.1301 - accuracy: 0.9300\n",
      "3440/5349 [==================>...........] - ETA: 1s - loss: 0.1302 - accuracy: 0.9298\n",
      "3605/5349 [===================>..........] - ETA: 1s - loss: 0.1302 - accuracy: 0.9299\n",
      "3770/5349 [====================>.........] - ETA: 0s - loss: 0.1304 - accuracy: 0.9298\n",
      "3932/5349 [=====================>........] - ETA: 0s - loss: 0.1305 - accuracy: 0.9297\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.1304 - accuracy: 0.9297\n",
      "4264/5349 [======================>.......] - ETA: 0s - loss: 0.1303 - accuracy: 0.9298\n",
      "4432/5349 [=======================>......] - ETA: 0s - loss: 0.1303 - accuracy: 0.9297\n",
      "4581/5349 [========================>.....] - ETA: 0s - loss: 0.1301 - accuracy: 0.9299\n",
      "4750/5349 [=========================>....] - ETA: 0s - loss: 0.1299 - accuracy: 0.9301\n",
      "4906/5349 [==========================>...] - ETA: 0s - loss: 0.1299 - accuracy: 0.9300\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.1296 - accuracy: 0.9301\n",
      "5235/5349 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9301\n",
      "5318/5349 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9302\n",
      "5349/5349 [==============================] - 4s 792us/step - loss: 0.1296 - accuracy: 0.9303 - val_loss: 0.1260 - val_accuracy: 0.9331\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1710 - accuracy: 0.9200\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1249 - accuracy: 0.9341\n",
      " 334/5349 [>.............................] - ETA: 3s - loss: 0.1248 - accuracy: 0.9343\n",
      " 491/5349 [=>............................] - ETA: 2s - loss: 0.1254 - accuracy: 0.9333\n",
      " 660/5349 [==>...........................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9330\n",
      " 823/5349 [===>..........................] - ETA: 2s - loss: 0.1249 - accuracy: 0.9332\n",
      " 993/5349 [====>.........................] - ETA: 2s - loss: 0.1252 - accuracy: 0.9331\n",
      "1151/5349 [=====>........................] - ETA: 2s - loss: 0.1257 - accuracy: 0.9321\n",
      "1311/5349 [======>.......................] - ETA: 2s - loss: 0.1259 - accuracy: 0.9318\n",
      "1477/5349 [=======>......................] - ETA: 2s - loss: 0.1259 - accuracy: 0.9317\n",
      "1645/5349 [========>.....................] - ETA: 2s - loss: 0.1257 - accuracy: 0.9317\n",
      "1727/5349 [========>.....................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9317\n",
      "1890/5349 [=========>....................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9318\n",
      "2057/5349 [==========>...................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9319\n",
      "2198/5349 [===========>..................] - ETA: 1s - loss: 0.1257 - accuracy: 0.9319\n",
      "2366/5349 [============>.................] - ETA: 1s - loss: 0.1258 - accuracy: 0.9319\n",
      "2527/5349 [=============>................] - ETA: 1s - loss: 0.1260 - accuracy: 0.9317\n",
      "2686/5349 [==============>...............] - ETA: 1s - loss: 0.1259 - accuracy: 0.9317\n",
      "2797/5349 [==============>...............] - ETA: 1s - loss: 0.1258 - accuracy: 0.9319\n",
      "2924/5349 [===============>..............] - ETA: 1s - loss: 0.1258 - accuracy: 0.9318\n",
      "3051/5349 [================>.............] - ETA: 1s - loss: 0.1258 - accuracy: 0.9318\n",
      "3259/5349 [=================>............] - ETA: 1s - loss: 0.1258 - accuracy: 0.9319\n",
      "3389/5349 [==================>...........] - ETA: 1s - loss: 0.1257 - accuracy: 0.9319\n",
      "3525/5349 [==================>...........] - ETA: 1s - loss: 0.1257 - accuracy: 0.9319\n",
      "3659/5349 [===================>..........] - ETA: 1s - loss: 0.1256 - accuracy: 0.9320\n",
      "3808/5349 [====================>.........] - ETA: 1s - loss: 0.1257 - accuracy: 0.9320\n",
      "3912/5349 [====================>.........] - ETA: 0s - loss: 0.1256 - accuracy: 0.9320\n",
      "4002/5349 [=====================>........] - ETA: 0s - loss: 0.1256 - accuracy: 0.9321\n",
      "4062/5349 [=====================>........] - ETA: 0s - loss: 0.1254 - accuracy: 0.9322\n",
      "4195/5349 [======================>.......] - ETA: 0s - loss: 0.1254 - accuracy: 0.9323\n",
      "4341/5349 [=======================>......] - ETA: 0s - loss: 0.1254 - accuracy: 0.9322\n",
      "4497/5349 [========================>.....] - ETA: 0s - loss: 0.1253 - accuracy: 0.9323\n",
      "4659/5349 [=========================>....] - ETA: 0s - loss: 0.1251 - accuracy: 0.9324\n",
      "4819/5349 [==========================>...] - ETA: 0s - loss: 0.1251 - accuracy: 0.9324\n",
      "4984/5349 [==========================>...] - ETA: 0s - loss: 0.1251 - accuracy: 0.9324\n",
      "5149/5349 [===========================>..] - ETA: 0s - loss: 0.1250 - accuracy: 0.9324\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9324\n",
      "5349/5349 [==============================] - 5s 849us/step - loss: 0.1251 - accuracy: 0.9324 - val_loss: 0.1377 - val_accuracy: 0.9245\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1249 - accuracy: 0.9300\n",
      " 159/5349 [..............................] - ETA: 3s - loss: 0.1209 - accuracy: 0.9360\n",
      " 325/5349 [>.............................] - ETA: 3s - loss: 0.1228 - accuracy: 0.9334\n",
      " 469/5349 [=>............................] - ETA: 3s - loss: 0.1222 - accuracy: 0.9343\n",
      " 637/5349 [==>...........................] - ETA: 2s - loss: 0.1216 - accuracy: 0.9348\n",
      " 799/5349 [===>..........................] - ETA: 2s - loss: 0.1212 - accuracy: 0.9349\n",
      " 965/5349 [====>.........................] - ETA: 2s - loss: 0.1211 - accuracy: 0.9350\n",
      "1104/5349 [=====>........................] - ETA: 2s - loss: 0.1216 - accuracy: 0.9345\n",
      "1258/5349 [======>.......................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9343\n",
      "1503/5349 [=======>......................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9343\n",
      "1672/5349 [========>.....................] - ETA: 2s - loss: 0.1216 - accuracy: 0.9345\n",
      "1836/5349 [=========>....................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9343\n",
      "2003/5349 [==========>...................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9343\n",
      "2159/5349 [===========>..................] - ETA: 2s - loss: 0.1220 - accuracy: 0.9343\n",
      "2316/5349 [===========>..................] - ETA: 1s - loss: 0.1221 - accuracy: 0.9343\n",
      "2382/5349 [============>.................] - ETA: 1s - loss: 0.1222 - accuracy: 0.9342\n",
      "2503/5349 [=============>................] - ETA: 1s - loss: 0.1224 - accuracy: 0.9341\n",
      "2532/5349 [=============>................] - ETA: 2s - loss: 0.1224 - accuracy: 0.9340\n",
      "2597/5349 [=============>................] - ETA: 2s - loss: 0.1224 - accuracy: 0.9340\n",
      "2666/5349 [=============>................] - ETA: 2s - loss: 0.1223 - accuracy: 0.9341\n",
      "2715/5349 [==============>...............] - ETA: 2s - loss: 0.1224 - accuracy: 0.9340\n",
      "2735/5349 [==============>...............] - ETA: 2s - loss: 0.1225 - accuracy: 0.9340\n",
      "2749/5349 [==============>...............] - ETA: 2s - loss: 0.1224 - accuracy: 0.9340\n",
      "2769/5349 [==============>...............] - ETA: 2s - loss: 0.1223 - accuracy: 0.9341\n",
      "2820/5349 [==============>...............] - ETA: 2s - loss: 0.1223 - accuracy: 0.9341\n",
      "2823/5349 [==============>...............] - ETA: 2s - loss: 0.1223 - accuracy: 0.9341\n",
      "2919/5349 [===============>..............] - ETA: 2s - loss: 0.1224 - accuracy: 0.9340\n",
      "3030/5349 [===============>..............] - ETA: 2s - loss: 0.1225 - accuracy: 0.9338\n",
      "3065/5349 [================>.............] - ETA: 2s - loss: 0.1225 - accuracy: 0.9338\n",
      "3183/5349 [================>.............] - ETA: 2s - loss: 0.1226 - accuracy: 0.9337\n",
      "3321/5349 [=================>............] - ETA: 1s - loss: 0.1225 - accuracy: 0.9338\n",
      "3410/5349 [==================>...........] - ETA: 1s - loss: 0.1224 - accuracy: 0.9338\n",
      "3552/5349 [==================>...........] - ETA: 1s - loss: 0.1223 - accuracy: 0.9338\n",
      "3753/5349 [====================>.........] - ETA: 1s - loss: 0.1223 - accuracy: 0.9339\n",
      "3900/5349 [====================>.........] - ETA: 1s - loss: 0.1221 - accuracy: 0.9339\n",
      "4030/5349 [=====================>........] - ETA: 1s - loss: 0.1221 - accuracy: 0.9339\n",
      "4180/5349 [======================>.......] - ETA: 1s - loss: 0.1221 - accuracy: 0.9339\n",
      "4349/5349 [=======================>......] - ETA: 0s - loss: 0.1219 - accuracy: 0.9340\n",
      "4495/5349 [========================>.....] - ETA: 0s - loss: 0.1221 - accuracy: 0.9339\n",
      "4576/5349 [========================>.....] - ETA: 0s - loss: 0.1222 - accuracy: 0.9338\n",
      "4703/5349 [=========================>....] - ETA: 0s - loss: 0.1224 - accuracy: 0.9337\n",
      "4841/5349 [==========================>...] - ETA: 0s - loss: 0.1225 - accuracy: 0.9337\n",
      "5058/5349 [===========================>..] - ETA: 0s - loss: 0.1225 - accuracy: 0.9336\n",
      "5199/5349 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9337\n",
      "5308/5349 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.9338\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1223 - accuracy: 0.9338 - val_loss: 0.1188 - val_accuracy: 0.9359\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1197 - accuracy: 0.9300\n",
      " 165/5349 [..............................] - ETA: 3s - loss: 0.1216 - accuracy: 0.9341\n",
      " 333/5349 [>.............................] - ETA: 3s - loss: 0.1230 - accuracy: 0.9333\n",
      " 456/5349 [=>............................] - ETA: 3s - loss: 0.1228 - accuracy: 0.9335\n",
      " 577/5349 [==>...........................] - ETA: 3s - loss: 0.1231 - accuracy: 0.9326\n",
      " 694/5349 [==>...........................] - ETA: 3s - loss: 0.1219 - accuracy: 0.9336\n",
      " 840/5349 [===>..........................] - ETA: 3s - loss: 0.1226 - accuracy: 0.9327\n",
      " 993/5349 [====>.........................] - ETA: 3s - loss: 0.1221 - accuracy: 0.9330\n",
      "1146/5349 [=====>........................] - ETA: 2s - loss: 0.1213 - accuracy: 0.9338\n",
      "1219/5349 [=====>........................] - ETA: 2s - loss: 0.1209 - accuracy: 0.9341\n",
      "1369/5349 [======>.......................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9346\n",
      "1527/5349 [=======>......................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9348\n",
      "1663/5349 [========>.....................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9349\n",
      "1816/5349 [=========>....................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9344\n",
      "1858/5349 [=========>....................] - ETA: 2s - loss: 0.1208 - accuracy: 0.9343\n",
      "1875/5349 [=========>....................] - ETA: 2s - loss: 0.1209 - accuracy: 0.9342\n",
      "1898/5349 [=========>....................] - ETA: 2s - loss: 0.1209 - accuracy: 0.9343\n",
      "1926/5349 [=========>....................] - ETA: 3s - loss: 0.1209 - accuracy: 0.9344\n",
      "1958/5349 [=========>....................] - ETA: 3s - loss: 0.1210 - accuracy: 0.9344\n",
      "1977/5349 [==========>...................] - ETA: 3s - loss: 0.1210 - accuracy: 0.9344\n",
      "2052/5349 [==========>...................] - ETA: 3s - loss: 0.1210 - accuracy: 0.9344\n",
      "2091/5349 [==========>...................] - ETA: 3s - loss: 0.1210 - accuracy: 0.9344\n",
      "2149/5349 [===========>..................] - ETA: 3s - loss: 0.1209 - accuracy: 0.9344\n",
      "2244/5349 [===========>..................] - ETA: 3s - loss: 0.1208 - accuracy: 0.9346\n",
      "2343/5349 [============>.................] - ETA: 3s - loss: 0.1206 - accuracy: 0.9349\n",
      "2489/5349 [============>.................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9347\n",
      "2645/5349 [=============>................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9346\n",
      "2809/5349 [==============>...............] - ETA: 2s - loss: 0.1206 - accuracy: 0.9345\n",
      "2892/5349 [===============>..............] - ETA: 2s - loss: 0.1206 - accuracy: 0.9345\n",
      "3050/5349 [================>.............] - ETA: 2s - loss: 0.1205 - accuracy: 0.9345\n",
      "3193/5349 [================>.............] - ETA: 1s - loss: 0.1206 - accuracy: 0.9345\n",
      "3323/5349 [=================>............] - ETA: 1s - loss: 0.1205 - accuracy: 0.9346\n",
      "3455/5349 [==================>...........] - ETA: 1s - loss: 0.1205 - accuracy: 0.9344\n",
      "3601/5349 [===================>..........] - ETA: 1s - loss: 0.1203 - accuracy: 0.9345\n",
      "3748/5349 [====================>.........] - ETA: 1s - loss: 0.1204 - accuracy: 0.9346\n",
      "3902/5349 [====================>.........] - ETA: 1s - loss: 0.1204 - accuracy: 0.9347\n",
      "4046/5349 [=====================>........] - ETA: 1s - loss: 0.1203 - accuracy: 0.9346\n",
      "4202/5349 [======================>.......] - ETA: 0s - loss: 0.1204 - accuracy: 0.9346\n",
      "4274/5349 [======================>.......] - ETA: 0s - loss: 0.1204 - accuracy: 0.9346\n",
      "4427/5349 [=======================>......] - ETA: 0s - loss: 0.1205 - accuracy: 0.9345\n",
      "4561/5349 [========================>.....] - ETA: 0s - loss: 0.1205 - accuracy: 0.9345\n",
      "4704/5349 [=========================>....] - ETA: 0s - loss: 0.1205 - accuracy: 0.9345\n",
      "4851/5349 [==========================>...] - ETA: 0s - loss: 0.1205 - accuracy: 0.9345\n",
      "4986/5349 [==========================>...] - ETA: 0s - loss: 0.1206 - accuracy: 0.9344\n",
      "5100/5349 [===========================>..] - ETA: 0s - loss: 0.1205 - accuracy: 0.9345\n",
      "5228/5349 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9345\n",
      "5299/5349 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9345\n",
      "5349/5349 [==============================] - 5s 1ms/step - loss: 0.1205 - accuracy: 0.9345 - val_loss: 0.1171 - val_accuracy: 0.9369\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1034 - accuracy: 0.9400\n",
      " 118/5349 [..............................] - ETA: 4s - loss: 0.1217 - accuracy: 0.9305\n",
      " 156/5349 [..............................] - ETA: 6s - loss: 0.1222 - accuracy: 0.9313\n",
      " 205/5349 [>.............................] - ETA: 7s - loss: 0.1216 - accuracy: 0.9317\n",
      " 267/5349 [>.............................] - ETA: 7s - loss: 0.1209 - accuracy: 0.9330\n",
      " 327/5349 [>.............................] - ETA: 7s - loss: 0.1203 - accuracy: 0.9329\n",
      " 389/5349 [=>............................] - ETA: 7s - loss: 0.1201 - accuracy: 0.9335\n",
      " 459/5349 [=>............................] - ETA: 7s - loss: 0.1203 - accuracy: 0.9339\n",
      " 534/5349 [=>............................] - ETA: 7s - loss: 0.1199 - accuracy: 0.9340\n",
      " 558/5349 [==>...........................] - ETA: 7s - loss: 0.1194 - accuracy: 0.9342\n",
      " 638/5349 [==>...........................] - ETA: 7s - loss: 0.1195 - accuracy: 0.9344\n",
      " 757/5349 [===>..........................] - ETA: 6s - loss: 0.1197 - accuracy: 0.9343\n",
      " 859/5349 [===>..........................] - ETA: 6s - loss: 0.1200 - accuracy: 0.9344\n",
      " 937/5349 [====>.........................] - ETA: 5s - loss: 0.1196 - accuracy: 0.9347\n",
      "1021/5349 [====>.........................] - ETA: 5s - loss: 0.1193 - accuracy: 0.9355\n",
      "1085/5349 [=====>........................] - ETA: 5s - loss: 0.1188 - accuracy: 0.9358\n",
      "1190/5349 [=====>........................] - ETA: 5s - loss: 0.1185 - accuracy: 0.9359\n",
      "1292/5349 [======>.......................] - ETA: 5s - loss: 0.1185 - accuracy: 0.9358\n",
      "1403/5349 [======>.......................] - ETA: 5s - loss: 0.1181 - accuracy: 0.9361\n",
      "1546/5349 [=======>......................] - ETA: 4s - loss: 0.1186 - accuracy: 0.9359\n",
      "1694/5349 [========>.....................] - ETA: 4s - loss: 0.1189 - accuracy: 0.9355\n",
      "1835/5349 [=========>....................] - ETA: 4s - loss: 0.1186 - accuracy: 0.9359\n",
      "1982/5349 [==========>...................] - ETA: 3s - loss: 0.1183 - accuracy: 0.9360\n",
      "2059/5349 [==========>...................] - ETA: 3s - loss: 0.1185 - accuracy: 0.9358\n",
      "2210/5349 [===========>..................] - ETA: 3s - loss: 0.1185 - accuracy: 0.9358\n",
      "2361/5349 [============>.................] - ETA: 3s - loss: 0.1182 - accuracy: 0.9361\n",
      "2513/5349 [=============>................] - ETA: 2s - loss: 0.1183 - accuracy: 0.9360\n",
      "2662/5349 [=============>................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9360\n",
      "2817/5349 [==============>...............] - ETA: 2s - loss: 0.1185 - accuracy: 0.9359\n",
      "2953/5349 [===============>..............] - ETA: 2s - loss: 0.1187 - accuracy: 0.9357\n",
      "3099/5349 [================>.............] - ETA: 2s - loss: 0.1187 - accuracy: 0.9357\n",
      "3252/5349 [=================>............] - ETA: 1s - loss: 0.1189 - accuracy: 0.9355\n",
      "3329/5349 [=================>............] - ETA: 1s - loss: 0.1191 - accuracy: 0.9353\n",
      "3482/5349 [==================>...........] - ETA: 1s - loss: 0.1189 - accuracy: 0.9354\n",
      "3636/5349 [===================>..........] - ETA: 1s - loss: 0.1190 - accuracy: 0.9353\n",
      "3796/5349 [====================>.........] - ETA: 1s - loss: 0.1189 - accuracy: 0.9353\n",
      "3879/5349 [====================>.........] - ETA: 1s - loss: 0.1190 - accuracy: 0.9353\n",
      "4012/5349 [=====================>........] - ETA: 1s - loss: 0.1191 - accuracy: 0.9352\n",
      "4147/5349 [======================>.......] - ETA: 1s - loss: 0.1191 - accuracy: 0.9353\n",
      "4289/5349 [=======================>......] - ETA: 0s - loss: 0.1192 - accuracy: 0.9352\n",
      "4501/5349 [========================>.....] - ETA: 0s - loss: 0.1191 - accuracy: 0.9353\n",
      "4653/5349 [=========================>....] - ETA: 0s - loss: 0.1191 - accuracy: 0.9353\n",
      "4789/5349 [=========================>....] - ETA: 0s - loss: 0.1191 - accuracy: 0.9353\n",
      "4927/5349 [==========================>...] - ETA: 0s - loss: 0.1190 - accuracy: 0.9352\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.1191 - accuracy: 0.9352\n",
      "5238/5349 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9352\n",
      "5317/5349 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9352\n",
      "5349/5349 [==============================] - 5s 1ms/step - loss: 0.1191 - accuracy: 0.9352 - val_loss: 0.1157 - val_accuracy: 0.9372\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1031 - accuracy: 0.9600\n",
      " 160/5349 [..............................] - ETA: 3s - loss: 0.1251 - accuracy: 0.9302\n",
      " 316/5349 [>.............................] - ETA: 3s - loss: 0.1249 - accuracy: 0.9307\n",
      " 465/5349 [=>............................] - ETA: 3s - loss: 0.1218 - accuracy: 0.9332\n",
      " 577/5349 [==>...........................] - ETA: 3s - loss: 0.1208 - accuracy: 0.9345\n",
      " 598/5349 [==>...........................] - ETA: 4s - loss: 0.1207 - accuracy: 0.9344\n",
      " 637/5349 [==>...........................] - ETA: 4s - loss: 0.1207 - accuracy: 0.9343\n",
      " 681/5349 [==>...........................] - ETA: 4s - loss: 0.1207 - accuracy: 0.9344\n",
      " 708/5349 [==>...........................] - ETA: 5s - loss: 0.1200 - accuracy: 0.9348\n",
      " 747/5349 [===>..........................] - ETA: 5s - loss: 0.1203 - accuracy: 0.9345\n",
      " 787/5349 [===>..........................] - ETA: 5s - loss: 0.1202 - accuracy: 0.9344\n",
      " 813/5349 [===>..........................] - ETA: 6s - loss: 0.1198 - accuracy: 0.9346\n",
      " 842/5349 [===>..........................] - ETA: 6s - loss: 0.1196 - accuracy: 0.9349\n",
      " 872/5349 [===>..........................] - ETA: 6s - loss: 0.1198 - accuracy: 0.9348\n",
      " 904/5349 [====>.........................] - ETA: 6s - loss: 0.1198 - accuracy: 0.9347\n",
      " 995/5349 [====>.........................] - ETA: 6s - loss: 0.1196 - accuracy: 0.9348\n",
      "1063/5349 [====>.........................] - ETA: 6s - loss: 0.1194 - accuracy: 0.9351\n",
      "1095/5349 [=====>........................] - ETA: 6s - loss: 0.1193 - accuracy: 0.9350\n",
      "1173/5349 [=====>........................] - ETA: 6s - loss: 0.1193 - accuracy: 0.9350\n",
      "1241/5349 [=====>........................] - ETA: 6s - loss: 0.1189 - accuracy: 0.9353\n",
      "1373/5349 [======>.......................] - ETA: 6s - loss: 0.1190 - accuracy: 0.9350\n",
      "1481/5349 [=======>......................] - ETA: 5s - loss: 0.1188 - accuracy: 0.9352\n",
      "1529/5349 [=======>......................] - ETA: 5s - loss: 0.1187 - accuracy: 0.9350\n",
      "1596/5349 [=======>......................] - ETA: 5s - loss: 0.1187 - accuracy: 0.9350\n",
      "1661/5349 [========>.....................] - ETA: 5s - loss: 0.1187 - accuracy: 0.9352\n",
      "1764/5349 [========>.....................] - ETA: 5s - loss: 0.1187 - accuracy: 0.9353\n",
      "1853/5349 [=========>....................] - ETA: 5s - loss: 0.1188 - accuracy: 0.9352\n",
      "1888/5349 [=========>....................] - ETA: 5s - loss: 0.1189 - accuracy: 0.9351\n",
      "1956/5349 [=========>....................] - ETA: 4s - loss: 0.1190 - accuracy: 0.9350\n",
      "2009/5349 [==========>...................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9349\n",
      "2047/5349 [==========>...................] - ETA: 4s - loss: 0.1193 - accuracy: 0.9348\n",
      "2096/5349 [==========>...................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9348\n",
      "2146/5349 [===========>..................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9349\n",
      "2181/5349 [===========>..................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9348\n",
      "2228/5349 [===========>..................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9348\n",
      "2274/5349 [===========>..................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9348\n",
      "2322/5349 [============>.................] - ETA: 4s - loss: 0.1190 - accuracy: 0.9349\n",
      "2350/5349 [============>.................] - ETA: 4s - loss: 0.1190 - accuracy: 0.9349\n",
      "2413/5349 [============>.................] - ETA: 4s - loss: 0.1190 - accuracy: 0.9349\n",
      "2467/5349 [============>.................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9349\n",
      "2531/5349 [=============>................] - ETA: 4s - loss: 0.1190 - accuracy: 0.9350\n",
      "2614/5349 [=============>................] - ETA: 4s - loss: 0.1191 - accuracy: 0.9350\n",
      "2654/5349 [=============>................] - ETA: 4s - loss: 0.1190 - accuracy: 0.9350\n",
      "2749/5349 [==============>...............] - ETA: 4s - loss: 0.1192 - accuracy: 0.9350\n",
      "2883/5349 [===============>..............] - ETA: 3s - loss: 0.1196 - accuracy: 0.9348\n",
      "3004/5349 [===============>..............] - ETA: 3s - loss: 0.1195 - accuracy: 0.9348\n",
      "3201/5349 [================>.............] - ETA: 3s - loss: 0.1196 - accuracy: 0.9347\n",
      "3321/5349 [=================>............] - ETA: 3s - loss: 0.1195 - accuracy: 0.9348\n",
      "3447/5349 [==================>...........] - ETA: 2s - loss: 0.1195 - accuracy: 0.9349\n",
      "3521/5349 [==================>...........] - ETA: 2s - loss: 0.1195 - accuracy: 0.9348\n",
      "3594/5349 [===================>..........] - ETA: 2s - loss: 0.1194 - accuracy: 0.9349\n",
      "3725/5349 [===================>..........] - ETA: 2s - loss: 0.1193 - accuracy: 0.9349\n",
      "3843/5349 [====================>.........] - ETA: 2s - loss: 0.1194 - accuracy: 0.9349\n",
      "4074/5349 [=====================>........] - ETA: 1s - loss: 0.1192 - accuracy: 0.9349\n",
      "4236/5349 [======================>.......] - ETA: 1s - loss: 0.1191 - accuracy: 0.9350\n",
      "4387/5349 [=======================>......] - ETA: 1s - loss: 0.1190 - accuracy: 0.9351\n",
      "4537/5349 [========================>.....] - ETA: 1s - loss: 0.1190 - accuracy: 0.9351\n",
      "4697/5349 [=========================>....] - ETA: 0s - loss: 0.1189 - accuracy: 0.9351\n",
      "4878/5349 [==========================>...] - ETA: 0s - loss: 0.1188 - accuracy: 0.9351\n",
      "5052/5349 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 0.9352\n",
      "5236/5349 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9352\n",
      "5347/5349 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9353\n",
      "5349/5349 [==============================] - 8s 2ms/step - loss: 0.1186 - accuracy: 0.9353 - val_loss: 0.1174 - val_accuracy: 0.9357\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 10/20\n",
      "  82/5349 [..............................] - ETA: 3s - loss: 0.1231 - accuracy: 0.9329\n",
      " 248/5349 [>.............................] - ETA: 3s - loss: 0.1174 - accuracy: 0.9378\n",
      " 406/5349 [=>............................] - ETA: 3s - loss: 0.1179 - accuracy: 0.9358\n",
      " 550/5349 [==>...........................] - ETA: 3s - loss: 0.1194 - accuracy: 0.9350\n",
      " 683/5349 [==>...........................] - ETA: 3s - loss: 0.1190 - accuracy: 0.9349\n",
      " 840/5349 [===>..........................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9348\n",
      "1001/5349 [====>.........................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9352\n",
      "1158/5349 [=====>........................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9350\n",
      "1403/5349 [======>.......................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9345\n",
      "1562/5349 [=======>......................] - ETA: 2s - loss: 0.1187 - accuracy: 0.9344\n",
      "1728/5349 [========>.....................] - ETA: 2s - loss: 0.1183 - accuracy: 0.9350\n",
      "1870/5349 [=========>....................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9352\n",
      "2035/5349 [==========>...................] - ETA: 2s - loss: 0.1180 - accuracy: 0.9351\n",
      "2195/5349 [===========>..................] - ETA: 2s - loss: 0.1179 - accuracy: 0.9350\n",
      "2362/5349 [============>.................] - ETA: 1s - loss: 0.1181 - accuracy: 0.9349\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.1183 - accuracy: 0.9349\n",
      "2688/5349 [==============>...............] - ETA: 1s - loss: 0.1183 - accuracy: 0.9348\n",
      "2842/5349 [==============>...............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9350\n",
      "2924/5349 [===============>..............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9349\n",
      "3090/5349 [================>.............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9351\n",
      "3248/5349 [=================>............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9352\n",
      "3412/5349 [==================>...........] - ETA: 1s - loss: 0.1181 - accuracy: 0.9352\n",
      "3571/5349 [===================>..........] - ETA: 1s - loss: 0.1181 - accuracy: 0.9352\n",
      "3734/5349 [===================>..........] - ETA: 1s - loss: 0.1181 - accuracy: 0.9353\n",
      "3890/5349 [====================>.........] - ETA: 0s - loss: 0.1180 - accuracy: 0.9353\n",
      "4057/5349 [=====================>........] - ETA: 0s - loss: 0.1181 - accuracy: 0.9352\n",
      "4203/5349 [======================>.......] - ETA: 0s - loss: 0.1180 - accuracy: 0.9353\n",
      "4369/5349 [=======================>......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9353\n",
      "4454/5349 [=======================>......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9355\n",
      "4613/5349 [========================>.....] - ETA: 0s - loss: 0.1179 - accuracy: 0.9355\n",
      "4781/5349 [=========================>....] - ETA: 0s - loss: 0.1177 - accuracy: 0.9356\n",
      "4922/5349 [==========================>...] - ETA: 0s - loss: 0.1177 - accuracy: 0.9356\n",
      "5050/5349 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.9356\n",
      "5175/5349 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.9357\n",
      "5282/5349 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.9356\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9357\n",
      "5349/5349 [==============================] - 5s 849us/step - loss: 0.1175 - accuracy: 0.9357 - val_loss: 0.1154 - val_accuracy: 0.9367\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 11/20\n",
      "  83/5349 [..............................] - ETA: 3s - loss: 0.1119 - accuracy: 0.9393\n",
      " 247/5349 [>.............................] - ETA: 3s - loss: 0.1173 - accuracy: 0.9358\n",
      " 413/5349 [=>............................] - ETA: 3s - loss: 0.1185 - accuracy: 0.9345\n",
      " 552/5349 [==>...........................] - ETA: 3s - loss: 0.1169 - accuracy: 0.9357\n",
      " 718/5349 [===>..........................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9360\n",
      " 870/5349 [===>..........................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9360\n",
      "1029/5349 [====>.........................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9361\n",
      "1181/5349 [=====>........................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9361\n",
      "1339/5349 [======>.......................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9360\n",
      "1572/5349 [=======>......................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9359\n",
      "1733/5349 [========>.....................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9360\n",
      "1887/5349 [=========>....................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9360\n",
      "2049/5349 [==========>...................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9358\n",
      "2197/5349 [===========>..................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9358\n",
      "2357/5349 [============>.................] - ETA: 1s - loss: 0.1174 - accuracy: 0.9359\n",
      "2474/5349 [============>.................] - ETA: 1s - loss: 0.1173 - accuracy: 0.9359\n",
      "2629/5349 [=============>................] - ETA: 1s - loss: 0.1172 - accuracy: 0.9360\n",
      "2771/5349 [==============>...............] - ETA: 1s - loss: 0.1171 - accuracy: 0.9361\n",
      "2938/5349 [===============>..............] - ETA: 1s - loss: 0.1171 - accuracy: 0.9360\n",
      "3177/5349 [================>.............] - ETA: 1s - loss: 0.1175 - accuracy: 0.9356\n",
      "3343/5349 [=================>............] - ETA: 1s - loss: 0.1174 - accuracy: 0.9357\n",
      "3504/5349 [==================>...........] - ETA: 1s - loss: 0.1174 - accuracy: 0.9357\n",
      "3674/5349 [===================>..........] - ETA: 1s - loss: 0.1173 - accuracy: 0.9358\n",
      "3840/5349 [====================>.........] - ETA: 0s - loss: 0.1173 - accuracy: 0.9358\n",
      "3998/5349 [=====================>........] - ETA: 0s - loss: 0.1174 - accuracy: 0.9357\n",
      "4155/5349 [======================>.......] - ETA: 0s - loss: 0.1174 - accuracy: 0.9357\n",
      "4322/5349 [=======================>......] - ETA: 0s - loss: 0.1174 - accuracy: 0.9357\n",
      "4470/5349 [========================>.....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9358\n",
      "4637/5349 [=========================>....] - ETA: 0s - loss: 0.1173 - accuracy: 0.9357\n",
      "4798/5349 [=========================>....] - ETA: 0s - loss: 0.1172 - accuracy: 0.9357\n",
      "5045/5349 [===========================>..] - ETA: 0s - loss: 0.1172 - accuracy: 0.9358\n",
      "5203/5349 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9358\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9359\n",
      "5349/5349 [==============================] - 5s 1ms/step - loss: 0.1171 - accuracy: 0.9359 - val_loss: 0.1130 - val_accuracy: 0.9377\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 37s - loss: 0.1231 - accuracy: 0.9500\n",
      "  39/5349 [..............................] - ETA: 14s - loss: 0.1160 - accuracy: 0.9364\n",
      "  74/5349 [..............................] - ETA: 14s - loss: 0.1169 - accuracy: 0.9346\n",
      "  89/5349 [..............................] - ETA: 18s - loss: 0.1153 - accuracy: 0.9363\n",
      " 103/5349 [..............................] - ETA: 18s - loss: 0.1147 - accuracy: 0.9372\n",
      " 128/5349 [..............................] - ETA: 18s - loss: 0.1148 - accuracy: 0.9380\n",
      " 149/5349 [..............................] - ETA: 19s - loss: 0.1150 - accuracy: 0.9373\n",
      " 179/5349 [>.............................] - ETA: 19s - loss: 0.1162 - accuracy: 0.9364\n",
      " 200/5349 [>.............................] - ETA: 20s - loss: 0.1159 - accuracy: 0.9367\n",
      " 211/5349 [>.............................] - ETA: 21s - loss: 0.1159 - accuracy: 0.9367\n",
      " 227/5349 [>.............................] - ETA: 22s - loss: 0.1169 - accuracy: 0.9359\n",
      " 242/5349 [>.............................] - ETA: 23s - loss: 0.1174 - accuracy: 0.9352\n",
      " 259/5349 [>.............................] - ETA: 24s - loss: 0.1179 - accuracy: 0.9351\n",
      " 268/5349 [>.............................] - ETA: 24s - loss: 0.1175 - accuracy: 0.9357\n",
      " 282/5349 [>.............................] - ETA: 25s - loss: 0.1169 - accuracy: 0.9360\n",
      " 296/5349 [>.............................] - ETA: 25s - loss: 0.1169 - accuracy: 0.9363\n",
      " 303/5349 [>.............................] - ETA: 26s - loss: 0.1168 - accuracy: 0.9363\n",
      " 314/5349 [>.............................] - ETA: 26s - loss: 0.1172 - accuracy: 0.9360\n",
      " 340/5349 [>.............................] - ETA: 25s - loss: 0.1175 - accuracy: 0.9360\n",
      " 353/5349 [>.............................] - ETA: 26s - loss: 0.1171 - accuracy: 0.9363\n",
      " 371/5349 [=>............................] - ETA: 26s - loss: 0.1171 - accuracy: 0.9367\n",
      " 392/5349 [=>............................] - ETA: 26s - loss: 0.1168 - accuracy: 0.9367\n",
      " 414/5349 [=>............................] - ETA: 26s - loss: 0.1168 - accuracy: 0.9366\n",
      " 437/5349 [=>............................] - ETA: 25s - loss: 0.1168 - accuracy: 0.9367\n",
      " 450/5349 [=>............................] - ETA: 26s - loss: 0.1169 - accuracy: 0.9367\n",
      " 470/5349 [=>............................] - ETA: 26s - loss: 0.1171 - accuracy: 0.9366\n",
      " 491/5349 [=>............................] - ETA: 26s - loss: 0.1170 - accuracy: 0.9365\n",
      " 516/5349 [=>............................] - ETA: 25s - loss: 0.1169 - accuracy: 0.9364\n",
      " 535/5349 [==>...........................] - ETA: 25s - loss: 0.1169 - accuracy: 0.9364\n",
      " 544/5349 [==>...........................] - ETA: 25s - loss: 0.1170 - accuracy: 0.9363\n",
      " 562/5349 [==>...........................] - ETA: 25s - loss: 0.1169 - accuracy: 0.9364\n",
      " 573/5349 [==>...........................] - ETA: 25s - loss: 0.1167 - accuracy: 0.9365\n",
      " 590/5349 [==>...........................] - ETA: 25s - loss: 0.1162 - accuracy: 0.9368\n",
      " 598/5349 [==>...........................] - ETA: 26s - loss: 0.1164 - accuracy: 0.9368\n",
      " 607/5349 [==>...........................] - ETA: 26s - loss: 0.1165 - accuracy: 0.9367\n",
      " 631/5349 [==>...........................] - ETA: 26s - loss: 0.1162 - accuracy: 0.9369\n",
      " 668/5349 [==>...........................] - ETA: 25s - loss: 0.1161 - accuracy: 0.9369\n",
      " 720/5349 [===>..........................] - ETA: 24s - loss: 0.1160 - accuracy: 0.9369\n",
      " 757/5349 [===>..........................] - ETA: 23s - loss: 0.1163 - accuracy: 0.9368\n",
      " 819/5349 [===>..........................] - ETA: 22s - loss: 0.1164 - accuracy: 0.9367\n",
      " 863/5349 [===>..........................] - ETA: 21s - loss: 0.1165 - accuracy: 0.9365\n",
      " 997/5349 [====>.........................] - ETA: 18s - loss: 0.1162 - accuracy: 0.9367\n",
      "1154/5349 [=====>........................] - ETA: 15s - loss: 0.1164 - accuracy: 0.9364\n",
      "1309/5349 [======>.......................] - ETA: 13s - loss: 0.1165 - accuracy: 0.9363\n",
      "1467/5349 [=======>......................] - ETA: 12s - loss: 0.1171 - accuracy: 0.9357\n",
      "1620/5349 [========>.....................] - ETA: 10s - loss: 0.1173 - accuracy: 0.9353\n",
      "1791/5349 [=========>....................] - ETA: 9s - loss: 0.1172 - accuracy: 0.9355 \n",
      "1949/5349 [=========>....................] - ETA: 8s - loss: 0.1171 - accuracy: 0.9356\n",
      "2111/5349 [==========>...................] - ETA: 7s - loss: 0.1169 - accuracy: 0.9358\n",
      "2228/5349 [===========>..................] - ETA: 7s - loss: 0.1169 - accuracy: 0.9358\n",
      "2386/5349 [============>.................] - ETA: 6s - loss: 0.1169 - accuracy: 0.9358\n",
      "2469/5349 [============>.................] - ETA: 6s - loss: 0.1168 - accuracy: 0.9359\n",
      "2611/5349 [=============>................] - ETA: 5s - loss: 0.1168 - accuracy: 0.9359\n",
      "2768/5349 [==============>...............] - ETA: 5s - loss: 0.1166 - accuracy: 0.9360\n",
      "2919/5349 [===============>..............] - ETA: 4s - loss: 0.1164 - accuracy: 0.9361\n",
      "3076/5349 [================>.............] - ETA: 4s - loss: 0.1164 - accuracy: 0.9361\n",
      "3228/5349 [=================>............] - ETA: 3s - loss: 0.1165 - accuracy: 0.9361\n",
      "3387/5349 [=================>............] - ETA: 3s - loss: 0.1166 - accuracy: 0.9360\n",
      "3539/5349 [==================>...........] - ETA: 3s - loss: 0.1169 - accuracy: 0.9359\n",
      "3703/5349 [===================>..........] - ETA: 2s - loss: 0.1169 - accuracy: 0.9359\n",
      "3857/5349 [====================>.........] - ETA: 2s - loss: 0.1170 - accuracy: 0.9359\n",
      "4126/5349 [======================>.......] - ETA: 1s - loss: 0.1169 - accuracy: 0.9358\n",
      "4303/5349 [=======================>......] - ETA: 1s - loss: 0.1167 - accuracy: 0.9359\n",
      "4478/5349 [========================>.....] - ETA: 1s - loss: 0.1166 - accuracy: 0.9360\n",
      "4613/5349 [========================>.....] - ETA: 1s - loss: 0.1166 - accuracy: 0.9360\n",
      "4783/5349 [=========================>....] - ETA: 0s - loss: 0.1167 - accuracy: 0.9359\n",
      "4943/5349 [==========================>...] - ETA: 0s - loss: 0.1166 - accuracy: 0.9360\n",
      "5128/5349 [===========================>..] - ETA: 0s - loss: 0.1165 - accuracy: 0.9361\n",
      "5303/5349 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9361\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1165 - accuracy: 0.9361 - val_loss: 0.1146 - val_accuracy: 0.9373\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0826 - accuracy: 0.9300\n",
      " 162/5349 [..............................] - ETA: 3s - loss: 0.1161 - accuracy: 0.9341\n",
      " 318/5349 [>.............................] - ETA: 3s - loss: 0.1160 - accuracy: 0.9361\n",
      " 470/5349 [=>............................] - ETA: 3s - loss: 0.1149 - accuracy: 0.9364\n",
      " 630/5349 [==>...........................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9365\n",
      " 708/5349 [==>...........................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9362\n",
      " 868/5349 [===>..........................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9361\n",
      "1022/5349 [====>.........................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9361\n",
      "1182/5349 [=====>........................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9363\n",
      "1349/5349 [======>.......................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9363\n",
      "1497/5349 [=======>......................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9363\n",
      "1661/5349 [========>.....................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9363\n",
      "1823/5349 [=========>....................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9364\n",
      "1987/5349 [==========>...................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9364\n",
      "2145/5349 [===========>..................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9363\n",
      "2311/5349 [===========>..................] - ETA: 1s - loss: 0.1154 - accuracy: 0.9364\n",
      "2470/5349 [============>.................] - ETA: 1s - loss: 0.1154 - accuracy: 0.9365\n",
      "2639/5349 [=============>................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9366\n",
      "2801/5349 [==============>...............] - ETA: 1s - loss: 0.1152 - accuracy: 0.9367\n",
      "2883/5349 [===============>..............] - ETA: 1s - loss: 0.1151 - accuracy: 0.9367\n",
      "3050/5349 [================>.............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9367\n",
      "3210/5349 [=================>............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9367\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9365\n",
      "3540/5349 [==================>...........] - ETA: 1s - loss: 0.1155 - accuracy: 0.9365\n",
      "3704/5349 [===================>..........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9365\n",
      "3852/5349 [====================>.........] - ETA: 0s - loss: 0.1157 - accuracy: 0.9365\n",
      "3998/5349 [=====================>........] - ETA: 0s - loss: 0.1158 - accuracy: 0.9364\n",
      "4133/5349 [======================>.......] - ETA: 0s - loss: 0.1158 - accuracy: 0.9364\n",
      "4282/5349 [=======================>......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9364\n",
      "4367/5349 [=======================>......] - ETA: 0s - loss: 0.1160 - accuracy: 0.9364\n",
      "4480/5349 [========================>.....] - ETA: 0s - loss: 0.1158 - accuracy: 0.9366\n",
      "4619/5349 [========================>.....] - ETA: 0s - loss: 0.1156 - accuracy: 0.9366\n",
      "4746/5349 [=========================>....] - ETA: 0s - loss: 0.1157 - accuracy: 0.9365\n",
      "4880/5349 [==========================>...] - ETA: 0s - loss: 0.1157 - accuracy: 0.9364\n",
      "5005/5349 [===========================>..] - ETA: 0s - loss: 0.1158 - accuracy: 0.9363\n",
      "5138/5349 [===========================>..] - ETA: 0s - loss: 0.1158 - accuracy: 0.9364\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9364\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9364\n",
      "5349/5349 [==============================] - 4s 829us/step - loss: 0.1157 - accuracy: 0.9364 - val_loss: 0.1310 - val_accuracy: 0.9278\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1009 - accuracy: 0.9400\n",
      " 161/5349 [..............................] - ETA: 3s - loss: 0.1168 - accuracy: 0.9358\n",
      " 325/5349 [>.............................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9362\n",
      " 485/5349 [=>............................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9362\n",
      " 651/5349 [==>...........................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9360\n",
      " 811/5349 [===>..........................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9363\n",
      " 974/5349 [====>.........................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9365\n",
      "1135/5349 [=====>........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9364\n",
      "1301/5349 [======>.......................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9365\n",
      "1460/5349 [=======>......................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9367\n",
      "1627/5349 [========>.....................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9368\n",
      "1785/5349 [=========>....................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9368\n",
      "1831/5349 [=========>....................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9367\n",
      "1920/5349 [=========>....................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9367\n",
      "2059/5349 [==========>...................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9366\n",
      "2214/5349 [===========>..................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9366\n",
      "2367/5349 [============>.................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9367\n",
      "2523/5349 [=============>................] - ETA: 1s - loss: 0.1154 - accuracy: 0.9366\n",
      "2674/5349 [=============>................] - ETA: 1s - loss: 0.1156 - accuracy: 0.9365\n",
      "2782/5349 [==============>...............] - ETA: 1s - loss: 0.1154 - accuracy: 0.9366\n",
      "2872/5349 [===============>..............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9365\n",
      "2889/5349 [===============>..............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9365\n",
      "2919/5349 [===============>..............] - ETA: 1s - loss: 0.1157 - accuracy: 0.9364\n",
      "2945/5349 [===============>..............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9364\n",
      "2976/5349 [===============>..............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9364\n",
      "3000/5349 [===============>..............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9364\n",
      "3035/5349 [================>.............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9364\n",
      "3063/5349 [================>.............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9365\n",
      "3094/5349 [================>.............] - ETA: 2s - loss: 0.1156 - accuracy: 0.9365\n",
      "3111/5349 [================>.............] - ETA: 2s - loss: 0.1157 - accuracy: 0.9365\n",
      "3138/5349 [================>.............] - ETA: 2s - loss: 0.1156 - accuracy: 0.9365\n",
      "3171/5349 [================>.............] - ETA: 2s - loss: 0.1156 - accuracy: 0.9365\n",
      "3213/5349 [=================>............] - ETA: 2s - loss: 0.1156 - accuracy: 0.9364\n",
      "3241/5349 [=================>............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3263/5349 [=================>............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3291/5349 [=================>............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9364\n",
      "3319/5349 [=================>............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3336/5349 [=================>............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3374/5349 [=================>............] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3397/5349 [==================>...........] - ETA: 2s - loss: 0.1157 - accuracy: 0.9363\n",
      "3421/5349 [==================>...........] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3457/5349 [==================>...........] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      "3486/5349 [==================>...........] - ETA: 2s - loss: 0.1157 - accuracy: 0.9364\n",
      "3511/5349 [==================>...........] - ETA: 2s - loss: 0.1157 - accuracy: 0.9364\n",
      "3554/5349 [==================>...........] - ETA: 2s - loss: 0.1156 - accuracy: 0.9365\n",
      "3606/5349 [===================>..........] - ETA: 2s - loss: 0.1156 - accuracy: 0.9365\n",
      "3635/5349 [===================>..........] - ETA: 2s - loss: 0.1155 - accuracy: 0.9365\n",
      "3669/5349 [===================>..........] - ETA: 2s - loss: 0.1155 - accuracy: 0.9366\n",
      "3776/5349 [====================>.........] - ETA: 2s - loss: 0.1154 - accuracy: 0.9367\n",
      "3868/5349 [====================>.........] - ETA: 1s - loss: 0.1153 - accuracy: 0.9368\n",
      "3977/5349 [=====================>........] - ETA: 1s - loss: 0.1153 - accuracy: 0.9367\n",
      "4106/5349 [======================>.......] - ETA: 1s - loss: 0.1152 - accuracy: 0.9368\n",
      "4264/5349 [======================>.......] - ETA: 1s - loss: 0.1153 - accuracy: 0.9368\n",
      "4341/5349 [=======================>......] - ETA: 1s - loss: 0.1154 - accuracy: 0.9367\n",
      "4502/5349 [========================>.....] - ETA: 1s - loss: 0.1153 - accuracy: 0.9368\n",
      "4659/5349 [=========================>....] - ETA: 0s - loss: 0.1152 - accuracy: 0.9368\n",
      "4817/5349 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9369\n",
      "4978/5349 [==========================>...] - ETA: 0s - loss: 0.1151 - accuracy: 0.9368\n",
      "5122/5349 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9368\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9367\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1152 - accuracy: 0.9368 - val_loss: 0.1645 - val_accuracy: 0.9163\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 15/20\n",
      "  70/5349 [..............................] - ETA: 3s - loss: 0.1175 - accuracy: 0.9371\n",
      " 164/5349 [..............................] - ETA: 4s - loss: 0.1208 - accuracy: 0.9362\n",
      " 297/5349 [>.............................] - ETA: 4s - loss: 0.1181 - accuracy: 0.9371\n",
      " 420/5349 [=>............................] - ETA: 4s - loss: 0.1167 - accuracy: 0.9372\n",
      " 593/5349 [==>...........................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9380\n",
      " 769/5349 [===>..........................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9375\n",
      " 951/5349 [====>.........................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9380\n",
      "1012/5349 [====>.........................] - ETA: 3s - loss: 0.1152 - accuracy: 0.9379\n",
      "1150/5349 [=====>........................] - ETA: 2s - loss: 0.1155 - accuracy: 0.9375\n",
      "1217/5349 [=====>........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9372\n",
      "1431/5349 [=======>......................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9372\n",
      "1591/5349 [=======>......................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9373\n",
      "1735/5349 [========>.....................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9374\n",
      "1893/5349 [=========>....................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9375\n",
      "2044/5349 [==========>...................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9374\n",
      "2204/5349 [===========>..................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9372\n",
      "2354/5349 [============>.................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9372\n",
      "2504/5349 [=============>................] - ETA: 1s - loss: 0.1149 - accuracy: 0.9373\n",
      "2647/5349 [=============>................] - ETA: 1s - loss: 0.1146 - accuracy: 0.9374\n",
      "2802/5349 [==============>...............] - ETA: 1s - loss: 0.1146 - accuracy: 0.9374\n",
      "2964/5349 [===============>..............] - ETA: 1s - loss: 0.1147 - accuracy: 0.9373\n",
      "3047/5349 [================>.............] - ETA: 1s - loss: 0.1148 - accuracy: 0.9372\n",
      "3212/5349 [=================>............] - ETA: 1s - loss: 0.1148 - accuracy: 0.9372\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1149 - accuracy: 0.9372\n",
      "3566/5349 [===================>..........] - ETA: 1s - loss: 0.1149 - accuracy: 0.9372\n",
      "3753/5349 [====================>.........] - ETA: 1s - loss: 0.1149 - accuracy: 0.9371\n",
      "3944/5349 [=====================>........] - ETA: 0s - loss: 0.1148 - accuracy: 0.9371\n",
      "4131/5349 [======================>.......] - ETA: 0s - loss: 0.1149 - accuracy: 0.9370\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1150 - accuracy: 0.9370\n",
      "4601/5349 [========================>.....] - ETA: 0s - loss: 0.1150 - accuracy: 0.9370\n",
      "4790/5349 [=========================>....] - ETA: 0s - loss: 0.1149 - accuracy: 0.9371\n",
      "4975/5349 [==========================>...] - ETA: 0s - loss: 0.1148 - accuracy: 0.9371\n",
      "5166/5349 [===========================>..] - ETA: 0s - loss: 0.1148 - accuracy: 0.9370\n",
      "5258/5349 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9369\n",
      "5349/5349 [==============================] - 4s 775us/step - loss: 0.1149 - accuracy: 0.9369 - val_loss: 0.1107 - val_accuracy: 0.9389\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 16/20\n",
      "  94/5349 [..............................] - ETA: 2s - loss: 0.1141 - accuracy: 0.9372\n",
      " 282/5349 [>.............................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9366\n",
      " 472/5349 [=>............................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9361\n",
      " 654/5349 [==>...........................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9363\n",
      " 935/5349 [====>.........................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9366\n",
      "1120/5349 [=====>........................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9368\n",
      "1310/5349 [======>.......................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9370\n",
      "1495/5349 [=======>......................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9370\n",
      "1683/5349 [========>.....................] - ETA: 1s - loss: 0.1149 - accuracy: 0.9368\n",
      "1869/5349 [=========>....................] - ETA: 1s - loss: 0.1149 - accuracy: 0.9370\n",
      "2058/5349 [==========>...................] - ETA: 1s - loss: 0.1149 - accuracy: 0.9369\n",
      "2342/5349 [============>.................] - ETA: 1s - loss: 0.1150 - accuracy: 0.9368\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.1148 - accuracy: 0.9371\n",
      "2715/5349 [==============>...............] - ETA: 1s - loss: 0.1147 - accuracy: 0.9372\n",
      "2904/5349 [===============>..............] - ETA: 1s - loss: 0.1145 - accuracy: 0.9373\n",
      "3076/5349 [================>.............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9376\n",
      "3266/5349 [=================>............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9375\n",
      "3453/5349 [==================>...........] - ETA: 1s - loss: 0.1139 - accuracy: 0.9377\n",
      "3739/5349 [===================>..........] - ETA: 0s - loss: 0.1141 - accuracy: 0.9375\n",
      "3925/5349 [=====================>........] - ETA: 0s - loss: 0.1142 - accuracy: 0.9375\n",
      "4114/5349 [======================>.......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9374\n",
      "4298/5349 [=======================>......] - ETA: 0s - loss: 0.1143 - accuracy: 0.9374\n",
      "4489/5349 [========================>.....] - ETA: 0s - loss: 0.1143 - accuracy: 0.9374\n",
      "4677/5349 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9373\n",
      "4869/5349 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9374\n",
      "5057/5349 [===========================>..] - ETA: 0s - loss: 0.1145 - accuracy: 0.9374\n",
      "5345/5349 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9372\n",
      "5349/5349 [==============================] - 4s 689us/step - loss: 0.1146 - accuracy: 0.9372 - val_loss: 0.1104 - val_accuracy: 0.9391\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1221 - accuracy: 0.9000\n",
      " 187/5349 [>.............................] - ETA: 2s - loss: 0.1105 - accuracy: 0.9388\n",
      " 375/5349 [=>............................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9383\n",
      " 558/5349 [==>...........................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9387\n",
      " 838/5349 [===>..........................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9378\n",
      "1025/5349 [====>.........................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9376\n",
      "1214/5349 [=====>........................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9376\n",
      "1404/5349 [======>.......................] - ETA: 2s - loss: 0.1136 - accuracy: 0.9375\n",
      "1594/5349 [=======>......................] - ETA: 2s - loss: 0.1139 - accuracy: 0.9374\n",
      "1785/5349 [=========>....................] - ETA: 1s - loss: 0.1147 - accuracy: 0.9369\n",
      "1975/5349 [==========>...................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9373\n",
      "2161/5349 [===========>..................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9373\n",
      "2408/5349 [============>.................] - ETA: 1s - loss: 0.1142 - accuracy: 0.9373\n",
      "2591/5349 [=============>................] - ETA: 1s - loss: 0.1141 - accuracy: 0.9373\n",
      "2771/5349 [==============>...............] - ETA: 1s - loss: 0.1142 - accuracy: 0.9372\n",
      "2929/5349 [===============>..............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9373\n",
      "3046/5349 [================>.............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9372\n",
      "3183/5349 [================>.............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9373\n",
      "3336/5349 [=================>............] - ETA: 1s - loss: 0.1141 - accuracy: 0.9373\n",
      "3520/5349 [==================>...........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9372\n",
      "3804/5349 [====================>.........] - ETA: 0s - loss: 0.1141 - accuracy: 0.9372\n",
      "3990/5349 [=====================>........] - ETA: 0s - loss: 0.1141 - accuracy: 0.9373\n",
      "4179/5349 [======================>.......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9373\n",
      "4367/5349 [=======================>......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9374\n",
      "4555/5349 [========================>.....] - ETA: 0s - loss: 0.1141 - accuracy: 0.9373\n",
      "4725/5349 [=========================>....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9373\n",
      "4907/5349 [==========================>...] - ETA: 0s - loss: 0.1140 - accuracy: 0.9373\n",
      "5114/5349 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.9373\n",
      "5296/5349 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9372\n",
      "5349/5349 [==============================] - 4s 711us/step - loss: 0.1141 - accuracy: 0.9372 - val_loss: 0.1137 - val_accuracy: 0.9375\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 18/20\n",
      "  96/5349 [..............................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9377\n",
      " 251/5349 [>.............................] - ETA: 3s - loss: 0.1131 - accuracy: 0.9377\n",
      " 402/5349 [=>............................] - ETA: 3s - loss: 0.1134 - accuracy: 0.9375\n",
      " 543/5349 [==>...........................] - ETA: 3s - loss: 0.1140 - accuracy: 0.9374\n",
      " 725/5349 [===>..........................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9364\n",
      " 903/5349 [====>.........................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9370\n",
      "1003/5349 [====>.........................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9371\n",
      "1040/5349 [====>.........................] - ETA: 2s - loss: 0.1145 - accuracy: 0.9371\n",
      "1102/5349 [=====>........................] - ETA: 3s - loss: 0.1147 - accuracy: 0.9373\n",
      "1183/5349 [=====>........................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9374\n",
      "1256/5349 [======>.......................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9374\n",
      "1316/5349 [======>.......................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9375\n",
      "1365/5349 [======>.......................] - ETA: 3s - loss: 0.1144 - accuracy: 0.9374\n",
      "1398/5349 [======>.......................] - ETA: 3s - loss: 0.1144 - accuracy: 0.9374\n",
      "1429/5349 [=======>......................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9372\n",
      "1443/5349 [=======>......................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9373\n",
      "1488/5349 [=======>......................] - ETA: 4s - loss: 0.1146 - accuracy: 0.9372\n",
      "1532/5349 [=======>......................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9371\n",
      "1565/5349 [=======>......................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9370\n",
      "1629/5349 [========>.....................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9373\n",
      "1670/5349 [========>.....................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9372\n",
      "1720/5349 [========>.....................] - ETA: 4s - loss: 0.1144 - accuracy: 0.9373\n",
      "1773/5349 [========>.....................] - ETA: 4s - loss: 0.1146 - accuracy: 0.9371\n",
      "1792/5349 [=========>....................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9370\n",
      "1866/5349 [=========>....................] - ETA: 4s - loss: 0.1149 - accuracy: 0.9369\n",
      "1916/5349 [=========>....................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9368\n",
      "1961/5349 [=========>....................] - ETA: 4s - loss: 0.1150 - accuracy: 0.9368\n",
      "2034/5349 [==========>...................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9370\n",
      "2082/5349 [==========>...................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9371\n",
      "2133/5349 [==========>...................] - ETA: 4s - loss: 0.1147 - accuracy: 0.9372\n",
      "2188/5349 [===========>..................] - ETA: 4s - loss: 0.1148 - accuracy: 0.9371\n",
      "2240/5349 [===========>..................] - ETA: 4s - loss: 0.1146 - accuracy: 0.9372\n",
      "2275/5349 [===========>..................] - ETA: 4s - loss: 0.1145 - accuracy: 0.9373\n",
      "2432/5349 [============>.................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9372\n",
      "2578/5349 [=============>................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9374\n",
      "2745/5349 [==============>...............] - ETA: 3s - loss: 0.1144 - accuracy: 0.9374\n",
      "2924/5349 [===============>..............] - ETA: 2s - loss: 0.1142 - accuracy: 0.9374\n",
      "3104/5349 [================>.............] - ETA: 2s - loss: 0.1145 - accuracy: 0.9373\n",
      "3303/5349 [=================>............] - ETA: 2s - loss: 0.1145 - accuracy: 0.9373\n",
      "3501/5349 [==================>...........] - ETA: 2s - loss: 0.1143 - accuracy: 0.9374\n",
      "3601/5349 [===================>..........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9374\n",
      "3799/5349 [====================>.........] - ETA: 1s - loss: 0.1141 - accuracy: 0.9374\n",
      "3994/5349 [=====================>........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9374\n",
      "4192/5349 [======================>.......] - ETA: 1s - loss: 0.1141 - accuracy: 0.9375\n",
      "4386/5349 [=======================>......] - ETA: 0s - loss: 0.1141 - accuracy: 0.9375\n",
      "4586/5349 [========================>.....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9374\n",
      "4784/5349 [=========================>....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9374\n",
      "4976/5349 [==========================>...] - ETA: 0s - loss: 0.1142 - accuracy: 0.9374\n",
      "5065/5349 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.9374\n",
      "5253/5349 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9373\n",
      "5347/5349 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9374\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1141 - accuracy: 0.9374 - val_loss: 0.1113 - val_accuracy: 0.9399\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 19/20\n",
      "  86/5349 [..............................] - ETA: 3s - loss: 0.1108 - accuracy: 0.9399\n",
      " 274/5349 [>.............................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9387\n",
      " 460/5349 [=>............................] - ETA: 2s - loss: 0.1117 - accuracy: 0.9397\n",
      " 645/5349 [==>...........................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9385\n",
      " 929/5349 [====>.........................] - ETA: 2s - loss: 0.1136 - accuracy: 0.9375\n",
      "1115/5349 [=====>........................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9378\n",
      "1305/5349 [======>.......................] - ETA: 2s - loss: 0.1128 - accuracy: 0.9383\n",
      "1490/5349 [=======>......................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9380\n",
      "1681/5349 [========>.....................] - ETA: 1s - loss: 0.1134 - accuracy: 0.9378\n",
      "1865/5349 [=========>....................] - ETA: 1s - loss: 0.1135 - accuracy: 0.9378\n",
      "2055/5349 [==========>...................] - ETA: 1s - loss: 0.1135 - accuracy: 0.9377\n",
      "2319/5349 [============>.................] - ETA: 1s - loss: 0.1135 - accuracy: 0.9376\n",
      "2510/5349 [=============>................] - ETA: 1s - loss: 0.1137 - accuracy: 0.9374\n",
      "2693/5349 [==============>...............] - ETA: 1s - loss: 0.1135 - accuracy: 0.9375\n",
      "2879/5349 [===============>..............] - ETA: 1s - loss: 0.1134 - accuracy: 0.9377\n",
      "3068/5349 [================>.............] - ETA: 1s - loss: 0.1135 - accuracy: 0.9377\n",
      "3256/5349 [=================>............] - ETA: 1s - loss: 0.1134 - accuracy: 0.9377\n",
      "3443/5349 [==================>...........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9378\n",
      "3632/5349 [===================>..........] - ETA: 0s - loss: 0.1135 - accuracy: 0.9377\n",
      "3817/5349 [====================>.........] - ETA: 0s - loss: 0.1136 - accuracy: 0.9376\n",
      "3912/5349 [====================>.........] - ETA: 0s - loss: 0.1136 - accuracy: 0.9376\n",
      "4100/5349 [=====================>........] - ETA: 0s - loss: 0.1136 - accuracy: 0.9376\n",
      "4286/5349 [=======================>......] - ETA: 0s - loss: 0.1133 - accuracy: 0.9377\n",
      "4474/5349 [========================>.....] - ETA: 0s - loss: 0.1135 - accuracy: 0.9377\n",
      "4660/5349 [=========================>....] - ETA: 0s - loss: 0.1134 - accuracy: 0.9378\n",
      "4851/5349 [==========================>...] - ETA: 0s - loss: 0.1135 - accuracy: 0.9376\n",
      "5023/5349 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9376\n",
      "5211/5349 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9377\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9376\n",
      "5349/5349 [==============================] - 4s 688us/step - loss: 0.1135 - accuracy: 0.9377 - val_loss: 0.1110 - val_accuracy: 0.9390\n",
      "\u001B[36m(train_DNN pid=5786)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1135 - accuracy: 0.9500\n",
      " 188/5349 [>.............................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9352\n",
      " 379/5349 [=>............................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9362\n",
      " 657/5349 [==>...........................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9362\n",
      " 845/5349 [===>..........................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9368\n",
      "1032/5349 [====>.........................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9372\n",
      "1221/5349 [=====>........................] - ETA: 2s - loss: 0.1136 - accuracy: 0.9372\n",
      "1406/5349 [======>.......................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9372\n",
      "1598/5349 [=======>......................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9371\n",
      "1782/5349 [========>.....................] - ETA: 1s - loss: 0.1136 - accuracy: 0.9374\n",
      "1962/5349 [==========>...................] - ETA: 1s - loss: 0.1130 - accuracy: 0.9379\n",
      "2054/5349 [==========>...................] - ETA: 1s - loss: 0.1131 - accuracy: 0.9379\n",
      "2215/5349 [===========>..................] - ETA: 1s - loss: 0.1133 - accuracy: 0.9378\n",
      "2403/5349 [============>.................] - ETA: 1s - loss: 0.1132 - accuracy: 0.9379\n",
      "2591/5349 [=============>................] - ETA: 1s - loss: 0.1132 - accuracy: 0.9378\n",
      "2779/5349 [==============>...............] - ETA: 1s - loss: 0.1132 - accuracy: 0.9378\n",
      "2967/5349 [===============>..............] - ETA: 1s - loss: 0.1130 - accuracy: 0.9379\n",
      "3159/5349 [================>.............] - ETA: 1s - loss: 0.1129 - accuracy: 0.9379\n",
      "3442/5349 [==================>...........] - ETA: 1s - loss: 0.1128 - accuracy: 0.9380\n",
      "3633/5349 [===================>..........] - ETA: 0s - loss: 0.1129 - accuracy: 0.9379\n",
      "3818/5349 [====================>.........] - ETA: 0s - loss: 0.1131 - accuracy: 0.9378\n",
      "4007/5349 [=====================>........] - ETA: 0s - loss: 0.1130 - accuracy: 0.9379\n",
      "4195/5349 [======================>.......] - ETA: 0s - loss: 0.1129 - accuracy: 0.9380\n",
      "4392/5349 [=======================>......] - ETA: 0s - loss: 0.1129 - accuracy: 0.9380\n",
      "4582/5349 [========================>.....] - ETA: 0s - loss: 0.1131 - accuracy: 0.9378\n",
      "4742/5349 [=========================>....] - ETA: 0s - loss: 0.1130 - accuracy: 0.9379\n",
      "4833/5349 [==========================>...] - ETA: 0s - loss: 0.1131 - accuracy: 0.9378\n",
      "5018/5349 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.9378\n",
      "5201/5349 [============================>.] - ETA: 0s - loss: 0.1130 - accuracy: 0.9378\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9377\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 20:26 - loss: 0.6206 - accuracy: 0.8500\n",
      " 163/5349 [..............................] - ETA: 3s - loss: 0.4145 - accuracy: 0.8872\n",
      " 344/5349 [>.............................] - ETA: 2s - loss: 0.3350 - accuracy: 0.8799\n",
      " 524/5349 [=>............................] - ETA: 2s - loss: 0.2939 - accuracy: 0.8830\n",
      " 709/5349 [==>...........................] - ETA: 2s - loss: 0.2683 - accuracy: 0.8880\n",
      " 893/5349 [====>.........................] - ETA: 2s - loss: 0.2500 - accuracy: 0.8919\n",
      "1073/5349 [=====>........................] - ETA: 2s - loss: 0.2377 - accuracy: 0.8945\n",
      "1252/5349 [======>.......................] - ETA: 2s - loss: 0.2280 - accuracy: 0.8971\n",
      "1434/5349 [=======>......................] - ETA: 2s - loss: 0.2205 - accuracy: 0.8988\n",
      "1526/5349 [=======>......................] - ETA: 2s - loss: 0.2171 - accuracy: 0.8999\n",
      "1705/5349 [========>.....................] - ETA: 2s - loss: 0.2120 - accuracy: 0.9010\n",
      "1889/5349 [=========>....................] - ETA: 1s - loss: 0.2071 - accuracy: 0.9021\n",
      "2056/5349 [==========>...................] - ETA: 1s - loss: 0.2035 - accuracy: 0.9029\n",
      "2237/5349 [===========>..................] - ETA: 1s - loss: 0.2004 - accuracy: 0.9038\n",
      "2415/5349 [============>.................] - ETA: 1s - loss: 0.1975 - accuracy: 0.9048\n",
      "2599/5349 [=============>................] - ETA: 1s - loss: 0.1948 - accuracy: 0.9056\n",
      "2779/5349 [==============>...............] - ETA: 1s - loss: 0.1922 - accuracy: 0.9063\n",
      "3051/5349 [================>.............] - ETA: 1s - loss: 0.1893 - accuracy: 0.9070\n",
      "3233/5349 [=================>............] - ETA: 1s - loss: 0.1876 - accuracy: 0.9073\n",
      "3418/5349 [==================>...........] - ETA: 1s - loss: 0.1859 - accuracy: 0.9079\n",
      "3599/5349 [===================>..........] - ETA: 0s - loss: 0.1843 - accuracy: 0.9084\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.1830 - accuracy: 0.9087\n",
      "3961/5349 [=====================>........] - ETA: 0s - loss: 0.1818 - accuracy: 0.9090\n",
      "4143/5349 [======================>.......] - ETA: 0s - loss: 0.1806 - accuracy: 0.9094\n",
      "4224/5349 [======================>.......] - ETA: 0s - loss: 0.1800 - accuracy: 0.9096\n",
      "4392/5349 [=======================>......] - ETA: 0s - loss: 0.1792 - accuracy: 0.9098\n",
      "4570/5349 [========================>.....] - ETA: 0s - loss: 0.1780 - accuracy: 0.9103\n",
      "4750/5349 [=========================>....] - ETA: 0s - loss: 0.1771 - accuracy: 0.9105\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.1762 - accuracy: 0.9108\n",
      "5114/5349 [===========================>..] - ETA: 0s - loss: 0.1754 - accuracy: 0.9111\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9113\n",
      "5349/5349 [==============================] - 4s 795us/step - loss: 0.1744 - accuracy: 0.9114 - val_loss: 0.1554 - val_accuracy: 0.9151\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1441 - accuracy: 0.9400\n",
      " 162/5349 [..............................] - ETA: 3s - loss: 0.1491 - accuracy: 0.9209\n",
      " 342/5349 [>.............................] - ETA: 2s - loss: 0.1506 - accuracy: 0.9207\n",
      " 520/5349 [=>............................] - ETA: 2s - loss: 0.1498 - accuracy: 0.9211\n",
      " 699/5349 [==>...........................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9210\n",
      " 839/5349 [===>..........................] - ETA: 2s - loss: 0.1492 - accuracy: 0.9209\n",
      "1062/5349 [====>.........................] - ETA: 2s - loss: 0.1488 - accuracy: 0.9208\n",
      "1239/5349 [=====>........................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9199\n",
      "1419/5349 [======>.......................] - ETA: 2s - loss: 0.1496 - accuracy: 0.9195\n",
      "1594/5349 [=======>......................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9195\n",
      "1778/5349 [========>.....................] - ETA: 2s - loss: 0.1496 - accuracy: 0.9191\n",
      "1956/5349 [=========>....................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9191\n",
      "2139/5349 [==========>...................] - ETA: 1s - loss: 0.1496 - accuracy: 0.9188\n",
      "2320/5349 [============>.................] - ETA: 1s - loss: 0.1495 - accuracy: 0.9190\n",
      "2412/5349 [============>.................] - ETA: 1s - loss: 0.1492 - accuracy: 0.9192\n",
      "2596/5349 [=============>................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9196\n",
      "2779/5349 [==============>...............] - ETA: 1s - loss: 0.1483 - accuracy: 0.9196\n",
      "2964/5349 [===============>..............] - ETA: 1s - loss: 0.1480 - accuracy: 0.9199\n",
      "3144/5349 [================>.............] - ETA: 1s - loss: 0.1479 - accuracy: 0.9200\n",
      "3332/5349 [=================>............] - ETA: 1s - loss: 0.1477 - accuracy: 0.9202\n",
      "3503/5349 [==================>...........] - ETA: 1s - loss: 0.1475 - accuracy: 0.9203\n",
      "3687/5349 [===================>..........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9203\n",
      "3867/5349 [====================>.........] - ETA: 0s - loss: 0.1473 - accuracy: 0.9204\n",
      "3960/5349 [=====================>........] - ETA: 0s - loss: 0.1472 - accuracy: 0.9203\n",
      "4143/5349 [======================>.......] - ETA: 0s - loss: 0.1470 - accuracy: 0.9205\n",
      "4326/5349 [=======================>......] - ETA: 0s - loss: 0.1468 - accuracy: 0.9206\n",
      "4509/5349 [========================>.....] - ETA: 0s - loss: 0.1467 - accuracy: 0.9206\n",
      "4690/5349 [=========================>....] - ETA: 0s - loss: 0.1463 - accuracy: 0.9209\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.1462 - accuracy: 0.9211\n",
      "5061/5349 [===========================>..] - ETA: 0s - loss: 0.1461 - accuracy: 0.9212\n",
      "5243/5349 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9213\n",
      "5334/5349 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9214\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1459 - accuracy: 0.9214 - val_loss: 0.1379 - val_accuracy: 0.9270\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 3/20\n",
      "  63/5349 [..............................] - ETA: 4s - loss: 0.1387 - accuracy: 0.9246 \n",
      " 229/5349 [>.............................] - ETA: 3s - loss: 0.1368 - accuracy: 0.9264\n",
      " 412/5349 [=>............................] - ETA: 3s - loss: 0.1395 - accuracy: 0.9252\n",
      " 588/5349 [==>...........................] - ETA: 2s - loss: 0.1399 - accuracy: 0.9250\n",
      " 773/5349 [===>..........................] - ETA: 2s - loss: 0.1392 - accuracy: 0.9259\n",
      " 955/5349 [====>.........................] - ETA: 2s - loss: 0.1392 - accuracy: 0.9263\n",
      "1141/5349 [=====>........................] - ETA: 2s - loss: 0.1387 - accuracy: 0.9266\n",
      "1234/5349 [=====>........................] - ETA: 2s - loss: 0.1387 - accuracy: 0.9266\n",
      "1416/5349 [======>.......................] - ETA: 2s - loss: 0.1387 - accuracy: 0.9265\n",
      "1601/5349 [=======>......................] - ETA: 2s - loss: 0.1385 - accuracy: 0.9265\n",
      "1790/5349 [=========>....................] - ETA: 2s - loss: 0.1382 - accuracy: 0.9266\n",
      "1983/5349 [==========>...................] - ETA: 1s - loss: 0.1381 - accuracy: 0.9265\n",
      "2178/5349 [===========>..................] - ETA: 1s - loss: 0.1377 - accuracy: 0.9267\n",
      "2370/5349 [============>.................] - ETA: 1s - loss: 0.1377 - accuracy: 0.9267\n",
      "2560/5349 [=============>................] - ETA: 1s - loss: 0.1378 - accuracy: 0.9263\n",
      "2841/5349 [==============>...............] - ETA: 1s - loss: 0.1372 - accuracy: 0.9268\n",
      "3016/5349 [===============>..............] - ETA: 1s - loss: 0.1371 - accuracy: 0.9269\n",
      "3209/5349 [================>.............] - ETA: 1s - loss: 0.1368 - accuracy: 0.9271\n",
      "3401/5349 [==================>...........] - ETA: 1s - loss: 0.1365 - accuracy: 0.9273\n",
      "3594/5349 [===================>..........] - ETA: 0s - loss: 0.1362 - accuracy: 0.9274\n",
      "3786/5349 [====================>.........] - ETA: 0s - loss: 0.1360 - accuracy: 0.9275\n",
      "3978/5349 [=====================>........] - ETA: 0s - loss: 0.1358 - accuracy: 0.9275\n",
      "4174/5349 [======================>.......] - ETA: 0s - loss: 0.1358 - accuracy: 0.9274\n",
      "4441/5349 [=======================>......] - ETA: 0s - loss: 0.1355 - accuracy: 0.9276\n",
      "4595/5349 [========================>.....] - ETA: 0s - loss: 0.1353 - accuracy: 0.9277\n",
      "4753/5349 [=========================>....] - ETA: 0s - loss: 0.1352 - accuracy: 0.9278\n",
      "4942/5349 [==========================>...] - ETA: 0s - loss: 0.1352 - accuracy: 0.9277\n",
      "5123/5349 [===========================>..] - ETA: 0s - loss: 0.1350 - accuracy: 0.9278\n",
      "5302/5349 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.9280\n",
      "5349/5349 [==============================] - 4s 707us/step - loss: 0.1348 - accuracy: 0.9279 - val_loss: 0.1296 - val_accuracy: 0.9304\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1580 - accuracy: 0.8900\n",
      " 183/5349 [>.............................] - ETA: 2s - loss: 0.1310 - accuracy: 0.9299\n",
      " 365/5349 [=>............................] - ETA: 2s - loss: 0.1292 - accuracy: 0.9298\n",
      " 541/5349 [==>...........................] - ETA: 2s - loss: 0.1293 - accuracy: 0.9307\n",
      " 722/5349 [===>..........................] - ETA: 2s - loss: 0.1304 - accuracy: 0.9309\n",
      " 900/5349 [====>.........................] - ETA: 2s - loss: 0.1298 - accuracy: 0.9309\n",
      "1171/5349 [=====>........................] - ETA: 2s - loss: 0.1294 - accuracy: 0.9312\n",
      "1351/5349 [======>.......................] - ETA: 2s - loss: 0.1289 - accuracy: 0.9316\n",
      "1533/5349 [=======>......................] - ETA: 2s - loss: 0.1293 - accuracy: 0.9311\n",
      "1712/5349 [========>.....................] - ETA: 2s - loss: 0.1294 - accuracy: 0.9310\n",
      "1893/5349 [=========>....................] - ETA: 1s - loss: 0.1297 - accuracy: 0.9309\n",
      "2060/5349 [==========>...................] - ETA: 1s - loss: 0.1296 - accuracy: 0.9309\n",
      "2238/5349 [===========>..................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9309\n",
      "2419/5349 [============>.................] - ETA: 1s - loss: 0.1291 - accuracy: 0.9309\n",
      "2693/5349 [==============>...............] - ETA: 1s - loss: 0.1289 - accuracy: 0.9311\n",
      "2873/5349 [===============>..............] - ETA: 1s - loss: 0.1288 - accuracy: 0.9311\n",
      "3056/5349 [================>.............] - ETA: 1s - loss: 0.1286 - accuracy: 0.9314\n",
      "3234/5349 [=================>............] - ETA: 1s - loss: 0.1289 - accuracy: 0.9312\n",
      "3419/5349 [==================>...........] - ETA: 1s - loss: 0.1289 - accuracy: 0.9312\n",
      "3599/5349 [===================>..........] - ETA: 0s - loss: 0.1289 - accuracy: 0.9312\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.1288 - accuracy: 0.9312\n",
      "4054/5349 [=====================>........] - ETA: 0s - loss: 0.1286 - accuracy: 0.9313\n",
      "4236/5349 [======================>.......] - ETA: 0s - loss: 0.1285 - accuracy: 0.9314\n",
      "4413/5349 [=======================>......] - ETA: 0s - loss: 0.1285 - accuracy: 0.9314\n",
      "4595/5349 [========================>.....] - ETA: 0s - loss: 0.1285 - accuracy: 0.9313\n",
      "4762/5349 [=========================>....] - ETA: 0s - loss: 0.1284 - accuracy: 0.9313\n",
      "4941/5349 [==========================>...] - ETA: 0s - loss: 0.1285 - accuracy: 0.9312\n",
      "5118/5349 [===========================>..] - ETA: 0s - loss: 0.1285 - accuracy: 0.9312\n",
      "5304/5349 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9312\n",
      "5349/5349 [==============================] - 4s 714us/step - loss: 0.1285 - accuracy: 0.9312 - val_loss: 0.1236 - val_accuracy: 0.9331\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1113 - accuracy: 0.9300\n",
      " 172/5349 [..............................] - ETA: 3s - loss: 0.1233 - accuracy: 0.9337\n",
      " 352/5349 [>.............................] - ETA: 2s - loss: 0.1267 - accuracy: 0.9317\n",
      " 620/5349 [==>...........................] - ETA: 2s - loss: 0.1265 - accuracy: 0.9320\n",
      " 802/5349 [===>..........................] - ETA: 2s - loss: 0.1263 - accuracy: 0.9319\n",
      " 978/5349 [====>.........................] - ETA: 2s - loss: 0.1260 - accuracy: 0.9320\n",
      "1160/5349 [=====>........................] - ETA: 2s - loss: 0.1265 - accuracy: 0.9316\n",
      "1324/5349 [======>.......................] - ETA: 2s - loss: 0.1265 - accuracy: 0.9315\n",
      "1508/5349 [=======>......................] - ETA: 2s - loss: 0.1262 - accuracy: 0.9319\n",
      "1688/5349 [========>.....................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9322\n",
      "1867/5349 [=========>....................] - ETA: 1s - loss: 0.1257 - accuracy: 0.9322\n",
      "1958/5349 [=========>....................] - ETA: 1s - loss: 0.1261 - accuracy: 0.9320\n",
      "2114/5349 [==========>...................] - ETA: 1s - loss: 0.1262 - accuracy: 0.9320\n",
      "2265/5349 [===========>..................] - ETA: 1s - loss: 0.1263 - accuracy: 0.9318\n",
      "2429/5349 [============>.................] - ETA: 1s - loss: 0.1262 - accuracy: 0.9318\n",
      "2606/5349 [=============>................] - ETA: 1s - loss: 0.1261 - accuracy: 0.9321\n",
      "2784/5349 [==============>...............] - ETA: 1s - loss: 0.1262 - accuracy: 0.9319\n",
      "2962/5349 [===============>..............] - ETA: 1s - loss: 0.1263 - accuracy: 0.9320\n",
      "3140/5349 [================>.............] - ETA: 1s - loss: 0.1263 - accuracy: 0.9321\n",
      "3324/5349 [=================>............] - ETA: 1s - loss: 0.1261 - accuracy: 0.9322\n",
      "3414/5349 [==================>...........] - ETA: 1s - loss: 0.1260 - accuracy: 0.9322\n",
      "3592/5349 [===================>..........] - ETA: 1s - loss: 0.1263 - accuracy: 0.9322\n",
      "3775/5349 [====================>.........] - ETA: 0s - loss: 0.1262 - accuracy: 0.9321\n",
      "3940/5349 [=====================>........] - ETA: 0s - loss: 0.1261 - accuracy: 0.9323\n",
      "4117/5349 [======================>.......] - ETA: 0s - loss: 0.1261 - accuracy: 0.9323\n",
      "4295/5349 [=======================>......] - ETA: 0s - loss: 0.1261 - accuracy: 0.9323\n",
      "4474/5349 [========================>.....] - ETA: 0s - loss: 0.1260 - accuracy: 0.9324\n",
      "4566/5349 [========================>.....] - ETA: 0s - loss: 0.1260 - accuracy: 0.9324\n",
      "4745/5349 [=========================>....] - ETA: 0s - loss: 0.1258 - accuracy: 0.9325\n",
      "4926/5349 [==========================>...] - ETA: 0s - loss: 0.1256 - accuracy: 0.9326\n",
      "5104/5349 [===========================>..] - ETA: 0s - loss: 0.1255 - accuracy: 0.9327\n",
      "5286/5349 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9327\n",
      "5349/5349 [==============================] - 5s 998us/step - loss: 0.1254 - accuracy: 0.9327 - val_loss: 0.1229 - val_accuracy: 0.9329\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 1:27 - loss: 0.2050 - accuracy: 0.8500\n",
      "  36/5349 [..............................] - ETA: 15s - loss: 0.1193 - accuracy: 0.9344\n",
      "  64/5349 [..............................] - ETA: 17s - loss: 0.1184 - accuracy: 0.9359\n",
      "  99/5349 [..............................] - ETA: 16s - loss: 0.1210 - accuracy: 0.9341\n",
      " 131/5349 [..............................] - ETA: 16s - loss: 0.1216 - accuracy: 0.9345\n",
      " 149/5349 [..............................] - ETA: 16s - loss: 0.1219 - accuracy: 0.9340\n",
      " 198/5349 [>.............................] - ETA: 14s - loss: 0.1231 - accuracy: 0.9332\n",
      " 231/5349 [>.............................] - ETA: 15s - loss: 0.1220 - accuracy: 0.9341\n",
      " 287/5349 [>.............................] - ETA: 13s - loss: 0.1213 - accuracy: 0.9352\n",
      " 337/5349 [>.............................] - ETA: 13s - loss: 0.1228 - accuracy: 0.9333\n",
      " 385/5349 [=>............................] - ETA: 12s - loss: 0.1240 - accuracy: 0.9328\n",
      " 465/5349 [=>............................] - ETA: 11s - loss: 0.1240 - accuracy: 0.9329\n",
      " 520/5349 [=>............................] - ETA: 11s - loss: 0.1231 - accuracy: 0.9332\n",
      " 571/5349 [==>...........................] - ETA: 11s - loss: 0.1233 - accuracy: 0.9332\n",
      " 705/5349 [==>...........................] - ETA: 9s - loss: 0.1235 - accuracy: 0.9331 \n",
      " 860/5349 [===>..........................] - ETA: 8s - loss: 0.1230 - accuracy: 0.9336\n",
      "1029/5349 [====>.........................] - ETA: 6s - loss: 0.1233 - accuracy: 0.9336\n",
      "1208/5349 [=====>........................] - ETA: 5s - loss: 0.1230 - accuracy: 0.9341\n",
      "1366/5349 [======>.......................] - ETA: 5s - loss: 0.1232 - accuracy: 0.9339\n",
      "1537/5349 [=======>......................] - ETA: 4s - loss: 0.1234 - accuracy: 0.9339\n",
      "1811/5349 [=========>....................] - ETA: 4s - loss: 0.1232 - accuracy: 0.9340\n",
      "1998/5349 [==========>...................] - ETA: 3s - loss: 0.1237 - accuracy: 0.9336\n",
      "2181/5349 [===========>..................] - ETA: 3s - loss: 0.1239 - accuracy: 0.9336\n",
      "2353/5349 [============>.................] - ETA: 3s - loss: 0.1238 - accuracy: 0.9336\n",
      "2519/5349 [=============>................] - ETA: 2s - loss: 0.1236 - accuracy: 0.9338\n",
      "2697/5349 [==============>...............] - ETA: 2s - loss: 0.1234 - accuracy: 0.9339\n",
      "2878/5349 [===============>..............] - ETA: 2s - loss: 0.1235 - accuracy: 0.9339\n",
      "3061/5349 [================>.............] - ETA: 2s - loss: 0.1235 - accuracy: 0.9339\n",
      "3152/5349 [================>.............] - ETA: 1s - loss: 0.1235 - accuracy: 0.9338\n",
      "3332/5349 [=================>............] - ETA: 1s - loss: 0.1234 - accuracy: 0.9339\n",
      "3511/5349 [==================>...........] - ETA: 1s - loss: 0.1234 - accuracy: 0.9339\n",
      "3679/5349 [===================>..........] - ETA: 1s - loss: 0.1233 - accuracy: 0.9340\n",
      "3857/5349 [====================>.........] - ETA: 1s - loss: 0.1231 - accuracy: 0.9340\n",
      "4033/5349 [=====================>........] - ETA: 1s - loss: 0.1229 - accuracy: 0.9341\n",
      "4306/5349 [=======================>......] - ETA: 0s - loss: 0.1231 - accuracy: 0.9340\n",
      "4483/5349 [========================>.....] - ETA: 0s - loss: 0.1231 - accuracy: 0.9339\n",
      "4664/5349 [=========================>....] - ETA: 0s - loss: 0.1231 - accuracy: 0.9339\n",
      "4844/5349 [==========================>...] - ETA: 0s - loss: 0.1233 - accuracy: 0.9338\n",
      "5008/5349 [===========================>..] - ETA: 0s - loss: 0.1233 - accuracy: 0.9337\n",
      "5189/5349 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9336\n",
      "5278/5349 [============================>.] - ETA: 0s - loss: 0.1234 - accuracy: 0.9336\n",
      "5349/5349 [==============================] - 5s 920us/step - loss: 0.1234 - accuracy: 0.9336 - val_loss: 0.1220 - val_accuracy: 0.9346\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 7/20\n",
      "  90/5349 [..............................] - ETA: 2s - loss: 0.1244 - accuracy: 0.9282\n",
      " 273/5349 [>.............................] - ETA: 2s - loss: 0.1247 - accuracy: 0.9314\n",
      " 452/5349 [=>............................] - ETA: 2s - loss: 0.1238 - accuracy: 0.9322\n",
      " 635/5349 [==>...........................] - ETA: 2s - loss: 0.1235 - accuracy: 0.9326\n",
      " 820/5349 [===>..........................] - ETA: 2s - loss: 0.1237 - accuracy: 0.9327\n",
      " 986/5349 [====>.........................] - ETA: 2s - loss: 0.1231 - accuracy: 0.9333\n",
      "1171/5349 [=====>........................] - ETA: 2s - loss: 0.1230 - accuracy: 0.9333\n",
      "1349/5349 [======>.......................] - ETA: 2s - loss: 0.1226 - accuracy: 0.9337\n",
      "1622/5349 [========>.....................] - ETA: 2s - loss: 0.1219 - accuracy: 0.9339\n",
      "1804/5349 [=========>....................] - ETA: 1s - loss: 0.1221 - accuracy: 0.9339\n",
      "1991/5349 [==========>...................] - ETA: 1s - loss: 0.1221 - accuracy: 0.9339\n",
      "2171/5349 [===========>..................] - ETA: 1s - loss: 0.1220 - accuracy: 0.9339\n",
      "2356/5349 [============>.................] - ETA: 1s - loss: 0.1221 - accuracy: 0.9338\n",
      "2534/5349 [=============>................] - ETA: 1s - loss: 0.1222 - accuracy: 0.9338\n",
      "2717/5349 [==============>...............] - ETA: 1s - loss: 0.1223 - accuracy: 0.9338\n",
      "2897/5349 [===============>..............] - ETA: 1s - loss: 0.1222 - accuracy: 0.9338\n",
      "2990/5349 [===============>..............] - ETA: 1s - loss: 0.1222 - accuracy: 0.9338\n",
      "3173/5349 [================>.............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9336\n",
      "3353/5349 [=================>............] - ETA: 1s - loss: 0.1226 - accuracy: 0.9335\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1227 - accuracy: 0.9335\n",
      "3699/5349 [===================>..........] - ETA: 0s - loss: 0.1226 - accuracy: 0.9336\n",
      "3883/5349 [====================>.........] - ETA: 0s - loss: 0.1222 - accuracy: 0.9339\n",
      "4064/5349 [=====================>........] - ETA: 0s - loss: 0.1223 - accuracy: 0.9338\n",
      "4251/5349 [======================>.......] - ETA: 0s - loss: 0.1221 - accuracy: 0.9340\n",
      "4431/5349 [=======================>......] - ETA: 0s - loss: 0.1221 - accuracy: 0.9340\n",
      "4707/5349 [=========================>....] - ETA: 0s - loss: 0.1221 - accuracy: 0.9340\n",
      "4890/5349 [==========================>...] - ETA: 0s - loss: 0.1220 - accuracy: 0.9341\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.1220 - accuracy: 0.9341\n",
      "5253/5349 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9341\n",
      "5344/5349 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9341\n",
      "5349/5349 [==============================] - 4s 711us/step - loss: 0.1221 - accuracy: 0.9341 - val_loss: 0.1309 - val_accuracy: 0.9325\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 8/20\n",
      "  90/5349 [..............................] - ETA: 2s - loss: 0.1216 - accuracy: 0.9336\n",
      " 275/5349 [>.............................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9359\n",
      " 548/5349 [==>...........................] - ETA: 2s - loss: 0.1188 - accuracy: 0.9349\n",
      " 717/5349 [===>..........................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9349\n",
      " 900/5349 [====>.........................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9349\n",
      "1080/5349 [=====>........................] - ETA: 2s - loss: 0.1204 - accuracy: 0.9346\n",
      "1268/5349 [======>.......................] - ETA: 2s - loss: 0.1217 - accuracy: 0.9337\n",
      "1542/5349 [=======>......................] - ETA: 2s - loss: 0.1213 - accuracy: 0.9341\n",
      "1724/5349 [========>.....................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9337\n",
      "1907/5349 [=========>....................] - ETA: 1s - loss: 0.1216 - accuracy: 0.9337\n",
      "2093/5349 [==========>...................] - ETA: 1s - loss: 0.1216 - accuracy: 0.9341\n",
      "2243/5349 [===========>..................] - ETA: 1s - loss: 0.1216 - accuracy: 0.9340\n",
      "2517/5349 [=============>................] - ETA: 1s - loss: 0.1214 - accuracy: 0.9341\n",
      "2696/5349 [==============>...............] - ETA: 1s - loss: 0.1215 - accuracy: 0.9341\n",
      "2858/5349 [===============>..............] - ETA: 1s - loss: 0.1215 - accuracy: 0.9342\n",
      "3037/5349 [================>.............] - ETA: 1s - loss: 0.1214 - accuracy: 0.9342\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1214 - accuracy: 0.9343\n",
      "3493/5349 [==================>...........] - ETA: 1s - loss: 0.1213 - accuracy: 0.9342\n",
      "3672/5349 [===================>..........] - ETA: 0s - loss: 0.1211 - accuracy: 0.9344\n",
      "3844/5349 [====================>.........] - ETA: 0s - loss: 0.1210 - accuracy: 0.9345\n",
      "3992/5349 [=====================>........] - ETA: 0s - loss: 0.1210 - accuracy: 0.9346\n",
      "4171/5349 [======================>.......] - ETA: 0s - loss: 0.1210 - accuracy: 0.9345\n",
      "4448/5349 [=======================>......] - ETA: 0s - loss: 0.1210 - accuracy: 0.9345\n",
      "4619/5349 [========================>.....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9346\n",
      "4774/5349 [=========================>....] - ETA: 0s - loss: 0.1212 - accuracy: 0.9344\n",
      "4921/5349 [==========================>...] - ETA: 0s - loss: 0.1210 - accuracy: 0.9345\n",
      "5095/5349 [===========================>..] - ETA: 0s - loss: 0.1209 - accuracy: 0.9345\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 0.9346\n",
      "5349/5349 [==============================] - 4s 819us/step - loss: 0.1209 - accuracy: 0.9346 - val_loss: 0.1168 - val_accuracy: 0.9382\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 9/20\n",
      "  86/5349 [..............................] - ETA: 3s - loss: 0.1183 - accuracy: 0.9337\n",
      " 357/5349 [=>............................] - ETA: 2s - loss: 0.1192 - accuracy: 0.9354\n",
      " 459/5349 [=>............................] - ETA: 3s - loss: 0.1186 - accuracy: 0.9358\n",
      " 523/5349 [=>............................] - ETA: 3s - loss: 0.1185 - accuracy: 0.9359\n",
      " 597/5349 [==>...........................] - ETA: 4s - loss: 0.1184 - accuracy: 0.9364\n",
      " 698/5349 [==>...........................] - ETA: 4s - loss: 0.1196 - accuracy: 0.9353\n",
      " 762/5349 [===>..........................] - ETA: 4s - loss: 0.1199 - accuracy: 0.9353\n",
      " 812/5349 [===>..........................] - ETA: 4s - loss: 0.1204 - accuracy: 0.9348\n",
      " 865/5349 [===>..........................] - ETA: 5s - loss: 0.1204 - accuracy: 0.9348\n",
      " 917/5349 [====>.........................] - ETA: 5s - loss: 0.1204 - accuracy: 0.9348\n",
      " 977/5349 [====>.........................] - ETA: 5s - loss: 0.1204 - accuracy: 0.9347\n",
      "1038/5349 [====>.........................] - ETA: 5s - loss: 0.1203 - accuracy: 0.9349\n",
      "1059/5349 [====>.........................] - ETA: 5s - loss: 0.1200 - accuracy: 0.9351\n",
      "1101/5349 [=====>........................] - ETA: 5s - loss: 0.1199 - accuracy: 0.9353\n",
      "1148/5349 [=====>........................] - ETA: 5s - loss: 0.1200 - accuracy: 0.9351\n",
      "1192/5349 [=====>........................] - ETA: 5s - loss: 0.1201 - accuracy: 0.9350\n",
      "1247/5349 [=====>........................] - ETA: 5s - loss: 0.1202 - accuracy: 0.9349\n",
      "1317/5349 [======>.......................] - ETA: 5s - loss: 0.1202 - accuracy: 0.9348\n",
      "1355/5349 [======>.......................] - ETA: 5s - loss: 0.1202 - accuracy: 0.9347\n",
      "1389/5349 [======>.......................] - ETA: 6s - loss: 0.1205 - accuracy: 0.9345\n",
      "1423/5349 [======>.......................] - ETA: 6s - loss: 0.1205 - accuracy: 0.9346\n",
      "1465/5349 [=======>......................] - ETA: 6s - loss: 0.1207 - accuracy: 0.9345\n",
      "1491/5349 [=======>......................] - ETA: 6s - loss: 0.1206 - accuracy: 0.9346\n",
      "1546/5349 [=======>......................] - ETA: 6s - loss: 0.1209 - accuracy: 0.9345\n",
      "1611/5349 [========>.....................] - ETA: 5s - loss: 0.1211 - accuracy: 0.9343\n",
      "1665/5349 [========>.....................] - ETA: 5s - loss: 0.1210 - accuracy: 0.9344\n",
      "1719/5349 [========>.....................] - ETA: 5s - loss: 0.1209 - accuracy: 0.9344\n",
      "1870/5349 [=========>....................] - ETA: 5s - loss: 0.1209 - accuracy: 0.9346\n",
      "2032/5349 [==========>...................] - ETA: 4s - loss: 0.1211 - accuracy: 0.9345\n",
      "2280/5349 [===========>..................] - ETA: 4s - loss: 0.1205 - accuracy: 0.9347\n",
      "2466/5349 [============>.................] - ETA: 3s - loss: 0.1206 - accuracy: 0.9347\n",
      "2656/5349 [=============>................] - ETA: 3s - loss: 0.1205 - accuracy: 0.9347\n",
      "2825/5349 [==============>...............] - ETA: 3s - loss: 0.1205 - accuracy: 0.9347\n",
      "3098/5349 [================>.............] - ETA: 2s - loss: 0.1204 - accuracy: 0.9348\n",
      "3287/5349 [=================>............] - ETA: 2s - loss: 0.1202 - accuracy: 0.9348\n",
      "3477/5349 [==================>...........] - ETA: 2s - loss: 0.1200 - accuracy: 0.9350\n",
      "3668/5349 [===================>..........] - ETA: 1s - loss: 0.1200 - accuracy: 0.9350\n",
      "3839/5349 [====================>.........] - ETA: 1s - loss: 0.1200 - accuracy: 0.9351\n",
      "4019/5349 [=====================>........] - ETA: 1s - loss: 0.1200 - accuracy: 0.9351\n",
      "4275/5349 [======================>.......] - ETA: 1s - loss: 0.1202 - accuracy: 0.9350\n",
      "4457/5349 [=======================>......] - ETA: 0s - loss: 0.1202 - accuracy: 0.9350\n",
      "4641/5349 [=========================>....] - ETA: 0s - loss: 0.1200 - accuracy: 0.9351\n",
      "4824/5349 [==========================>...] - ETA: 0s - loss: 0.1198 - accuracy: 0.9353\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.1198 - accuracy: 0.9352\n",
      "5280/5349 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9352\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1198 - accuracy: 0.9352 - val_loss: 0.1159 - val_accuracy: 0.9364\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 10/20\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1198 - accuracy: 0.9364\n",
      " 177/5349 [..............................] - ETA: 2s - loss: 0.1210 - accuracy: 0.9354\n",
      " 360/5349 [=>............................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9355\n",
      " 541/5349 [==>...........................] - ETA: 2s - loss: 0.1218 - accuracy: 0.9333\n",
      " 620/5349 [==>...........................] - ETA: 2s - loss: 0.1212 - accuracy: 0.9336\n",
      " 643/5349 [==>...........................] - ETA: 3s - loss: 0.1213 - accuracy: 0.9334\n",
      " 731/5349 [===>..........................] - ETA: 3s - loss: 0.1211 - accuracy: 0.9339\n",
      " 879/5349 [===>..........................] - ETA: 3s - loss: 0.1210 - accuracy: 0.9339\n",
      "1041/5349 [====>.........................] - ETA: 3s - loss: 0.1209 - accuracy: 0.9338\n",
      "1213/5349 [=====>........................] - ETA: 2s - loss: 0.1212 - accuracy: 0.9339\n",
      "1398/5349 [======>.......................] - ETA: 2s - loss: 0.1207 - accuracy: 0.9343\n",
      "1673/5349 [========>.....................] - ETA: 2s - loss: 0.1204 - accuracy: 0.9344\n",
      "1854/5349 [=========>....................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9345\n",
      "2036/5349 [==========>...................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9345\n",
      "2193/5349 [===========>..................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9345\n",
      "2336/5349 [============>.................] - ETA: 1s - loss: 0.1200 - accuracy: 0.9347\n",
      "2494/5349 [============>.................] - ETA: 1s - loss: 0.1202 - accuracy: 0.9346\n",
      "2745/5349 [==============>...............] - ETA: 1s - loss: 0.1200 - accuracy: 0.9349\n",
      "2920/5349 [===============>..............] - ETA: 1s - loss: 0.1199 - accuracy: 0.9350\n",
      "3086/5349 [================>.............] - ETA: 1s - loss: 0.1198 - accuracy: 0.9350\n",
      "3262/5349 [=================>............] - ETA: 1s - loss: 0.1197 - accuracy: 0.9349\n",
      "3440/5349 [==================>...........] - ETA: 1s - loss: 0.1198 - accuracy: 0.9349\n",
      "3709/5349 [===================>..........] - ETA: 1s - loss: 0.1195 - accuracy: 0.9351\n",
      "3886/5349 [====================>.........] - ETA: 0s - loss: 0.1195 - accuracy: 0.9351\n",
      "4063/5349 [=====================>........] - ETA: 0s - loss: 0.1196 - accuracy: 0.9351\n",
      "4242/5349 [======================>.......] - ETA: 0s - loss: 0.1194 - accuracy: 0.9352\n",
      "4409/5349 [=======================>......] - ETA: 0s - loss: 0.1195 - accuracy: 0.9351\n",
      "4663/5349 [=========================>....] - ETA: 0s - loss: 0.1193 - accuracy: 0.9352\n",
      "4830/5349 [==========================>...] - ETA: 0s - loss: 0.1194 - accuracy: 0.9351\n",
      "5009/5349 [===========================>..] - ETA: 0s - loss: 0.1195 - accuracy: 0.9351\n",
      "5186/5349 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.9352\n",
      "5331/5349 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9351\n",
      "5349/5349 [==============================] - 4s 778us/step - loss: 0.1194 - accuracy: 0.9351 - val_loss: 0.1150 - val_accuracy: 0.9367\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1078 - accuracy: 0.9500\n",
      " 268/5349 [>.............................] - ETA: 2s - loss: 0.1191 - accuracy: 0.9343\n",
      " 453/5349 [=>............................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9343\n",
      " 633/5349 [==>...........................] - ETA: 2s - loss: 0.1204 - accuracy: 0.9341\n",
      " 814/5349 [===>..........................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9345\n",
      " 993/5349 [====>.........................] - ETA: 2s - loss: 0.1196 - accuracy: 0.9350\n",
      "1260/5349 [======>.......................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9352\n",
      "1446/5349 [=======>......................] - ETA: 2s - loss: 0.1196 - accuracy: 0.9352\n",
      "1631/5349 [========>.....................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9349\n",
      "1809/5349 [=========>....................] - ETA: 1s - loss: 0.1196 - accuracy: 0.9350\n",
      "1991/5349 [==========>...................] - ETA: 1s - loss: 0.1196 - accuracy: 0.9350\n",
      "2267/5349 [===========>..................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9353\n",
      "2451/5349 [============>.................] - ETA: 1s - loss: 0.1192 - accuracy: 0.9355\n",
      "2636/5349 [=============>................] - ETA: 1s - loss: 0.1190 - accuracy: 0.9356\n",
      "2819/5349 [==============>...............] - ETA: 1s - loss: 0.1189 - accuracy: 0.9357\n",
      "3002/5349 [===============>..............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9357\n",
      "3268/5349 [=================>............] - ETA: 1s - loss: 0.1188 - accuracy: 0.9357\n",
      "3452/5349 [==================>...........] - ETA: 1s - loss: 0.1188 - accuracy: 0.9358\n",
      "3637/5349 [===================>..........] - ETA: 0s - loss: 0.1187 - accuracy: 0.9358\n",
      "3818/5349 [====================>.........] - ETA: 0s - loss: 0.1188 - accuracy: 0.9358\n",
      "4091/5349 [=====================>........] - ETA: 0s - loss: 0.1188 - accuracy: 0.9358\n",
      "4270/5349 [======================>.......] - ETA: 0s - loss: 0.1188 - accuracy: 0.9357\n",
      "4454/5349 [=======================>......] - ETA: 0s - loss: 0.1186 - accuracy: 0.9359\n",
      "4637/5349 [=========================>....] - ETA: 0s - loss: 0.1185 - accuracy: 0.9360\n",
      "4822/5349 [==========================>...] - ETA: 0s - loss: 0.1187 - accuracy: 0.9357\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.1187 - accuracy: 0.9358\n",
      "5098/5349 [===========================>..] - ETA: 0s - loss: 0.1187 - accuracy: 0.9359\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1186 - accuracy: 0.9358\n",
      "5349/5349 [==============================] - 4s 712us/step - loss: 0.1187 - accuracy: 0.9358 - val_loss: 0.1163 - val_accuracy: 0.9354\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 12/20\n",
      "  87/5349 [..............................] - ETA: 3s - loss: 0.1249 - accuracy: 0.9310\n",
      " 334/5349 [>.............................] - ETA: 3s - loss: 0.1171 - accuracy: 0.9366\n",
      " 513/5349 [=>............................] - ETA: 2s - loss: 0.1175 - accuracy: 0.9351\n",
      " 695/5349 [==>...........................] - ETA: 2s - loss: 0.1181 - accuracy: 0.9350\n",
      " 878/5349 [===>..........................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9353\n",
      "1063/5349 [====>.........................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9353\n",
      "1340/5349 [======>.......................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9354\n",
      "1522/5349 [=======>......................] - ETA: 2s - loss: 0.1185 - accuracy: 0.9354\n",
      "1704/5349 [========>.....................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9356\n",
      "1882/5349 [=========>....................] - ETA: 1s - loss: 0.1189 - accuracy: 0.9355\n",
      "2155/5349 [===========>..................] - ETA: 1s - loss: 0.1187 - accuracy: 0.9355\n",
      "2334/5349 [============>.................] - ETA: 1s - loss: 0.1189 - accuracy: 0.9355\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.1188 - accuracy: 0.9355\n",
      "2705/5349 [==============>...............] - ETA: 1s - loss: 0.1187 - accuracy: 0.9355\n",
      "2884/5349 [===============>..............] - ETA: 1s - loss: 0.1187 - accuracy: 0.9354\n",
      "3068/5349 [================>.............] - ETA: 1s - loss: 0.1186 - accuracy: 0.9354\n",
      "3250/5349 [=================>............] - ETA: 1s - loss: 0.1186 - accuracy: 0.9355\n",
      "3342/5349 [=================>............] - ETA: 1s - loss: 0.1186 - accuracy: 0.9355\n",
      "3518/5349 [==================>...........] - ETA: 1s - loss: 0.1184 - accuracy: 0.9356\n",
      "3631/5349 [===================>..........] - ETA: 0s - loss: 0.1182 - accuracy: 0.9357\n",
      "3739/5349 [===================>..........] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "3888/5349 [====================>.........] - ETA: 0s - loss: 0.1181 - accuracy: 0.9359\n",
      "4029/5349 [=====================>........] - ETA: 0s - loss: 0.1180 - accuracy: 0.9359\n",
      "4092/5349 [=====================>........] - ETA: 0s - loss: 0.1180 - accuracy: 0.9359\n",
      "4132/5349 [======================>.......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "4177/5349 [======================>.......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "4250/5349 [======================>.......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "4299/5349 [=======================>......] - ETA: 0s - loss: 0.1180 - accuracy: 0.9360\n",
      "4400/5349 [=======================>......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9360\n",
      "4459/5349 [========================>.....] - ETA: 0s - loss: 0.1181 - accuracy: 0.9359\n",
      "4515/5349 [========================>.....] - ETA: 0s - loss: 0.1181 - accuracy: 0.9358\n",
      "4577/5349 [========================>.....] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "4670/5349 [=========================>....] - ETA: 0s - loss: 0.1180 - accuracy: 0.9359\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.1180 - accuracy: 0.9360\n",
      "4761/5349 [=========================>....] - ETA: 0s - loss: 0.1180 - accuracy: 0.9360\n",
      "4842/5349 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.9360\n",
      "4915/5349 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.9360\n",
      "5005/5349 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 0.9360\n",
      "5073/5349 [===========================>..] - ETA: 0s - loss: 0.1181 - accuracy: 0.9359\n",
      "5167/5349 [===========================>..] - ETA: 0s - loss: 0.1182 - accuracy: 0.9359\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 0.9358\n",
      "5349/5349 [==============================] - 5s 973us/step - loss: 0.1181 - accuracy: 0.9359 - val_loss: 0.1159 - val_accuracy: 0.9357\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 13/20\n",
      "  68/5349 [..............................] - ETA: 3s - loss: 0.1095 - accuracy: 0.9413\n",
      " 162/5349 [..............................] - ETA: 4s - loss: 0.1151 - accuracy: 0.9374\n",
      " 194/5349 [>.............................] - ETA: 5s - loss: 0.1150 - accuracy: 0.9367\n",
      " 234/5349 [>.............................] - ETA: 6s - loss: 0.1157 - accuracy: 0.9364\n",
      " 281/5349 [>.............................] - ETA: 7s - loss: 0.1160 - accuracy: 0.9362\n",
      " 341/5349 [>.............................] - ETA: 7s - loss: 0.1155 - accuracy: 0.9374\n",
      " 408/5349 [=>............................] - ETA: 7s - loss: 0.1173 - accuracy: 0.9362\n",
      " 466/5349 [=>............................] - ETA: 7s - loss: 0.1171 - accuracy: 0.9362\n",
      " 529/5349 [=>............................] - ETA: 7s - loss: 0.1169 - accuracy: 0.9362\n",
      " 579/5349 [==>...........................] - ETA: 7s - loss: 0.1167 - accuracy: 0.9362\n",
      " 616/5349 [==>...........................] - ETA: 7s - loss: 0.1168 - accuracy: 0.9362\n",
      " 668/5349 [==>...........................] - ETA: 7s - loss: 0.1171 - accuracy: 0.9361\n",
      " 702/5349 [==>...........................] - ETA: 7s - loss: 0.1171 - accuracy: 0.9363\n",
      " 744/5349 [===>..........................] - ETA: 7s - loss: 0.1172 - accuracy: 0.9360\n",
      " 803/5349 [===>..........................] - ETA: 7s - loss: 0.1175 - accuracy: 0.9359\n",
      " 848/5349 [===>..........................] - ETA: 7s - loss: 0.1177 - accuracy: 0.9359\n",
      " 912/5349 [====>.........................] - ETA: 7s - loss: 0.1180 - accuracy: 0.9359\n",
      " 965/5349 [====>.........................] - ETA: 7s - loss: 0.1183 - accuracy: 0.9357\n",
      "1027/5349 [====>.........................] - ETA: 7s - loss: 0.1181 - accuracy: 0.9359\n",
      "1122/5349 [=====>........................] - ETA: 7s - loss: 0.1183 - accuracy: 0.9357\n",
      "1294/5349 [======>.......................] - ETA: 6s - loss: 0.1180 - accuracy: 0.9360\n",
      "1551/5349 [=======>......................] - ETA: 5s - loss: 0.1171 - accuracy: 0.9366\n",
      "1741/5349 [========>.....................] - ETA: 4s - loss: 0.1172 - accuracy: 0.9366\n",
      "1935/5349 [=========>....................] - ETA: 4s - loss: 0.1173 - accuracy: 0.9366\n",
      "2063/5349 [==========>...................] - ETA: 3s - loss: 0.1170 - accuracy: 0.9368\n",
      "2240/5349 [===========>..................] - ETA: 3s - loss: 0.1173 - accuracy: 0.9367\n",
      "2401/5349 [============>.................] - ETA: 3s - loss: 0.1174 - accuracy: 0.9366\n",
      "2571/5349 [=============>................] - ETA: 3s - loss: 0.1177 - accuracy: 0.9364\n",
      "2677/5349 [==============>...............] - ETA: 2s - loss: 0.1178 - accuracy: 0.9362\n",
      "2779/5349 [==============>...............] - ETA: 2s - loss: 0.1177 - accuracy: 0.9363\n",
      "2900/5349 [===============>..............] - ETA: 2s - loss: 0.1180 - accuracy: 0.9361\n",
      "3051/5349 [================>.............] - ETA: 2s - loss: 0.1178 - accuracy: 0.9362\n",
      "3145/5349 [================>.............] - ETA: 2s - loss: 0.1178 - accuracy: 0.9362\n",
      "3215/5349 [=================>............] - ETA: 2s - loss: 0.1179 - accuracy: 0.9362\n",
      "3357/5349 [=================>............] - ETA: 2s - loss: 0.1179 - accuracy: 0.9360\n",
      "3499/5349 [==================>...........] - ETA: 1s - loss: 0.1178 - accuracy: 0.9361\n",
      "3649/5349 [===================>..........] - ETA: 1s - loss: 0.1179 - accuracy: 0.9360\n",
      "3780/5349 [====================>.........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9360\n",
      "3897/5349 [====================>.........] - ETA: 1s - loss: 0.1178 - accuracy: 0.9362\n",
      "4009/5349 [=====================>........] - ETA: 1s - loss: 0.1178 - accuracy: 0.9363\n",
      "4194/5349 [======================>.......] - ETA: 1s - loss: 0.1176 - accuracy: 0.9364\n",
      "4330/5349 [=======================>......] - ETA: 1s - loss: 0.1175 - accuracy: 0.9364\n",
      "4467/5349 [========================>.....] - ETA: 0s - loss: 0.1175 - accuracy: 0.9364\n",
      "4605/5349 [========================>.....] - ETA: 0s - loss: 0.1175 - accuracy: 0.9364\n",
      "4739/5349 [=========================>....] - ETA: 0s - loss: 0.1174 - accuracy: 0.9364\n",
      "4880/5349 [==========================>...] - ETA: 0s - loss: 0.1173 - accuracy: 0.9365\n",
      "5080/5349 [===========================>..] - ETA: 0s - loss: 0.1174 - accuracy: 0.9364\n",
      "5219/5349 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9364\n",
      "5349/5349 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9364\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1173 - accuracy: 0.9364 - val_loss: 0.1126 - val_accuracy: 0.9404\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1089 - accuracy: 0.9600\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1200 - accuracy: 0.9341\n",
      " 335/5349 [>.............................] - ETA: 3s - loss: 0.1187 - accuracy: 0.9359\n",
      " 500/5349 [=>............................] - ETA: 2s - loss: 0.1182 - accuracy: 0.9369\n",
      " 582/5349 [==>...........................] - ETA: 2s - loss: 0.1178 - accuracy: 0.9372\n",
      " 733/5349 [===>..........................] - ETA: 2s - loss: 0.1176 - accuracy: 0.9373\n",
      " 876/5349 [===>..........................] - ETA: 2s - loss: 0.1174 - accuracy: 0.9370\n",
      "1017/5349 [====>.........................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9375\n",
      "1115/5349 [=====>........................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9372\n",
      "1244/5349 [=====>........................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9371\n",
      "1389/5349 [======>.......................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9372\n",
      "1623/5349 [========>.....................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9370\n",
      "1774/5349 [========>.....................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9369\n",
      "1892/5349 [=========>....................] - ETA: 2s - loss: 0.1173 - accuracy: 0.9368\n",
      "2010/5349 [==========>...................] - ETA: 2s - loss: 0.1172 - accuracy: 0.9368\n",
      "2117/5349 [==========>...................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9368\n",
      "2204/5349 [===========>..................] - ETA: 2s - loss: 0.1170 - accuracy: 0.9367\n",
      "2323/5349 [============>.................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9368\n",
      "2507/5349 [=============>................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9367\n",
      "2643/5349 [=============>................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9367\n",
      "2761/5349 [==============>...............] - ETA: 1s - loss: 0.1170 - accuracy: 0.9366\n",
      "2896/5349 [===============>..............] - ETA: 1s - loss: 0.1170 - accuracy: 0.9367\n",
      "2966/5349 [===============>..............] - ETA: 1s - loss: 0.1169 - accuracy: 0.9368\n",
      "3043/5349 [================>.............] - ETA: 1s - loss: 0.1167 - accuracy: 0.9369\n",
      "3152/5349 [================>.............] - ETA: 1s - loss: 0.1166 - accuracy: 0.9370\n",
      "3285/5349 [=================>............] - ETA: 1s - loss: 0.1167 - accuracy: 0.9370\n",
      "3419/5349 [==================>...........] - ETA: 1s - loss: 0.1166 - accuracy: 0.9370\n",
      "3652/5349 [===================>..........] - ETA: 1s - loss: 0.1167 - accuracy: 0.9369\n",
      "3806/5349 [====================>.........] - ETA: 1s - loss: 0.1168 - accuracy: 0.9368\n",
      "3966/5349 [=====================>........] - ETA: 1s - loss: 0.1169 - accuracy: 0.9366\n",
      "4121/5349 [======================>.......] - ETA: 0s - loss: 0.1170 - accuracy: 0.9366\n",
      "4278/5349 [======================>.......] - ETA: 0s - loss: 0.1172 - accuracy: 0.9364\n",
      "4421/5349 [=======================>......] - ETA: 0s - loss: 0.1170 - accuracy: 0.9364\n",
      "4583/5349 [========================>.....] - ETA: 0s - loss: 0.1170 - accuracy: 0.9365\n",
      "4735/5349 [=========================>....] - ETA: 0s - loss: 0.1169 - accuracy: 0.9366\n",
      "4898/5349 [==========================>...] - ETA: 0s - loss: 0.1170 - accuracy: 0.9366\n",
      "5130/5349 [===========================>..] - ETA: 0s - loss: 0.1169 - accuracy: 0.9366\n",
      "5290/5349 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9366\n",
      "5349/5349 [==============================] - 5s 912us/step - loss: 0.1170 - accuracy: 0.9366 - val_loss: 0.1158 - val_accuracy: 0.9357\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 15/20\n",
      "  79/5349 [..............................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9396\n",
      " 223/5349 [>.............................] - ETA: 3s - loss: 0.1172 - accuracy: 0.9362\n",
      " 381/5349 [=>............................] - ETA: 3s - loss: 0.1190 - accuracy: 0.9345\n",
      " 535/5349 [==>...........................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9353\n",
      " 644/5349 [==>...........................] - ETA: 3s - loss: 0.1183 - accuracy: 0.9352\n",
      " 727/5349 [===>..........................] - ETA: 3s - loss: 0.1178 - accuracy: 0.9362\n",
      " 785/5349 [===>..........................] - ETA: 3s - loss: 0.1180 - accuracy: 0.9359\n",
      " 811/5349 [===>..........................] - ETA: 4s - loss: 0.1176 - accuracy: 0.9362\n",
      " 825/5349 [===>..........................] - ETA: 4s - loss: 0.1177 - accuracy: 0.9361\n",
      " 860/5349 [===>..........................] - ETA: 4s - loss: 0.1176 - accuracy: 0.9362\n",
      " 885/5349 [===>..........................] - ETA: 5s - loss: 0.1174 - accuracy: 0.9361\n",
      " 913/5349 [====>.........................] - ETA: 5s - loss: 0.1176 - accuracy: 0.9361\n",
      " 958/5349 [====>.........................] - ETA: 5s - loss: 0.1174 - accuracy: 0.9361\n",
      " 997/5349 [====>.........................] - ETA: 5s - loss: 0.1169 - accuracy: 0.9365\n",
      "1018/5349 [====>.........................] - ETA: 5s - loss: 0.1170 - accuracy: 0.9363\n",
      "1053/5349 [====>.........................] - ETA: 6s - loss: 0.1170 - accuracy: 0.9363\n",
      "1095/5349 [=====>........................] - ETA: 6s - loss: 0.1168 - accuracy: 0.9364\n",
      "1149/5349 [=====>........................] - ETA: 6s - loss: 0.1169 - accuracy: 0.9364\n",
      "1202/5349 [=====>........................] - ETA: 6s - loss: 0.1174 - accuracy: 0.9360\n",
      "1232/5349 [=====>........................] - ETA: 6s - loss: 0.1172 - accuracy: 0.9361\n",
      "1253/5349 [======>.......................] - ETA: 6s - loss: 0.1171 - accuracy: 0.9363\n",
      "1291/5349 [======>.......................] - ETA: 6s - loss: 0.1170 - accuracy: 0.9362\n",
      "1348/5349 [======>.......................] - ETA: 6s - loss: 0.1169 - accuracy: 0.9362\n",
      "1377/5349 [======>.......................] - ETA: 6s - loss: 0.1168 - accuracy: 0.9362\n",
      "1415/5349 [======>.......................] - ETA: 6s - loss: 0.1166 - accuracy: 0.9364\n",
      "1436/5349 [=======>......................] - ETA: 7s - loss: 0.1166 - accuracy: 0.9364\n",
      "1468/5349 [=======>......................] - ETA: 7s - loss: 0.1165 - accuracy: 0.9365\n",
      "1484/5349 [=======>......................] - ETA: 7s - loss: 0.1166 - accuracy: 0.9364\n",
      "1514/5349 [=======>......................] - ETA: 7s - loss: 0.1164 - accuracy: 0.9365\n",
      "1536/5349 [=======>......................] - ETA: 7s - loss: 0.1163 - accuracy: 0.9366\n",
      "1562/5349 [=======>......................] - ETA: 7s - loss: 0.1162 - accuracy: 0.9366\n",
      "1592/5349 [=======>......................] - ETA: 7s - loss: 0.1161 - accuracy: 0.9367\n",
      "1615/5349 [========>.....................] - ETA: 7s - loss: 0.1162 - accuracy: 0.9366\n",
      "1650/5349 [========>.....................] - ETA: 7s - loss: 0.1162 - accuracy: 0.9367\n",
      "1684/5349 [========>.....................] - ETA: 7s - loss: 0.1161 - accuracy: 0.9367\n",
      "1807/5349 [=========>....................] - ETA: 7s - loss: 0.1162 - accuracy: 0.9369\n",
      "1910/5349 [=========>....................] - ETA: 6s - loss: 0.1159 - accuracy: 0.9372\n",
      "2022/5349 [==========>...................] - ETA: 6s - loss: 0.1159 - accuracy: 0.9372\n",
      "2146/5349 [===========>..................] - ETA: 5s - loss: 0.1160 - accuracy: 0.9371\n",
      "2310/5349 [===========>..................] - ETA: 5s - loss: 0.1161 - accuracy: 0.9369\n",
      "2549/5349 [=============>................] - ETA: 4s - loss: 0.1160 - accuracy: 0.9368\n",
      "2683/5349 [==============>...............] - ETA: 4s - loss: 0.1161 - accuracy: 0.9368\n",
      "2843/5349 [==============>...............] - ETA: 3s - loss: 0.1159 - accuracy: 0.9368\n",
      "3013/5349 [===============>..............] - ETA: 3s - loss: 0.1160 - accuracy: 0.9369\n",
      "3179/5349 [================>.............] - ETA: 3s - loss: 0.1161 - accuracy: 0.9367\n",
      "3338/5349 [=================>............] - ETA: 2s - loss: 0.1160 - accuracy: 0.9368\n",
      "3495/5349 [==================>...........] - ETA: 2s - loss: 0.1160 - accuracy: 0.9368\n",
      "3722/5349 [===================>..........] - ETA: 2s - loss: 0.1162 - accuracy: 0.9368\n",
      "3867/5349 [====================>.........] - ETA: 1s - loss: 0.1162 - accuracy: 0.9368\n",
      "4022/5349 [=====================>........] - ETA: 1s - loss: 0.1164 - accuracy: 0.9367\n",
      "4174/5349 [======================>.......] - ETA: 1s - loss: 0.1164 - accuracy: 0.9367\n",
      "4325/5349 [=======================>......] - ETA: 1s - loss: 0.1165 - accuracy: 0.9367\n",
      "4472/5349 [========================>.....] - ETA: 1s - loss: 0.1163 - accuracy: 0.9369\n",
      "4619/5349 [========================>.....] - ETA: 0s - loss: 0.1163 - accuracy: 0.9368\n",
      "4829/5349 [==========================>...] - ETA: 0s - loss: 0.1163 - accuracy: 0.9369\n",
      "4959/5349 [==========================>...] - ETA: 0s - loss: 0.1163 - accuracy: 0.9368\n",
      "5105/5349 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.9368\n",
      "5257/5349 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9367\n",
      "5327/5349 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.9368\n",
      "5349/5349 [==============================] - 8s 2ms/step - loss: 0.1163 - accuracy: 0.9368 - val_loss: 0.1136 - val_accuracy: 0.9381\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.0936 - accuracy: 0.9300\n",
      " 153/5349 [..............................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9388\n",
      " 304/5349 [>.............................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9388\n",
      " 442/5349 [=>............................] - ETA: 3s - loss: 0.1138 - accuracy: 0.9388\n",
      " 592/5349 [==>...........................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9380\n",
      " 739/5349 [===>..........................] - ETA: 3s - loss: 0.1158 - accuracy: 0.9373\n",
      " 962/5349 [====>.........................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9370\n",
      "1110/5349 [=====>........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9374\n",
      "1263/5349 [======>.......................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9373\n",
      "1410/5349 [======>.......................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9371\n",
      "1570/5349 [=======>......................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9369\n",
      "1723/5349 [========>.....................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9371\n",
      "1881/5349 [=========>....................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9369\n",
      "2037/5349 [==========>...................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9369\n",
      "2197/5349 [===========>..................] - ETA: 2s - loss: 0.1168 - accuracy: 0.9368\n",
      "2276/5349 [===========>..................] - ETA: 2s - loss: 0.1166 - accuracy: 0.9370\n",
      "2432/5349 [============>.................] - ETA: 1s - loss: 0.1166 - accuracy: 0.9371\n",
      "2593/5349 [=============>................] - ETA: 1s - loss: 0.1167 - accuracy: 0.9370\n",
      "2738/5349 [==============>...............] - ETA: 1s - loss: 0.1167 - accuracy: 0.9369\n",
      "2896/5349 [===============>..............] - ETA: 1s - loss: 0.1165 - accuracy: 0.9370\n",
      "3055/5349 [================>.............] - ETA: 1s - loss: 0.1163 - accuracy: 0.9371\n",
      "3210/5349 [=================>............] - ETA: 1s - loss: 0.1164 - accuracy: 0.9370\n",
      "3364/5349 [=================>............] - ETA: 1s - loss: 0.1163 - accuracy: 0.9371\n",
      "3521/5349 [==================>...........] - ETA: 1s - loss: 0.1164 - accuracy: 0.9369\n",
      "3664/5349 [===================>..........] - ETA: 1s - loss: 0.1162 - accuracy: 0.9371\n",
      "3824/5349 [====================>.........] - ETA: 1s - loss: 0.1162 - accuracy: 0.9371\n",
      "3902/5349 [====================>.........] - ETA: 0s - loss: 0.1161 - accuracy: 0.9371\n",
      "4062/5349 [=====================>........] - ETA: 0s - loss: 0.1164 - accuracy: 0.9370\n",
      "4222/5349 [======================>.......] - ETA: 0s - loss: 0.1164 - accuracy: 0.9369\n",
      "4377/5349 [=======================>......] - ETA: 0s - loss: 0.1163 - accuracy: 0.9370\n",
      "4536/5349 [========================>.....] - ETA: 0s - loss: 0.1162 - accuracy: 0.9370\n",
      "4692/5349 [=========================>....] - ETA: 0s - loss: 0.1161 - accuracy: 0.9371\n",
      "4851/5349 [==========================>...] - ETA: 0s - loss: 0.1161 - accuracy: 0.9372\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.1161 - accuracy: 0.9371\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.1161 - accuracy: 0.9371\n",
      "5233/5349 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9371\n",
      "5304/5349 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9371\n",
      "5349/5349 [==============================] - 4s 834us/step - loss: 0.1160 - accuracy: 0.9371 - val_loss: 0.1140 - val_accuracy: 0.9375\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1724 - accuracy: 0.9000\n",
      " 158/5349 [..............................] - ETA: 3s - loss: 0.1132 - accuracy: 0.9381\n",
      " 315/5349 [>.............................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9366\n",
      " 473/5349 [=>............................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9363\n",
      " 634/5349 [==>...........................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9363\n",
      " 786/5349 [===>..........................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9372\n",
      " 934/5349 [====>.........................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9368\n",
      "1089/5349 [=====>........................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9371\n",
      "1248/5349 [=====>........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9373\n",
      "1391/5349 [======>.......................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9372\n",
      "1472/5349 [=======>......................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9369\n",
      "1629/5349 [========>.....................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9367\n",
      "1786/5349 [=========>....................] - ETA: 2s - loss: 0.1165 - accuracy: 0.9367\n",
      "1946/5349 [=========>....................] - ETA: 2s - loss: 0.1164 - accuracy: 0.9368\n",
      "2097/5349 [==========>...................] - ETA: 2s - loss: 0.1162 - accuracy: 0.9370\n",
      "2254/5349 [===========>..................] - ETA: 2s - loss: 0.1158 - accuracy: 0.9372\n",
      "2409/5349 [============>.................] - ETA: 1s - loss: 0.1158 - accuracy: 0.9372\n",
      "2570/5349 [=============>................] - ETA: 1s - loss: 0.1157 - accuracy: 0.9373\n",
      "2725/5349 [==============>...............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9373\n",
      "2886/5349 [===============>..............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9373\n",
      "2966/5349 [===============>..............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9372\n",
      "3123/5349 [================>.............] - ETA: 1s - loss: 0.1158 - accuracy: 0.9371\n",
      "3284/5349 [=================>............] - ETA: 1s - loss: 0.1157 - accuracy: 0.9373\n",
      "3438/5349 [==================>...........] - ETA: 1s - loss: 0.1155 - accuracy: 0.9374\n",
      "3599/5349 [===================>..........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9372\n",
      "3739/5349 [===================>..........] - ETA: 1s - loss: 0.1156 - accuracy: 0.9372\n",
      "3894/5349 [====================>.........] - ETA: 0s - loss: 0.1157 - accuracy: 0.9371\n",
      "4127/5349 [======================>.......] - ETA: 0s - loss: 0.1156 - accuracy: 0.9372\n",
      "4285/5349 [=======================>......] - ETA: 0s - loss: 0.1155 - accuracy: 0.9372\n",
      "4401/5349 [=======================>......] - ETA: 0s - loss: 0.1155 - accuracy: 0.9372\n",
      "4485/5349 [========================>.....] - ETA: 0s - loss: 0.1155 - accuracy: 0.9372\n",
      "4544/5349 [========================>.....] - ETA: 0s - loss: 0.1155 - accuracy: 0.9373\n",
      "4580/5349 [========================>.....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4603/5349 [========================>.....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9374\n",
      "4638/5349 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4649/5349 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4667/5349 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4682/5349 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4695/5349 [=========================>....] - ETA: 0s - loss: 0.1154 - accuracy: 0.9374\n",
      "4740/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4754/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "4767/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "4796/5349 [=========================>....] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "4817/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4825/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4843/5349 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4868/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4890/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4899/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4913/5349 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4937/5349 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4952/5349 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "4962/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4969/5349 [==========================>...] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "5011/5349 [===========================>..] - ETA: 0s - loss: 0.1154 - accuracy: 0.9374\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5033/5349 [===========================>..] - ETA: 0s - loss: 0.1154 - accuracy: 0.9374\n",
      "5047/5349 [===========================>..] - ETA: 0s - loss: 0.1154 - accuracy: 0.9373\n",
      "5072/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5078/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5097/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5122/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5141/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5158/5349 [===========================>..] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5183/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "5216/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9374\n",
      "5260/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "5285/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "5302/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9373\n",
      "5349/5349 [==============================] - 9s 2ms/step - loss: 0.1153 - accuracy: 0.9373 - val_loss: 0.1127 - val_accuracy: 0.9414\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1095 - accuracy: 0.9400\n",
      " 229/5349 [>.............................] - ETA: 3s - loss: 0.1142 - accuracy: 0.9371\n",
      " 384/5349 [=>............................] - ETA: 3s - loss: 0.1156 - accuracy: 0.9361\n",
      " 529/5349 [=>............................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9360\n",
      " 684/5349 [==>...........................] - ETA: 3s - loss: 0.1151 - accuracy: 0.9368\n",
      " 805/5349 [===>..........................] - ETA: 3s - loss: 0.1149 - accuracy: 0.9372\n",
      " 958/5349 [====>.........................] - ETA: 3s - loss: 0.1150 - accuracy: 0.9373\n",
      "1097/5349 [=====>........................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9379\n",
      "1256/5349 [======>.......................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9380\n",
      "1525/5349 [=======>......................] - ETA: 2s - loss: 0.1146 - accuracy: 0.9377\n",
      "1704/5349 [========>.....................] - ETA: 2s - loss: 0.1150 - accuracy: 0.9377\n",
      "1868/5349 [=========>....................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9377\n",
      "2047/5349 [==========>...................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9378\n",
      "2236/5349 [===========>..................] - ETA: 1s - loss: 0.1154 - accuracy: 0.9372\n",
      "2421/5349 [============>.................] - ETA: 1s - loss: 0.1154 - accuracy: 0.9373\n",
      "2708/5349 [==============>...............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9372\n",
      "2895/5349 [===============>..............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9374\n",
      "3070/5349 [================>.............] - ETA: 1s - loss: 0.1152 - accuracy: 0.9375\n",
      "3241/5349 [=================>............] - ETA: 1s - loss: 0.1151 - accuracy: 0.9374\n",
      "3513/5349 [==================>...........] - ETA: 1s - loss: 0.1152 - accuracy: 0.9374\n",
      "3703/5349 [===================>..........] - ETA: 0s - loss: 0.1152 - accuracy: 0.9375\n",
      "3895/5349 [====================>.........] - ETA: 0s - loss: 0.1152 - accuracy: 0.9374\n",
      "4085/5349 [=====================>........] - ETA: 0s - loss: 0.1151 - accuracy: 0.9374\n",
      "4277/5349 [======================>.......] - ETA: 0s - loss: 0.1151 - accuracy: 0.9374\n",
      "4469/5349 [========================>.....] - ETA: 0s - loss: 0.1151 - accuracy: 0.9374\n",
      "4713/5349 [=========================>....] - ETA: 0s - loss: 0.1152 - accuracy: 0.9373\n",
      "4878/5349 [==========================>...] - ETA: 0s - loss: 0.1152 - accuracy: 0.9373\n",
      "5060/5349 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9373\n",
      "5239/5349 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9374\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9374\n",
      "5349/5349 [==============================] - 4s 742us/step - loss: 0.1150 - accuracy: 0.9374 - val_loss: 0.1120 - val_accuracy: 0.9420\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1077 - accuracy: 0.9600\n",
      " 185/5349 [>.............................] - ETA: 2s - loss: 0.1126 - accuracy: 0.9392\n",
      " 368/5349 [=>............................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9388\n",
      " 549/5349 [==>...........................] - ETA: 2s - loss: 0.1143 - accuracy: 0.9373\n",
      " 732/5349 [===>..........................] - ETA: 2s - loss: 0.1141 - accuracy: 0.9373\n",
      " 905/5349 [====>.........................] - ETA: 2s - loss: 0.1138 - accuracy: 0.9377\n",
      "1088/5349 [=====>........................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9372\n",
      "1179/5349 [=====>........................] - ETA: 2s - loss: 0.1147 - accuracy: 0.9371\n",
      "1356/5349 [======>.......................] - ETA: 2s - loss: 0.1149 - accuracy: 0.9371\n",
      "1538/5349 [=======>......................] - ETA: 2s - loss: 0.1151 - accuracy: 0.9371\n",
      "1717/5349 [========>.....................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9370\n",
      "1903/5349 [=========>....................] - ETA: 1s - loss: 0.1150 - accuracy: 0.9371\n",
      "2085/5349 [==========>...................] - ETA: 1s - loss: 0.1148 - accuracy: 0.9374\n",
      "2344/5349 [============>.................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9372\n",
      "2523/5349 [=============>................] - ETA: 1s - loss: 0.1150 - accuracy: 0.9374\n",
      "2705/5349 [==============>...............] - ETA: 1s - loss: 0.1150 - accuracy: 0.9375\n",
      "2887/5349 [===============>..............] - ETA: 1s - loss: 0.1150 - accuracy: 0.9375\n",
      "3070/5349 [================>.............] - ETA: 1s - loss: 0.1151 - accuracy: 0.9374\n",
      "3249/5349 [=================>............] - ETA: 1s - loss: 0.1151 - accuracy: 0.9374\n",
      "3342/5349 [=================>............] - ETA: 1s - loss: 0.1151 - accuracy: 0.9373\n",
      "3521/5349 [==================>...........] - ETA: 1s - loss: 0.1151 - accuracy: 0.9372\n",
      "3700/5349 [===================>..........] - ETA: 0s - loss: 0.1152 - accuracy: 0.9371\n",
      "3866/5349 [====================>.........] - ETA: 0s - loss: 0.1150 - accuracy: 0.9373\n",
      "4046/5349 [=====================>........] - ETA: 0s - loss: 0.1149 - accuracy: 0.9374\n",
      "4227/5349 [======================>.......] - ETA: 0s - loss: 0.1148 - accuracy: 0.9374\n",
      "4495/5349 [========================>.....] - ETA: 0s - loss: 0.1147 - accuracy: 0.9374\n",
      "4676/5349 [=========================>....] - ETA: 0s - loss: 0.1148 - accuracy: 0.9373\n",
      "4857/5349 [==========================>...] - ETA: 0s - loss: 0.1148 - accuracy: 0.9373\n",
      "5036/5349 [===========================>..] - ETA: 0s - loss: 0.1148 - accuracy: 0.9373\n",
      "5216/5349 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9374\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9373\n",
      "5349/5349 [==============================] - 4s 713us/step - loss: 0.1146 - accuracy: 0.9374 - val_loss: 0.1124 - val_accuracy: 0.9394\n",
      "\u001B[36m(train_DNN pid=5853)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1345 - accuracy: 0.9400\n",
      " 185/5349 [>.............................] - ETA: 2s - loss: 0.1115 - accuracy: 0.9401\n",
      " 370/5349 [=>............................] - ETA: 2s - loss: 0.1116 - accuracy: 0.9395\n",
      " 550/5349 [==>...........................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9387\n",
      " 735/5349 [===>..........................] - ETA: 2s - loss: 0.1135 - accuracy: 0.9385\n",
      " 828/5349 [===>..........................] - ETA: 2s - loss: 0.1132 - accuracy: 0.9385\n",
      "1009/5349 [====>.........................] - ETA: 2s - loss: 0.1137 - accuracy: 0.9381\n",
      "1190/5349 [=====>........................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9384\n",
      "1368/5349 [======>.......................] - ETA: 2s - loss: 0.1132 - accuracy: 0.9384\n",
      "1553/5349 [=======>......................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9386\n",
      "1723/5349 [========>.....................] - ETA: 2s - loss: 0.1134 - accuracy: 0.9387\n",
      "1994/5349 [==========>...................] - ETA: 1s - loss: 0.1134 - accuracy: 0.9386\n",
      "2178/5349 [===========>..................] - ETA: 1s - loss: 0.1135 - accuracy: 0.9387\n",
      "2334/5349 [============>.................] - ETA: 1s - loss: 0.1138 - accuracy: 0.9385\n",
      "2485/5349 [============>.................] - ETA: 1s - loss: 0.1140 - accuracy: 0.9383\n",
      "2672/5349 [=============>................] - ETA: 1s - loss: 0.1143 - accuracy: 0.9380\n",
      "2946/5349 [===============>..............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9379\n",
      "3129/5349 [================>.............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9378\n",
      "3310/5349 [=================>............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9379\n",
      "3493/5349 [==================>...........] - ETA: 1s - loss: 0.1144 - accuracy: 0.9378\n",
      "3677/5349 [===================>..........] - ETA: 0s - loss: 0.1145 - accuracy: 0.9378\n",
      "3856/5349 [====================>.........] - ETA: 0s - loss: 0.1145 - accuracy: 0.9378\n",
      "4039/5349 [=====================>........] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "4311/5349 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "4494/5349 [========================>.....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "4658/5349 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "4844/5349 [==========================>...] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "5026/5349 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9380\n",
      "5114/5349 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "5294/5349 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9380\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 26:03 - loss: 0.8803 - accuracy: 0.3000\n",
      " 277/5349 [>.............................] - ETA: 2s - loss: 0.6884 - accuracy: 0.6590\n",
      " 501/5349 [=>............................] - ETA: 2s - loss: 0.6260 - accuracy: 0.7419\n",
      " 717/5349 [===>..........................] - ETA: 2s - loss: 0.5823 - accuracy: 0.7775\n",
      " 942/5349 [====>.........................] - ETA: 2s - loss: 0.5450 - accuracy: 0.8002\n",
      "1165/5349 [=====>........................] - ETA: 1s - loss: 0.5159 - accuracy: 0.8137\n",
      "1496/5349 [=======>......................] - ETA: 1s - loss: 0.4809 - accuracy: 0.8275\n",
      "1719/5349 [========>.....................] - ETA: 1s - loss: 0.4616 - accuracy: 0.8344\n",
      "1941/5349 [=========>....................] - ETA: 1s - loss: 0.4444 - accuracy: 0.8400\n",
      "2163/5349 [===========>..................] - ETA: 1s - loss: 0.4293 - accuracy: 0.8445\n",
      "2497/5349 [=============>................] - ETA: 1s - loss: 0.4101 - accuracy: 0.8497\n",
      "2720/5349 [==============>...............] - ETA: 1s - loss: 0.3988 - accuracy: 0.8526\n",
      "2941/5349 [===============>..............] - ETA: 1s - loss: 0.3884 - accuracy: 0.8554\n",
      "3165/5349 [================>.............] - ETA: 1s - loss: 0.3791 - accuracy: 0.8577\n",
      "3379/5349 [=================>............] - ETA: 0s - loss: 0.3708 - accuracy: 0.8599\n",
      "3525/5349 [==================>...........] - ETA: 0s - loss: 0.3656 - accuracy: 0.8613\n",
      "3819/5349 [====================>.........] - ETA: 0s - loss: 0.3557 - accuracy: 0.8638\n",
      "4040/5349 [=====================>........] - ETA: 0s - loss: 0.3491 - accuracy: 0.8655\n",
      "4265/5349 [======================>.......] - ETA: 0s - loss: 0.3430 - accuracy: 0.8669\n",
      "4484/5349 [========================>.....] - ETA: 0s - loss: 0.3374 - accuracy: 0.8681\n",
      "4703/5349 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.8694\n",
      "4811/5349 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.8698\n",
      "5033/5349 [===========================>..] - ETA: 0s - loss: 0.3251 - accuracy: 0.8707\n",
      "5247/5349 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8718\n",
      "5349/5349 [==============================] - 5s 798us/step - loss: 0.3187 - accuracy: 0.8722 - val_loss: 0.2203 - val_accuracy: 0.8970\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1934 - accuracy: 0.9200\n",
      "  77/5349 [..............................] - ETA: 6s - loss: 0.2108 - accuracy: 0.8978\n",
      " 316/5349 [>.............................] - ETA: 4s - loss: 0.2127 - accuracy: 0.8965\n",
      " 492/5349 [=>............................] - ETA: 3s - loss: 0.2124 - accuracy: 0.8963\n",
      " 694/5349 [==>...........................] - ETA: 3s - loss: 0.2120 - accuracy: 0.8962\n",
      " 889/5349 [===>..........................] - ETA: 2s - loss: 0.2116 - accuracy: 0.8957\n",
      "1077/5349 [=====>........................] - ETA: 2s - loss: 0.2116 - accuracy: 0.8954\n",
      "1362/5349 [======>.......................] - ETA: 2s - loss: 0.2107 - accuracy: 0.8956\n",
      "1563/5349 [=======>......................] - ETA: 2s - loss: 0.2099 - accuracy: 0.8960\n",
      "1769/5349 [========>.....................] - ETA: 2s - loss: 0.2090 - accuracy: 0.8960\n",
      "1976/5349 [==========>...................] - ETA: 1s - loss: 0.2085 - accuracy: 0.8965\n",
      "2184/5349 [===========>..................] - ETA: 1s - loss: 0.2080 - accuracy: 0.8967\n",
      "2497/5349 [=============>................] - ETA: 1s - loss: 0.2072 - accuracy: 0.8967\n",
      "2703/5349 [==============>...............] - ETA: 1s - loss: 0.2065 - accuracy: 0.8967\n",
      "2902/5349 [===============>..............] - ETA: 1s - loss: 0.2060 - accuracy: 0.8969\n",
      "3015/5349 [===============>..............] - ETA: 1s - loss: 0.2056 - accuracy: 0.8971\n",
      "3071/5349 [================>.............] - ETA: 1s - loss: 0.2054 - accuracy: 0.8972\n",
      "3140/5349 [================>.............] - ETA: 1s - loss: 0.2053 - accuracy: 0.8972\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.2052 - accuracy: 0.8972\n",
      "3229/5349 [=================>............] - ETA: 1s - loss: 0.2051 - accuracy: 0.8972\n",
      "3279/5349 [=================>............] - ETA: 1s - loss: 0.2049 - accuracy: 0.8973\n",
      "3336/5349 [=================>............] - ETA: 1s - loss: 0.2048 - accuracy: 0.8973\n",
      "3411/5349 [==================>...........] - ETA: 1s - loss: 0.2046 - accuracy: 0.8974\n",
      "3455/5349 [==================>...........] - ETA: 1s - loss: 0.2046 - accuracy: 0.8974\n",
      "3520/5349 [==================>...........] - ETA: 1s - loss: 0.2045 - accuracy: 0.8974\n",
      "3567/5349 [===================>..........] - ETA: 1s - loss: 0.2044 - accuracy: 0.8974\n",
      "3599/5349 [===================>..........] - ETA: 1s - loss: 0.2043 - accuracy: 0.8974\n",
      "3674/5349 [===================>..........] - ETA: 1s - loss: 0.2042 - accuracy: 0.8974\n",
      "3730/5349 [===================>..........] - ETA: 1s - loss: 0.2040 - accuracy: 0.8974\n",
      "3798/5349 [====================>.........] - ETA: 1s - loss: 0.2038 - accuracy: 0.8975\n",
      "3863/5349 [====================>.........] - ETA: 1s - loss: 0.2037 - accuracy: 0.8975\n",
      "3914/5349 [====================>.........] - ETA: 1s - loss: 0.2036 - accuracy: 0.8975\n",
      "3962/5349 [=====================>........] - ETA: 1s - loss: 0.2034 - accuracy: 0.8977\n",
      "4009/5349 [=====================>........] - ETA: 1s - loss: 0.2032 - accuracy: 0.8977\n",
      "4083/5349 [=====================>........] - ETA: 1s - loss: 0.2031 - accuracy: 0.8977\n",
      "4153/5349 [======================>.......] - ETA: 1s - loss: 0.2029 - accuracy: 0.8978\n",
      "4232/5349 [======================>.......] - ETA: 0s - loss: 0.2026 - accuracy: 0.8980\n",
      "4317/5349 [=======================>......] - ETA: 0s - loss: 0.2025 - accuracy: 0.8979\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.2023 - accuracy: 0.8980\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.2020 - accuracy: 0.8981\n",
      "4715/5349 [=========================>....] - ETA: 0s - loss: 0.2015 - accuracy: 0.8982\n",
      "4872/5349 [==========================>...] - ETA: 0s - loss: 0.2010 - accuracy: 0.8984\n",
      "5030/5349 [===========================>..] - ETA: 0s - loss: 0.2007 - accuracy: 0.8985\n",
      "5332/5349 [============================>.] - ETA: 0s - loss: 0.2001 - accuracy: 0.8988\n",
      "5349/5349 [==============================] - 5s 996us/step - loss: 0.2000 - accuracy: 0.8988 - val_loss: 0.1873 - val_accuracy: 0.9024\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2813 - accuracy: 0.8600\n",
      " 214/5349 [>.............................] - ETA: 2s - loss: 0.1884 - accuracy: 0.9005\n",
      " 420/5349 [=>............................] - ETA: 2s - loss: 0.1891 - accuracy: 0.9005\n",
      " 633/5349 [==>...........................] - ETA: 2s - loss: 0.1895 - accuracy: 0.9009\n",
      " 958/5349 [====>.........................] - ETA: 2s - loss: 0.1883 - accuracy: 0.9019\n",
      "1174/5349 [=====>........................] - ETA: 1s - loss: 0.1879 - accuracy: 0.9023\n",
      "1382/5349 [======>.......................] - ETA: 1s - loss: 0.1875 - accuracy: 0.9021\n",
      "1597/5349 [=======>......................] - ETA: 1s - loss: 0.1871 - accuracy: 0.9021\n",
      "1919/5349 [=========>....................] - ETA: 1s - loss: 0.1861 - accuracy: 0.9032\n",
      "2132/5349 [==========>...................] - ETA: 1s - loss: 0.1860 - accuracy: 0.9032\n",
      "2349/5349 [============>.................] - ETA: 1s - loss: 0.1859 - accuracy: 0.9034\n",
      "2569/5349 [=============>................] - ETA: 1s - loss: 0.1859 - accuracy: 0.9032\n",
      "2894/5349 [===============>..............] - ETA: 1s - loss: 0.1853 - accuracy: 0.9035\n",
      "3114/5349 [================>.............] - ETA: 1s - loss: 0.1852 - accuracy: 0.9035\n",
      "3331/5349 [=================>............] - ETA: 0s - loss: 0.1849 - accuracy: 0.9037\n",
      "3550/5349 [==================>...........] - ETA: 0s - loss: 0.1845 - accuracy: 0.9039\n",
      "3876/5349 [====================>.........] - ETA: 0s - loss: 0.1841 - accuracy: 0.9042\n",
      "4097/5349 [=====================>........] - ETA: 0s - loss: 0.1838 - accuracy: 0.9042\n",
      "4318/5349 [=======================>......] - ETA: 0s - loss: 0.1838 - accuracy: 0.9042\n",
      "4536/5349 [========================>.....] - ETA: 0s - loss: 0.1835 - accuracy: 0.9044\n",
      "4760/5349 [=========================>....] - ETA: 0s - loss: 0.1832 - accuracy: 0.9044\n",
      "5098/5349 [===========================>..] - ETA: 0s - loss: 0.1830 - accuracy: 0.9045\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9044\n",
      "5349/5349 [==============================] - 3s 626us/step - loss: 0.1830 - accuracy: 0.9045 - val_loss: 0.1765 - val_accuracy: 0.9082\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 4/20\n",
      " 218/5349 [>.............................] - ETA: 2s - loss: 0.1799 - accuracy: 0.9048\n",
      " 436/5349 [=>............................] - ETA: 2s - loss: 0.1791 - accuracy: 0.9059\n",
      " 654/5349 [==>...........................] - ETA: 2s - loss: 0.1782 - accuracy: 0.9063\n",
      " 872/5349 [===>..........................] - ETA: 2s - loss: 0.1779 - accuracy: 0.9067\n",
      "1081/5349 [=====>........................] - ETA: 1s - loss: 0.1773 - accuracy: 0.9071\n",
      "1415/5349 [======>.......................] - ETA: 1s - loss: 0.1769 - accuracy: 0.9073\n",
      "1640/5349 [========>.....................] - ETA: 1s - loss: 0.1769 - accuracy: 0.9070\n",
      "1866/5349 [=========>....................] - ETA: 1s - loss: 0.1769 - accuracy: 0.9071\n",
      "2081/5349 [==========>...................] - ETA: 1s - loss: 0.1768 - accuracy: 0.9071\n",
      "2302/5349 [===========>..................] - ETA: 1s - loss: 0.1767 - accuracy: 0.9071\n",
      "2525/5349 [=============>................] - ETA: 1s - loss: 0.1771 - accuracy: 0.9068\n",
      "2838/5349 [==============>...............] - ETA: 1s - loss: 0.1769 - accuracy: 0.9070\n",
      "2994/5349 [===============>..............] - ETA: 1s - loss: 0.1767 - accuracy: 0.9071\n",
      "3208/5349 [================>.............] - ETA: 1s - loss: 0.1767 - accuracy: 0.9070\n",
      "3429/5349 [==================>...........] - ETA: 0s - loss: 0.1766 - accuracy: 0.9069\n",
      "3656/5349 [===================>..........] - ETA: 0s - loss: 0.1762 - accuracy: 0.9073\n",
      "3871/5349 [====================>.........] - ETA: 0s - loss: 0.1761 - accuracy: 0.9075\n",
      "4192/5349 [======================>.......] - ETA: 0s - loss: 0.1759 - accuracy: 0.9075\n",
      "4413/5349 [=======================>......] - ETA: 0s - loss: 0.1756 - accuracy: 0.9076\n",
      "4633/5349 [========================>.....] - ETA: 0s - loss: 0.1757 - accuracy: 0.9075\n",
      "4854/5349 [==========================>...] - ETA: 0s - loss: 0.1756 - accuracy: 0.9075\n",
      "5076/5349 [===========================>..] - ETA: 0s - loss: 0.1753 - accuracy: 0.9077\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9079\n",
      "5349/5349 [==============================] - 3s 627us/step - loss: 0.1750 - accuracy: 0.9079 - val_loss: 0.1706 - val_accuracy: 0.9112\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1583 - accuracy: 0.9200\n",
      " 317/5349 [>.............................] - ETA: 2s - loss: 0.1717 - accuracy: 0.9081\n",
      " 535/5349 [==>...........................] - ETA: 2s - loss: 0.1718 - accuracy: 0.9080\n",
      " 757/5349 [===>..........................] - ETA: 2s - loss: 0.1717 - accuracy: 0.9084\n",
      " 982/5349 [====>.........................] - ETA: 2s - loss: 0.1719 - accuracy: 0.9083\n",
      "1204/5349 [=====>........................] - ETA: 1s - loss: 0.1716 - accuracy: 0.9085\n",
      "1313/5349 [======>.......................] - ETA: 1s - loss: 0.1719 - accuracy: 0.9084\n",
      "1535/5349 [=======>......................] - ETA: 1s - loss: 0.1717 - accuracy: 0.9086\n",
      "1753/5349 [========>.....................] - ETA: 1s - loss: 0.1718 - accuracy: 0.9087\n",
      "1972/5349 [==========>...................] - ETA: 1s - loss: 0.1722 - accuracy: 0.9084\n",
      "2196/5349 [===========>..................] - ETA: 1s - loss: 0.1722 - accuracy: 0.9084\n",
      "2526/5349 [=============>................] - ETA: 1s - loss: 0.1723 - accuracy: 0.9082\n",
      "2747/5349 [==============>...............] - ETA: 1s - loss: 0.1722 - accuracy: 0.9084\n",
      "2966/5349 [===============>..............] - ETA: 1s - loss: 0.1719 - accuracy: 0.9086\n",
      "3190/5349 [================>.............] - ETA: 0s - loss: 0.1717 - accuracy: 0.9088\n",
      "3415/5349 [==================>...........] - ETA: 0s - loss: 0.1713 - accuracy: 0.9090\n",
      "3632/5349 [===================>..........] - ETA: 0s - loss: 0.1712 - accuracy: 0.9091\n",
      "3970/5349 [=====================>........] - ETA: 0s - loss: 0.1711 - accuracy: 0.9091\n",
      "4175/5349 [======================>.......] - ETA: 0s - loss: 0.1709 - accuracy: 0.9092\n",
      "4399/5349 [=======================>......] - ETA: 0s - loss: 0.1707 - accuracy: 0.9093\n",
      "4572/5349 [========================>.....] - ETA: 0s - loss: 0.1707 - accuracy: 0.9093\n",
      "4691/5349 [=========================>....] - ETA: 0s - loss: 0.1705 - accuracy: 0.9093\n",
      "4963/5349 [==========================>...] - ETA: 0s - loss: 0.1703 - accuracy: 0.9096\n",
      "5159/5349 [===========================>..] - ETA: 0s - loss: 0.1702 - accuracy: 0.9096\n",
      "5254/5349 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9096\n",
      "5349/5349 [==============================] - 3s 640us/step - loss: 0.1702 - accuracy: 0.9096 - val_loss: 0.1659 - val_accuracy: 0.9128\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1893 - accuracy: 0.8800\n",
      " 215/5349 [>.............................] - ETA: 2s - loss: 0.1684 - accuracy: 0.9109\n",
      " 544/5349 [==>...........................] - ETA: 2s - loss: 0.1682 - accuracy: 0.9103\n",
      " 765/5349 [===>..........................] - ETA: 2s - loss: 0.1686 - accuracy: 0.9098\n",
      " 980/5349 [====>.........................] - ETA: 2s - loss: 0.1682 - accuracy: 0.9102\n",
      "1193/5349 [=====>........................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9104\n",
      "1516/5349 [=======>......................] - ETA: 1s - loss: 0.1679 - accuracy: 0.9107\n",
      "1729/5349 [========>.....................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9105\n",
      "1950/5349 [=========>....................] - ETA: 1s - loss: 0.1676 - accuracy: 0.9108\n",
      "2161/5349 [===========>..................] - ETA: 1s - loss: 0.1677 - accuracy: 0.9108\n",
      "2375/5349 [============>.................] - ETA: 1s - loss: 0.1678 - accuracy: 0.9106\n",
      "2564/5349 [=============>................] - ETA: 1s - loss: 0.1678 - accuracy: 0.9106\n",
      "2615/5349 [=============>................] - ETA: 1s - loss: 0.1677 - accuracy: 0.9108\n",
      "2685/5349 [==============>...............] - ETA: 1s - loss: 0.1676 - accuracy: 0.9108\n",
      "2784/5349 [==============>...............] - ETA: 1s - loss: 0.1676 - accuracy: 0.9106\n",
      "2879/5349 [===============>..............] - ETA: 1s - loss: 0.1676 - accuracy: 0.9107\n",
      "2940/5349 [===============>..............] - ETA: 1s - loss: 0.1675 - accuracy: 0.9107\n",
      "2998/5349 [===============>..............] - ETA: 1s - loss: 0.1675 - accuracy: 0.9107\n",
      "3050/5349 [================>.............] - ETA: 1s - loss: 0.1674 - accuracy: 0.9107\n",
      "3131/5349 [================>.............] - ETA: 1s - loss: 0.1675 - accuracy: 0.9106\n",
      "3189/5349 [================>.............] - ETA: 1s - loss: 0.1676 - accuracy: 0.9106\n",
      "3283/5349 [=================>............] - ETA: 1s - loss: 0.1676 - accuracy: 0.9105\n",
      "3348/5349 [=================>............] - ETA: 1s - loss: 0.1675 - accuracy: 0.9106\n",
      "3417/5349 [==================>...........] - ETA: 1s - loss: 0.1675 - accuracy: 0.9106\n",
      "3573/5349 [===================>..........] - ETA: 1s - loss: 0.1674 - accuracy: 0.9107\n",
      "3645/5349 [===================>..........] - ETA: 1s - loss: 0.1675 - accuracy: 0.9106\n",
      "3708/5349 [===================>..........] - ETA: 1s - loss: 0.1674 - accuracy: 0.9107\n",
      "3788/5349 [====================>.........] - ETA: 1s - loss: 0.1675 - accuracy: 0.9107\n",
      "3877/5349 [====================>.........] - ETA: 1s - loss: 0.1674 - accuracy: 0.9106\n",
      "4009/5349 [=====================>........] - ETA: 1s - loss: 0.1673 - accuracy: 0.9108\n",
      "4081/5349 [=====================>........] - ETA: 1s - loss: 0.1673 - accuracy: 0.9108\n",
      "4264/5349 [======================>.......] - ETA: 0s - loss: 0.1673 - accuracy: 0.9108\n",
      "4448/5349 [=======================>......] - ETA: 0s - loss: 0.1673 - accuracy: 0.9108\n",
      "4644/5349 [=========================>....] - ETA: 0s - loss: 0.1673 - accuracy: 0.9108\n",
      "4844/5349 [==========================>...] - ETA: 0s - loss: 0.1673 - accuracy: 0.9108\n",
      "5059/5349 [===========================>..] - ETA: 0s - loss: 0.1672 - accuracy: 0.9108\n",
      "5167/5349 [===========================>..] - ETA: 0s - loss: 0.1673 - accuracy: 0.9107\n",
      "5247/5349 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9108\n",
      "5349/5349 [==============================] - 5s 916us/step - loss: 0.1671 - accuracy: 0.9109 - val_loss: 0.1629 - val_accuracy: 0.9139\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1506 - accuracy: 0.9200\n",
      " 216/5349 [>.............................] - ETA: 2s - loss: 0.1638 - accuracy: 0.9119\n",
      " 436/5349 [=>............................] - ETA: 2s - loss: 0.1640 - accuracy: 0.9126\n",
      " 657/5349 [==>...........................] - ETA: 2s - loss: 0.1640 - accuracy: 0.9122\n",
      " 993/5349 [====>.........................] - ETA: 1s - loss: 0.1646 - accuracy: 0.9121\n",
      "1212/5349 [=====>........................] - ETA: 1s - loss: 0.1637 - accuracy: 0.9127\n",
      "1429/5349 [=======>......................] - ETA: 1s - loss: 0.1636 - accuracy: 0.9126\n",
      "1651/5349 [========>.....................] - ETA: 1s - loss: 0.1638 - accuracy: 0.9128\n",
      "1875/5349 [=========>....................] - ETA: 1s - loss: 0.1640 - accuracy: 0.9127\n",
      "2117/5349 [==========>...................] - ETA: 1s - loss: 0.1639 - accuracy: 0.9127\n",
      "2295/5349 [===========>..................] - ETA: 1s - loss: 0.1641 - accuracy: 0.9125\n",
      "2515/5349 [=============>................] - ETA: 1s - loss: 0.1642 - accuracy: 0.9124\n",
      "2737/5349 [==============>...............] - ETA: 1s - loss: 0.1644 - accuracy: 0.9122\n",
      "2954/5349 [===============>..............] - ETA: 1s - loss: 0.1645 - accuracy: 0.9122\n",
      "3292/5349 [=================>............] - ETA: 0s - loss: 0.1646 - accuracy: 0.9121\n",
      "3507/5349 [==================>...........] - ETA: 0s - loss: 0.1647 - accuracy: 0.9121\n",
      "3711/5349 [===================>..........] - ETA: 0s - loss: 0.1648 - accuracy: 0.9119\n",
      "3934/5349 [=====================>........] - ETA: 0s - loss: 0.1649 - accuracy: 0.9119\n",
      "4156/5349 [======================>.......] - ETA: 0s - loss: 0.1648 - accuracy: 0.9119\n",
      "4486/5349 [========================>.....] - ETA: 0s - loss: 0.1648 - accuracy: 0.9119\n",
      "4706/5349 [=========================>....] - ETA: 0s - loss: 0.1647 - accuracy: 0.9119\n",
      "4922/5349 [==========================>...] - ETA: 0s - loss: 0.1646 - accuracy: 0.9120\n",
      "5144/5349 [===========================>..] - ETA: 0s - loss: 0.1645 - accuracy: 0.9120\n",
      "5255/5349 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9121\n",
      "5349/5349 [==============================] - 3s 631us/step - loss: 0.1644 - accuracy: 0.9120 - val_loss: 0.1615 - val_accuracy: 0.9140\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1258 - accuracy: 0.9400\n",
      " 333/5349 [>.............................] - ETA: 2s - loss: 0.1640 - accuracy: 0.9132\n",
      " 535/5349 [==>...........................] - ETA: 2s - loss: 0.1641 - accuracy: 0.9120\n",
      " 756/5349 [===>..........................] - ETA: 2s - loss: 0.1641 - accuracy: 0.9117\n",
      " 982/5349 [====>.........................] - ETA: 2s - loss: 0.1630 - accuracy: 0.9121\n",
      "1207/5349 [=====>........................] - ETA: 1s - loss: 0.1628 - accuracy: 0.9122\n",
      "1426/5349 [======>.......................] - ETA: 1s - loss: 0.1626 - accuracy: 0.9127\n",
      "1651/5349 [========>.....................] - ETA: 1s - loss: 0.1628 - accuracy: 0.9127\n",
      "1762/5349 [========>.....................] - ETA: 1s - loss: 0.1629 - accuracy: 0.9127\n",
      "1985/5349 [==========>...................] - ETA: 1s - loss: 0.1629 - accuracy: 0.9128\n",
      "2208/5349 [===========>..................] - ETA: 1s - loss: 0.1629 - accuracy: 0.9127\n",
      "2429/5349 [============>.................] - ETA: 1s - loss: 0.1629 - accuracy: 0.9129\n",
      "2652/5349 [=============>................] - ETA: 1s - loss: 0.1630 - accuracy: 0.9128\n",
      "2868/5349 [===============>..............] - ETA: 1s - loss: 0.1627 - accuracy: 0.9130\n",
      "3196/5349 [================>.............] - ETA: 0s - loss: 0.1626 - accuracy: 0.9131\n",
      "3416/5349 [==================>...........] - ETA: 0s - loss: 0.1627 - accuracy: 0.9131\n",
      "3640/5349 [===================>..........] - ETA: 0s - loss: 0.1626 - accuracy: 0.9131\n",
      "3857/5349 [====================>.........] - ETA: 0s - loss: 0.1626 - accuracy: 0.9131\n",
      "4159/5349 [======================>.......] - ETA: 0s - loss: 0.1627 - accuracy: 0.9131\n",
      "4379/5349 [=======================>......] - ETA: 0s - loss: 0.1629 - accuracy: 0.9129\n",
      "4602/5349 [========================>.....] - ETA: 0s - loss: 0.1627 - accuracy: 0.9130\n",
      "4819/5349 [==========================>...] - ETA: 0s - loss: 0.1626 - accuracy: 0.9131\n",
      "5041/5349 [===========================>..] - ETA: 0s - loss: 0.1625 - accuracy: 0.9130\n",
      "5264/5349 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9130\n",
      "5349/5349 [==============================] - 3s 620us/step - loss: 0.1625 - accuracy: 0.9130 - val_loss: 0.1592 - val_accuracy: 0.9144\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 9/20\n",
      " 221/5349 [>.............................] - ETA: 2s - loss: 0.1654 - accuracy: 0.9100\n",
      " 443/5349 [=>............................] - ETA: 2s - loss: 0.1633 - accuracy: 0.9113\n",
      " 668/5349 [==>...........................] - ETA: 2s - loss: 0.1627 - accuracy: 0.9120\n",
      " 889/5349 [===>..........................] - ETA: 2s - loss: 0.1622 - accuracy: 0.9124\n",
      "1108/5349 [=====>........................] - ETA: 1s - loss: 0.1621 - accuracy: 0.9124\n",
      "1329/5349 [======>.......................] - ETA: 1s - loss: 0.1618 - accuracy: 0.9129\n",
      "1554/5349 [=======>......................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9128\n",
      "1666/5349 [========>.....................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9127\n",
      "1887/5349 [=========>....................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9127\n",
      "2109/5349 [==========>...................] - ETA: 1s - loss: 0.1617 - accuracy: 0.9129\n",
      "2332/5349 [============>.................] - ETA: 1s - loss: 0.1617 - accuracy: 0.9130\n",
      "2548/5349 [=============>................] - ETA: 1s - loss: 0.1617 - accuracy: 0.9130\n",
      "2880/5349 [===============>..............] - ETA: 1s - loss: 0.1616 - accuracy: 0.9130\n",
      "3099/5349 [================>.............] - ETA: 1s - loss: 0.1614 - accuracy: 0.9133\n",
      "3319/5349 [=================>............] - ETA: 0s - loss: 0.1614 - accuracy: 0.9131\n",
      "3543/5349 [==================>...........] - ETA: 0s - loss: 0.1616 - accuracy: 0.9130\n",
      "3862/5349 [====================>.........] - ETA: 0s - loss: 0.1614 - accuracy: 0.9131\n",
      "4083/5349 [=====================>........] - ETA: 0s - loss: 0.1613 - accuracy: 0.9133\n",
      "4304/5349 [=======================>......] - ETA: 0s - loss: 0.1612 - accuracy: 0.9133\n",
      "4527/5349 [========================>.....] - ETA: 0s - loss: 0.1611 - accuracy: 0.9134\n",
      "4735/5349 [=========================>....] - ETA: 0s - loss: 0.1611 - accuracy: 0.9135\n",
      "5069/5349 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.9136\n",
      "5197/5349 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9136\n",
      "5322/5349 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9136\n",
      "5349/5349 [==============================] - 4s 805us/step - loss: 0.1610 - accuracy: 0.9136 - val_loss: 0.1593 - val_accuracy: 0.9145\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2001 - accuracy: 0.9200\n",
      "  84/5349 [..............................] - ETA: 3s - loss: 0.1568 - accuracy: 0.9176\n",
      " 255/5349 [>.............................] - ETA: 3s - loss: 0.1559 - accuracy: 0.9174\n",
      " 436/5349 [=>............................] - ETA: 2s - loss: 0.1574 - accuracy: 0.9168\n",
      " 477/5349 [=>............................] - ETA: 3s - loss: 0.1569 - accuracy: 0.9175\n",
      " 521/5349 [=>............................] - ETA: 3s - loss: 0.1579 - accuracy: 0.9166\n",
      " 552/5349 [==>...........................] - ETA: 4s - loss: 0.1576 - accuracy: 0.9167\n",
      " 603/5349 [==>...........................] - ETA: 4s - loss: 0.1580 - accuracy: 0.9162\n",
      " 645/5349 [==>...........................] - ETA: 4s - loss: 0.1588 - accuracy: 0.9161\n",
      " 677/5349 [==>...........................] - ETA: 5s - loss: 0.1591 - accuracy: 0.9158\n",
      " 689/5349 [==>...........................] - ETA: 5s - loss: 0.1590 - accuracy: 0.9158\n",
      " 735/5349 [===>..........................] - ETA: 6s - loss: 0.1588 - accuracy: 0.9159\n",
      " 778/5349 [===>..........................] - ETA: 6s - loss: 0.1584 - accuracy: 0.9163\n",
      " 811/5349 [===>..........................] - ETA: 6s - loss: 0.1582 - accuracy: 0.9165\n",
      " 842/5349 [===>..........................] - ETA: 7s - loss: 0.1586 - accuracy: 0.9162\n",
      " 870/5349 [===>..........................] - ETA: 7s - loss: 0.1586 - accuracy: 0.9162\n",
      " 906/5349 [====>.........................] - ETA: 7s - loss: 0.1587 - accuracy: 0.9160\n",
      " 925/5349 [====>.........................] - ETA: 7s - loss: 0.1588 - accuracy: 0.9159\n",
      " 964/5349 [====>.........................] - ETA: 7s - loss: 0.1588 - accuracy: 0.9160\n",
      " 993/5349 [====>.........................] - ETA: 7s - loss: 0.1589 - accuracy: 0.9158\n",
      "1018/5349 [====>.........................] - ETA: 8s - loss: 0.1589 - accuracy: 0.9158\n",
      "1042/5349 [====>.........................] - ETA: 8s - loss: 0.1589 - accuracy: 0.9157\n",
      "1055/5349 [====>.........................] - ETA: 8s - loss: 0.1589 - accuracy: 0.9157\n",
      "1088/5349 [=====>........................] - ETA: 8s - loss: 0.1590 - accuracy: 0.9157\n",
      "1094/5349 [=====>........................] - ETA: 8s - loss: 0.1590 - accuracy: 0.9157\n",
      "1136/5349 [=====>........................] - ETA: 8s - loss: 0.1589 - accuracy: 0.9159\n",
      "1166/5349 [=====>........................] - ETA: 9s - loss: 0.1588 - accuracy: 0.9160\n",
      "1187/5349 [=====>........................] - ETA: 9s - loss: 0.1589 - accuracy: 0.9158\n",
      "1220/5349 [=====>........................] - ETA: 9s - loss: 0.1587 - accuracy: 0.9159\n",
      "1254/5349 [======>.......................] - ETA: 9s - loss: 0.1588 - accuracy: 0.9159\n",
      "1299/5349 [======>.......................] - ETA: 9s - loss: 0.1590 - accuracy: 0.9157\n",
      "1323/5349 [======>.......................] - ETA: 9s - loss: 0.1590 - accuracy: 0.9158\n",
      "1350/5349 [======>.......................] - ETA: 9s - loss: 0.1592 - accuracy: 0.9156\n",
      "1389/5349 [======>.......................] - ETA: 9s - loss: 0.1596 - accuracy: 0.9152\n",
      "1422/5349 [======>.......................] - ETA: 9s - loss: 0.1596 - accuracy: 0.9152\n",
      "1440/5349 [=======>......................] - ETA: 9s - loss: 0.1597 - accuracy: 0.9152\n",
      "1445/5349 [=======>......................] - ETA: 9s - loss: 0.1596 - accuracy: 0.9152\n",
      "1463/5349 [=======>......................] - ETA: 9s - loss: 0.1596 - accuracy: 0.9152\n",
      "1515/5349 [=======>......................] - ETA: 9s - loss: 0.1596 - accuracy: 0.9152\n",
      "1575/5349 [=======>......................] - ETA: 9s - loss: 0.1598 - accuracy: 0.9149\n",
      "1633/5349 [========>.....................] - ETA: 9s - loss: 0.1598 - accuracy: 0.9149\n",
      "1664/5349 [========>.....................] - ETA: 9s - loss: 0.1599 - accuracy: 0.9148\n",
      "1736/5349 [========>.....................] - ETA: 8s - loss: 0.1600 - accuracy: 0.9147\n",
      "1910/5349 [=========>....................] - ETA: 7s - loss: 0.1604 - accuracy: 0.9143\n",
      "2078/5349 [==========>...................] - ETA: 7s - loss: 0.1602 - accuracy: 0.9144\n",
      "2236/5349 [===========>..................] - ETA: 6s - loss: 0.1602 - accuracy: 0.9142\n",
      "2408/5349 [============>.................] - ETA: 5s - loss: 0.1600 - accuracy: 0.9144\n",
      "2596/5349 [=============>................] - ETA: 5s - loss: 0.1599 - accuracy: 0.9144\n",
      "2782/5349 [==============>...............] - ETA: 4s - loss: 0.1601 - accuracy: 0.9143\n",
      "2880/5349 [===============>..............] - ETA: 4s - loss: 0.1600 - accuracy: 0.9144\n",
      "3075/5349 [================>.............] - ETA: 3s - loss: 0.1600 - accuracy: 0.9143\n",
      "3245/5349 [=================>............] - ETA: 3s - loss: 0.1601 - accuracy: 0.9142\n",
      "3441/5349 [==================>...........] - ETA: 2s - loss: 0.1601 - accuracy: 0.9142\n",
      "3603/5349 [===================>..........] - ETA: 2s - loss: 0.1600 - accuracy: 0.9142\n",
      "3799/5349 [====================>.........] - ETA: 2s - loss: 0.1599 - accuracy: 0.9143\n",
      "3981/5349 [=====================>........] - ETA: 1s - loss: 0.1599 - accuracy: 0.9143\n",
      "4272/5349 [======================>.......] - ETA: 1s - loss: 0.1598 - accuracy: 0.9143\n",
      "4463/5349 [========================>.....] - ETA: 1s - loss: 0.1598 - accuracy: 0.9143\n",
      "4659/5349 [=========================>....] - ETA: 0s - loss: 0.1598 - accuracy: 0.9143\n",
      "4845/5349 [==========================>...] - ETA: 0s - loss: 0.1598 - accuracy: 0.9143\n",
      "5036/5349 [===========================>..] - ETA: 0s - loss: 0.1598 - accuracy: 0.9143\n",
      "5207/5349 [============================>.] - ETA: 0s - loss: 0.1598 - accuracy: 0.9142\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9142\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1597 - accuracy: 0.9142 - val_loss: 0.1566 - val_accuracy: 0.9158\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 11/20\n",
      " 182/5349 [>.............................] - ETA: 2s - loss: 0.1587 - accuracy: 0.9148\n",
      " 366/5349 [=>............................] - ETA: 2s - loss: 0.1589 - accuracy: 0.9149\n",
      " 551/5349 [==>...........................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9138\n",
      " 727/5349 [===>..........................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9141\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.1595 - accuracy: 0.9140\n",
      "1089/5349 [=====>........................] - ETA: 2s - loss: 0.1597 - accuracy: 0.9141\n",
      "1253/5349 [======>.......................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9142\n",
      "1431/5349 [=======>......................] - ETA: 2s - loss: 0.1596 - accuracy: 0.9139\n",
      "1682/5349 [========>.....................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9140\n",
      "1856/5349 [=========>....................] - ETA: 1s - loss: 0.1598 - accuracy: 0.9138\n",
      "2038/5349 [==========>...................] - ETA: 1s - loss: 0.1597 - accuracy: 0.9139\n",
      "2199/5349 [===========>..................] - ETA: 1s - loss: 0.1596 - accuracy: 0.9140\n",
      "2375/5349 [============>.................] - ETA: 1s - loss: 0.1593 - accuracy: 0.9143\n",
      "2550/5349 [=============>................] - ETA: 1s - loss: 0.1592 - accuracy: 0.9144\n",
      "2732/5349 [==============>...............] - ETA: 1s - loss: 0.1592 - accuracy: 0.9141\n",
      "2908/5349 [===============>..............] - ETA: 1s - loss: 0.1590 - accuracy: 0.9143\n",
      "3092/5349 [================>.............] - ETA: 1s - loss: 0.1589 - accuracy: 0.9143\n",
      "3266/5349 [=================>............] - ETA: 1s - loss: 0.1591 - accuracy: 0.9142\n",
      "3439/5349 [==================>...........] - ETA: 1s - loss: 0.1590 - accuracy: 0.9144\n",
      "3709/5349 [===================>..........] - ETA: 0s - loss: 0.1589 - accuracy: 0.9145\n",
      "3892/5349 [====================>.........] - ETA: 0s - loss: 0.1589 - accuracy: 0.9145\n",
      "4048/5349 [=====================>........] - ETA: 0s - loss: 0.1589 - accuracy: 0.9145\n",
      "4229/5349 [======================>.......] - ETA: 0s - loss: 0.1588 - accuracy: 0.9145\n",
      "4405/5349 [=======================>......] - ETA: 0s - loss: 0.1587 - accuracy: 0.9147\n",
      "4582/5349 [========================>.....] - ETA: 0s - loss: 0.1586 - accuracy: 0.9148\n",
      "4757/5349 [=========================>....] - ETA: 0s - loss: 0.1585 - accuracy: 0.9148\n",
      "4935/5349 [==========================>...] - ETA: 0s - loss: 0.1585 - accuracy: 0.9148\n",
      "5199/5349 [============================>.] - ETA: 0s - loss: 0.1585 - accuracy: 0.9146\n",
      "5283/5349 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9146\n",
      "5349/5349 [==============================] - 4s 768us/step - loss: 0.1586 - accuracy: 0.9146 - val_loss: 0.1558 - val_accuracy: 0.9166\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1965 - accuracy: 0.8600\n",
      " 142/5349 [..............................] - ETA: 3s - loss: 0.1567 - accuracy: 0.9167\n",
      " 260/5349 [>.............................] - ETA: 3s - loss: 0.1566 - accuracy: 0.9165\n",
      " 420/5349 [=>............................] - ETA: 4s - loss: 0.1557 - accuracy: 0.9165\n",
      " 553/5349 [==>...........................] - ETA: 3s - loss: 0.1558 - accuracy: 0.9163\n",
      " 705/5349 [==>...........................] - ETA: 3s - loss: 0.1559 - accuracy: 0.9163\n",
      " 883/5349 [===>..........................] - ETA: 3s - loss: 0.1563 - accuracy: 0.9159\n",
      "1057/5349 [====>.........................] - ETA: 3s - loss: 0.1565 - accuracy: 0.9158\n",
      "1332/5349 [======>.......................] - ETA: 2s - loss: 0.1575 - accuracy: 0.9151\n",
      "1511/5349 [=======>......................] - ETA: 2s - loss: 0.1574 - accuracy: 0.9153\n",
      "1696/5349 [========>.....................] - ETA: 2s - loss: 0.1574 - accuracy: 0.9154\n",
      "1861/5349 [=========>....................] - ETA: 2s - loss: 0.1578 - accuracy: 0.9150\n",
      "2046/5349 [==========>...................] - ETA: 2s - loss: 0.1578 - accuracy: 0.9149\n",
      "2226/5349 [===========>..................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9150\n",
      "2409/5349 [============>.................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9152\n",
      "2592/5349 [=============>................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9154\n",
      "2781/5349 [==============>...............] - ETA: 1s - loss: 0.1578 - accuracy: 0.9153\n",
      "2933/5349 [===============>..............] - ETA: 1s - loss: 0.1577 - accuracy: 0.9154\n",
      "3099/5349 [================>.............] - ETA: 1s - loss: 0.1575 - accuracy: 0.9155\n",
      "3270/5349 [=================>............] - ETA: 1s - loss: 0.1576 - accuracy: 0.9152\n",
      "3430/5349 [==================>...........] - ETA: 1s - loss: 0.1575 - accuracy: 0.9154\n",
      "3603/5349 [===================>..........] - ETA: 1s - loss: 0.1577 - accuracy: 0.9152\n",
      "3860/5349 [====================>.........] - ETA: 0s - loss: 0.1578 - accuracy: 0.9152\n",
      "4030/5349 [=====================>........] - ETA: 0s - loss: 0.1579 - accuracy: 0.9151\n",
      "4208/5349 [======================>.......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9152\n",
      "4380/5349 [=======================>......] - ETA: 0s - loss: 0.1577 - accuracy: 0.9153\n",
      "4556/5349 [========================>.....] - ETA: 0s - loss: 0.1578 - accuracy: 0.9153\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.1577 - accuracy: 0.9153\n",
      "4911/5349 [==========================>...] - ETA: 0s - loss: 0.1579 - accuracy: 0.9152\n",
      "5169/5349 [===========================>..] - ETA: 0s - loss: 0.1579 - accuracy: 0.9151\n",
      "5339/5349 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9151\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1579 - accuracy: 0.9151 - val_loss: 0.1548 - val_accuracy: 0.9171\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 45s - loss: 0.1679 - accuracy: 0.9000\n",
      "  46/5349 [..............................] - ETA: 12s - loss: 0.1593 - accuracy: 0.9107\n",
      " 101/5349 [..............................] - ETA: 13s - loss: 0.1587 - accuracy: 0.9126\n",
      " 145/5349 [..............................] - ETA: 13s - loss: 0.1578 - accuracy: 0.9145\n",
      " 180/5349 [>.............................] - ETA: 13s - loss: 0.1561 - accuracy: 0.9162\n",
      " 226/5349 [>.............................] - ETA: 13s - loss: 0.1557 - accuracy: 0.9163\n",
      " 350/5349 [>.............................] - ETA: 10s - loss: 0.1547 - accuracy: 0.9167\n",
      " 470/5349 [=>............................] - ETA: 8s - loss: 0.1545 - accuracy: 0.9172\n",
      " 627/5349 [==>...........................] - ETA: 7s - loss: 0.1553 - accuracy: 0.9163\n",
      " 694/5349 [==>...........................] - ETA: 6s - loss: 0.1560 - accuracy: 0.9160\n",
      " 832/5349 [===>..........................] - ETA: 6s - loss: 0.1560 - accuracy: 0.9161\n",
      "1039/5349 [====>.........................] - ETA: 5s - loss: 0.1568 - accuracy: 0.9160\n",
      "1180/5349 [=====>........................] - ETA: 4s - loss: 0.1562 - accuracy: 0.9162\n",
      "1303/5349 [======>.......................] - ETA: 4s - loss: 0.1564 - accuracy: 0.9159\n",
      "1448/5349 [=======>......................] - ETA: 4s - loss: 0.1565 - accuracy: 0.9159\n",
      "1576/5349 [=======>......................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9153\n",
      "1714/5349 [========>.....................] - ETA: 3s - loss: 0.1570 - accuracy: 0.9155\n",
      "1758/5349 [========>.....................] - ETA: 3s - loss: 0.1569 - accuracy: 0.9156\n",
      "1869/5349 [=========>....................] - ETA: 3s - loss: 0.1572 - accuracy: 0.9154\n",
      "2000/5349 [==========>...................] - ETA: 3s - loss: 0.1574 - accuracy: 0.9152\n",
      "2118/5349 [==========>...................] - ETA: 3s - loss: 0.1574 - accuracy: 0.9153\n",
      "2261/5349 [===========>..................] - ETA: 3s - loss: 0.1572 - accuracy: 0.9154\n",
      "2437/5349 [============>.................] - ETA: 2s - loss: 0.1572 - accuracy: 0.9154\n",
      "2697/5349 [==============>...............] - ETA: 2s - loss: 0.1573 - accuracy: 0.9152\n",
      "2875/5349 [===============>..............] - ETA: 2s - loss: 0.1574 - accuracy: 0.9152\n",
      "3049/5349 [================>.............] - ETA: 2s - loss: 0.1573 - accuracy: 0.9152\n",
      "3207/5349 [================>.............] - ETA: 1s - loss: 0.1574 - accuracy: 0.9152\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1574 - accuracy: 0.9152\n",
      "3535/5349 [==================>...........] - ETA: 1s - loss: 0.1575 - accuracy: 0.9151\n",
      "3622/5349 [===================>..........] - ETA: 1s - loss: 0.1574 - accuracy: 0.9153\n",
      "3799/5349 [====================>.........] - ETA: 1s - loss: 0.1573 - accuracy: 0.9154\n",
      "3970/5349 [=====================>........] - ETA: 1s - loss: 0.1573 - accuracy: 0.9154\n",
      "4144/5349 [======================>.......] - ETA: 0s - loss: 0.1572 - accuracy: 0.9154\n",
      "4314/5349 [=======================>......] - ETA: 0s - loss: 0.1571 - accuracy: 0.9155\n",
      "4476/5349 [========================>.....] - ETA: 0s - loss: 0.1573 - accuracy: 0.9154\n",
      "4741/5349 [=========================>....] - ETA: 0s - loss: 0.1573 - accuracy: 0.9153\n",
      "4919/5349 [==========================>...] - ETA: 0s - loss: 0.1573 - accuracy: 0.9153\n",
      "5094/5349 [===========================>..] - ETA: 0s - loss: 0.1573 - accuracy: 0.9153\n",
      "5268/5349 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9153\n",
      "5349/5349 [==============================] - 5s 946us/step - loss: 0.1573 - accuracy: 0.9153 - val_loss: 0.1542 - val_accuracy: 0.9169\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1577 - accuracy: 0.8900\n",
      " 182/5349 [>.............................] - ETA: 2s - loss: 0.1572 - accuracy: 0.9162\n",
      " 367/5349 [=>............................] - ETA: 2s - loss: 0.1576 - accuracy: 0.9162\n",
      " 542/5349 [==>...........................] - ETA: 2s - loss: 0.1571 - accuracy: 0.9160\n",
      " 815/5349 [===>..........................] - ETA: 2s - loss: 0.1572 - accuracy: 0.9153\n",
      " 995/5349 [====>.........................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9159\n",
      "1177/5349 [=====>........................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9157\n",
      "1353/5349 [======>.......................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9156\n",
      "1537/5349 [=======>......................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9152\n",
      "1712/5349 [========>.....................] - ETA: 2s - loss: 0.1568 - accuracy: 0.9153\n",
      "1892/5349 [=========>....................] - ETA: 1s - loss: 0.1567 - accuracy: 0.9153\n",
      "2068/5349 [==========>...................] - ETA: 1s - loss: 0.1566 - accuracy: 0.9155\n",
      "2249/5349 [===========>..................] - ETA: 1s - loss: 0.1563 - accuracy: 0.9156\n",
      "2407/5349 [============>.................] - ETA: 1s - loss: 0.1563 - accuracy: 0.9158\n",
      "2672/5349 [=============>................] - ETA: 1s - loss: 0.1565 - accuracy: 0.9156\n",
      "2845/5349 [==============>...............] - ETA: 1s - loss: 0.1565 - accuracy: 0.9156\n",
      "3018/5349 [===============>..............] - ETA: 1s - loss: 0.1567 - accuracy: 0.9156\n",
      "3179/5349 [================>.............] - ETA: 1s - loss: 0.1565 - accuracy: 0.9157\n",
      "3363/5349 [=================>............] - ETA: 1s - loss: 0.1566 - accuracy: 0.9157\n",
      "3542/5349 [==================>...........] - ETA: 1s - loss: 0.1567 - accuracy: 0.9156\n",
      "3725/5349 [===================>..........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9154\n",
      "3903/5349 [====================>.........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9154\n",
      "3994/5349 [=====================>........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9154\n",
      "4174/5349 [======================>.......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9154\n",
      "4337/5349 [=======================>......] - ETA: 0s - loss: 0.1570 - accuracy: 0.9153\n",
      "4518/5349 [========================>.....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9154\n",
      "4693/5349 [=========================>....] - ETA: 0s - loss: 0.1567 - accuracy: 0.9156\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.1569 - accuracy: 0.9156\n",
      "5054/5349 [===========================>..] - ETA: 0s - loss: 0.1567 - accuracy: 0.9157\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9157\n",
      "5349/5349 [==============================] - 4s 748us/step - loss: 0.1567 - accuracy: 0.9157 - val_loss: 0.1537 - val_accuracy: 0.9172\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 15/20\n",
      "  92/5349 [..............................] - ETA: 2s - loss: 0.1531 - accuracy: 0.9197\n",
      " 273/5349 [>.............................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9188\n",
      " 456/5349 [=>............................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9173\n",
      " 632/5349 [==>...........................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9171\n",
      " 789/5349 [===>..........................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9166\n",
      " 931/5349 [====>.........................] - ETA: 2s - loss: 0.1544 - accuracy: 0.9168\n",
      "1171/5349 [=====>........................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9161\n",
      "1325/5349 [======>.......................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9164\n",
      "1492/5349 [=======>......................] - ETA: 2s - loss: 0.1548 - accuracy: 0.9165\n",
      "1636/5349 [========>.....................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9162\n",
      "1736/5349 [========>.....................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9162\n",
      "1834/5349 [=========>....................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9159\n",
      "1944/5349 [=========>....................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9160\n",
      "2005/5349 [==========>...................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9159\n",
      "2163/5349 [===========>..................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9159\n",
      "2347/5349 [============>.................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9157\n",
      "2516/5349 [=============>................] - ETA: 1s - loss: 0.1561 - accuracy: 0.9157\n",
      "2696/5349 [==============>...............] - ETA: 1s - loss: 0.1560 - accuracy: 0.9158\n",
      "2871/5349 [===============>..............] - ETA: 1s - loss: 0.1561 - accuracy: 0.9158\n",
      "3085/5349 [================>.............] - ETA: 1s - loss: 0.1561 - accuracy: 0.9157\n",
      "3192/5349 [================>.............] - ETA: 1s - loss: 0.1560 - accuracy: 0.9158\n",
      "3408/5349 [==================>...........] - ETA: 1s - loss: 0.1557 - accuracy: 0.9161\n",
      "3625/5349 [===================>..........] - ETA: 1s - loss: 0.1560 - accuracy: 0.9160\n",
      "3837/5349 [====================>.........] - ETA: 0s - loss: 0.1562 - accuracy: 0.9159\n",
      "4051/5349 [=====================>........] - ETA: 0s - loss: 0.1562 - accuracy: 0.9158\n",
      "4332/5349 [=======================>......] - ETA: 0s - loss: 0.1561 - accuracy: 0.9158\n",
      "4553/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9158\n",
      "4768/5349 [=========================>....] - ETA: 0s - loss: 0.1561 - accuracy: 0.9158\n",
      "4984/5349 [==========================>...] - ETA: 0s - loss: 0.1560 - accuracy: 0.9159\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 0.9159\n",
      "5349/5349 [==============================] - 5s 895us/step - loss: 0.1559 - accuracy: 0.9159 - val_loss: 0.1530 - val_accuracy: 0.9175\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 16/20\n",
      "  35/5349 [..............................] - ETA: 7s - loss: 0.1538 - accuracy: 0.9140 \n",
      "  97/5349 [..............................] - ETA: 8s - loss: 0.1548 - accuracy: 0.9155\n",
      " 169/5349 [..............................] - ETA: 7s - loss: 0.1551 - accuracy: 0.9150\n",
      " 243/5349 [>.............................] - ETA: 7s - loss: 0.1544 - accuracy: 0.9151\n",
      " 310/5349 [>.............................] - ETA: 7s - loss: 0.1535 - accuracy: 0.9162\n",
      " 425/5349 [=>............................] - ETA: 7s - loss: 0.1551 - accuracy: 0.9154\n",
      " 508/5349 [=>............................] - ETA: 6s - loss: 0.1545 - accuracy: 0.9162\n",
      " 593/5349 [==>...........................] - ETA: 6s - loss: 0.1553 - accuracy: 0.9160\n",
      " 675/5349 [==>...........................] - ETA: 6s - loss: 0.1557 - accuracy: 0.9158\n",
      " 748/5349 [===>..........................] - ETA: 6s - loss: 0.1557 - accuracy: 0.9161\n",
      " 814/5349 [===>..........................] - ETA: 5s - loss: 0.1553 - accuracy: 0.9162\n",
      "1000/5349 [====>.........................] - ETA: 5s - loss: 0.1549 - accuracy: 0.9164\n",
      "1182/5349 [=====>........................] - ETA: 4s - loss: 0.1547 - accuracy: 0.9166\n",
      "1378/5349 [======>.......................] - ETA: 3s - loss: 0.1546 - accuracy: 0.9167\n",
      "1693/5349 [========>.....................] - ETA: 3s - loss: 0.1543 - accuracy: 0.9170\n",
      "1908/5349 [=========>....................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9168\n",
      "2119/5349 [==========>...................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9167\n",
      "2334/5349 [============>.................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9164\n",
      "2644/5349 [=============>................] - ETA: 2s - loss: 0.1551 - accuracy: 0.9161\n",
      "2858/5349 [===============>..............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9162\n",
      "3074/5349 [================>.............] - ETA: 1s - loss: 0.1549 - accuracy: 0.9162\n",
      "3291/5349 [=================>............] - ETA: 1s - loss: 0.1551 - accuracy: 0.9162\n",
      "3509/5349 [==================>...........] - ETA: 1s - loss: 0.1551 - accuracy: 0.9162\n",
      "3836/5349 [====================>.........] - ETA: 0s - loss: 0.1550 - accuracy: 0.9163\n",
      "4051/5349 [=====================>........] - ETA: 0s - loss: 0.1549 - accuracy: 0.9164\n",
      "4237/5349 [======================>.......] - ETA: 0s - loss: 0.1549 - accuracy: 0.9164\n",
      "4421/5349 [=======================>......] - ETA: 0s - loss: 0.1550 - accuracy: 0.9164\n",
      "4751/5349 [=========================>....] - ETA: 0s - loss: 0.1551 - accuracy: 0.9164\n",
      "4973/5349 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9164\n",
      "5198/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9163\n",
      "5303/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9163\n",
      "5349/5349 [==============================] - 4s 772us/step - loss: 0.1551 - accuracy: 0.9163 - val_loss: 0.1524 - val_accuracy: 0.9178\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1373 - accuracy: 0.9200\n",
      " 111/5349 [..............................] - ETA: 2s - loss: 0.1577 - accuracy: 0.9120\n",
      " 335/5349 [>.............................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9154\n",
      " 539/5349 [==>...........................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9157\n",
      " 760/5349 [===>..........................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9159\n",
      "1094/5349 [=====>........................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9156\n",
      "1317/5349 [======>.......................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9161\n",
      "1522/5349 [=======>......................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9161\n",
      "1745/5349 [========>.....................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "1963/5349 [==========>...................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9162\n",
      "2295/5349 [===========>..................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9162\n",
      "2520/5349 [=============>................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9162\n",
      "2742/5349 [==============>...............] - ETA: 1s - loss: 0.1550 - accuracy: 0.9162\n",
      "2949/5349 [===============>..............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9163\n",
      "3160/5349 [================>.............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9163\n",
      "3385/5349 [=================>............] - ETA: 0s - loss: 0.1548 - accuracy: 0.9164\n",
      "3712/5349 [===================>..........] - ETA: 0s - loss: 0.1549 - accuracy: 0.9162\n",
      "3933/5349 [=====================>........] - ETA: 0s - loss: 0.1548 - accuracy: 0.9163\n",
      "4157/5349 [======================>.......] - ETA: 0s - loss: 0.1547 - accuracy: 0.9164\n",
      "4378/5349 [=======================>......] - ETA: 0s - loss: 0.1546 - accuracy: 0.9165\n",
      "4684/5349 [=========================>....] - ETA: 0s - loss: 0.1546 - accuracy: 0.9165\n",
      "4902/5349 [==========================>...] - ETA: 0s - loss: 0.1547 - accuracy: 0.9164\n",
      "5127/5349 [===========================>..] - ETA: 0s - loss: 0.1547 - accuracy: 0.9164\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9164\n",
      "5349/5349 [==============================] - 3s 625us/step - loss: 0.1547 - accuracy: 0.9164 - val_loss: 0.1522 - val_accuracy: 0.9182\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1299 - accuracy: 0.9400\n",
      " 219/5349 [>.............................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9159\n",
      " 443/5349 [=>............................] - ETA: 2s - loss: 0.1544 - accuracy: 0.9163\n",
      " 662/5349 [==>...........................] - ETA: 2s - loss: 0.1552 - accuracy: 0.9157\n",
      " 773/5349 [===>..........................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9154\n",
      " 994/5349 [====>.........................] - ETA: 1s - loss: 0.1548 - accuracy: 0.9163\n",
      "1216/5349 [=====>........................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9171\n",
      "1439/5349 [=======>......................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9171\n",
      "1661/5349 [========>.....................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9168\n",
      "1984/5349 [==========>...................] - ETA: 1s - loss: 0.1536 - accuracy: 0.9172\n",
      "2193/5349 [===========>..................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9171\n",
      "2410/5349 [============>.................] - ETA: 1s - loss: 0.1536 - accuracy: 0.9171\n",
      "2631/5349 [=============>................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9169\n",
      "2844/5349 [==============>...............] - ETA: 1s - loss: 0.1543 - accuracy: 0.9166\n",
      "2952/5349 [===============>..............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9166\n",
      "3163/5349 [================>.............] - ETA: 1s - loss: 0.1545 - accuracy: 0.9165\n",
      "3383/5349 [=================>............] - ETA: 0s - loss: 0.1545 - accuracy: 0.9165\n",
      "3601/5349 [===================>..........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9165\n",
      "3815/5349 [====================>.........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9165\n",
      "4036/5349 [=====================>........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9165\n",
      "4251/5349 [======================>.......] - ETA: 0s - loss: 0.1542 - accuracy: 0.9168\n",
      "4585/5349 [========================>.....] - ETA: 0s - loss: 0.1541 - accuracy: 0.9168\n",
      "4783/5349 [=========================>....] - ETA: 0s - loss: 0.1542 - accuracy: 0.9167\n",
      "5008/5349 [===========================>..] - ETA: 0s - loss: 0.1542 - accuracy: 0.9167\n",
      "5229/5349 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9167\n",
      "5334/5349 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9167\n",
      "5349/5349 [==============================] - 3s 624us/step - loss: 0.1541 - accuracy: 0.9167 - val_loss: 0.1516 - val_accuracy: 0.9183\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 19/20\n",
      " 219/5349 [>.............................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9181\n",
      " 435/5349 [=>............................] - ETA: 2s - loss: 0.1514 - accuracy: 0.9193\n",
      " 651/5349 [==>...........................] - ETA: 2s - loss: 0.1527 - accuracy: 0.9182\n",
      " 862/5349 [===>..........................] - ETA: 2s - loss: 0.1527 - accuracy: 0.9178\n",
      "1084/5349 [=====>........................] - ETA: 1s - loss: 0.1532 - accuracy: 0.9178\n",
      "1296/5349 [======>.......................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9172\n",
      "1617/5349 [========>.....................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9170\n",
      "1805/5349 [=========>....................] - ETA: 1s - loss: 0.1542 - accuracy: 0.9169\n",
      "1917/5349 [=========>....................] - ETA: 1s - loss: 0.1540 - accuracy: 0.9171\n",
      "2039/5349 [==========>...................] - ETA: 1s - loss: 0.1539 - accuracy: 0.9170\n",
      "2163/5349 [===========>..................] - ETA: 1s - loss: 0.1539 - accuracy: 0.9171\n",
      "2283/5349 [===========>..................] - ETA: 1s - loss: 0.1537 - accuracy: 0.9172\n",
      "2492/5349 [============>.................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9174\n",
      "2619/5349 [=============>................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9174\n",
      "2801/5349 [==============>...............] - ETA: 1s - loss: 0.1536 - accuracy: 0.9174\n",
      "2974/5349 [===============>..............] - ETA: 1s - loss: 0.1534 - accuracy: 0.9175\n",
      "3163/5349 [================>.............] - ETA: 1s - loss: 0.1534 - accuracy: 0.9175\n",
      "3342/5349 [=================>............] - ETA: 1s - loss: 0.1536 - accuracy: 0.9172\n",
      "3527/5349 [==================>...........] - ETA: 1s - loss: 0.1536 - accuracy: 0.9172\n",
      "3694/5349 [===================>..........] - ETA: 0s - loss: 0.1537 - accuracy: 0.9171\n",
      "3787/5349 [====================>.........] - ETA: 0s - loss: 0.1536 - accuracy: 0.9171\n",
      "3955/5349 [=====================>........] - ETA: 0s - loss: 0.1537 - accuracy: 0.9170\n",
      "4137/5349 [======================>.......] - ETA: 0s - loss: 0.1538 - accuracy: 0.9169\n",
      "4333/5349 [=======================>......] - ETA: 0s - loss: 0.1538 - accuracy: 0.9169\n",
      "4482/5349 [========================>.....] - ETA: 0s - loss: 0.1538 - accuracy: 0.9169\n",
      "4668/5349 [=========================>....] - ETA: 0s - loss: 0.1538 - accuracy: 0.9170\n",
      "4843/5349 [==========================>...] - ETA: 0s - loss: 0.1539 - accuracy: 0.9170\n",
      "4931/5349 [==========================>...] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5056/5349 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.9170\n",
      "5104/5349 [===========================>..] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5166/5349 [===========================>..] - ETA: 0s - loss: 0.1538 - accuracy: 0.9170\n",
      "5222/5349 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5274/5349 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5304/5349 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5325/5349 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9169\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1540 - accuracy: 0.9169 - val_loss: 0.1535 - val_accuracy: 0.9166\n",
      "\u001B[36m(train_DNN pid=5973)\u001B[0m Epoch 20/20\n",
      " 165/5349 [..............................] - ETA: 3s - loss: 0.1546 - accuracy: 0.9146\n",
      " 341/5349 [>.............................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9154\n",
      " 514/5349 [=>............................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9164\n",
      " 650/5349 [==>...........................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9169\n",
      " 781/5349 [===>..........................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9169\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.1533 - accuracy: 0.9172\n",
      "1124/5349 [=====>........................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9167\n",
      "1271/5349 [======>.......................] - ETA: 2s - loss: 0.1542 - accuracy: 0.9169\n",
      "1410/5349 [======>.......................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9168\n",
      "1559/5349 [=======>......................] - ETA: 2s - loss: 0.1540 - accuracy: 0.9170\n",
      "1719/5349 [========>.....................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9174\n",
      "1805/5349 [=========>....................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9176\n",
      "2012/5349 [==========>...................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9175\n",
      "2157/5349 [===========>..................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9174\n",
      "2346/5349 [============>.................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9176\n",
      "2508/5349 [=============>................] - ETA: 1s - loss: 0.1534 - accuracy: 0.9176\n",
      "2700/5349 [==============>...............] - ETA: 1s - loss: 0.1535 - accuracy: 0.9175\n",
      "2883/5349 [===============>..............] - ETA: 1s - loss: 0.1534 - accuracy: 0.9176\n",
      "3079/5349 [================>.............] - ETA: 1s - loss: 0.1534 - accuracy: 0.9176\n",
      "3262/5349 [=================>............] - ETA: 1s - loss: 0.1536 - accuracy: 0.9174\n",
      "3541/5349 [==================>...........] - ETA: 1s - loss: 0.1533 - accuracy: 0.9176\n",
      "3720/5349 [===================>..........] - ETA: 1s - loss: 0.1534 - accuracy: 0.9176\n",
      "3895/5349 [====================>.........] - ETA: 0s - loss: 0.1534 - accuracy: 0.9176\n",
      "4052/5349 [=====================>........] - ETA: 0s - loss: 0.1533 - accuracy: 0.9176\n",
      "4231/5349 [======================>.......] - ETA: 0s - loss: 0.1533 - accuracy: 0.9177\n",
      "4313/5349 [=======================>......] - ETA: 0s - loss: 0.1533 - accuracy: 0.9176\n",
      "4484/5349 [========================>.....] - ETA: 0s - loss: 0.1532 - accuracy: 0.9177\n",
      "4644/5349 [=========================>....] - ETA: 0s - loss: 0.1532 - accuracy: 0.9177\n",
      "4812/5349 [=========================>....] - ETA: 0s - loss: 0.1531 - accuracy: 0.9178\n",
      "4992/5349 [==========================>...] - ETA: 0s - loss: 0.1531 - accuracy: 0.9178\n",
      "5166/5349 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.9176\n",
      "5327/5349 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9175\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 28:50 - loss: 0.5251 - accuracy: 0.8700\n",
      " 136/5349 [..............................] - ETA: 3s - loss: 0.4162 - accuracy: 0.8383\n",
      " 277/5349 [>.............................] - ETA: 3s - loss: 0.3157 - accuracy: 0.8591\n",
      " 485/5349 [=>............................] - ETA: 3s - loss: 0.2531 - accuracy: 0.8824\n",
      " 631/5349 [==>...........................] - ETA: 3s - loss: 0.2318 - accuracy: 0.8906\n",
      " 770/5349 [===>..........................] - ETA: 3s - loss: 0.2189 - accuracy: 0.8951\n",
      " 914/5349 [====>.........................] - ETA: 3s - loss: 0.2089 - accuracy: 0.8987\n",
      "1051/5349 [====>.........................] - ETA: 3s - loss: 0.2027 - accuracy: 0.9007\n",
      "1180/5349 [=====>........................] - ETA: 3s - loss: 0.1977 - accuracy: 0.9026\n",
      "1310/5349 [======>.......................] - ETA: 2s - loss: 0.1938 - accuracy: 0.9041\n",
      "1455/5349 [=======>......................] - ETA: 2s - loss: 0.1902 - accuracy: 0.9052\n",
      "1584/5349 [=======>......................] - ETA: 2s - loss: 0.1872 - accuracy: 0.9063\n",
      "1714/5349 [========>.....................] - ETA: 2s - loss: 0.1843 - accuracy: 0.9076\n",
      "1839/5349 [=========>....................] - ETA: 2s - loss: 0.1823 - accuracy: 0.9084\n",
      "2012/5349 [==========>...................] - ETA: 2s - loss: 0.1801 - accuracy: 0.9090\n",
      "2113/5349 [==========>...................] - ETA: 2s - loss: 0.1789 - accuracy: 0.9094\n",
      "2195/5349 [===========>..................] - ETA: 2s - loss: 0.1781 - accuracy: 0.9097\n",
      "2270/5349 [===========>..................] - ETA: 2s - loss: 0.1772 - accuracy: 0.9101\n",
      "2378/5349 [============>.................] - ETA: 2s - loss: 0.1760 - accuracy: 0.9104\n",
      "2446/5349 [============>.................] - ETA: 2s - loss: 0.1754 - accuracy: 0.9105\n",
      "2563/5349 [=============>................] - ETA: 2s - loss: 0.1744 - accuracy: 0.9108\n",
      "2649/5349 [=============>................] - ETA: 2s - loss: 0.1738 - accuracy: 0.9110\n",
      "2757/5349 [==============>...............] - ETA: 2s - loss: 0.1731 - accuracy: 0.9112\n",
      "2843/5349 [==============>...............] - ETA: 2s - loss: 0.1726 - accuracy: 0.9113\n",
      "2943/5349 [===============>..............] - ETA: 2s - loss: 0.1719 - accuracy: 0.9115\n",
      "3116/5349 [================>.............] - ETA: 1s - loss: 0.1707 - accuracy: 0.9119\n",
      "3244/5349 [=================>............] - ETA: 1s - loss: 0.1700 - accuracy: 0.9121\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1692 - accuracy: 0.9124\n",
      "3511/5349 [==================>...........] - ETA: 1s - loss: 0.1686 - accuracy: 0.9125\n",
      "3640/5349 [===================>..........] - ETA: 1s - loss: 0.1678 - accuracy: 0.9128\n",
      "3772/5349 [====================>.........] - ETA: 1s - loss: 0.1670 - accuracy: 0.9133\n",
      "3903/5349 [====================>.........] - ETA: 1s - loss: 0.1665 - accuracy: 0.9133\n",
      "4043/5349 [=====================>........] - ETA: 1s - loss: 0.1657 - accuracy: 0.9137\n",
      "4164/5349 [======================>.......] - ETA: 1s - loss: 0.1654 - accuracy: 0.9137\n",
      "4367/5349 [=======================>......] - ETA: 0s - loss: 0.1647 - accuracy: 0.9140\n",
      "4497/5349 [========================>.....] - ETA: 0s - loss: 0.1641 - accuracy: 0.9142\n",
      "4632/5349 [========================>.....] - ETA: 0s - loss: 0.1637 - accuracy: 0.9144\n",
      "4754/5349 [=========================>....] - ETA: 0s - loss: 0.1633 - accuracy: 0.9146\n",
      "4895/5349 [==========================>...] - ETA: 0s - loss: 0.1629 - accuracy: 0.9147\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.1624 - accuracy: 0.9149\n",
      "5165/5349 [===========================>..] - ETA: 0s - loss: 0.1621 - accuracy: 0.9151\n",
      "5231/5349 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9151\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9151\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1617 - accuracy: 0.9152 - val_loss: 0.1449 - val_accuracy: 0.9215\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1224 - accuracy: 0.9300\n",
      " 131/5349 [..............................] - ETA: 4s - loss: 0.1492 - accuracy: 0.9174\n",
      " 270/5349 [>.............................] - ETA: 3s - loss: 0.1488 - accuracy: 0.9183\n",
      " 328/5349 [>.............................] - ETA: 3s - loss: 0.1486 - accuracy: 0.9188\n",
      " 461/5349 [=>............................] - ETA: 3s - loss: 0.1472 - accuracy: 0.9204\n",
      " 599/5349 [==>...........................] - ETA: 3s - loss: 0.1462 - accuracy: 0.9211\n",
      " 728/5349 [===>..........................] - ETA: 3s - loss: 0.1459 - accuracy: 0.9214\n",
      " 867/5349 [===>..........................] - ETA: 3s - loss: 0.1459 - accuracy: 0.9213\n",
      " 997/5349 [====>.........................] - ETA: 3s - loss: 0.1459 - accuracy: 0.9210\n",
      "1126/5349 [=====>........................] - ETA: 3s - loss: 0.1459 - accuracy: 0.9208\n",
      "1254/5349 [======>.......................] - ETA: 3s - loss: 0.1457 - accuracy: 0.9208\n",
      "1457/5349 [=======>......................] - ETA: 2s - loss: 0.1457 - accuracy: 0.9211\n",
      "1592/5349 [=======>......................] - ETA: 2s - loss: 0.1459 - accuracy: 0.9208\n",
      "1728/5349 [========>.....................] - ETA: 2s - loss: 0.1455 - accuracy: 0.9209\n",
      "1835/5349 [=========>....................] - ETA: 2s - loss: 0.1451 - accuracy: 0.9213\n",
      "1971/5349 [==========>...................] - ETA: 2s - loss: 0.1452 - accuracy: 0.9213\n",
      "2067/5349 [==========>...................] - ETA: 2s - loss: 0.1451 - accuracy: 0.9213\n",
      "2204/5349 [===========>..................] - ETA: 2s - loss: 0.1446 - accuracy: 0.9216\n",
      "2327/5349 [============>.................] - ETA: 2s - loss: 0.1445 - accuracy: 0.9217\n",
      "2464/5349 [============>.................] - ETA: 2s - loss: 0.1443 - accuracy: 0.9219\n",
      "2598/5349 [=============>................] - ETA: 2s - loss: 0.1444 - accuracy: 0.9218\n",
      "2805/5349 [==============>...............] - ETA: 1s - loss: 0.1442 - accuracy: 0.9219\n",
      "2937/5349 [===============>..............] - ETA: 1s - loss: 0.1444 - accuracy: 0.9218\n",
      "3072/5349 [================>.............] - ETA: 1s - loss: 0.1443 - accuracy: 0.9218\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.1441 - accuracy: 0.9220\n",
      "3342/5349 [=================>............] - ETA: 1s - loss: 0.1440 - accuracy: 0.9220\n",
      "3475/5349 [==================>...........] - ETA: 1s - loss: 0.1438 - accuracy: 0.9221\n",
      "3613/5349 [===================>..........] - ETA: 1s - loss: 0.1435 - accuracy: 0.9223\n",
      "3747/5349 [====================>.........] - ETA: 1s - loss: 0.1434 - accuracy: 0.9224\n",
      "3950/5349 [=====================>........] - ETA: 1s - loss: 0.1434 - accuracy: 0.9224\n",
      "4086/5349 [=====================>........] - ETA: 0s - loss: 0.1433 - accuracy: 0.9225\n",
      "4225/5349 [======================>.......] - ETA: 0s - loss: 0.1432 - accuracy: 0.9226\n",
      "4348/5349 [=======================>......] - ETA: 0s - loss: 0.1432 - accuracy: 0.9226\n",
      "4465/5349 [========================>.....] - ETA: 0s - loss: 0.1430 - accuracy: 0.9227\n",
      "4544/5349 [========================>.....] - ETA: 0s - loss: 0.1429 - accuracy: 0.9227\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1428 - accuracy: 0.9229\n",
      "4783/5349 [=========================>....] - ETA: 0s - loss: 0.1428 - accuracy: 0.9228\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.1427 - accuracy: 0.9228\n",
      "5060/5349 [===========================>..] - ETA: 0s - loss: 0.1427 - accuracy: 0.9228\n",
      "5155/5349 [===========================>..] - ETA: 0s - loss: 0.1426 - accuracy: 0.9229\n",
      "5268/5349 [============================>.] - ETA: 0s - loss: 0.1425 - accuracy: 0.9230\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1424 - accuracy: 0.9231\n",
      "5349/5349 [==============================] - 5s 1ms/step - loss: 0.1424 - accuracy: 0.9230 - val_loss: 0.1371 - val_accuracy: 0.9289\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 32s - loss: 0.1440 - accuracy: 0.8900\n",
      "  54/5349 [..............................] - ETA: 10s - loss: 0.1397 - accuracy: 0.9272\n",
      "  85/5349 [..............................] - ETA: 13s - loss: 0.1400 - accuracy: 0.9279\n",
      " 103/5349 [..............................] - ETA: 13s - loss: 0.1389 - accuracy: 0.9283\n",
      " 190/5349 [>.............................] - ETA: 10s - loss: 0.1381 - accuracy: 0.9267\n",
      " 278/5349 [>.............................] - ETA: 8s - loss: 0.1377 - accuracy: 0.9258\n",
      " 329/5349 [>.............................] - ETA: 8s - loss: 0.1385 - accuracy: 0.9253\n",
      " 377/5349 [=>............................] - ETA: 8s - loss: 0.1376 - accuracy: 0.9261\n",
      " 418/5349 [=>............................] - ETA: 9s - loss: 0.1382 - accuracy: 0.9256\n",
      " 442/5349 [=>............................] - ETA: 9s - loss: 0.1379 - accuracy: 0.9261\n",
      " 490/5349 [=>............................] - ETA: 9s - loss: 0.1374 - accuracy: 0.9261\n",
      " 557/5349 [==>...........................] - ETA: 8s - loss: 0.1369 - accuracy: 0.9261\n",
      " 589/5349 [==>...........................] - ETA: 9s - loss: 0.1367 - accuracy: 0.9264\n",
      " 624/5349 [==>...........................] - ETA: 9s - loss: 0.1369 - accuracy: 0.9264\n",
      " 673/5349 [==>...........................] - ETA: 9s - loss: 0.1368 - accuracy: 0.9266\n",
      " 709/5349 [==>...........................] - ETA: 9s - loss: 0.1365 - accuracy: 0.9269\n",
      " 743/5349 [===>..........................] - ETA: 9s - loss: 0.1367 - accuracy: 0.9265\n",
      " 814/5349 [===>..........................] - ETA: 9s - loss: 0.1367 - accuracy: 0.9262\n",
      " 874/5349 [===>..........................] - ETA: 9s - loss: 0.1369 - accuracy: 0.9260\n",
      " 913/5349 [====>.........................] - ETA: 9s - loss: 0.1373 - accuracy: 0.9256\n",
      " 963/5349 [====>.........................] - ETA: 9s - loss: 0.1375 - accuracy: 0.9256\n",
      "1005/5349 [====>.........................] - ETA: 9s - loss: 0.1374 - accuracy: 0.9258\n",
      "1098/5349 [=====>........................] - ETA: 8s - loss: 0.1372 - accuracy: 0.9262\n",
      "1150/5349 [=====>........................] - ETA: 8s - loss: 0.1375 - accuracy: 0.9262\n",
      "1221/5349 [=====>........................] - ETA: 8s - loss: 0.1371 - accuracy: 0.9266\n",
      "1360/5349 [======>.......................] - ETA: 7s - loss: 0.1367 - accuracy: 0.9269\n",
      "1473/5349 [=======>......................] - ETA: 7s - loss: 0.1368 - accuracy: 0.9267\n",
      "1584/5349 [=======>......................] - ETA: 6s - loss: 0.1372 - accuracy: 0.9265\n",
      "1660/5349 [========>.....................] - ETA: 6s - loss: 0.1372 - accuracy: 0.9265\n",
      "1824/5349 [=========>....................] - ETA: 5s - loss: 0.1370 - accuracy: 0.9265\n",
      "1987/5349 [==========>...................] - ETA: 5s - loss: 0.1371 - accuracy: 0.9266\n",
      "2152/5349 [===========>..................] - ETA: 4s - loss: 0.1369 - accuracy: 0.9269\n",
      "2313/5349 [===========>..................] - ETA: 4s - loss: 0.1367 - accuracy: 0.9271\n",
      "2561/5349 [=============>................] - ETA: 3s - loss: 0.1362 - accuracy: 0.9274\n",
      "2719/5349 [==============>...............] - ETA: 3s - loss: 0.1363 - accuracy: 0.9273\n",
      "2882/5349 [===============>..............] - ETA: 3s - loss: 0.1365 - accuracy: 0.9273\n",
      "3046/5349 [================>.............] - ETA: 2s - loss: 0.1364 - accuracy: 0.9274\n",
      "3295/5349 [=================>............] - ETA: 2s - loss: 0.1365 - accuracy: 0.9272\n",
      "3452/5349 [==================>...........] - ETA: 2s - loss: 0.1366 - accuracy: 0.9272\n",
      "3617/5349 [===================>..........] - ETA: 1s - loss: 0.1365 - accuracy: 0.9273\n",
      "3779/5349 [====================>.........] - ETA: 1s - loss: 0.1365 - accuracy: 0.9273\n",
      "4016/5349 [=====================>........] - ETA: 1s - loss: 0.1364 - accuracy: 0.9274\n",
      "4159/5349 [======================>.......] - ETA: 1s - loss: 0.1361 - accuracy: 0.9275\n",
      "4315/5349 [=======================>......] - ETA: 1s - loss: 0.1360 - accuracy: 0.9277\n",
      "4467/5349 [========================>.....] - ETA: 0s - loss: 0.1358 - accuracy: 0.9277\n",
      "4621/5349 [========================>.....] - ETA: 0s - loss: 0.1359 - accuracy: 0.9278\n",
      "4776/5349 [=========================>....] - ETA: 0s - loss: 0.1358 - accuracy: 0.9278\n",
      "4932/5349 [==========================>...] - ETA: 0s - loss: 0.1358 - accuracy: 0.9277\n",
      "5164/5349 [===========================>..] - ETA: 0s - loss: 0.1356 - accuracy: 0.9279\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.9280\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1354 - accuracy: 0.9280 - val_loss: 0.1312 - val_accuracy: 0.9305\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 4/20\n",
      " 156/5349 [..............................] - ETA: 3s - loss: 0.1301 - accuracy: 0.9290\n",
      " 312/5349 [>.............................] - ETA: 3s - loss: 0.1304 - accuracy: 0.9296\n",
      " 472/5349 [=>............................] - ETA: 3s - loss: 0.1311 - accuracy: 0.9289\n",
      " 628/5349 [==>...........................] - ETA: 3s - loss: 0.1312 - accuracy: 0.9285\n",
      " 789/5349 [===>..........................] - ETA: 2s - loss: 0.1307 - accuracy: 0.9287\n",
      "1024/5349 [====>.........................] - ETA: 2s - loss: 0.1305 - accuracy: 0.9290\n",
      "1181/5349 [=====>........................] - ETA: 2s - loss: 0.1308 - accuracy: 0.9292\n",
      "1335/5349 [======>.......................] - ETA: 2s - loss: 0.1309 - accuracy: 0.9295\n",
      "1494/5349 [=======>......................] - ETA: 2s - loss: 0.1313 - accuracy: 0.9294\n",
      "1647/5349 [========>.....................] - ETA: 2s - loss: 0.1308 - accuracy: 0.9296\n",
      "1885/5349 [=========>....................] - ETA: 2s - loss: 0.1304 - accuracy: 0.9301\n",
      "2028/5349 [==========>...................] - ETA: 2s - loss: 0.1305 - accuracy: 0.9301\n",
      "2187/5349 [===========>..................] - ETA: 2s - loss: 0.1301 - accuracy: 0.9304\n",
      "2340/5349 [============>.................] - ETA: 1s - loss: 0.1303 - accuracy: 0.9302\n",
      "2576/5349 [=============>................] - ETA: 1s - loss: 0.1301 - accuracy: 0.9303\n",
      "2730/5349 [==============>...............] - ETA: 1s - loss: 0.1303 - accuracy: 0.9302\n",
      "2887/5349 [===============>..............] - ETA: 1s - loss: 0.1303 - accuracy: 0.9300\n",
      "3044/5349 [================>.............] - ETA: 1s - loss: 0.1299 - accuracy: 0.9303\n",
      "3202/5349 [================>.............] - ETA: 1s - loss: 0.1298 - accuracy: 0.9304\n",
      "3282/5349 [=================>............] - ETA: 1s - loss: 0.1296 - accuracy: 0.9305\n",
      "3435/5349 [==================>...........] - ETA: 1s - loss: 0.1295 - accuracy: 0.9307\n",
      "3593/5349 [===================>..........] - ETA: 1s - loss: 0.1295 - accuracy: 0.9308\n",
      "3746/5349 [====================>.........] - ETA: 1s - loss: 0.1292 - accuracy: 0.9311\n",
      "3889/5349 [====================>.........] - ETA: 0s - loss: 0.1291 - accuracy: 0.9312\n",
      "4043/5349 [=====================>........] - ETA: 0s - loss: 0.1290 - accuracy: 0.9313\n",
      "4122/5349 [======================>.......] - ETA: 0s - loss: 0.1289 - accuracy: 0.9314\n",
      "4275/5349 [======================>.......] - ETA: 0s - loss: 0.1290 - accuracy: 0.9313\n",
      "4418/5349 [=======================>......] - ETA: 0s - loss: 0.1288 - accuracy: 0.9314\n",
      "4578/5349 [========================>.....] - ETA: 0s - loss: 0.1287 - accuracy: 0.9315\n",
      "4733/5349 [=========================>....] - ETA: 0s - loss: 0.1287 - accuracy: 0.9315\n",
      "4889/5349 [==========================>...] - ETA: 0s - loss: 0.1285 - accuracy: 0.9315\n",
      "4966/5349 [==========================>...] - ETA: 0s - loss: 0.1285 - accuracy: 0.9316\n",
      "5121/5349 [===========================>..] - ETA: 0s - loss: 0.1284 - accuracy: 0.9317\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9316\n",
      "5349/5349 [==============================] - 4s 808us/step - loss: 0.1283 - accuracy: 0.9316 - val_loss: 0.1241 - val_accuracy: 0.9343\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 5/20\n",
      " 159/5349 [..............................] - ETA: 3s - loss: 0.1298 - accuracy: 0.9297\n",
      " 318/5349 [>.............................] - ETA: 3s - loss: 0.1282 - accuracy: 0.9308\n",
      " 480/5349 [=>............................] - ETA: 3s - loss: 0.1268 - accuracy: 0.9324\n",
      " 623/5349 [==>...........................] - ETA: 3s - loss: 0.1270 - accuracy: 0.9324\n",
      " 781/5349 [===>..........................] - ETA: 2s - loss: 0.1268 - accuracy: 0.9323\n",
      "1015/5349 [====>.........................] - ETA: 2s - loss: 0.1257 - accuracy: 0.9328\n",
      "1173/5349 [=====>........................] - ETA: 2s - loss: 0.1256 - accuracy: 0.9329\n",
      "1330/5349 [======>.......................] - ETA: 2s - loss: 0.1260 - accuracy: 0.9328\n",
      "1489/5349 [=======>......................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9329\n",
      "1725/5349 [========>.....................] - ETA: 2s - loss: 0.1259 - accuracy: 0.9330\n",
      "1883/5349 [=========>....................] - ETA: 2s - loss: 0.1258 - accuracy: 0.9328\n",
      "2038/5349 [==========>...................] - ETA: 2s - loss: 0.1259 - accuracy: 0.9327\n",
      "2196/5349 [===========>..................] - ETA: 2s - loss: 0.1260 - accuracy: 0.9325\n",
      "2428/5349 [============>.................] - ETA: 1s - loss: 0.1255 - accuracy: 0.9328\n",
      "2587/5349 [=============>................] - ETA: 1s - loss: 0.1253 - accuracy: 0.9328\n",
      "2728/5349 [==============>...............] - ETA: 1s - loss: 0.1250 - accuracy: 0.9330\n",
      "2886/5349 [===============>..............] - ETA: 1s - loss: 0.1250 - accuracy: 0.9329\n",
      "3038/5349 [================>.............] - ETA: 1s - loss: 0.1250 - accuracy: 0.9329\n",
      "3273/5349 [=================>............] - ETA: 1s - loss: 0.1250 - accuracy: 0.9330\n",
      "3428/5349 [==================>...........] - ETA: 1s - loss: 0.1249 - accuracy: 0.9331\n",
      "3578/5349 [===================>..........] - ETA: 1s - loss: 0.1248 - accuracy: 0.9332\n",
      "3734/5349 [===================>..........] - ETA: 1s - loss: 0.1245 - accuracy: 0.9335\n",
      "3891/5349 [====================>.........] - ETA: 0s - loss: 0.1244 - accuracy: 0.9335\n",
      "4108/5349 [======================>.......] - ETA: 0s - loss: 0.1242 - accuracy: 0.9335\n",
      "4255/5349 [======================>.......] - ETA: 0s - loss: 0.1242 - accuracy: 0.9334\n",
      "4415/5349 [=======================>......] - ETA: 0s - loss: 0.1242 - accuracy: 0.9335\n",
      "4573/5349 [========================>.....] - ETA: 0s - loss: 0.1242 - accuracy: 0.9334\n",
      "4721/5349 [=========================>....] - ETA: 0s - loss: 0.1243 - accuracy: 0.9333\n",
      "4798/5349 [=========================>....] - ETA: 0s - loss: 0.1242 - accuracy: 0.9334\n",
      "4953/5349 [==========================>...] - ETA: 0s - loss: 0.1242 - accuracy: 0.9335\n",
      "5109/5349 [===========================>..] - ETA: 0s - loss: 0.1242 - accuracy: 0.9335\n",
      "5253/5349 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9336\n",
      "5331/5349 [============================>.] - ETA: 0s - loss: 0.1239 - accuracy: 0.9336\n",
      "5349/5349 [==============================] - 4s 818us/step - loss: 0.1239 - accuracy: 0.9336 - val_loss: 0.1205 - val_accuracy: 0.9381\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 6/20\n",
      "  78/5349 [..............................] - ETA: 3s - loss: 0.1218 - accuracy: 0.9342\n",
      " 205/5349 [>.............................] - ETA: 3s - loss: 0.1226 - accuracy: 0.9326\n",
      " 248/5349 [>.............................] - ETA: 5s - loss: 0.1219 - accuracy: 0.9323\n",
      " 295/5349 [>.............................] - ETA: 6s - loss: 0.1215 - accuracy: 0.9324\n",
      " 368/5349 [=>............................] - ETA: 6s - loss: 0.1215 - accuracy: 0.9337\n",
      " 421/5349 [=>............................] - ETA: 6s - loss: 0.1224 - accuracy: 0.9333\n",
      " 457/5349 [=>............................] - ETA: 6s - loss: 0.1222 - accuracy: 0.9333\n",
      " 517/5349 [=>............................] - ETA: 6s - loss: 0.1223 - accuracy: 0.9332\n",
      " 551/5349 [==>...........................] - ETA: 7s - loss: 0.1219 - accuracy: 0.9333\n",
      " 604/5349 [==>...........................] - ETA: 7s - loss: 0.1215 - accuracy: 0.9339\n",
      " 664/5349 [==>...........................] - ETA: 7s - loss: 0.1207 - accuracy: 0.9346\n",
      " 724/5349 [===>..........................] - ETA: 7s - loss: 0.1214 - accuracy: 0.9342\n",
      " 782/5349 [===>..........................] - ETA: 7s - loss: 0.1218 - accuracy: 0.9342\n",
      " 837/5349 [===>..........................] - ETA: 7s - loss: 0.1219 - accuracy: 0.9341\n",
      " 884/5349 [===>..........................] - ETA: 7s - loss: 0.1217 - accuracy: 0.9342\n",
      " 958/5349 [====>.........................] - ETA: 7s - loss: 0.1220 - accuracy: 0.9341\n",
      "1022/5349 [====>.........................] - ETA: 7s - loss: 0.1222 - accuracy: 0.9342\n",
      "1083/5349 [=====>........................] - ETA: 7s - loss: 0.1221 - accuracy: 0.9343\n",
      "1128/5349 [=====>........................] - ETA: 7s - loss: 0.1219 - accuracy: 0.9344\n",
      "1180/5349 [=====>........................] - ETA: 7s - loss: 0.1220 - accuracy: 0.9345\n",
      "1202/5349 [=====>........................] - ETA: 7s - loss: 0.1220 - accuracy: 0.9345\n",
      "1262/5349 [======>.......................] - ETA: 7s - loss: 0.1222 - accuracy: 0.9343\n",
      "1322/5349 [======>.......................] - ETA: 6s - loss: 0.1220 - accuracy: 0.9344\n",
      "1368/5349 [======>.......................] - ETA: 6s - loss: 0.1221 - accuracy: 0.9343\n",
      "1425/5349 [======>.......................] - ETA: 6s - loss: 0.1221 - accuracy: 0.9343\n",
      "1484/5349 [=======>......................] - ETA: 6s - loss: 0.1224 - accuracy: 0.9340\n",
      "1567/5349 [=======>......................] - ETA: 6s - loss: 0.1224 - accuracy: 0.9339\n",
      "1630/5349 [========>.....................] - ETA: 6s - loss: 0.1225 - accuracy: 0.9339\n",
      "1725/5349 [========>.....................] - ETA: 6s - loss: 0.1225 - accuracy: 0.9339\n",
      "1867/5349 [=========>....................] - ETA: 5s - loss: 0.1224 - accuracy: 0.9340\n",
      "2033/5349 [==========>...................] - ETA: 5s - loss: 0.1226 - accuracy: 0.9338\n",
      "2193/5349 [===========>..................] - ETA: 4s - loss: 0.1226 - accuracy: 0.9336\n",
      "2360/5349 [============>.................] - ETA: 4s - loss: 0.1225 - accuracy: 0.9339\n",
      "2519/5349 [=============>................] - ETA: 3s - loss: 0.1224 - accuracy: 0.9338\n",
      "2764/5349 [==============>...............] - ETA: 3s - loss: 0.1221 - accuracy: 0.9342\n",
      "2924/5349 [===============>..............] - ETA: 3s - loss: 0.1222 - accuracy: 0.9341\n",
      "3089/5349 [================>.............] - ETA: 2s - loss: 0.1219 - accuracy: 0.9343\n",
      "3248/5349 [=================>............] - ETA: 2s - loss: 0.1222 - accuracy: 0.9341\n",
      "3495/5349 [==================>...........] - ETA: 2s - loss: 0.1221 - accuracy: 0.9343\n",
      "3644/5349 [===================>..........] - ETA: 1s - loss: 0.1220 - accuracy: 0.9344\n",
      "3810/5349 [====================>.........] - ETA: 1s - loss: 0.1220 - accuracy: 0.9344\n",
      "3971/5349 [=====================>........] - ETA: 1s - loss: 0.1218 - accuracy: 0.9346\n",
      "4130/5349 [======================>.......] - ETA: 1s - loss: 0.1217 - accuracy: 0.9346\n",
      "4286/5349 [=======================>......] - ETA: 1s - loss: 0.1215 - accuracy: 0.9347\n",
      "4445/5349 [=======================>......] - ETA: 0s - loss: 0.1216 - accuracy: 0.9346\n",
      "4677/5349 [=========================>....] - ETA: 0s - loss: 0.1215 - accuracy: 0.9346\n",
      "4831/5349 [==========================>...] - ETA: 0s - loss: 0.1216 - accuracy: 0.9346\n",
      "4987/5349 [==========================>...] - ETA: 0s - loss: 0.1215 - accuracy: 0.9346\n",
      "5128/5349 [===========================>..] - ETA: 0s - loss: 0.1215 - accuracy: 0.9347\n",
      "5280/5349 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9348\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1213 - accuracy: 0.9348 - val_loss: 0.1231 - val_accuracy: 0.9312\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 7/20\n",
      "  79/5349 [..............................] - ETA: 3s - loss: 0.1203 - accuracy: 0.9349\n",
      " 311/5349 [>.............................] - ETA: 3s - loss: 0.1192 - accuracy: 0.9365\n",
      " 471/5349 [=>............................] - ETA: 3s - loss: 0.1197 - accuracy: 0.9356\n",
      " 628/5349 [==>...........................] - ETA: 3s - loss: 0.1192 - accuracy: 0.9358\n",
      " 781/5349 [===>..........................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9356\n",
      " 937/5349 [====>.........................] - ETA: 2s - loss: 0.1201 - accuracy: 0.9355\n",
      "1093/5349 [=====>........................] - ETA: 2s - loss: 0.1198 - accuracy: 0.9358\n",
      "1328/5349 [======>.......................] - ETA: 2s - loss: 0.1199 - accuracy: 0.9354\n",
      "1487/5349 [=======>......................] - ETA: 2s - loss: 0.1205 - accuracy: 0.9349\n",
      "1629/5349 [========>.....................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9350\n",
      "1787/5349 [=========>....................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9350\n",
      "2021/5349 [==========>...................] - ETA: 2s - loss: 0.1202 - accuracy: 0.9351\n",
      "2169/5349 [===========>..................] - ETA: 2s - loss: 0.1203 - accuracy: 0.9351\n",
      "2325/5349 [============>.................] - ETA: 1s - loss: 0.1200 - accuracy: 0.9352\n",
      "2483/5349 [============>.................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9354\n",
      "2639/5349 [=============>................] - ETA: 1s - loss: 0.1200 - accuracy: 0.9355\n",
      "2720/5349 [==============>...............] - ETA: 1s - loss: 0.1199 - accuracy: 0.9354\n",
      "2875/5349 [===============>..............] - ETA: 1s - loss: 0.1198 - accuracy: 0.9355\n",
      "3033/5349 [================>.............] - ETA: 1s - loss: 0.1196 - accuracy: 0.9357\n",
      "3191/5349 [================>.............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9356\n",
      "3347/5349 [=================>............] - ETA: 1s - loss: 0.1195 - accuracy: 0.9356\n",
      "3502/5349 [==================>...........] - ETA: 1s - loss: 0.1194 - accuracy: 0.9356\n",
      "3655/5349 [===================>..........] - ETA: 1s - loss: 0.1194 - accuracy: 0.9356\n",
      "3892/5349 [====================>.........] - ETA: 0s - loss: 0.1193 - accuracy: 0.9357\n",
      "4037/5349 [=====================>........] - ETA: 0s - loss: 0.1191 - accuracy: 0.9358\n",
      "4194/5349 [======================>.......] - ETA: 0s - loss: 0.1190 - accuracy: 0.9360\n",
      "4346/5349 [=======================>......] - ETA: 0s - loss: 0.1191 - accuracy: 0.9359\n",
      "4497/5349 [========================>.....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9360\n",
      "4647/5349 [=========================>....] - ETA: 0s - loss: 0.1189 - accuracy: 0.9361\n",
      "4724/5349 [=========================>....] - ETA: 0s - loss: 0.1190 - accuracy: 0.9360\n",
      "4883/5349 [==========================>...] - ETA: 0s - loss: 0.1191 - accuracy: 0.9360\n",
      "5039/5349 [===========================>..] - ETA: 0s - loss: 0.1190 - accuracy: 0.9360\n",
      "5193/5349 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9361\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9360\n",
      "5349/5349 [==============================] - 4s 807us/step - loss: 0.1192 - accuracy: 0.9360 - val_loss: 0.1157 - val_accuracy: 0.9382\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 8/20\n",
      "  80/5349 [..............................] - ETA: 3s - loss: 0.1157 - accuracy: 0.9376\n",
      " 236/5349 [>.............................] - ETA: 3s - loss: 0.1193 - accuracy: 0.9358\n",
      " 394/5349 [=>............................] - ETA: 3s - loss: 0.1185 - accuracy: 0.9364\n",
      " 540/5349 [==>...........................] - ETA: 3s - loss: 0.1182 - accuracy: 0.9371\n",
      " 697/5349 [==>...........................] - ETA: 3s - loss: 0.1195 - accuracy: 0.9363\n",
      " 933/5349 [====>.........................] - ETA: 2s - loss: 0.1196 - accuracy: 0.9357\n",
      "1094/5349 [=====>........................] - ETA: 2s - loss: 0.1194 - accuracy: 0.9361\n",
      "1250/5349 [======>.......................] - ETA: 2s - loss: 0.1193 - accuracy: 0.9362\n",
      "1410/5349 [======>.......................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9361\n",
      "1647/5349 [========>.....................] - ETA: 2s - loss: 0.1195 - accuracy: 0.9363\n",
      "1805/5349 [=========>....................] - ETA: 2s - loss: 0.1189 - accuracy: 0.9367\n",
      "1961/5349 [=========>....................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9368\n",
      "2121/5349 [==========>...................] - ETA: 2s - loss: 0.1184 - accuracy: 0.9369\n",
      "2279/5349 [===========>..................] - ETA: 1s - loss: 0.1181 - accuracy: 0.9370\n",
      "2357/5349 [============>.................] - ETA: 1s - loss: 0.1181 - accuracy: 0.9370\n",
      "2513/5349 [=============>................] - ETA: 1s - loss: 0.1181 - accuracy: 0.9368\n",
      "2673/5349 [=============>................] - ETA: 1s - loss: 0.1182 - accuracy: 0.9367\n",
      "2833/5349 [==============>...............] - ETA: 1s - loss: 0.1184 - accuracy: 0.9366\n",
      "2979/5349 [===============>..............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9367\n",
      "3218/5349 [=================>............] - ETA: 1s - loss: 0.1182 - accuracy: 0.9368\n",
      "3374/5349 [=================>............] - ETA: 1s - loss: 0.1181 - accuracy: 0.9367\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1179 - accuracy: 0.9368\n",
      "3689/5349 [===================>..........] - ETA: 1s - loss: 0.1180 - accuracy: 0.9369\n",
      "3847/5349 [====================>.........] - ETA: 0s - loss: 0.1180 - accuracy: 0.9370\n",
      "3927/5349 [=====================>........] - ETA: 0s - loss: 0.1179 - accuracy: 0.9371\n",
      "4086/5349 [=====================>........] - ETA: 0s - loss: 0.1178 - accuracy: 0.9371\n",
      "4199/5349 [======================>.......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9371\n",
      "4297/5349 [=======================>......] - ETA: 0s - loss: 0.1179 - accuracy: 0.9371\n",
      "4514/5349 [========================>.....] - ETA: 0s - loss: 0.1179 - accuracy: 0.9370\n",
      "4668/5349 [=========================>....] - ETA: 0s - loss: 0.1180 - accuracy: 0.9369\n",
      "4820/5349 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.9369\n",
      "4979/5349 [==========================>...] - ETA: 0s - loss: 0.1178 - accuracy: 0.9370\n",
      "5141/5349 [===========================>..] - ETA: 0s - loss: 0.1176 - accuracy: 0.9371\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9372\n",
      "5349/5349 [==============================] - 4s 821us/step - loss: 0.1174 - accuracy: 0.9372 - val_loss: 0.1154 - val_accuracy: 0.9367\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 9/20\n",
      "  57/5349 [..............................] - ETA: 4s - loss: 0.1110 - accuracy: 0.9430\n",
      " 141/5349 [..............................] - ETA: 5s - loss: 0.1128 - accuracy: 0.9416\n",
      " 181/5349 [>.............................] - ETA: 6s - loss: 0.1138 - accuracy: 0.9410\n",
      " 202/5349 [>.............................] - ETA: 8s - loss: 0.1141 - accuracy: 0.9405\n",
      " 221/5349 [>.............................] - ETA: 9s - loss: 0.1139 - accuracy: 0.9406\n",
      " 275/5349 [>.............................] - ETA: 9s - loss: 0.1133 - accuracy: 0.9403\n",
      " 306/5349 [>.............................] - ETA: 10s - loss: 0.1130 - accuracy: 0.9409\n",
      " 352/5349 [>.............................] - ETA: 10s - loss: 0.1127 - accuracy: 0.9413\n",
      " 386/5349 [=>............................] - ETA: 10s - loss: 0.1129 - accuracy: 0.9408\n",
      " 427/5349 [=>............................] - ETA: 11s - loss: 0.1126 - accuracy: 0.9407\n",
      " 496/5349 [=>............................] - ETA: 10s - loss: 0.1126 - accuracy: 0.9405\n",
      " 559/5349 [==>...........................] - ETA: 9s - loss: 0.1133 - accuracy: 0.9402 \n",
      " 578/5349 [==>...........................] - ETA: 9s - loss: 0.1137 - accuracy: 0.9399\n",
      " 635/5349 [==>...........................] - ETA: 9s - loss: 0.1133 - accuracy: 0.9402\n",
      " 678/5349 [==>...........................] - ETA: 9s - loss: 0.1132 - accuracy: 0.9405\n",
      " 733/5349 [===>..........................] - ETA: 9s - loss: 0.1128 - accuracy: 0.9405\n",
      " 795/5349 [===>..........................] - ETA: 9s - loss: 0.1133 - accuracy: 0.9401\n",
      " 844/5349 [===>..........................] - ETA: 9s - loss: 0.1132 - accuracy: 0.9400\n",
      " 865/5349 [===>..........................] - ETA: 9s - loss: 0.1132 - accuracy: 0.9400\n",
      " 906/5349 [====>.........................] - ETA: 9s - loss: 0.1136 - accuracy: 0.9397\n",
      " 943/5349 [====>.........................] - ETA: 9s - loss: 0.1139 - accuracy: 0.9396\n",
      " 997/5349 [====>.........................] - ETA: 9s - loss: 0.1141 - accuracy: 0.9394\n",
      "1056/5349 [====>.........................] - ETA: 8s - loss: 0.1142 - accuracy: 0.9395\n",
      "1116/5349 [=====>........................] - ETA: 8s - loss: 0.1144 - accuracy: 0.9393\n",
      "1178/5349 [=====>........................] - ETA: 8s - loss: 0.1146 - accuracy: 0.9389\n",
      "1322/5349 [======>.......................] - ETA: 7s - loss: 0.1148 - accuracy: 0.9391\n",
      "1376/5349 [======>.......................] - ETA: 7s - loss: 0.1151 - accuracy: 0.9389\n",
      "1492/5349 [=======>......................] - ETA: 6s - loss: 0.1151 - accuracy: 0.9389\n",
      "1602/5349 [=======>......................] - ETA: 6s - loss: 0.1151 - accuracy: 0.9389\n",
      "1697/5349 [========>.....................] - ETA: 6s - loss: 0.1150 - accuracy: 0.9388\n",
      "1852/5349 [=========>....................] - ETA: 5s - loss: 0.1152 - accuracy: 0.9387\n",
      "2005/5349 [==========>...................] - ETA: 5s - loss: 0.1155 - accuracy: 0.9384\n",
      "2159/5349 [===========>..................] - ETA: 4s - loss: 0.1157 - accuracy: 0.9383\n",
      "2239/5349 [===========>..................] - ETA: 4s - loss: 0.1159 - accuracy: 0.9380\n",
      "2392/5349 [============>.................] - ETA: 4s - loss: 0.1161 - accuracy: 0.9378\n",
      "2552/5349 [=============>................] - ETA: 3s - loss: 0.1159 - accuracy: 0.9380\n",
      "2709/5349 [==============>...............] - ETA: 3s - loss: 0.1162 - accuracy: 0.9379\n",
      "2872/5349 [===============>..............] - ETA: 3s - loss: 0.1165 - accuracy: 0.9376\n",
      "3108/5349 [================>.............] - ETA: 2s - loss: 0.1166 - accuracy: 0.9374\n",
      "3275/5349 [=================>............] - ETA: 2s - loss: 0.1166 - accuracy: 0.9375\n",
      "3435/5349 [==================>...........] - ETA: 2s - loss: 0.1166 - accuracy: 0.9375\n",
      "3595/5349 [===================>..........] - ETA: 1s - loss: 0.1167 - accuracy: 0.9374\n",
      "3759/5349 [====================>.........] - ETA: 1s - loss: 0.1167 - accuracy: 0.9374\n",
      "3924/5349 [=====================>........] - ETA: 1s - loss: 0.1168 - accuracy: 0.9373\n",
      "4170/5349 [======================>.......] - ETA: 1s - loss: 0.1169 - accuracy: 0.9372\n",
      "4334/5349 [=======================>......] - ETA: 1s - loss: 0.1169 - accuracy: 0.9371\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.1168 - accuracy: 0.9371\n",
      "4661/5349 [=========================>....] - ETA: 0s - loss: 0.1168 - accuracy: 0.9371\n",
      "4824/5349 [==========================>...] - ETA: 0s - loss: 0.1167 - accuracy: 0.9371\n",
      "4988/5349 [==========================>...] - ETA: 0s - loss: 0.1167 - accuracy: 0.9371\n",
      "5068/5349 [===========================>..] - ETA: 0s - loss: 0.1167 - accuracy: 0.9371\n",
      "5229/5349 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9373\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9373\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1165 - accuracy: 0.9374 - val_loss: 0.1140 - val_accuracy: 0.9396\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.0750 - accuracy: 0.9800\n",
      " 157/5349 [..............................] - ETA: 3s - loss: 0.1136 - accuracy: 0.9410\n",
      " 315/5349 [>.............................] - ETA: 3s - loss: 0.1127 - accuracy: 0.9409\n",
      " 469/5349 [=>............................] - ETA: 3s - loss: 0.1148 - accuracy: 0.9387\n",
      " 550/5349 [==>...........................] - ETA: 3s - loss: 0.1149 - accuracy: 0.9382\n",
      " 710/5349 [==>...........................] - ETA: 2s - loss: 0.1153 - accuracy: 0.9378\n",
      " 866/5349 [===>..........................] - ETA: 2s - loss: 0.1152 - accuracy: 0.9377\n",
      "1024/5349 [====>.........................] - ETA: 2s - loss: 0.1156 - accuracy: 0.9374\n",
      "1179/5349 [=====>........................] - ETA: 2s - loss: 0.1169 - accuracy: 0.9366\n",
      "1336/5349 [======>.......................] - ETA: 2s - loss: 0.1167 - accuracy: 0.9369\n",
      "1484/5349 [=======>......................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9370\n",
      "1563/5349 [=======>......................] - ETA: 2s - loss: 0.1161 - accuracy: 0.9371\n",
      "1723/5349 [========>.....................] - ETA: 2s - loss: 0.1163 - accuracy: 0.9368\n",
      "1879/5349 [=========>....................] - ETA: 2s - loss: 0.1159 - accuracy: 0.9373\n",
      "2038/5349 [==========>...................] - ETA: 2s - loss: 0.1157 - accuracy: 0.9374\n",
      "2197/5349 [===========>..................] - ETA: 2s - loss: 0.1154 - accuracy: 0.9376\n",
      "2355/5349 [============>.................] - ETA: 1s - loss: 0.1155 - accuracy: 0.9375\n",
      "2590/5349 [=============>................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9378\n",
      "2749/5349 [==============>...............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9378\n",
      "2909/5349 [===============>..............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9378\n",
      "3066/5349 [================>.............] - ETA: 1s - loss: 0.1155 - accuracy: 0.9376\n",
      "3223/5349 [=================>............] - ETA: 1s - loss: 0.1156 - accuracy: 0.9376\n",
      "3381/5349 [=================>............] - ETA: 1s - loss: 0.1157 - accuracy: 0.9375\n",
      "3620/5349 [===================>..........] - ETA: 1s - loss: 0.1157 - accuracy: 0.9374\n",
      "3780/5349 [====================>.........] - ETA: 1s - loss: 0.1157 - accuracy: 0.9374\n",
      "3941/5349 [=====================>........] - ETA: 0s - loss: 0.1155 - accuracy: 0.9375\n",
      "4087/5349 [=====================>........] - ETA: 0s - loss: 0.1155 - accuracy: 0.9375\n",
      "4245/5349 [======================>.......] - ETA: 0s - loss: 0.1155 - accuracy: 0.9375\n",
      "4404/5349 [=======================>......] - ETA: 0s - loss: 0.1155 - accuracy: 0.9376\n",
      "4644/5349 [=========================>....] - ETA: 0s - loss: 0.1156 - accuracy: 0.9375\n",
      "4801/5349 [=========================>....] - ETA: 0s - loss: 0.1155 - accuracy: 0.9376\n",
      "4958/5349 [==========================>...] - ETA: 0s - loss: 0.1156 - accuracy: 0.9375\n",
      "5113/5349 [===========================>..] - ETA: 0s - loss: 0.1156 - accuracy: 0.9374\n",
      "5271/5349 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9374\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9374\n",
      "5349/5349 [==============================] - 4s 796us/step - loss: 0.1156 - accuracy: 0.9374 - val_loss: 0.1151 - val_accuracy: 0.9303\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1069 - accuracy: 0.9400\n",
      " 139/5349 [..............................] - ETA: 3s - loss: 0.1154 - accuracy: 0.9383\n",
      " 215/5349 [>.............................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9387\n",
      " 374/5349 [=>............................] - ETA: 3s - loss: 0.1144 - accuracy: 0.9391\n",
      " 532/5349 [=>............................] - ETA: 3s - loss: 0.1143 - accuracy: 0.9390\n",
      " 690/5349 [==>...........................] - ETA: 3s - loss: 0.1153 - accuracy: 0.9387\n",
      " 926/5349 [====>.........................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9393\n",
      "1086/5349 [=====>........................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9394\n",
      "1242/5349 [=====>........................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9392\n",
      "1402/5349 [======>.......................] - ETA: 2s - loss: 0.1148 - accuracy: 0.9387\n",
      "1559/5349 [=======>......................] - ETA: 2s - loss: 0.1144 - accuracy: 0.9391\n",
      "1796/5349 [=========>....................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9393\n",
      "1956/5349 [=========>....................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9393\n",
      "2102/5349 [==========>...................] - ETA: 2s - loss: 0.1140 - accuracy: 0.9390\n",
      "2257/5349 [===========>..................] - ETA: 2s - loss: 0.1142 - accuracy: 0.9389\n",
      "2497/5349 [=============>................] - ETA: 1s - loss: 0.1146 - accuracy: 0.9386\n",
      "2653/5349 [=============>................] - ETA: 1s - loss: 0.1146 - accuracy: 0.9385\n",
      "2812/5349 [==============>...............] - ETA: 1s - loss: 0.1147 - accuracy: 0.9386\n",
      "2972/5349 [===============>..............] - ETA: 1s - loss: 0.1147 - accuracy: 0.9386\n",
      "3133/5349 [================>.............] - ETA: 1s - loss: 0.1146 - accuracy: 0.9386\n",
      "3213/5349 [=================>............] - ETA: 1s - loss: 0.1144 - accuracy: 0.9387\n",
      "3371/5349 [=================>............] - ETA: 1s - loss: 0.1143 - accuracy: 0.9387\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9389\n",
      "3683/5349 [===================>..........] - ETA: 1s - loss: 0.1142 - accuracy: 0.9388\n",
      "3847/5349 [====================>.........] - ETA: 0s - loss: 0.1143 - accuracy: 0.9387\n",
      "3992/5349 [=====================>........] - ETA: 0s - loss: 0.1142 - accuracy: 0.9388\n",
      "4234/5349 [======================>.......] - ETA: 0s - loss: 0.1142 - accuracy: 0.9388\n",
      "4392/5349 [=======================>......] - ETA: 0s - loss: 0.1142 - accuracy: 0.9388\n",
      "4546/5349 [========================>.....] - ETA: 0s - loss: 0.1142 - accuracy: 0.9387\n",
      "4677/5349 [=========================>....] - ETA: 0s - loss: 0.1143 - accuracy: 0.9386\n",
      "4835/5349 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9385\n",
      "4915/5349 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9385\n",
      "5072/5349 [===========================>..] - ETA: 0s - loss: 0.1146 - accuracy: 0.9384\n",
      "5230/5349 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9383\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9384\n",
      "5349/5349 [==============================] - 4s 806us/step - loss: 0.1145 - accuracy: 0.9384 - val_loss: 0.1112 - val_accuracy: 0.9397\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 12/20\n",
      "  77/5349 [..............................] - ETA: 3s - loss: 0.1093 - accuracy: 0.9403\n",
      " 235/5349 [>.............................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9419\n",
      " 318/5349 [>.............................] - ETA: 3s - loss: 0.1115 - accuracy: 0.9422\n",
      " 411/5349 [=>............................] - ETA: 4s - loss: 0.1121 - accuracy: 0.9410\n",
      " 514/5349 [=>............................] - ETA: 4s - loss: 0.1135 - accuracy: 0.9390\n",
      " 567/5349 [==>...........................] - ETA: 4s - loss: 0.1139 - accuracy: 0.9389\n",
      " 598/5349 [==>...........................] - ETA: 4s - loss: 0.1139 - accuracy: 0.9388\n",
      " 643/5349 [==>...........................] - ETA: 5s - loss: 0.1142 - accuracy: 0.9386\n",
      " 666/5349 [==>...........................] - ETA: 5s - loss: 0.1146 - accuracy: 0.9382\n",
      " 706/5349 [==>...........................] - ETA: 6s - loss: 0.1150 - accuracy: 0.9380\n",
      " 755/5349 [===>..........................] - ETA: 6s - loss: 0.1151 - accuracy: 0.9377\n",
      " 794/5349 [===>..........................] - ETA: 6s - loss: 0.1152 - accuracy: 0.9377\n",
      " 825/5349 [===>..........................] - ETA: 6s - loss: 0.1149 - accuracy: 0.9379\n",
      " 850/5349 [===>..........................] - ETA: 6s - loss: 0.1148 - accuracy: 0.9381\n",
      " 889/5349 [===>..........................] - ETA: 6s - loss: 0.1149 - accuracy: 0.9380\n",
      " 928/5349 [====>.........................] - ETA: 7s - loss: 0.1151 - accuracy: 0.9378\n",
      " 978/5349 [====>.........................] - ETA: 7s - loss: 0.1147 - accuracy: 0.9382\n",
      "1006/5349 [====>.........................] - ETA: 7s - loss: 0.1148 - accuracy: 0.9383\n",
      "1047/5349 [====>.........................] - ETA: 7s - loss: 0.1146 - accuracy: 0.9384\n",
      "1097/5349 [=====>........................] - ETA: 7s - loss: 0.1142 - accuracy: 0.9387\n",
      "1134/5349 [=====>........................] - ETA: 7s - loss: 0.1143 - accuracy: 0.9387\n",
      "1150/5349 [=====>........................] - ETA: 7s - loss: 0.1142 - accuracy: 0.9388\n",
      "1189/5349 [=====>........................] - ETA: 7s - loss: 0.1139 - accuracy: 0.9388\n",
      "1239/5349 [=====>........................] - ETA: 7s - loss: 0.1141 - accuracy: 0.9387\n",
      "1288/5349 [======>.......................] - ETA: 7s - loss: 0.1141 - accuracy: 0.9388\n",
      "1321/5349 [======>.......................] - ETA: 7s - loss: 0.1142 - accuracy: 0.9386\n",
      "1374/5349 [======>.......................] - ETA: 7s - loss: 0.1144 - accuracy: 0.9382\n",
      "1468/5349 [=======>......................] - ETA: 7s - loss: 0.1143 - accuracy: 0.9382\n",
      "1632/5349 [========>.....................] - ETA: 6s - loss: 0.1144 - accuracy: 0.9381\n",
      "1762/5349 [========>.....................] - ETA: 5s - loss: 0.1143 - accuracy: 0.9382\n",
      "1919/5349 [=========>....................] - ETA: 5s - loss: 0.1145 - accuracy: 0.9379\n",
      "2077/5349 [==========>...................] - ETA: 4s - loss: 0.1146 - accuracy: 0.9380\n",
      "2232/5349 [===========>..................] - ETA: 4s - loss: 0.1143 - accuracy: 0.9380\n",
      "2476/5349 [============>.................] - ETA: 3s - loss: 0.1146 - accuracy: 0.9378\n",
      "2627/5349 [=============>................] - ETA: 3s - loss: 0.1145 - accuracy: 0.9378\n",
      "2794/5349 [==============>...............] - ETA: 3s - loss: 0.1147 - accuracy: 0.9376\n",
      "2954/5349 [===============>..............] - ETA: 2s - loss: 0.1145 - accuracy: 0.9379\n",
      "3123/5349 [================>.............] - ETA: 2s - loss: 0.1146 - accuracy: 0.9379\n",
      "3370/5349 [=================>............] - ETA: 2s - loss: 0.1144 - accuracy: 0.9380\n",
      "3534/5349 [==================>...........] - ETA: 2s - loss: 0.1144 - accuracy: 0.9379\n",
      "3697/5349 [===================>..........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9378\n",
      "3864/5349 [====================>.........] - ETA: 1s - loss: 0.1144 - accuracy: 0.9378\n",
      "4025/5349 [=====================>........] - ETA: 1s - loss: 0.1145 - accuracy: 0.9378\n",
      "4192/5349 [======================>.......] - ETA: 1s - loss: 0.1147 - accuracy: 0.9376\n",
      "4355/5349 [=======================>......] - ETA: 1s - loss: 0.1146 - accuracy: 0.9377\n",
      "4517/5349 [========================>.....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "4759/5349 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9380\n",
      "4905/5349 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9378\n",
      "5066/5349 [===========================>..] - ETA: 0s - loss: 0.1144 - accuracy: 0.9379\n",
      "5221/5349 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9380\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9381\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1141 - accuracy: 0.9381 - val_loss: 0.1100 - val_accuracy: 0.9418\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 21s - loss: 0.1243 - accuracy: 0.9000\n",
      "  25/5349 [..............................] - ETA: 23s - loss: 0.1113 - accuracy: 0.9376\n",
      "  51/5349 [..............................] - ETA: 22s - loss: 0.1137 - accuracy: 0.9361\n",
      " 148/5349 [..............................] - ETA: 10s - loss: 0.1144 - accuracy: 0.9370\n",
      " 218/5349 [>.............................] - ETA: 8s - loss: 0.1127 - accuracy: 0.9399 \n",
      " 372/5349 [=>............................] - ETA: 6s - loss: 0.1120 - accuracy: 0.9397\n",
      " 516/5349 [=>............................] - ETA: 5s - loss: 0.1118 - accuracy: 0.9397\n",
      " 673/5349 [==>...........................] - ETA: 4s - loss: 0.1122 - accuracy: 0.9400\n",
      " 833/5349 [===>..........................] - ETA: 4s - loss: 0.1124 - accuracy: 0.9397\n",
      " 991/5349 [====>.........................] - ETA: 3s - loss: 0.1128 - accuracy: 0.9391\n",
      "1228/5349 [=====>........................] - ETA: 3s - loss: 0.1128 - accuracy: 0.9389\n",
      "1385/5349 [======>.......................] - ETA: 3s - loss: 0.1126 - accuracy: 0.9393\n",
      "1543/5349 [=======>......................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9392\n",
      "1702/5349 [========>.....................] - ETA: 2s - loss: 0.1121 - accuracy: 0.9395\n",
      "1857/5349 [=========>....................] - ETA: 2s - loss: 0.1122 - accuracy: 0.9396\n",
      "2013/5349 [==========>...................] - ETA: 2s - loss: 0.1124 - accuracy: 0.9394\n",
      "2092/5349 [==========>...................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9394\n",
      "2251/5349 [===========>..................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9394\n",
      "2409/5349 [============>.................] - ETA: 2s - loss: 0.1131 - accuracy: 0.9389\n",
      "2565/5349 [=============>................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9389\n",
      "2714/5349 [==============>...............] - ETA: 1s - loss: 0.1131 - accuracy: 0.9390\n",
      "2866/5349 [===============>..............] - ETA: 1s - loss: 0.1130 - accuracy: 0.9390\n",
      "3103/5349 [================>.............] - ETA: 1s - loss: 0.1129 - accuracy: 0.9391\n",
      "3264/5349 [=================>............] - ETA: 1s - loss: 0.1131 - accuracy: 0.9389\n",
      "3420/5349 [==================>...........] - ETA: 1s - loss: 0.1131 - accuracy: 0.9389\n",
      "3579/5349 [===================>..........] - ETA: 1s - loss: 0.1133 - accuracy: 0.9387\n",
      "3738/5349 [===================>..........] - ETA: 1s - loss: 0.1131 - accuracy: 0.9389\n",
      "3895/5349 [====================>.........] - ETA: 1s - loss: 0.1129 - accuracy: 0.9390\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.1129 - accuracy: 0.9391\n",
      "4134/5349 [======================>.......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9390\n",
      "4293/5349 [=======================>......] - ETA: 0s - loss: 0.1130 - accuracy: 0.9391\n",
      "4451/5349 [=======================>......] - ETA: 0s - loss: 0.1131 - accuracy: 0.9390\n",
      "4605/5349 [========================>.....] - ETA: 0s - loss: 0.1132 - accuracy: 0.9389\n",
      "4847/5349 [==========================>...] - ETA: 0s - loss: 0.1130 - accuracy: 0.9390\n",
      "4993/5349 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.9390\n",
      "5149/5349 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.9389\n",
      "5309/5349 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9389\n",
      "5349/5349 [==============================] - 5s 842us/step - loss: 0.1131 - accuracy: 0.9389 - val_loss: 0.1118 - val_accuracy: 0.9356\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 11s - loss: 0.1649 - accuracy: 0.9200\n",
      "  58/5349 [..............................] - ETA: 9s - loss: 0.1144 - accuracy: 0.9367\n",
      " 113/5349 [..............................] - ETA: 9s - loss: 0.1107 - accuracy: 0.9405\n",
      " 221/5349 [>.............................] - ETA: 7s - loss: 0.1118 - accuracy: 0.9409\n",
      " 292/5349 [>.............................] - ETA: 6s - loss: 0.1116 - accuracy: 0.9407\n",
      " 447/5349 [=>............................] - ETA: 4s - loss: 0.1115 - accuracy: 0.9398\n",
      " 603/5349 [==>...........................] - ETA: 4s - loss: 0.1123 - accuracy: 0.9394\n",
      " 763/5349 [===>..........................] - ETA: 3s - loss: 0.1122 - accuracy: 0.9393\n",
      " 922/5349 [====>.........................] - ETA: 3s - loss: 0.1123 - accuracy: 0.9393\n",
      "1158/5349 [=====>........................] - ETA: 3s - loss: 0.1123 - accuracy: 0.9395\n",
      "1315/5349 [======>.......................] - ETA: 3s - loss: 0.1126 - accuracy: 0.9391\n",
      "1460/5349 [=======>......................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9392\n",
      "1614/5349 [========>.....................] - ETA: 2s - loss: 0.1128 - accuracy: 0.9388\n",
      "1768/5349 [========>.....................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9388\n",
      "2006/5349 [==========>...................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9388\n",
      "2162/5349 [===========>..................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9388\n",
      "2321/5349 [============>.................] - ETA: 2s - loss: 0.1129 - accuracy: 0.9391\n",
      "2478/5349 [============>.................] - ETA: 2s - loss: 0.1127 - accuracy: 0.9393\n",
      "2637/5349 [=============>................] - ETA: 1s - loss: 0.1126 - accuracy: 0.9394\n",
      "2716/5349 [==============>...............] - ETA: 1s - loss: 0.1127 - accuracy: 0.9393\n",
      "2871/5349 [===============>..............] - ETA: 1s - loss: 0.1129 - accuracy: 0.9392\n",
      "3025/5349 [===============>..............] - ETA: 1s - loss: 0.1126 - accuracy: 0.9393\n",
      "3179/5349 [================>.............] - ETA: 1s - loss: 0.1125 - accuracy: 0.9393\n",
      "3328/5349 [=================>............] - ETA: 1s - loss: 0.1126 - accuracy: 0.9393\n",
      "3565/5349 [==================>...........] - ETA: 1s - loss: 0.1126 - accuracy: 0.9393\n",
      "3711/5349 [===================>..........] - ETA: 1s - loss: 0.1126 - accuracy: 0.9393\n",
      "3868/5349 [====================>.........] - ETA: 1s - loss: 0.1126 - accuracy: 0.9393\n",
      "4025/5349 [=====================>........] - ETA: 0s - loss: 0.1126 - accuracy: 0.9394\n",
      "4183/5349 [======================>.......] - ETA: 0s - loss: 0.1127 - accuracy: 0.9392\n",
      "4418/5349 [=======================>......] - ETA: 0s - loss: 0.1128 - accuracy: 0.9391\n",
      "4567/5349 [========================>.....] - ETA: 0s - loss: 0.1129 - accuracy: 0.9390\n",
      "4706/5349 [=========================>....] - ETA: 0s - loss: 0.1130 - accuracy: 0.9390\n",
      "4863/5349 [==========================>...] - ETA: 0s - loss: 0.1128 - accuracy: 0.9390\n",
      "5022/5349 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9390\n",
      "5102/5349 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9390\n",
      "5258/5349 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9390\n",
      "5330/5349 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9390\n",
      "5349/5349 [==============================] - 5s 1ms/step - loss: 0.1128 - accuracy: 0.9390 - val_loss: 0.1140 - val_accuracy: 0.9391\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 12s - loss: 0.1149 - accuracy: 0.9300\n",
      "  48/5349 [..............................] - ETA: 11s - loss: 0.1124 - accuracy: 0.9367\n",
      " 128/5349 [..............................] - ETA: 8s - loss: 0.1124 - accuracy: 0.9391\n",
      " 184/5349 [>.............................] - ETA: 10s - loss: 0.1128 - accuracy: 0.9398\n",
      " 254/5349 [>.............................] - ETA: 9s - loss: 0.1106 - accuracy: 0.9401\n",
      " 293/5349 [>.............................] - ETA: 9s - loss: 0.1095 - accuracy: 0.9410\n",
      " 338/5349 [>.............................] - ETA: 9s - loss: 0.1101 - accuracy: 0.9407\n",
      " 397/5349 [=>............................] - ETA: 9s - loss: 0.1108 - accuracy: 0.9406\n",
      " 469/5349 [=>............................] - ETA: 9s - loss: 0.1108 - accuracy: 0.9405\n",
      " 509/5349 [=>............................] - ETA: 9s - loss: 0.1108 - accuracy: 0.9402\n",
      " 552/5349 [==>...........................] - ETA: 9s - loss: 0.1108 - accuracy: 0.9402\n",
      " 571/5349 [==>...........................] - ETA: 10s - loss: 0.1108 - accuracy: 0.9402\n",
      " 603/5349 [==>...........................] - ETA: 10s - loss: 0.1110 - accuracy: 0.9404\n",
      " 648/5349 [==>...........................] - ETA: 10s - loss: 0.1108 - accuracy: 0.9408\n",
      " 687/5349 [==>...........................] - ETA: 10s - loss: 0.1106 - accuracy: 0.9408\n",
      " 741/5349 [===>..........................] - ETA: 10s - loss: 0.1106 - accuracy: 0.9410\n",
      " 796/5349 [===>..........................] - ETA: 10s - loss: 0.1105 - accuracy: 0.9410\n",
      " 840/5349 [===>..........................] - ETA: 10s - loss: 0.1105 - accuracy: 0.9410\n",
      " 904/5349 [====>.........................] - ETA: 9s - loss: 0.1108 - accuracy: 0.9410 \n",
      "1105/5349 [=====>........................] - ETA: 8s - loss: 0.1108 - accuracy: 0.9411\n",
      "1202/5349 [=====>........................] - ETA: 7s - loss: 0.1109 - accuracy: 0.9408\n",
      "1328/5349 [======>.......................] - ETA: 7s - loss: 0.1110 - accuracy: 0.9405\n",
      "1487/5349 [=======>......................] - ETA: 6s - loss: 0.1112 - accuracy: 0.9401\n",
      "1634/5349 [========>.....................] - ETA: 5s - loss: 0.1112 - accuracy: 0.9404\n",
      "1713/5349 [========>.....................] - ETA: 5s - loss: 0.1112 - accuracy: 0.9404\n",
      "1870/5349 [=========>....................] - ETA: 5s - loss: 0.1110 - accuracy: 0.9403\n",
      "2030/5349 [==========>...................] - ETA: 4s - loss: 0.1110 - accuracy: 0.9404\n",
      "2195/5349 [===========>..................] - ETA: 4s - loss: 0.1110 - accuracy: 0.9404\n",
      "2359/5349 [============>.................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9404\n",
      "2605/5349 [=============>................] - ETA: 3s - loss: 0.1112 - accuracy: 0.9400\n",
      "2770/5349 [==============>...............] - ETA: 3s - loss: 0.1112 - accuracy: 0.9401\n",
      "2933/5349 [===============>..............] - ETA: 2s - loss: 0.1112 - accuracy: 0.9401\n",
      "3095/5349 [================>.............] - ETA: 2s - loss: 0.1113 - accuracy: 0.9399\n",
      "3260/5349 [=================>............] - ETA: 2s - loss: 0.1114 - accuracy: 0.9400\n",
      "3488/5349 [==================>...........] - ETA: 1s - loss: 0.1117 - accuracy: 0.9397\n",
      "3652/5349 [===================>..........] - ETA: 1s - loss: 0.1117 - accuracy: 0.9397\n",
      "3813/5349 [====================>.........] - ETA: 1s - loss: 0.1116 - accuracy: 0.9397\n",
      "3957/5349 [=====================>........] - ETA: 1s - loss: 0.1117 - accuracy: 0.9397\n",
      "4109/5349 [======================>.......] - ETA: 1s - loss: 0.1117 - accuracy: 0.9397\n",
      "4265/5349 [======================>.......] - ETA: 1s - loss: 0.1118 - accuracy: 0.9396\n",
      "4496/5349 [========================>.....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9396\n",
      "4649/5349 [=========================>....] - ETA: 0s - loss: 0.1120 - accuracy: 0.9396\n",
      "4807/5349 [=========================>....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9396\n",
      "4966/5349 [==========================>...] - ETA: 0s - loss: 0.1120 - accuracy: 0.9396\n",
      "5123/5349 [===========================>..] - ETA: 0s - loss: 0.1120 - accuracy: 0.9396\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9396\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1121 - accuracy: 0.9396 - val_loss: 0.1113 - val_accuracy: 0.9397\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0557 - accuracy: 0.9900\n",
      " 158/5349 [..............................] - ETA: 3s - loss: 0.1110 - accuracy: 0.9416\n",
      " 318/5349 [>.............................] - ETA: 3s - loss: 0.1109 - accuracy: 0.9409\n",
      " 475/5349 [=>............................] - ETA: 3s - loss: 0.1137 - accuracy: 0.9395\n",
      " 632/5349 [==>...........................] - ETA: 3s - loss: 0.1131 - accuracy: 0.9400\n",
      " 868/5349 [===>..........................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9398\n",
      "1023/5349 [====>.........................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9393\n",
      "1181/5349 [=====>........................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9393\n",
      "1340/5349 [======>.......................] - ETA: 2s - loss: 0.1130 - accuracy: 0.9395\n",
      "1577/5349 [=======>......................] - ETA: 2s - loss: 0.1133 - accuracy: 0.9391\n",
      "1735/5349 [========>.....................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9397\n",
      "1897/5349 [=========>....................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9397\n",
      "2053/5349 [==========>...................] - ETA: 2s - loss: 0.1123 - accuracy: 0.9396\n",
      "2212/5349 [===========>..................] - ETA: 1s - loss: 0.1123 - accuracy: 0.9396\n",
      "2287/5349 [===========>..................] - ETA: 1s - loss: 0.1121 - accuracy: 0.9398\n",
      "2436/5349 [============>.................] - ETA: 1s - loss: 0.1122 - accuracy: 0.9398\n",
      "2590/5349 [=============>................] - ETA: 1s - loss: 0.1124 - accuracy: 0.9395\n",
      "2747/5349 [==============>...............] - ETA: 1s - loss: 0.1125 - accuracy: 0.9393\n",
      "2905/5349 [===============>..............] - ETA: 1s - loss: 0.1124 - accuracy: 0.9394\n",
      "3064/5349 [================>.............] - ETA: 1s - loss: 0.1123 - accuracy: 0.9394\n",
      "3295/5349 [=================>............] - ETA: 1s - loss: 0.1124 - accuracy: 0.9389\n",
      "3452/5349 [==================>...........] - ETA: 1s - loss: 0.1124 - accuracy: 0.9389\n",
      "3607/5349 [===================>..........] - ETA: 1s - loss: 0.1123 - accuracy: 0.9390\n",
      "3764/5349 [====================>.........] - ETA: 1s - loss: 0.1124 - accuracy: 0.9389\n",
      "3916/5349 [====================>.........] - ETA: 0s - loss: 0.1124 - accuracy: 0.9389\n",
      "4154/5349 [======================>.......] - ETA: 0s - loss: 0.1123 - accuracy: 0.9391\n",
      "4314/5349 [=======================>......] - ETA: 0s - loss: 0.1124 - accuracy: 0.9390\n",
      "4473/5349 [========================>.....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9391\n",
      "4625/5349 [========================>.....] - ETA: 0s - loss: 0.1123 - accuracy: 0.9391\n",
      "4783/5349 [=========================>....] - ETA: 0s - loss: 0.1122 - accuracy: 0.9392\n",
      "4943/5349 [==========================>...] - ETA: 0s - loss: 0.1120 - accuracy: 0.9392\n",
      "5181/5349 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9393\n",
      "5339/5349 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9393\n",
      "5349/5349 [==============================] - 4s 797us/step - loss: 0.1120 - accuracy: 0.9393 - val_loss: 0.1124 - val_accuracy: 0.9296\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1280 - accuracy: 0.9000\n",
      " 158/5349 [..............................] - ETA: 3s - loss: 0.1131 - accuracy: 0.9399\n",
      " 398/5349 [=>............................] - ETA: 3s - loss: 0.1113 - accuracy: 0.9396\n",
      " 556/5349 [==>...........................] - ETA: 3s - loss: 0.1101 - accuracy: 0.9406\n",
      " 715/5349 [===>..........................] - ETA: 2s - loss: 0.1097 - accuracy: 0.9406\n",
      " 874/5349 [===>..........................] - ETA: 2s - loss: 0.1110 - accuracy: 0.9397\n",
      "1032/5349 [====>.........................] - ETA: 2s - loss: 0.1119 - accuracy: 0.9392\n",
      "1264/5349 [======>.......................] - ETA: 2s - loss: 0.1125 - accuracy: 0.9384\n",
      "1421/5349 [======>.......................] - ETA: 2s - loss: 0.1119 - accuracy: 0.9389\n",
      "1580/5349 [=======>......................] - ETA: 2s - loss: 0.1116 - accuracy: 0.9393\n",
      "1738/5349 [========>.....................] - ETA: 2s - loss: 0.1114 - accuracy: 0.9395\n",
      "1897/5349 [=========>....................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9396\n",
      "1976/5349 [==========>...................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9396\n",
      "2134/5349 [==========>...................] - ETA: 2s - loss: 0.1110 - accuracy: 0.9398\n",
      "2291/5349 [===========>..................] - ETA: 1s - loss: 0.1112 - accuracy: 0.9399\n",
      "2451/5349 [============>.................] - ETA: 1s - loss: 0.1113 - accuracy: 0.9397\n",
      "2609/5349 [=============>................] - ETA: 1s - loss: 0.1113 - accuracy: 0.9398\n",
      "2767/5349 [==============>...............] - ETA: 1s - loss: 0.1114 - accuracy: 0.9398\n",
      "2997/5349 [===============>..............] - ETA: 1s - loss: 0.1118 - accuracy: 0.9394\n",
      "3159/5349 [================>.............] - ETA: 1s - loss: 0.1116 - accuracy: 0.9396\n",
      "3318/5349 [=================>............] - ETA: 1s - loss: 0.1118 - accuracy: 0.9394\n",
      "3476/5349 [==================>...........] - ETA: 1s - loss: 0.1118 - accuracy: 0.9394\n",
      "3708/5349 [===================>..........] - ETA: 1s - loss: 0.1119 - accuracy: 0.9394\n",
      "3864/5349 [====================>.........] - ETA: 0s - loss: 0.1121 - accuracy: 0.9392\n",
      "4024/5349 [=====================>........] - ETA: 0s - loss: 0.1120 - accuracy: 0.9392\n",
      "4185/5349 [======================>.......] - ETA: 0s - loss: 0.1119 - accuracy: 0.9393\n",
      "4344/5349 [=======================>......] - ETA: 0s - loss: 0.1119 - accuracy: 0.9392\n",
      "4525/5349 [========================>.....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9392\n",
      "4633/5349 [========================>.....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9392\n",
      "4740/5349 [=========================>....] - ETA: 0s - loss: 0.1119 - accuracy: 0.9392\n",
      "4857/5349 [==========================>...] - ETA: 0s - loss: 0.1119 - accuracy: 0.9392\n",
      "4962/5349 [==========================>...] - ETA: 0s - loss: 0.1118 - accuracy: 0.9392\n",
      "5077/5349 [===========================>..] - ETA: 0s - loss: 0.1118 - accuracy: 0.9393\n",
      "5269/5349 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9392\n",
      "5333/5349 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9392\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1118 - accuracy: 0.9392 - val_loss: 0.1094 - val_accuracy: 0.9408\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 1:45 - loss: 0.1450 - accuracy: 0.9200\n",
      "  91/5349 [..............................] - ETA: 5s - loss: 0.1059 - accuracy: 0.9440\n",
      " 156/5349 [..............................] - ETA: 6s - loss: 0.1082 - accuracy: 0.9417\n",
      " 214/5349 [>.............................] - ETA: 7s - loss: 0.1106 - accuracy: 0.9407\n",
      " 310/5349 [>.............................] - ETA: 6s - loss: 0.1117 - accuracy: 0.9389\n",
      " 429/5349 [=>............................] - ETA: 5s - loss: 0.1116 - accuracy: 0.9390\n",
      " 557/5349 [==>...........................] - ETA: 5s - loss: 0.1112 - accuracy: 0.9387\n",
      " 678/5349 [==>...........................] - ETA: 4s - loss: 0.1102 - accuracy: 0.9392\n",
      " 868/5349 [===>..........................] - ETA: 4s - loss: 0.1107 - accuracy: 0.9389\n",
      " 993/5349 [====>.........................] - ETA: 4s - loss: 0.1109 - accuracy: 0.9387\n",
      "1128/5349 [=====>........................] - ETA: 3s - loss: 0.1115 - accuracy: 0.9383\n",
      "1269/5349 [======>.......................] - ETA: 3s - loss: 0.1114 - accuracy: 0.9384\n",
      "1415/5349 [======>.......................] - ETA: 3s - loss: 0.1115 - accuracy: 0.9384\n",
      "1556/5349 [=======>......................] - ETA: 3s - loss: 0.1115 - accuracy: 0.9385\n",
      "1764/5349 [========>.....................] - ETA: 3s - loss: 0.1114 - accuracy: 0.9387\n",
      "1903/5349 [=========>....................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9389\n",
      "2045/5349 [==========>...................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9391\n",
      "2182/5349 [===========>..................] - ETA: 2s - loss: 0.1109 - accuracy: 0.9393\n",
      "2312/5349 [===========>..................] - ETA: 2s - loss: 0.1108 - accuracy: 0.9393\n",
      "2445/5349 [============>.................] - ETA: 2s - loss: 0.1110 - accuracy: 0.9392\n",
      "2582/5349 [=============>................] - ETA: 2s - loss: 0.1108 - accuracy: 0.9393\n",
      "2777/5349 [==============>...............] - ETA: 2s - loss: 0.1109 - accuracy: 0.9392\n",
      "2845/5349 [==============>...............] - ETA: 2s - loss: 0.1109 - accuracy: 0.9392\n",
      "2893/5349 [===============>..............] - ETA: 2s - loss: 0.1110 - accuracy: 0.9392\n",
      "2992/5349 [===============>..............] - ETA: 1s - loss: 0.1112 - accuracy: 0.9390\n",
      "3086/5349 [================>.............] - ETA: 1s - loss: 0.1111 - accuracy: 0.9391\n",
      "3193/5349 [================>.............] - ETA: 1s - loss: 0.1111 - accuracy: 0.9391\n",
      "3292/5349 [=================>............] - ETA: 1s - loss: 0.1112 - accuracy: 0.9391\n",
      "3430/5349 [==================>...........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9391\n",
      "3524/5349 [==================>...........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9391\n",
      "3611/5349 [===================>..........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9393\n",
      "3678/5349 [===================>..........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9392\n",
      "3748/5349 [====================>.........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9393\n",
      "3827/5349 [====================>.........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9392\n",
      "3939/5349 [=====================>........] - ETA: 1s - loss: 0.1110 - accuracy: 0.9393\n",
      "4135/5349 [======================>.......] - ETA: 1s - loss: 0.1110 - accuracy: 0.9394\n",
      "4262/5349 [======================>.......] - ETA: 0s - loss: 0.1111 - accuracy: 0.9394\n",
      "4390/5349 [=======================>......] - ETA: 0s - loss: 0.1110 - accuracy: 0.9394\n",
      "4522/5349 [========================>.....] - ETA: 0s - loss: 0.1110 - accuracy: 0.9394\n",
      "4648/5349 [=========================>....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9393\n",
      "4767/5349 [=========================>....] - ETA: 0s - loss: 0.1113 - accuracy: 0.9392\n",
      "4899/5349 [==========================>...] - ETA: 0s - loss: 0.1113 - accuracy: 0.9392\n",
      "5095/5349 [===========================>..] - ETA: 0s - loss: 0.1114 - accuracy: 0.9392\n",
      "5227/5349 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9393\n",
      "5289/5349 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9393\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1112 - accuracy: 0.9394 - val_loss: 0.1199 - val_accuracy: 0.9382\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 19/20\n",
      "  66/5349 [..............................] - ETA: 4s - loss: 0.1075 - accuracy: 0.9447\n",
      " 199/5349 [>.............................] - ETA: 3s - loss: 0.1086 - accuracy: 0.9406\n",
      " 265/5349 [>.............................] - ETA: 3s - loss: 0.1090 - accuracy: 0.9404\n",
      " 397/5349 [=>............................] - ETA: 3s - loss: 0.1094 - accuracy: 0.9404\n",
      " 527/5349 [=>............................] - ETA: 3s - loss: 0.1090 - accuracy: 0.9408\n",
      " 664/5349 [==>...........................] - ETA: 3s - loss: 0.1096 - accuracy: 0.9402\n",
      " 796/5349 [===>..........................] - ETA: 3s - loss: 0.1099 - accuracy: 0.9402\n",
      " 931/5349 [====>.........................] - ETA: 3s - loss: 0.1099 - accuracy: 0.9403\n",
      "1055/5349 [====>.........................] - ETA: 3s - loss: 0.1098 - accuracy: 0.9405\n",
      "1180/5349 [=====>........................] - ETA: 3s - loss: 0.1098 - accuracy: 0.9405\n",
      "1308/5349 [======>.......................] - ETA: 3s - loss: 0.1098 - accuracy: 0.9407\n",
      "1442/5349 [=======>......................] - ETA: 3s - loss: 0.1105 - accuracy: 0.9402\n",
      "1640/5349 [========>.....................] - ETA: 2s - loss: 0.1104 - accuracy: 0.9403\n",
      "1754/5349 [========>.....................] - ETA: 2s - loss: 0.1106 - accuracy: 0.9402\n",
      "1885/5349 [=========>....................] - ETA: 2s - loss: 0.1112 - accuracy: 0.9397\n",
      "2013/5349 [==========>...................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9399\n",
      "2142/5349 [===========>..................] - ETA: 2s - loss: 0.1109 - accuracy: 0.9401\n",
      "2276/5349 [===========>..................] - ETA: 2s - loss: 0.1111 - accuracy: 0.9400\n",
      "2406/5349 [============>.................] - ETA: 2s - loss: 0.1110 - accuracy: 0.9401\n",
      "2463/5349 [============>.................] - ETA: 2s - loss: 0.1109 - accuracy: 0.9401\n",
      "2591/5349 [=============>................] - ETA: 2s - loss: 0.1110 - accuracy: 0.9400\n",
      "2719/5349 [==============>...............] - ETA: 2s - loss: 0.1110 - accuracy: 0.9401\n",
      "2851/5349 [==============>...............] - ETA: 1s - loss: 0.1111 - accuracy: 0.9401\n",
      "2983/5349 [===============>..............] - ETA: 1s - loss: 0.1111 - accuracy: 0.9403\n",
      "3101/5349 [================>.............] - ETA: 1s - loss: 0.1112 - accuracy: 0.9403\n",
      "3233/5349 [=================>............] - ETA: 1s - loss: 0.1112 - accuracy: 0.9402\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1112 - accuracy: 0.9402\n",
      "3421/5349 [==================>...........] - ETA: 1s - loss: 0.1112 - accuracy: 0.9402\n",
      "3554/5349 [==================>...........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9402\n",
      "3687/5349 [===================>..........] - ETA: 1s - loss: 0.1110 - accuracy: 0.9403\n",
      "3819/5349 [====================>.........] - ETA: 1s - loss: 0.1110 - accuracy: 0.9402\n",
      "3950/5349 [=====================>........] - ETA: 1s - loss: 0.1111 - accuracy: 0.9402\n",
      "4082/5349 [=====================>........] - ETA: 0s - loss: 0.1112 - accuracy: 0.9400\n",
      "4205/5349 [======================>.......] - ETA: 0s - loss: 0.1112 - accuracy: 0.9399\n",
      "4333/5349 [=======================>......] - ETA: 0s - loss: 0.1112 - accuracy: 0.9400\n",
      "4395/5349 [=======================>......] - ETA: 0s - loss: 0.1111 - accuracy: 0.9400\n",
      "4516/5349 [========================>.....] - ETA: 0s - loss: 0.1111 - accuracy: 0.9400\n",
      "4646/5349 [=========================>....] - ETA: 0s - loss: 0.1110 - accuracy: 0.9400\n",
      "4777/5349 [=========================>....] - ETA: 0s - loss: 0.1110 - accuracy: 0.9400\n",
      "4906/5349 [==========================>...] - ETA: 0s - loss: 0.1110 - accuracy: 0.9399\n",
      "5030/5349 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9400\n",
      "5159/5349 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9400\n",
      "5288/5349 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9400\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1110 - accuracy: 0.9400 - val_loss: 0.1084 - val_accuracy: 0.9421\n",
      "\u001B[36m(train_DNN pid=6021)\u001B[0m Epoch 20/20\n",
      "  20/5349 [..............................] - ETA: 14s - loss: 0.1140 - accuracy: 0.9355\n",
      "  60/5349 [..............................] - ETA: 13s - loss: 0.1131 - accuracy: 0.9363\n",
      " 153/5349 [..............................] - ETA: 8s - loss: 0.1113 - accuracy: 0.9401\n",
      " 189/5349 [>.............................] - ETA: 8s - loss: 0.1129 - accuracy: 0.9397\n",
      " 306/5349 [>.............................] - ETA: 6s - loss: 0.1097 - accuracy: 0.9408\n",
      " 412/5349 [=>............................] - ETA: 6s - loss: 0.1102 - accuracy: 0.9406\n",
      " 471/5349 [=>............................] - ETA: 6s - loss: 0.1102 - accuracy: 0.9411\n",
      " 494/5349 [=>............................] - ETA: 7s - loss: 0.1099 - accuracy: 0.9411\n",
      " 515/5349 [=>............................] - ETA: 7s - loss: 0.1097 - accuracy: 0.9412\n",
      " 551/5349 [==>...........................] - ETA: 8s - loss: 0.1094 - accuracy: 0.9414\n",
      " 596/5349 [==>...........................] - ETA: 8s - loss: 0.1098 - accuracy: 0.9411\n",
      " 615/5349 [==>...........................] - ETA: 9s - loss: 0.1099 - accuracy: 0.9411\n",
      " 639/5349 [==>...........................] - ETA: 9s - loss: 0.1100 - accuracy: 0.9411\n",
      " 676/5349 [==>...........................] - ETA: 9s - loss: 0.1100 - accuracy: 0.9412\n",
      " 710/5349 [==>...........................] - ETA: 9s - loss: 0.1098 - accuracy: 0.9411\n",
      " 751/5349 [===>..........................] - ETA: 9s - loss: 0.1100 - accuracy: 0.9405\n",
      " 776/5349 [===>..........................] - ETA: 10s - loss: 0.1097 - accuracy: 0.9408\n",
      " 816/5349 [===>..........................] - ETA: 10s - loss: 0.1096 - accuracy: 0.9406\n",
      " 836/5349 [===>..........................] - ETA: 10s - loss: 0.1095 - accuracy: 0.9406\n",
      " 870/5349 [===>..........................] - ETA: 10s - loss: 0.1096 - accuracy: 0.9406\n",
      " 890/5349 [===>..........................] - ETA: 10s - loss: 0.1095 - accuracy: 0.9407\n",
      " 920/5349 [====>.........................] - ETA: 10s - loss: 0.1094 - accuracy: 0.9408\n",
      " 941/5349 [====>.........................] - ETA: 11s - loss: 0.1093 - accuracy: 0.9409\n",
      " 959/5349 [====>.........................] - ETA: 11s - loss: 0.1093 - accuracy: 0.9408\n",
      " 990/5349 [====>.........................] - ETA: 11s - loss: 0.1092 - accuracy: 0.9409\n",
      "1021/5349 [====>.........................] - ETA: 11s - loss: 0.1093 - accuracy: 0.9409\n",
      "1055/5349 [====>.........................] - ETA: 11s - loss: 0.1091 - accuracy: 0.9411\n",
      "1072/5349 [=====>........................] - ETA: 11s - loss: 0.1091 - accuracy: 0.9412\n",
      "1095/5349 [=====>........................] - ETA: 11s - loss: 0.1093 - accuracy: 0.9411\n",
      "1125/5349 [=====>........................] - ETA: 11s - loss: 0.1093 - accuracy: 0.9409\n",
      "1158/5349 [=====>........................] - ETA: 11s - loss: 0.1090 - accuracy: 0.9411\n",
      "1191/5349 [=====>........................] - ETA: 11s - loss: 0.1089 - accuracy: 0.9411\n",
      "1215/5349 [=====>........................] - ETA: 11s - loss: 0.1090 - accuracy: 0.9410\n",
      "1252/5349 [======>.......................] - ETA: 11s - loss: 0.1093 - accuracy: 0.9408\n",
      "1307/5349 [======>.......................] - ETA: 10s - loss: 0.1091 - accuracy: 0.9410\n",
      "1384/5349 [======>.......................] - ETA: 10s - loss: 0.1093 - accuracy: 0.9407\n",
      "1484/5349 [=======>......................] - ETA: 9s - loss: 0.1090 - accuracy: 0.9408 \n",
      "1568/5349 [=======>......................] - ETA: 9s - loss: 0.1092 - accuracy: 0.9409\n",
      "1682/5349 [========>.....................] - ETA: 8s - loss: 0.1095 - accuracy: 0.9406\n",
      "1805/5349 [=========>....................] - ETA: 7s - loss: 0.1094 - accuracy: 0.9406\n",
      "2005/5349 [==========>...................] - ETA: 6s - loss: 0.1094 - accuracy: 0.9406\n",
      "2137/5349 [==========>...................] - ETA: 6s - loss: 0.1096 - accuracy: 0.9404\n",
      "2269/5349 [===========>..................] - ETA: 5s - loss: 0.1098 - accuracy: 0.9403\n",
      "2396/5349 [============>.................] - ETA: 5s - loss: 0.1099 - accuracy: 0.9402\n",
      "2532/5349 [=============>................] - ETA: 5s - loss: 0.1098 - accuracy: 0.9402\n",
      "2632/5349 [=============>................] - ETA: 4s - loss: 0.1098 - accuracy: 0.9401\n",
      "2737/5349 [==============>...............] - ETA: 4s - loss: 0.1097 - accuracy: 0.9401\n",
      "2943/5349 [===============>..............] - ETA: 4s - loss: 0.1097 - accuracy: 0.9403\n",
      "3089/5349 [================>.............] - ETA: 3s - loss: 0.1099 - accuracy: 0.9401\n",
      "3231/5349 [=================>............] - ETA: 3s - loss: 0.1101 - accuracy: 0.9401\n",
      "3374/5349 [=================>............] - ETA: 3s - loss: 0.1101 - accuracy: 0.9401\n",
      "3513/5349 [==================>...........] - ETA: 2s - loss: 0.1102 - accuracy: 0.9399\n",
      "3661/5349 [===================>..........] - ETA: 2s - loss: 0.1103 - accuracy: 0.9399\n",
      "3877/5349 [====================>.........] - ETA: 2s - loss: 0.1103 - accuracy: 0.9400\n",
      "4022/5349 [=====================>........] - ETA: 1s - loss: 0.1104 - accuracy: 0.9399\n",
      "4141/5349 [======================>.......] - ETA: 1s - loss: 0.1105 - accuracy: 0.9398\n",
      "4283/5349 [=======================>......] - ETA: 1s - loss: 0.1105 - accuracy: 0.9399\n",
      "4424/5349 [=======================>......] - ETA: 1s - loss: 0.1105 - accuracy: 0.9399\n",
      "4562/5349 [========================>.....] - ETA: 1s - loss: 0.1105 - accuracy: 0.9400\n",
      "4704/5349 [=========================>....] - ETA: 0s - loss: 0.1104 - accuracy: 0.9401\n",
      "4840/5349 [==========================>...] - ETA: 0s - loss: 0.1105 - accuracy: 0.9400\n",
      "4900/5349 [==========================>...] - ETA: 0s - loss: 0.1105 - accuracy: 0.9400\n",
      "5024/5349 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.9399\n",
      "5151/5349 [===========================>..] - ETA: 0s - loss: 0.1107 - accuracy: 0.9398\n",
      "5276/5349 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9398\n",
      "5336/5349 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9398\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1107 - accuracy: 0.9398 - val_loss: 0.1075 - val_accuracy: 0.9436\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 1/20\n",
      "  25/5349 [..............................] - ETA: 11s - loss: 0.5846 - accuracy: 0.8412  \n",
      "  75/5349 [..............................] - ETA: 10s - loss: 0.5640 - accuracy: 0.8469\n",
      " 240/5349 [>.............................] - ETA: 5s - loss: 0.5100 - accuracy: 0.8511\n",
      " 307/5349 [>.............................] - ETA: 5s - loss: 0.4925 - accuracy: 0.8540\n",
      " 617/5349 [==>...........................] - ETA: 3s - loss: 0.4376 - accuracy: 0.8576\n",
      " 854/5349 [===>..........................] - ETA: 3s - loss: 0.4108 - accuracy: 0.8580\n",
      "1091/5349 [=====>........................] - ETA: 2s - loss: 0.3911 - accuracy: 0.8580\n",
      "1329/5349 [======>.......................] - ETA: 2s - loss: 0.3752 - accuracy: 0.8584\n",
      "1569/5349 [=======>......................] - ETA: 2s - loss: 0.3626 - accuracy: 0.8589\n",
      "1898/5349 [=========>....................] - ETA: 1s - loss: 0.3487 - accuracy: 0.8589\n",
      "2131/5349 [==========>...................] - ETA: 1s - loss: 0.3402 - accuracy: 0.8594\n",
      "2356/5349 [============>.................] - ETA: 1s - loss: 0.3328 - accuracy: 0.8600\n",
      "2597/5349 [=============>................] - ETA: 1s - loss: 0.3263 - accuracy: 0.8602\n",
      "2839/5349 [==============>...............] - ETA: 1s - loss: 0.3204 - accuracy: 0.8606\n",
      "3079/5349 [================>.............] - ETA: 1s - loss: 0.3151 - accuracy: 0.8611\n",
      "3444/5349 [==================>...........] - ETA: 0s - loss: 0.3079 - accuracy: 0.8618\n",
      "3682/5349 [===================>..........] - ETA: 0s - loss: 0.3037 - accuracy: 0.8623\n",
      "3922/5349 [====================>.........] - ETA: 0s - loss: 0.2998 - accuracy: 0.8629\n",
      "4159/5349 [======================>.......] - ETA: 0s - loss: 0.2964 - accuracy: 0.8632\n",
      "4375/5349 [=======================>......] - ETA: 0s - loss: 0.2934 - accuracy: 0.8637\n",
      "4707/5349 [=========================>....] - ETA: 0s - loss: 0.2890 - accuracy: 0.8646\n",
      "4934/5349 [==========================>...] - ETA: 0s - loss: 0.2862 - accuracy: 0.8651\n",
      "5179/5349 [============================>.] - ETA: 0s - loss: 0.2834 - accuracy: 0.8657\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8661\n",
      "5349/5349 [==============================] - 4s 698us/step - loss: 0.2815 - accuracy: 0.8661 - val_loss: 0.2582 - val_accuracy: 0.8531\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 2/20\n",
      " 124/5349 [..............................] - ETA: 2s - loss: 0.2257 - accuracy: 0.8733\n",
      " 375/5349 [=>............................] - ETA: 2s - loss: 0.2242 - accuracy: 0.8775\n",
      " 627/5349 [==>...........................] - ETA: 1s - loss: 0.2238 - accuracy: 0.8776\n",
      " 752/5349 [===>..........................] - ETA: 1s - loss: 0.2233 - accuracy: 0.8782\n",
      " 999/5349 [====>.........................] - ETA: 1s - loss: 0.2221 - accuracy: 0.8786\n",
      "1254/5349 [======>.......................] - ETA: 1s - loss: 0.2214 - accuracy: 0.8791\n",
      "1498/5349 [=======>......................] - ETA: 1s - loss: 0.2205 - accuracy: 0.8794\n",
      "1751/5349 [========>.....................] - ETA: 1s - loss: 0.2194 - accuracy: 0.8802\n",
      "1874/5349 [=========>....................] - ETA: 1s - loss: 0.2190 - accuracy: 0.8804\n",
      "2117/5349 [==========>...................] - ETA: 1s - loss: 0.2184 - accuracy: 0.8809\n",
      "2362/5349 [============>.................] - ETA: 1s - loss: 0.2178 - accuracy: 0.8811\n",
      "2603/5349 [=============>................] - ETA: 1s - loss: 0.2169 - accuracy: 0.8817\n",
      "2853/5349 [===============>..............] - ETA: 1s - loss: 0.2164 - accuracy: 0.8819\n",
      "2980/5349 [===============>..............] - ETA: 0s - loss: 0.2161 - accuracy: 0.8821\n",
      "3221/5349 [=================>............] - ETA: 0s - loss: 0.2159 - accuracy: 0.8822\n",
      "3472/5349 [==================>...........] - ETA: 0s - loss: 0.2155 - accuracy: 0.8825\n",
      "3725/5349 [===================>..........] - ETA: 0s - loss: 0.2148 - accuracy: 0.8830\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.2145 - accuracy: 0.8831\n",
      "4223/5349 [======================>.......] - ETA: 0s - loss: 0.2139 - accuracy: 0.8837\n",
      "4349/5349 [=======================>......] - ETA: 0s - loss: 0.2137 - accuracy: 0.8839\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.2131 - accuracy: 0.8843\n",
      "4840/5349 [==========================>...] - ETA: 0s - loss: 0.2126 - accuracy: 0.8847\n",
      "5081/5349 [===========================>..] - ETA: 0s - loss: 0.2122 - accuracy: 0.8849\n",
      "5325/5349 [============================>.] - ETA: 0s - loss: 0.2118 - accuracy: 0.8852\n",
      "5349/5349 [==============================] - 3s 566us/step - loss: 0.2117 - accuracy: 0.8852 - val_loss: 0.2071 - val_accuracy: 0.8765\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 3/20\n",
      " 128/5349 [..............................] - ETA: 2s - loss: 0.1978 - accuracy: 0.8959\n",
      " 378/5349 [=>............................] - ETA: 1s - loss: 0.2016 - accuracy: 0.8914\n",
      " 630/5349 [==>...........................] - ETA: 1s - loss: 0.2013 - accuracy: 0.8916\n",
      " 872/5349 [===>..........................] - ETA: 1s - loss: 0.2013 - accuracy: 0.8916\n",
      "1123/5349 [=====>........................] - ETA: 1s - loss: 0.2007 - accuracy: 0.8925\n",
      "1500/5349 [=======>......................] - ETA: 1s - loss: 0.2009 - accuracy: 0.8924\n",
      "1750/5349 [========>.....................] - ETA: 1s - loss: 0.2010 - accuracy: 0.8924\n",
      "1993/5349 [==========>...................] - ETA: 1s - loss: 0.2008 - accuracy: 0.8926\n",
      "2247/5349 [===========>..................] - ETA: 1s - loss: 0.2003 - accuracy: 0.8929\n",
      "2493/5349 [============>.................] - ETA: 1s - loss: 0.1997 - accuracy: 0.8934\n",
      "2742/5349 [==============>...............] - ETA: 1s - loss: 0.1995 - accuracy: 0.8935\n",
      "3084/5349 [================>.............] - ETA: 0s - loss: 0.1993 - accuracy: 0.8938\n",
      "3333/5349 [=================>............] - ETA: 0s - loss: 0.1992 - accuracy: 0.8937\n",
      "3568/5349 [===================>..........] - ETA: 0s - loss: 0.1989 - accuracy: 0.8939\n",
      "3816/5349 [====================>.........] - ETA: 0s - loss: 0.1987 - accuracy: 0.8940\n",
      "4062/5349 [=====================>........] - ETA: 0s - loss: 0.1981 - accuracy: 0.8946\n",
      "4417/5349 [=======================>......] - ETA: 0s - loss: 0.1977 - accuracy: 0.8949\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.1974 - accuracy: 0.8950\n",
      "4871/5349 [==========================>...] - ETA: 0s - loss: 0.1971 - accuracy: 0.8952\n",
      "5114/5349 [===========================>..] - ETA: 0s - loss: 0.1968 - accuracy: 0.8954\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.8955\n",
      "5349/5349 [==============================] - 3s 568us/step - loss: 0.1965 - accuracy: 0.8956 - val_loss: 0.1928 - val_accuracy: 0.9007\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 4/20\n",
      " 127/5349 [..............................] - ETA: 2s - loss: 0.1924 - accuracy: 0.8969\n",
      " 509/5349 [=>............................] - ETA: 1s - loss: 0.1919 - accuracy: 0.8984\n",
      " 762/5349 [===>..........................] - ETA: 1s - loss: 0.1918 - accuracy: 0.8987\n",
      "1008/5349 [====>.........................] - ETA: 1s - loss: 0.1912 - accuracy: 0.8990\n",
      "1260/5349 [======>.......................] - ETA: 1s - loss: 0.1918 - accuracy: 0.8984\n",
      "1385/5349 [======>.......................] - ETA: 1s - loss: 0.1917 - accuracy: 0.8983\n",
      "1612/5349 [========>.....................] - ETA: 1s - loss: 0.1911 - accuracy: 0.8992\n",
      "1864/5349 [=========>....................] - ETA: 1s - loss: 0.1907 - accuracy: 0.8995\n",
      "2111/5349 [==========>...................] - ETA: 1s - loss: 0.1904 - accuracy: 0.8999\n",
      "2489/5349 [============>.................] - ETA: 1s - loss: 0.1903 - accuracy: 0.8999\n",
      "2732/5349 [==============>...............] - ETA: 1s - loss: 0.1899 - accuracy: 0.9002\n",
      "2989/5349 [===============>..............] - ETA: 0s - loss: 0.1898 - accuracy: 0.9000\n",
      "3233/5349 [=================>............] - ETA: 0s - loss: 0.1895 - accuracy: 0.9003\n",
      "3482/5349 [==================>...........] - ETA: 0s - loss: 0.1892 - accuracy: 0.9004\n",
      "3860/5349 [====================>.........] - ETA: 0s - loss: 0.1890 - accuracy: 0.9005\n",
      "4097/5349 [=====================>........] - ETA: 0s - loss: 0.1890 - accuracy: 0.9004\n",
      "4226/5349 [======================>.......] - ETA: 0s - loss: 0.1891 - accuracy: 0.9001\n",
      "4472/5349 [========================>.....] - ETA: 0s - loss: 0.1889 - accuracy: 0.9003\n",
      "4844/5349 [==========================>...] - ETA: 0s - loss: 0.1887 - accuracy: 0.9003\n",
      "5080/5349 [===========================>..] - ETA: 0s - loss: 0.1886 - accuracy: 0.9004\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9006\n",
      "5349/5349 [==============================] - 4s 683us/step - loss: 0.1883 - accuracy: 0.9005 - val_loss: 0.1898 - val_accuracy: 0.8881\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 5/20\n",
      "  29/5349 [..............................] - ETA: 9s - loss: 0.1817 - accuracy: 0.9048 \n",
      "  47/5349 [..............................] - ETA: 17s - loss: 0.1817 - accuracy: 0.9066\n",
      "  60/5349 [..............................] - ETA: 23s - loss: 0.1815 - accuracy: 0.9067\n",
      " 121/5349 [..............................] - ETA: 16s - loss: 0.1823 - accuracy: 0.9044\n",
      " 175/5349 [..............................] - ETA: 12s - loss: 0.1837 - accuracy: 0.9034\n",
      " 230/5349 [>.............................] - ETA: 11s - loss: 0.1820 - accuracy: 0.9060\n",
      " 303/5349 [>.............................] - ETA: 10s - loss: 0.1836 - accuracy: 0.9041\n",
      " 387/5349 [=>............................] - ETA: 9s - loss: 0.1840 - accuracy: 0.9038\n",
      " 472/5349 [=>............................] - ETA: 8s - loss: 0.1863 - accuracy: 0.9008\n",
      " 544/5349 [==>...........................] - ETA: 8s - loss: 0.1863 - accuracy: 0.9007\n",
      " 638/5349 [==>...........................] - ETA: 7s - loss: 0.1859 - accuracy: 0.9012\n",
      " 698/5349 [==>...........................] - ETA: 7s - loss: 0.1858 - accuracy: 0.9016\n",
      " 767/5349 [===>..........................] - ETA: 7s - loss: 0.1859 - accuracy: 0.9016\n",
      " 850/5349 [===>..........................] - ETA: 7s - loss: 0.1858 - accuracy: 0.9014\n",
      " 925/5349 [====>.........................] - ETA: 7s - loss: 0.1859 - accuracy: 0.9014\n",
      "1069/5349 [====>.........................] - ETA: 6s - loss: 0.1857 - accuracy: 0.9013\n",
      "1135/5349 [=====>........................] - ETA: 6s - loss: 0.1856 - accuracy: 0.9014\n",
      "1198/5349 [=====>........................] - ETA: 6s - loss: 0.1855 - accuracy: 0.9014\n",
      "1282/5349 [======>.......................] - ETA: 6s - loss: 0.1859 - accuracy: 0.9010\n",
      "1368/5349 [======>.......................] - ETA: 5s - loss: 0.1863 - accuracy: 0.9006\n",
      "1475/5349 [=======>......................] - ETA: 5s - loss: 0.1860 - accuracy: 0.9010\n",
      "1653/5349 [========>.....................] - ETA: 5s - loss: 0.1858 - accuracy: 0.9010\n",
      "1810/5349 [=========>....................] - ETA: 4s - loss: 0.1856 - accuracy: 0.9013\n",
      "1988/5349 [==========>...................] - ETA: 4s - loss: 0.1853 - accuracy: 0.9016\n",
      "2221/5349 [===========>..................] - ETA: 3s - loss: 0.1850 - accuracy: 0.9018\n",
      "2585/5349 [=============>................] - ETA: 2s - loss: 0.1844 - accuracy: 0.9025\n",
      "2828/5349 [==============>...............] - ETA: 2s - loss: 0.1844 - accuracy: 0.9026\n",
      "3071/5349 [================>.............] - ETA: 2s - loss: 0.1841 - accuracy: 0.9029\n",
      "3306/5349 [=================>............] - ETA: 1s - loss: 0.1842 - accuracy: 0.9028\n",
      "3546/5349 [==================>...........] - ETA: 1s - loss: 0.1840 - accuracy: 0.9030\n",
      "3664/5349 [===================>..........] - ETA: 1s - loss: 0.1838 - accuracy: 0.9031\n",
      "3898/5349 [====================>.........] - ETA: 1s - loss: 0.1839 - accuracy: 0.9030\n",
      "4140/5349 [======================>.......] - ETA: 0s - loss: 0.1835 - accuracy: 0.9032\n",
      "4361/5349 [=======================>......] - ETA: 0s - loss: 0.1833 - accuracy: 0.9032\n",
      "4603/5349 [========================>.....] - ETA: 0s - loss: 0.1835 - accuracy: 0.9030\n",
      "4955/5349 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.9029\n",
      "5195/5349 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9029\n",
      "5314/5349 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9029\n",
      "5349/5349 [==============================] - 5s 888us/step - loss: 0.1835 - accuracy: 0.9029 - val_loss: 0.1830 - val_accuracy: 0.8974\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 6/20\n",
      " 239/5349 [>.............................] - ETA: 2s - loss: 0.1798 - accuracy: 0.9036\n",
      " 464/5349 [=>............................] - ETA: 2s - loss: 0.1807 - accuracy: 0.9036\n",
      " 631/5349 [==>...........................] - ETA: 2s - loss: 0.1812 - accuracy: 0.9030\n",
      " 817/5349 [===>..........................] - ETA: 2s - loss: 0.1805 - accuracy: 0.9032\n",
      "1158/5349 [=====>........................] - ETA: 2s - loss: 0.1810 - accuracy: 0.9026\n",
      "1385/5349 [======>.......................] - ETA: 1s - loss: 0.1807 - accuracy: 0.9029\n",
      "1626/5349 [========>.....................] - ETA: 1s - loss: 0.1811 - accuracy: 0.9025\n",
      "1862/5349 [=========>....................] - ETA: 1s - loss: 0.1811 - accuracy: 0.9027\n",
      "2110/5349 [==========>...................] - ETA: 1s - loss: 0.1810 - accuracy: 0.9029\n",
      "2234/5349 [===========>..................] - ETA: 1s - loss: 0.1813 - accuracy: 0.9028\n",
      "2469/5349 [============>.................] - ETA: 1s - loss: 0.1813 - accuracy: 0.9029\n",
      "2712/5349 [==============>...............] - ETA: 1s - loss: 0.1813 - accuracy: 0.9028\n",
      "2948/5349 [===============>..............] - ETA: 1s - loss: 0.1811 - accuracy: 0.9030\n",
      "3195/5349 [================>.............] - ETA: 0s - loss: 0.1808 - accuracy: 0.9033\n",
      "3565/5349 [==================>...........] - ETA: 0s - loss: 0.1808 - accuracy: 0.9034\n",
      "3819/5349 [====================>.........] - ETA: 0s - loss: 0.1806 - accuracy: 0.9035\n",
      "4065/5349 [=====================>........] - ETA: 0s - loss: 0.1806 - accuracy: 0.9037\n",
      "4317/5349 [=======================>......] - ETA: 0s - loss: 0.1806 - accuracy: 0.9037\n",
      "4546/5349 [========================>.....] - ETA: 0s - loss: 0.1805 - accuracy: 0.9038\n",
      "4925/5349 [==========================>...] - ETA: 0s - loss: 0.1802 - accuracy: 0.9040\n",
      "5169/5349 [===========================>..] - ETA: 0s - loss: 0.1801 - accuracy: 0.9041\n",
      "5293/5349 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.9040\n",
      "5349/5349 [==============================] - 3s 610us/step - loss: 0.1801 - accuracy: 0.9040 - val_loss: 0.1840 - val_accuracy: 0.8867\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1525 - accuracy: 0.9600\n",
      " 377/5349 [=>............................] - ETA: 1s - loss: 0.1790 - accuracy: 0.9029\n",
      " 628/5349 [==>...........................] - ETA: 1s - loss: 0.1794 - accuracy: 0.9026\n",
      " 871/5349 [===>..........................] - ETA: 1s - loss: 0.1790 - accuracy: 0.9027\n",
      "1120/5349 [=====>........................] - ETA: 1s - loss: 0.1789 - accuracy: 0.9033\n",
      "1488/5349 [=======>......................] - ETA: 1s - loss: 0.1790 - accuracy: 0.9031\n",
      "1743/5349 [========>.....................] - ETA: 1s - loss: 0.1783 - accuracy: 0.9039\n",
      "1971/5349 [==========>...................] - ETA: 1s - loss: 0.1782 - accuracy: 0.9039\n",
      "2221/5349 [===========>..................] - ETA: 1s - loss: 0.1788 - accuracy: 0.9033\n",
      "2466/5349 [============>.................] - ETA: 1s - loss: 0.1788 - accuracy: 0.9034\n",
      "2593/5349 [=============>................] - ETA: 1s - loss: 0.1788 - accuracy: 0.9034\n",
      "2844/5349 [==============>...............] - ETA: 1s - loss: 0.1787 - accuracy: 0.9037\n",
      "3090/5349 [================>.............] - ETA: 0s - loss: 0.1785 - accuracy: 0.9039\n",
      "3338/5349 [=================>............] - ETA: 0s - loss: 0.1783 - accuracy: 0.9040\n",
      "3578/5349 [===================>..........] - ETA: 0s - loss: 0.1784 - accuracy: 0.9039\n",
      "3832/5349 [====================>.........] - ETA: 0s - loss: 0.1782 - accuracy: 0.9042\n",
      "4180/5349 [======================>.......] - ETA: 0s - loss: 0.1785 - accuracy: 0.9039\n",
      "4334/5349 [=======================>......] - ETA: 0s - loss: 0.1786 - accuracy: 0.9037\n",
      "4563/5349 [========================>.....] - ETA: 0s - loss: 0.1784 - accuracy: 0.9038\n",
      "4811/5349 [=========================>....] - ETA: 0s - loss: 0.1781 - accuracy: 0.9042\n",
      "5062/5349 [===========================>..] - ETA: 0s - loss: 0.1779 - accuracy: 0.9043\n",
      "5315/5349 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9043\n",
      "5349/5349 [==============================] - 3s 577us/step - loss: 0.1779 - accuracy: 0.9043 - val_loss: 0.1770 - val_accuracy: 0.9015\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 8/20\n",
      " 125/5349 [..............................] - ETA: 2s - loss: 0.1793 - accuracy: 0.9013\n",
      " 348/5349 [>.............................] - ETA: 2s - loss: 0.1773 - accuracy: 0.9032\n",
      " 580/5349 [==>...........................] - ETA: 2s - loss: 0.1785 - accuracy: 0.9029\n",
      " 818/5349 [===>..........................] - ETA: 1s - loss: 0.1781 - accuracy: 0.9036\n",
      "1066/5349 [====>.........................] - ETA: 1s - loss: 0.1771 - accuracy: 0.9043\n",
      "1309/5349 [======>.......................] - ETA: 1s - loss: 0.1774 - accuracy: 0.9037\n",
      "1641/5349 [========>.....................] - ETA: 1s - loss: 0.1773 - accuracy: 0.9040\n",
      "1862/5349 [=========>....................] - ETA: 1s - loss: 0.1775 - accuracy: 0.9038\n",
      "2094/5349 [==========>...................] - ETA: 1s - loss: 0.1776 - accuracy: 0.9037\n",
      "2336/5349 [============>.................] - ETA: 1s - loss: 0.1772 - accuracy: 0.9040\n",
      "2706/5349 [==============>...............] - ETA: 1s - loss: 0.1770 - accuracy: 0.9039\n",
      "2958/5349 [===============>..............] - ETA: 1s - loss: 0.1766 - accuracy: 0.9042\n",
      "3202/5349 [================>.............] - ETA: 0s - loss: 0.1765 - accuracy: 0.9043\n",
      "3439/5349 [==================>...........] - ETA: 0s - loss: 0.1766 - accuracy: 0.9042\n",
      "3642/5349 [===================>..........] - ETA: 0s - loss: 0.1765 - accuracy: 0.9043\n",
      "3886/5349 [====================>.........] - ETA: 0s - loss: 0.1764 - accuracy: 0.9044\n",
      "4251/5349 [======================>.......] - ETA: 0s - loss: 0.1762 - accuracy: 0.9045\n",
      "4501/5349 [========================>.....] - ETA: 0s - loss: 0.1760 - accuracy: 0.9047\n",
      "4752/5349 [=========================>....] - ETA: 0s - loss: 0.1758 - accuracy: 0.9048\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.1757 - accuracy: 0.9049\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9048\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9049\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1756 - accuracy: 0.9050 - val_loss: 0.1806 - val_accuracy: 0.8861\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 9/20\n",
      "  20/5349 [..............................] - ETA: 14s - loss: 0.1766 - accuracy: 0.9015\n",
      "  68/5349 [..............................] - ETA: 12s - loss: 0.1737 - accuracy: 0.9079\n",
      "  97/5349 [..............................] - ETA: 11s - loss: 0.1741 - accuracy: 0.9073\n",
      " 153/5349 [..............................] - ETA: 10s - loss: 0.1731 - accuracy: 0.9075\n",
      " 199/5349 [>.............................] - ETA: 10s - loss: 0.1738 - accuracy: 0.9073\n",
      " 270/5349 [>.............................] - ETA: 9s - loss: 0.1735 - accuracy: 0.9070 \n",
      " 334/5349 [>.............................] - ETA: 9s - loss: 0.1741 - accuracy: 0.9060\n",
      " 353/5349 [>.............................] - ETA: 9s - loss: 0.1747 - accuracy: 0.9055\n",
      " 418/5349 [=>............................] - ETA: 9s - loss: 0.1745 - accuracy: 0.9057\n",
      " 559/5349 [==>...........................] - ETA: 7s - loss: 0.1742 - accuracy: 0.9060\n",
      " 721/5349 [===>..........................] - ETA: 6s - loss: 0.1742 - accuracy: 0.9056\n",
      " 878/5349 [===>..........................] - ETA: 5s - loss: 0.1742 - accuracy: 0.9056\n",
      " 951/5349 [====>.........................] - ETA: 5s - loss: 0.1743 - accuracy: 0.9055\n",
      "1092/5349 [=====>........................] - ETA: 4s - loss: 0.1744 - accuracy: 0.9054\n",
      "1273/5349 [======>.......................] - ETA: 4s - loss: 0.1746 - accuracy: 0.9050\n",
      "1472/5349 [=======>......................] - ETA: 3s - loss: 0.1746 - accuracy: 0.9050\n",
      "1662/5349 [========>.....................] - ETA: 3s - loss: 0.1746 - accuracy: 0.9050\n",
      "1862/5349 [=========>....................] - ETA: 3s - loss: 0.1744 - accuracy: 0.9051\n",
      "2055/5349 [==========>...................] - ETA: 2s - loss: 0.1749 - accuracy: 0.9047\n",
      "2356/5349 [============>.................] - ETA: 2s - loss: 0.1746 - accuracy: 0.9050\n",
      "2553/5349 [=============>................] - ETA: 2s - loss: 0.1746 - accuracy: 0.9050\n",
      "2749/5349 [==============>...............] - ETA: 1s - loss: 0.1747 - accuracy: 0.9050\n",
      "2931/5349 [===============>..............] - ETA: 1s - loss: 0.1745 - accuracy: 0.9051\n",
      "3133/5349 [================>.............] - ETA: 1s - loss: 0.1743 - accuracy: 0.9054\n",
      "3325/5349 [=================>............] - ETA: 1s - loss: 0.1744 - accuracy: 0.9053\n",
      "3522/5349 [==================>...........] - ETA: 1s - loss: 0.1743 - accuracy: 0.9054\n",
      "3620/5349 [===================>..........] - ETA: 1s - loss: 0.1742 - accuracy: 0.9054\n",
      "3817/5349 [====================>.........] - ETA: 1s - loss: 0.1739 - accuracy: 0.9056\n",
      "4004/5349 [=====================>........] - ETA: 0s - loss: 0.1740 - accuracy: 0.9054\n",
      "4202/5349 [======================>.......] - ETA: 0s - loss: 0.1742 - accuracy: 0.9052\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1741 - accuracy: 0.9053\n",
      "4626/5349 [========================>.....] - ETA: 0s - loss: 0.1741 - accuracy: 0.9053\n",
      "4850/5349 [==========================>...] - ETA: 0s - loss: 0.1741 - accuracy: 0.9053\n",
      "5043/5349 [===========================>..] - ETA: 0s - loss: 0.1741 - accuracy: 0.9052\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9052\n",
      "5349/5349 [==============================] - 4s 801us/step - loss: 0.1742 - accuracy: 0.9052 - val_loss: 0.1739 - val_accuracy: 0.8986\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 10/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.2239 - accuracy: 0.8600\n",
      " 296/5349 [>.............................] - ETA: 2s - loss: 0.1728 - accuracy: 0.9062\n",
      " 486/5349 [=>............................] - ETA: 2s - loss: 0.1722 - accuracy: 0.9064\n",
      " 678/5349 [==>...........................] - ETA: 2s - loss: 0.1730 - accuracy: 0.9053\n",
      " 887/5349 [===>..........................] - ETA: 2s - loss: 0.1736 - accuracy: 0.9055\n",
      "1083/5349 [=====>........................] - ETA: 2s - loss: 0.1730 - accuracy: 0.9057\n",
      "1287/5349 [======>.......................] - ETA: 2s - loss: 0.1725 - accuracy: 0.9063\n",
      "1483/5349 [=======>......................] - ETA: 1s - loss: 0.1723 - accuracy: 0.9065\n",
      "1584/5349 [=======>......................] - ETA: 1s - loss: 0.1724 - accuracy: 0.9062\n",
      "1777/5349 [========>.....................] - ETA: 1s - loss: 0.1729 - accuracy: 0.9056\n",
      "1969/5349 [==========>...................] - ETA: 1s - loss: 0.1729 - accuracy: 0.9057\n",
      "2176/5349 [===========>..................] - ETA: 1s - loss: 0.1730 - accuracy: 0.9056\n",
      "2371/5349 [============>.................] - ETA: 1s - loss: 0.1728 - accuracy: 0.9059\n",
      "2554/5349 [=============>................] - ETA: 1s - loss: 0.1730 - accuracy: 0.9056\n",
      "2752/5349 [==============>...............] - ETA: 1s - loss: 0.1731 - accuracy: 0.9055\n",
      "2960/5349 [===============>..............] - ETA: 1s - loss: 0.1728 - accuracy: 0.9058\n",
      "3161/5349 [================>.............] - ETA: 1s - loss: 0.1729 - accuracy: 0.9057\n",
      "3368/5349 [=================>............] - ETA: 1s - loss: 0.1728 - accuracy: 0.9059\n",
      "3570/5349 [===================>..........] - ETA: 0s - loss: 0.1727 - accuracy: 0.9059\n",
      "3880/5349 [====================>.........] - ETA: 0s - loss: 0.1728 - accuracy: 0.9059\n",
      "4082/5349 [=====================>........] - ETA: 0s - loss: 0.1728 - accuracy: 0.9061\n",
      "4288/5349 [=======================>......] - ETA: 0s - loss: 0.1728 - accuracy: 0.9061\n",
      "4471/5349 [========================>.....] - ETA: 0s - loss: 0.1729 - accuracy: 0.9060\n",
      "4680/5349 [=========================>....] - ETA: 0s - loss: 0.1729 - accuracy: 0.9060\n",
      "4868/5349 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.9060\n",
      "4956/5349 [==========================>...] - ETA: 0s - loss: 0.1728 - accuracy: 0.9060\n",
      "5130/5349 [===========================>..] - ETA: 0s - loss: 0.1728 - accuracy: 0.9060\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9059\n",
      "5349/5349 [==============================] - 4s 710us/step - loss: 0.1729 - accuracy: 0.9059 - val_loss: 0.1731 - val_accuracy: 0.8978\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 11/20\n",
      " 105/5349 [..............................] - ETA: 2s - loss: 0.1674 - accuracy: 0.9131\n",
      " 317/5349 [>.............................] - ETA: 2s - loss: 0.1714 - accuracy: 0.9082\n",
      " 628/5349 [==>...........................] - ETA: 2s - loss: 0.1710 - accuracy: 0.9084\n",
      " 832/5349 [===>..........................] - ETA: 2s - loss: 0.1717 - accuracy: 0.9078\n",
      "1045/5349 [====>.........................] - ETA: 2s - loss: 0.1719 - accuracy: 0.9076\n",
      "1229/5349 [=====>........................] - ETA: 2s - loss: 0.1723 - accuracy: 0.9069\n",
      "1437/5349 [=======>......................] - ETA: 1s - loss: 0.1725 - accuracy: 0.9067\n",
      "1639/5349 [========>.....................] - ETA: 1s - loss: 0.1727 - accuracy: 0.9064\n",
      "1852/5349 [=========>....................] - ETA: 1s - loss: 0.1723 - accuracy: 0.9068\n",
      "2160/5349 [===========>..................] - ETA: 1s - loss: 0.1723 - accuracy: 0.9069\n",
      "2371/5349 [============>.................] - ETA: 1s - loss: 0.1722 - accuracy: 0.9068\n",
      "2573/5349 [=============>................] - ETA: 1s - loss: 0.1721 - accuracy: 0.9068\n",
      "2782/5349 [==============>...............] - ETA: 1s - loss: 0.1718 - accuracy: 0.9071\n",
      "2969/5349 [===============>..............] - ETA: 1s - loss: 0.1718 - accuracy: 0.9069\n",
      "3173/5349 [================>.............] - ETA: 1s - loss: 0.1719 - accuracy: 0.9067\n",
      "3373/5349 [=================>............] - ETA: 0s - loss: 0.1720 - accuracy: 0.9066\n",
      "3582/5349 [===================>..........] - ETA: 0s - loss: 0.1720 - accuracy: 0.9067\n",
      "3775/5349 [====================>.........] - ETA: 0s - loss: 0.1720 - accuracy: 0.9066\n",
      "3882/5349 [====================>.........] - ETA: 0s - loss: 0.1722 - accuracy: 0.9064\n",
      "4093/5349 [=====================>........] - ETA: 0s - loss: 0.1720 - accuracy: 0.9066\n",
      "4299/5349 [=======================>......] - ETA: 0s - loss: 0.1720 - accuracy: 0.9065\n",
      "4509/5349 [========================>.....] - ETA: 0s - loss: 0.1719 - accuracy: 0.9066\n",
      "4714/5349 [=========================>....] - ETA: 0s - loss: 0.1719 - accuracy: 0.9067\n",
      "4925/5349 [==========================>...] - ETA: 0s - loss: 0.1720 - accuracy: 0.9065\n",
      "5131/5349 [===========================>..] - ETA: 0s - loss: 0.1719 - accuracy: 0.9066\n",
      "5337/5349 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.9064\n",
      "5349/5349 [==============================] - 4s 677us/step - loss: 0.1720 - accuracy: 0.9064 - val_loss: 0.1731 - val_accuracy: 0.8938\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 12/20\n",
      " 100/5349 [..............................] - ETA: 2s - loss: 0.1735 - accuracy: 0.9031\n",
      " 301/5349 [>.............................] - ETA: 2s - loss: 0.1753 - accuracy: 0.9020\n",
      " 419/5349 [=>............................] - ETA: 3s - loss: 0.1760 - accuracy: 0.9019\n",
      " 423/5349 [=>............................] - ETA: 3s - loss: 0.1761 - accuracy: 0.9018\n",
      " 576/5349 [==>...........................] - ETA: 3s - loss: 0.1742 - accuracy: 0.9037\n",
      " 692/5349 [==>...........................] - ETA: 3s - loss: 0.1742 - accuracy: 0.9038\n",
      " 737/5349 [===>..........................] - ETA: 3s - loss: 0.1742 - accuracy: 0.9036\n",
      " 781/5349 [===>..........................] - ETA: 4s - loss: 0.1737 - accuracy: 0.9040\n",
      " 861/5349 [===>..........................] - ETA: 4s - loss: 0.1737 - accuracy: 0.9042\n",
      " 909/5349 [====>.........................] - ETA: 4s - loss: 0.1739 - accuracy: 0.9042\n",
      " 946/5349 [====>.........................] - ETA: 5s - loss: 0.1737 - accuracy: 0.9042\n",
      " 992/5349 [====>.........................] - ETA: 5s - loss: 0.1732 - accuracy: 0.9049\n",
      "1041/5349 [====>.........................] - ETA: 5s - loss: 0.1732 - accuracy: 0.9051\n",
      "1086/5349 [=====>........................] - ETA: 5s - loss: 0.1730 - accuracy: 0.9053\n",
      "1114/5349 [=====>........................] - ETA: 5s - loss: 0.1732 - accuracy: 0.9051\n",
      "1155/5349 [=====>........................] - ETA: 5s - loss: 0.1728 - accuracy: 0.9057\n",
      "1196/5349 [=====>........................] - ETA: 5s - loss: 0.1728 - accuracy: 0.9056\n",
      "1255/5349 [======>.......................] - ETA: 5s - loss: 0.1727 - accuracy: 0.9057\n",
      "1309/5349 [======>.......................] - ETA: 5s - loss: 0.1728 - accuracy: 0.9054\n",
      "1350/5349 [======>.......................] - ETA: 5s - loss: 0.1727 - accuracy: 0.9055\n",
      "1373/5349 [======>.......................] - ETA: 5s - loss: 0.1725 - accuracy: 0.9057\n",
      "1414/5349 [======>.......................] - ETA: 5s - loss: 0.1721 - accuracy: 0.9061\n",
      "1459/5349 [=======>......................] - ETA: 5s - loss: 0.1724 - accuracy: 0.9059\n",
      "1503/5349 [=======>......................] - ETA: 6s - loss: 0.1724 - accuracy: 0.9059\n",
      "1522/5349 [=======>......................] - ETA: 6s - loss: 0.1723 - accuracy: 0.9059\n",
      "1543/5349 [=======>......................] - ETA: 6s - loss: 0.1723 - accuracy: 0.9059\n",
      "1578/5349 [=======>......................] - ETA: 6s - loss: 0.1722 - accuracy: 0.9059\n",
      "1611/5349 [========>.....................] - ETA: 6s - loss: 0.1720 - accuracy: 0.9061\n",
      "1656/5349 [========>.....................] - ETA: 6s - loss: 0.1722 - accuracy: 0.9061\n",
      "1710/5349 [========>.....................] - ETA: 6s - loss: 0.1723 - accuracy: 0.9059\n",
      "1731/5349 [========>.....................] - ETA: 6s - loss: 0.1723 - accuracy: 0.9059\n",
      "1774/5349 [========>.....................] - ETA: 6s - loss: 0.1722 - accuracy: 0.9060\n",
      "1809/5349 [=========>....................] - ETA: 6s - loss: 0.1721 - accuracy: 0.9061\n",
      "1843/5349 [=========>....................] - ETA: 6s - loss: 0.1721 - accuracy: 0.9062\n",
      "1889/5349 [=========>....................] - ETA: 6s - loss: 0.1720 - accuracy: 0.9063\n",
      "1968/5349 [==========>...................] - ETA: 5s - loss: 0.1721 - accuracy: 0.9063\n",
      "2109/5349 [==========>...................] - ETA: 5s - loss: 0.1722 - accuracy: 0.9062\n",
      "2263/5349 [===========>..................] - ETA: 4s - loss: 0.1723 - accuracy: 0.9061\n",
      "2393/5349 [============>.................] - ETA: 4s - loss: 0.1724 - accuracy: 0.9060\n",
      "2571/5349 [=============>................] - ETA: 4s - loss: 0.1720 - accuracy: 0.9065\n",
      "2730/5349 [==============>...............] - ETA: 3s - loss: 0.1719 - accuracy: 0.9065\n",
      "2885/5349 [===============>..............] - ETA: 3s - loss: 0.1717 - accuracy: 0.9065\n",
      "3049/5349 [================>.............] - ETA: 3s - loss: 0.1717 - accuracy: 0.9065\n",
      "3211/5349 [=================>............] - ETA: 2s - loss: 0.1716 - accuracy: 0.9066\n",
      "3366/5349 [=================>............] - ETA: 2s - loss: 0.1715 - accuracy: 0.9065\n",
      "3520/5349 [==================>...........] - ETA: 2s - loss: 0.1716 - accuracy: 0.9064\n",
      "3754/5349 [====================>.........] - ETA: 1s - loss: 0.1718 - accuracy: 0.9062\n",
      "3903/5349 [====================>.........] - ETA: 1s - loss: 0.1714 - accuracy: 0.9065\n",
      "4015/5349 [=====================>........] - ETA: 1s - loss: 0.1715 - accuracy: 0.9065\n",
      "4177/5349 [======================>.......] - ETA: 1s - loss: 0.1716 - accuracy: 0.9064\n",
      "4413/5349 [=======================>......] - ETA: 1s - loss: 0.1714 - accuracy: 0.9065\n",
      "4600/5349 [========================>.....] - ETA: 0s - loss: 0.1715 - accuracy: 0.9065\n",
      "4781/5349 [=========================>....] - ETA: 0s - loss: 0.1715 - accuracy: 0.9065\n",
      "4965/5349 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.9066\n",
      "5154/5349 [===========================>..] - ETA: 0s - loss: 0.1714 - accuracy: 0.9065\n",
      "5253/5349 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9065\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1712 - accuracy: 0.9066 - val_loss: 0.1680 - val_accuracy: 0.9107\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 13/20\n",
      "  99/5349 [..............................] - ETA: 2s - loss: 0.1747 - accuracy: 0.9012\n",
      " 309/5349 [>.............................] - ETA: 2s - loss: 0.1714 - accuracy: 0.9061\n",
      " 500/5349 [=>............................] - ETA: 2s - loss: 0.1720 - accuracy: 0.9055\n",
      " 655/5349 [==>...........................] - ETA: 2s - loss: 0.1714 - accuracy: 0.9064\n",
      " 846/5349 [===>..........................] - ETA: 2s - loss: 0.1708 - accuracy: 0.9069\n",
      "1143/5349 [=====>........................] - ETA: 2s - loss: 0.1709 - accuracy: 0.9067\n",
      "1347/5349 [======>.......................] - ETA: 2s - loss: 0.1710 - accuracy: 0.9067\n",
      "1535/5349 [=======>......................] - ETA: 1s - loss: 0.1708 - accuracy: 0.9066\n",
      "1738/5349 [========>.....................] - ETA: 1s - loss: 0.1705 - accuracy: 0.9067\n",
      "1932/5349 [=========>....................] - ETA: 1s - loss: 0.1706 - accuracy: 0.9066\n",
      "2135/5349 [==========>...................] - ETA: 1s - loss: 0.1704 - accuracy: 0.9068\n",
      "2336/5349 [============>.................] - ETA: 1s - loss: 0.1707 - accuracy: 0.9064\n",
      "2541/5349 [=============>................] - ETA: 1s - loss: 0.1703 - accuracy: 0.9067\n",
      "2747/5349 [==============>...............] - ETA: 1s - loss: 0.1703 - accuracy: 0.9068\n",
      "2852/5349 [==============>...............] - ETA: 1s - loss: 0.1703 - accuracy: 0.9068\n",
      "3058/5349 [================>.............] - ETA: 1s - loss: 0.1701 - accuracy: 0.9070\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.1702 - accuracy: 0.9069\n",
      "3444/5349 [==================>...........] - ETA: 0s - loss: 0.1703 - accuracy: 0.9068\n",
      "3607/5349 [===================>..........] - ETA: 0s - loss: 0.1704 - accuracy: 0.9067\n",
      "3816/5349 [====================>.........] - ETA: 0s - loss: 0.1702 - accuracy: 0.9069\n",
      "4017/5349 [=====================>........] - ETA: 0s - loss: 0.1703 - accuracy: 0.9067\n",
      "4324/5349 [=======================>......] - ETA: 0s - loss: 0.1700 - accuracy: 0.9070\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.1702 - accuracy: 0.9069\n",
      "4734/5349 [=========================>....] - ETA: 0s - loss: 0.1702 - accuracy: 0.9069\n",
      "4931/5349 [==========================>...] - ETA: 0s - loss: 0.1702 - accuracy: 0.9069\n",
      "5140/5349 [===========================>..] - ETA: 0s - loss: 0.1699 - accuracy: 0.9071\n",
      "5338/5349 [============================>.] - ETA: 0s - loss: 0.1701 - accuracy: 0.9070\n",
      "5349/5349 [==============================] - 4s 682us/step - loss: 0.1701 - accuracy: 0.9069 - val_loss: 0.1683 - val_accuracy: 0.9064\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1657 - accuracy: 0.9300\n",
      " 207/5349 [>.............................] - ETA: 2s - loss: 0.1683 - accuracy: 0.9073\n",
      " 515/5349 [=>............................] - ETA: 2s - loss: 0.1691 - accuracy: 0.9068\n",
      " 717/5349 [===>..........................] - ETA: 2s - loss: 0.1698 - accuracy: 0.9057\n",
      " 915/5349 [====>.........................] - ETA: 2s - loss: 0.1694 - accuracy: 0.9062\n",
      "1119/5349 [=====>........................] - ETA: 2s - loss: 0.1699 - accuracy: 0.9059\n",
      "1315/5349 [======>.......................] - ETA: 2s - loss: 0.1692 - accuracy: 0.9067\n",
      "1518/5349 [=======>......................] - ETA: 1s - loss: 0.1690 - accuracy: 0.9069\n",
      "1691/5349 [========>.....................] - ETA: 1s - loss: 0.1695 - accuracy: 0.9065\n",
      "1868/5349 [=========>....................] - ETA: 1s - loss: 0.1697 - accuracy: 0.9062\n",
      "2083/5349 [==========>...................] - ETA: 1s - loss: 0.1699 - accuracy: 0.9061\n",
      "2155/5349 [===========>..................] - ETA: 1s - loss: 0.1700 - accuracy: 0.9060\n",
      "2327/5349 [============>.................] - ETA: 1s - loss: 0.1699 - accuracy: 0.9063\n",
      "2524/5349 [=============>................] - ETA: 1s - loss: 0.1698 - accuracy: 0.9064\n",
      "2698/5349 [==============>...............] - ETA: 1s - loss: 0.1701 - accuracy: 0.9062\n",
      "2864/5349 [===============>..............] - ETA: 1s - loss: 0.1697 - accuracy: 0.9065\n",
      "3037/5349 [================>.............] - ETA: 1s - loss: 0.1698 - accuracy: 0.9064\n",
      "3214/5349 [=================>............] - ETA: 1s - loss: 0.1699 - accuracy: 0.9064\n",
      "3403/5349 [==================>...........] - ETA: 1s - loss: 0.1695 - accuracy: 0.9067\n",
      "3711/5349 [===================>..........] - ETA: 0s - loss: 0.1695 - accuracy: 0.9066\n",
      "3917/5349 [====================>.........] - ETA: 0s - loss: 0.1695 - accuracy: 0.9066\n",
      "4118/5349 [======================>.......] - ETA: 0s - loss: 0.1696 - accuracy: 0.9066\n",
      "4320/5349 [=======================>......] - ETA: 0s - loss: 0.1697 - accuracy: 0.9066\n",
      "4530/5349 [========================>.....] - ETA: 0s - loss: 0.1698 - accuracy: 0.9065\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.1698 - accuracy: 0.9065\n",
      "4936/5349 [==========================>...] - ETA: 0s - loss: 0.1697 - accuracy: 0.9067\n",
      "5224/5349 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9067\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9068\n",
      "5349/5349 [==============================] - 4s 697us/step - loss: 0.1695 - accuracy: 0.9068 - val_loss: 0.1683 - val_accuracy: 0.9079\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 15/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.2259 - accuracy: 0.8500\n",
      " 210/5349 [>.............................] - ETA: 2s - loss: 0.1645 - accuracy: 0.9128\n",
      " 520/5349 [=>............................] - ETA: 2s - loss: 0.1681 - accuracy: 0.9087\n",
      " 723/5349 [===>..........................] - ETA: 2s - loss: 0.1690 - accuracy: 0.9081\n",
      " 930/5349 [====>.........................] - ETA: 2s - loss: 0.1689 - accuracy: 0.9080\n",
      "1133/5349 [=====>........................] - ETA: 2s - loss: 0.1690 - accuracy: 0.9077\n",
      "1282/5349 [======>.......................] - ETA: 2s - loss: 0.1692 - accuracy: 0.9077\n",
      "1456/5349 [=======>......................] - ETA: 2s - loss: 0.1695 - accuracy: 0.9071\n",
      "1663/5349 [========>.....................] - ETA: 1s - loss: 0.1692 - accuracy: 0.9076\n",
      "1846/5349 [=========>....................] - ETA: 1s - loss: 0.1692 - accuracy: 0.9077\n",
      "2044/5349 [==========>...................] - ETA: 1s - loss: 0.1694 - accuracy: 0.9075\n",
      "2243/5349 [===========>..................] - ETA: 1s - loss: 0.1693 - accuracy: 0.9075\n",
      "2319/5349 [============>.................] - ETA: 1s - loss: 0.1693 - accuracy: 0.9075\n",
      "2432/5349 [============>.................] - ETA: 1s - loss: 0.1697 - accuracy: 0.9071\n",
      "2515/5349 [=============>................] - ETA: 1s - loss: 0.1698 - accuracy: 0.9070\n",
      "2633/5349 [=============>................] - ETA: 1s - loss: 0.1697 - accuracy: 0.9070\n",
      "2730/5349 [==============>...............] - ETA: 1s - loss: 0.1695 - accuracy: 0.9072\n",
      "2834/5349 [==============>...............] - ETA: 1s - loss: 0.1693 - accuracy: 0.9074\n",
      "2936/5349 [===============>..............] - ETA: 1s - loss: 0.1695 - accuracy: 0.9074\n",
      "3016/5349 [===============>..............] - ETA: 1s - loss: 0.1693 - accuracy: 0.9075\n",
      "3111/5349 [================>.............] - ETA: 1s - loss: 0.1692 - accuracy: 0.9076\n",
      "3202/5349 [================>.............] - ETA: 1s - loss: 0.1691 - accuracy: 0.9077\n",
      "3270/5349 [=================>............] - ETA: 1s - loss: 0.1690 - accuracy: 0.9077\n",
      "3310/5349 [=================>............] - ETA: 1s - loss: 0.1689 - accuracy: 0.9079\n",
      "3379/5349 [=================>............] - ETA: 1s - loss: 0.1690 - accuracy: 0.9078\n",
      "3423/5349 [==================>...........] - ETA: 1s - loss: 0.1690 - accuracy: 0.9078\n",
      "3474/5349 [==================>...........] - ETA: 1s - loss: 0.1690 - accuracy: 0.9077\n",
      "3541/5349 [==================>...........] - ETA: 1s - loss: 0.1690 - accuracy: 0.9077\n",
      "3566/5349 [===================>..........] - ETA: 1s - loss: 0.1690 - accuracy: 0.9077\n",
      "3645/5349 [===================>..........] - ETA: 1s - loss: 0.1689 - accuracy: 0.9078\n",
      "3712/5349 [===================>..........] - ETA: 1s - loss: 0.1689 - accuracy: 0.9078\n",
      "3795/5349 [====================>.........] - ETA: 1s - loss: 0.1688 - accuracy: 0.9078\n",
      "3881/5349 [====================>.........] - ETA: 1s - loss: 0.1688 - accuracy: 0.9079\n",
      "3921/5349 [====================>.........] - ETA: 1s - loss: 0.1687 - accuracy: 0.9079\n",
      "3999/5349 [=====================>........] - ETA: 1s - loss: 0.1687 - accuracy: 0.9079\n",
      "4060/5349 [=====================>........] - ETA: 1s - loss: 0.1687 - accuracy: 0.9079\n",
      "4126/5349 [======================>.......] - ETA: 1s - loss: 0.1687 - accuracy: 0.9080\n",
      "4185/5349 [======================>.......] - ETA: 1s - loss: 0.1687 - accuracy: 0.9080\n",
      "4384/5349 [=======================>......] - ETA: 0s - loss: 0.1687 - accuracy: 0.9080\n",
      "4622/5349 [========================>.....] - ETA: 0s - loss: 0.1689 - accuracy: 0.9077\n",
      "4806/5349 [=========================>....] - ETA: 0s - loss: 0.1688 - accuracy: 0.9077\n",
      "5001/5349 [===========================>..] - ETA: 0s - loss: 0.1687 - accuracy: 0.9078\n",
      "5224/5349 [============================>.] - ETA: 0s - loss: 0.1687 - accuracy: 0.9078\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.1686 - accuracy: 0.9078\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1687 - accuracy: 0.9077 - val_loss: 0.1660 - val_accuracy: 0.9115\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1473 - accuracy: 0.9200\n",
      " 346/5349 [>.............................] - ETA: 2s - loss: 0.1672 - accuracy: 0.9082\n",
      " 583/5349 [==>...........................] - ETA: 2s - loss: 0.1665 - accuracy: 0.9088\n",
      " 790/5349 [===>..........................] - ETA: 2s - loss: 0.1666 - accuracy: 0.9089\n",
      " 968/5349 [====>.........................] - ETA: 2s - loss: 0.1677 - accuracy: 0.9081\n",
      "1144/5349 [=====>........................] - ETA: 2s - loss: 0.1682 - accuracy: 0.9075\n",
      "1319/5349 [======>.......................] - ETA: 2s - loss: 0.1686 - accuracy: 0.9072\n",
      "1341/5349 [======>.......................] - ETA: 2s - loss: 0.1687 - accuracy: 0.9070\n",
      "1428/5349 [=======>......................] - ETA: 2s - loss: 0.1684 - accuracy: 0.9073\n",
      "1527/5349 [=======>......................] - ETA: 2s - loss: 0.1682 - accuracy: 0.9075\n",
      "1612/5349 [========>.....................] - ETA: 2s - loss: 0.1682 - accuracy: 0.9075\n",
      "1716/5349 [========>.....................] - ETA: 2s - loss: 0.1680 - accuracy: 0.9076\n",
      "1853/5349 [=========>....................] - ETA: 2s - loss: 0.1681 - accuracy: 0.9075\n",
      "2063/5349 [==========>...................] - ETA: 2s - loss: 0.1683 - accuracy: 0.9071\n",
      "2255/5349 [===========>..................] - ETA: 1s - loss: 0.1683 - accuracy: 0.9072\n",
      "2519/5349 [=============>................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9070\n",
      "2703/5349 [==============>...............] - ETA: 1s - loss: 0.1682 - accuracy: 0.9072\n",
      "2894/5349 [===============>..............] - ETA: 1s - loss: 0.1684 - accuracy: 0.9072\n",
      "3083/5349 [================>.............] - ETA: 1s - loss: 0.1682 - accuracy: 0.9074\n",
      "3291/5349 [=================>............] - ETA: 1s - loss: 0.1682 - accuracy: 0.9074\n",
      "3526/5349 [==================>...........] - ETA: 1s - loss: 0.1683 - accuracy: 0.9074\n",
      "3750/5349 [====================>.........] - ETA: 0s - loss: 0.1683 - accuracy: 0.9074\n",
      "4109/5349 [======================>.......] - ETA: 0s - loss: 0.1684 - accuracy: 0.9073\n",
      "4352/5349 [=======================>......] - ETA: 0s - loss: 0.1682 - accuracy: 0.9075\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.1682 - accuracy: 0.9075\n",
      "4835/5349 [==========================>...] - ETA: 0s - loss: 0.1681 - accuracy: 0.9077\n",
      "5075/5349 [===========================>..] - ETA: 0s - loss: 0.1680 - accuracy: 0.9078\n",
      "5306/5349 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9078\n",
      "5349/5349 [==============================] - 4s 695us/step - loss: 0.1679 - accuracy: 0.9078 - val_loss: 0.1661 - val_accuracy: 0.9103\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 17/20\n",
      " 252/5349 [>.............................] - ETA: 2s - loss: 0.1668 - accuracy: 0.9097\n",
      " 496/5349 [=>............................] - ETA: 1s - loss: 0.1672 - accuracy: 0.9088\n",
      " 745/5349 [===>..........................] - ETA: 1s - loss: 0.1693 - accuracy: 0.9066\n",
      " 990/5349 [====>.........................] - ETA: 1s - loss: 0.1689 - accuracy: 0.9071\n",
      "1228/5349 [=====>........................] - ETA: 1s - loss: 0.1689 - accuracy: 0.9067\n",
      "1479/5349 [=======>......................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9076\n",
      "1733/5349 [========>.....................] - ETA: 1s - loss: 0.1684 - accuracy: 0.9072\n",
      "2107/5349 [==========>...................] - ETA: 1s - loss: 0.1684 - accuracy: 0.9072\n",
      "2357/5349 [============>.................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9071\n",
      "2603/5349 [=============>................] - ETA: 1s - loss: 0.1685 - accuracy: 0.9072\n",
      "2854/5349 [===============>..............] - ETA: 1s - loss: 0.1684 - accuracy: 0.9074\n",
      "3102/5349 [================>.............] - ETA: 0s - loss: 0.1682 - accuracy: 0.9075\n",
      "3358/5349 [=================>............] - ETA: 0s - loss: 0.1682 - accuracy: 0.9076\n",
      "3614/5349 [===================>..........] - ETA: 0s - loss: 0.1685 - accuracy: 0.9073\n",
      "3970/5349 [=====================>........] - ETA: 0s - loss: 0.1682 - accuracy: 0.9076\n",
      "4217/5349 [======================>.......] - ETA: 0s - loss: 0.1682 - accuracy: 0.9076\n",
      "4471/5349 [========================>.....] - ETA: 0s - loss: 0.1681 - accuracy: 0.9078\n",
      "4718/5349 [=========================>....] - ETA: 0s - loss: 0.1681 - accuracy: 0.9077\n",
      "4972/5349 [==========================>...] - ETA: 0s - loss: 0.1680 - accuracy: 0.9078\n",
      "5221/5349 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9078\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9079\n",
      "5349/5349 [==============================] - 3s 561us/step - loss: 0.1678 - accuracy: 0.9079 - val_loss: 0.1637 - val_accuracy: 0.9134\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 18/20\n",
      " 103/5349 [..............................] - ETA: 2s - loss: 0.1674 - accuracy: 0.9050\n",
      " 475/5349 [=>............................] - ETA: 2s - loss: 0.1662 - accuracy: 0.9087\n",
      " 726/5349 [===>..........................] - ETA: 1s - loss: 0.1668 - accuracy: 0.9086\n",
      " 982/5349 [====>.........................] - ETA: 1s - loss: 0.1671 - accuracy: 0.9087\n",
      "1229/5349 [=====>........................] - ETA: 1s - loss: 0.1668 - accuracy: 0.9088\n",
      "1469/5349 [=======>......................] - ETA: 1s - loss: 0.1668 - accuracy: 0.9091\n",
      "1719/5349 [========>.....................] - ETA: 1s - loss: 0.1669 - accuracy: 0.9090\n",
      "1956/5349 [=========>....................] - ETA: 1s - loss: 0.1669 - accuracy: 0.9088\n",
      "2330/5349 [============>.................] - ETA: 1s - loss: 0.1671 - accuracy: 0.9087\n",
      "2579/5349 [=============>................] - ETA: 1s - loss: 0.1673 - accuracy: 0.9084\n",
      "2828/5349 [==============>...............] - ETA: 1s - loss: 0.1670 - accuracy: 0.9087\n",
      "3077/5349 [================>.............] - ETA: 0s - loss: 0.1669 - accuracy: 0.9089\n",
      "3322/5349 [=================>............] - ETA: 0s - loss: 0.1669 - accuracy: 0.9088\n",
      "3573/5349 [===================>..........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9085\n",
      "3792/5349 [====================>.........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9087\n",
      "4044/5349 [=====================>........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9087\n",
      "4168/5349 [======================>.......] - ETA: 0s - loss: 0.1672 - accuracy: 0.9086\n",
      "4414/5349 [=======================>......] - ETA: 0s - loss: 0.1670 - accuracy: 0.9088\n",
      "4662/5349 [=========================>....] - ETA: 0s - loss: 0.1672 - accuracy: 0.9086\n",
      "4911/5349 [==========================>...] - ETA: 0s - loss: 0.1673 - accuracy: 0.9086\n",
      "5160/5349 [===========================>..] - ETA: 0s - loss: 0.1672 - accuracy: 0.9087\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9087\n",
      "5349/5349 [==============================] - 3s 570us/step - loss: 0.1672 - accuracy: 0.9087 - val_loss: 0.1664 - val_accuracy: 0.9056\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 19/20\n",
      " 117/5349 [..............................] - ETA: 2s - loss: 0.1693 - accuracy: 0.9056\n",
      " 177/5349 [..............................] - ETA: 7s - loss: 0.1680 - accuracy: 0.9067\n",
      " 178/5349 [..............................] - ETA: 12s - loss: 0.1676 - accuracy: 0.9070\n",
      " 179/5349 [>.............................] - ETA: 14s - loss: 0.1676 - accuracy: 0.9071\n",
      " 201/5349 [>.............................] - ETA: 15s - loss: 0.1682 - accuracy: 0.9068\n",
      " 222/5349 [>.............................] - ETA: 16s - loss: 0.1684 - accuracy: 0.9080\n",
      " 232/5349 [>.............................] - ETA: 18s - loss: 0.1685 - accuracy: 0.9078\n",
      " 259/5349 [>.............................] - ETA: 18s - loss: 0.1687 - accuracy: 0.9080\n",
      " 291/5349 [>.............................] - ETA: 18s - loss: 0.1697 - accuracy: 0.9075\n",
      " 356/5349 [>.............................] - ETA: 16s - loss: 0.1681 - accuracy: 0.9085\n",
      " 375/5349 [=>............................] - ETA: 17s - loss: 0.1675 - accuracy: 0.9090\n",
      " 393/5349 [=>............................] - ETA: 18s - loss: 0.1672 - accuracy: 0.9092\n",
      " 406/5349 [=>............................] - ETA: 19s - loss: 0.1672 - accuracy: 0.9091\n",
      " 410/5349 [=>............................] - ETA: 20s - loss: 0.1672 - accuracy: 0.9091\n",
      " 416/5349 [=>............................] - ETA: 20s - loss: 0.1670 - accuracy: 0.9094\n",
      " 453/5349 [=>............................] - ETA: 19s - loss: 0.1668 - accuracy: 0.9095\n",
      " 471/5349 [=>............................] - ETA: 20s - loss: 0.1667 - accuracy: 0.9094\n",
      " 515/5349 [=>............................] - ETA: 19s - loss: 0.1678 - accuracy: 0.9085\n",
      " 563/5349 [==>...........................] - ETA: 18s - loss: 0.1683 - accuracy: 0.9078\n",
      " 598/5349 [==>...........................] - ETA: 17s - loss: 0.1679 - accuracy: 0.9083\n",
      " 632/5349 [==>...........................] - ETA: 17s - loss: 0.1674 - accuracy: 0.9088\n",
      " 684/5349 [==>...........................] - ETA: 17s - loss: 0.1671 - accuracy: 0.9094\n",
      " 731/5349 [===>..........................] - ETA: 16s - loss: 0.1674 - accuracy: 0.9092\n",
      " 771/5349 [===>..........................] - ETA: 16s - loss: 0.1681 - accuracy: 0.9085\n",
      " 814/5349 [===>..........................] - ETA: 15s - loss: 0.1686 - accuracy: 0.9080\n",
      " 824/5349 [===>..........................] - ETA: 16s - loss: 0.1686 - accuracy: 0.9081\n",
      " 840/5349 [===>..........................] - ETA: 16s - loss: 0.1687 - accuracy: 0.9081\n",
      " 857/5349 [===>..........................] - ETA: 15s - loss: 0.1684 - accuracy: 0.9083\n",
      " 871/5349 [===>..........................] - ETA: 16s - loss: 0.1683 - accuracy: 0.9084\n",
      " 898/5349 [====>.........................] - ETA: 16s - loss: 0.1683 - accuracy: 0.9082\n",
      " 917/5349 [====>.........................] - ETA: 16s - loss: 0.1683 - accuracy: 0.9083\n",
      " 934/5349 [====>.........................] - ETA: 16s - loss: 0.1681 - accuracy: 0.9085\n",
      " 961/5349 [====>.........................] - ETA: 16s - loss: 0.1681 - accuracy: 0.9084\n",
      " 968/5349 [====>.........................] - ETA: 16s - loss: 0.1680 - accuracy: 0.9084\n",
      " 990/5349 [====>.........................] - ETA: 16s - loss: 0.1679 - accuracy: 0.9086\n",
      "1023/5349 [====>.........................] - ETA: 16s - loss: 0.1683 - accuracy: 0.9081\n",
      "1034/5349 [====>.........................] - ETA: 16s - loss: 0.1682 - accuracy: 0.9081\n",
      "1044/5349 [====>.........................] - ETA: 17s - loss: 0.1682 - accuracy: 0.9082\n",
      "1072/5349 [=====>........................] - ETA: 17s - loss: 0.1683 - accuracy: 0.9082\n",
      "1087/5349 [=====>........................] - ETA: 17s - loss: 0.1684 - accuracy: 0.9081\n",
      "1096/5349 [=====>........................] - ETA: 17s - loss: 0.1683 - accuracy: 0.9082\n",
      "1111/5349 [=====>........................] - ETA: 17s - loss: 0.1682 - accuracy: 0.9082\n",
      "1129/5349 [=====>........................] - ETA: 17s - loss: 0.1680 - accuracy: 0.9084\n",
      "1135/5349 [=====>........................] - ETA: 17s - loss: 0.1680 - accuracy: 0.9084\n",
      "1159/5349 [=====>........................] - ETA: 17s - loss: 0.1681 - accuracy: 0.9083\n",
      "1186/5349 [=====>........................] - ETA: 17s - loss: 0.1680 - accuracy: 0.9084\n",
      "1207/5349 [=====>........................] - ETA: 17s - loss: 0.1679 - accuracy: 0.9085\n",
      "1230/5349 [=====>........................] - ETA: 17s - loss: 0.1679 - accuracy: 0.9084\n",
      "1254/5349 [======>.......................] - ETA: 17s - loss: 0.1678 - accuracy: 0.9085\n",
      "1279/5349 [======>.......................] - ETA: 17s - loss: 0.1678 - accuracy: 0.9084\n",
      "1304/5349 [======>.......................] - ETA: 17s - loss: 0.1678 - accuracy: 0.9084\n",
      "1317/5349 [======>.......................] - ETA: 17s - loss: 0.1677 - accuracy: 0.9084\n",
      "1322/5349 [======>.......................] - ETA: 17s - loss: 0.1678 - accuracy: 0.9083\n",
      "1335/5349 [======>.......................] - ETA: 17s - loss: 0.1678 - accuracy: 0.9083\n",
      "1407/5349 [======>.......................] - ETA: 16s - loss: 0.1677 - accuracy: 0.9084\n",
      "1559/5349 [=======>......................] - ETA: 14s - loss: 0.1678 - accuracy: 0.9083\n",
      "1663/5349 [========>.....................] - ETA: 13s - loss: 0.1674 - accuracy: 0.9085\n",
      "1723/5349 [========>.....................] - ETA: 13s - loss: 0.1673 - accuracy: 0.9085\n",
      "1771/5349 [========>.....................] - ETA: 12s - loss: 0.1673 - accuracy: 0.9084\n",
      "1849/5349 [=========>....................] - ETA: 12s - loss: 0.1672 - accuracy: 0.9084\n",
      "1945/5349 [=========>....................] - ETA: 11s - loss: 0.1672 - accuracy: 0.9084\n",
      "1995/5349 [==========>...................] - ETA: 11s - loss: 0.1671 - accuracy: 0.9084\n",
      "2136/5349 [==========>...................] - ETA: 10s - loss: 0.1666 - accuracy: 0.9088\n",
      "2226/5349 [===========>..................] - ETA: 9s - loss: 0.1668 - accuracy: 0.9086 \n",
      "2272/5349 [===========>..................] - ETA: 9s - loss: 0.1669 - accuracy: 0.9084\n",
      "2398/5349 [============>.................] - ETA: 8s - loss: 0.1670 - accuracy: 0.9083\n",
      "2577/5349 [=============>................] - ETA: 7s - loss: 0.1668 - accuracy: 0.9086\n",
      "2757/5349 [==============>...............] - ETA: 6s - loss: 0.1668 - accuracy: 0.9087\n",
      "2924/5349 [===============>..............] - ETA: 6s - loss: 0.1670 - accuracy: 0.9086\n",
      "2991/5349 [===============>..............] - ETA: 5s - loss: 0.1670 - accuracy: 0.9086\n",
      "3144/5349 [================>.............] - ETA: 5s - loss: 0.1669 - accuracy: 0.9086\n",
      "3259/5349 [=================>............] - ETA: 4s - loss: 0.1669 - accuracy: 0.9085\n",
      "3361/5349 [=================>............] - ETA: 4s - loss: 0.1670 - accuracy: 0.9085\n",
      "3442/5349 [==================>...........] - ETA: 4s - loss: 0.1670 - accuracy: 0.9085\n",
      "3589/5349 [===================>..........] - ETA: 3s - loss: 0.1670 - accuracy: 0.9085\n",
      "3703/5349 [===================>..........] - ETA: 3s - loss: 0.1670 - accuracy: 0.9085\n",
      "3750/5349 [====================>.........] - ETA: 3s - loss: 0.1668 - accuracy: 0.9086\n",
      "3879/5349 [====================>.........] - ETA: 3s - loss: 0.1666 - accuracy: 0.9088\n",
      "3990/5349 [=====================>........] - ETA: 2s - loss: 0.1666 - accuracy: 0.9087\n",
      "4088/5349 [=====================>........] - ETA: 2s - loss: 0.1667 - accuracy: 0.9086\n",
      "4250/5349 [======================>.......] - ETA: 2s - loss: 0.1667 - accuracy: 0.9086\n",
      "4426/5349 [=======================>......] - ETA: 1s - loss: 0.1668 - accuracy: 0.9084\n",
      "4520/5349 [========================>.....] - ETA: 1s - loss: 0.1668 - accuracy: 0.9083\n",
      "4709/5349 [=========================>....] - ETA: 1s - loss: 0.1669 - accuracy: 0.9083\n",
      "4901/5349 [==========================>...] - ETA: 0s - loss: 0.1667 - accuracy: 0.9085\n",
      "5076/5349 [===========================>..] - ETA: 0s - loss: 0.1668 - accuracy: 0.9084\n",
      "5243/5349 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9085\n",
      "5328/5349 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9085\n",
      "5349/5349 [==============================] - 11s 2ms/step - loss: 0.1666 - accuracy: 0.9085 - val_loss: 0.1807 - val_accuracy: 0.8746\n",
      "\u001B[36m(train_DNN pid=6078)\u001B[0m Epoch 20/20\n",
      "  75/5349 [..............................] - ETA: 3s - loss: 0.1624 - accuracy: 0.9123\n",
      " 248/5349 [>.............................] - ETA: 4s - loss: 0.1653 - accuracy: 0.9092\n",
      " 397/5349 [=>............................] - ETA: 3s - loss: 0.1656 - accuracy: 0.9088\n",
      " 520/5349 [=>............................] - ETA: 3s - loss: 0.1660 - accuracy: 0.9084\n",
      " 682/5349 [==>...........................] - ETA: 3s - loss: 0.1661 - accuracy: 0.9083\n",
      " 875/5349 [===>..........................] - ETA: 3s - loss: 0.1657 - accuracy: 0.9088\n",
      "1055/5349 [====>.........................] - ETA: 2s - loss: 0.1654 - accuracy: 0.9090\n",
      "1216/5349 [=====>........................] - ETA: 2s - loss: 0.1655 - accuracy: 0.9089\n",
      "1303/5349 [======>.......................] - ETA: 2s - loss: 0.1655 - accuracy: 0.9088\n",
      "1495/5349 [=======>......................] - ETA: 2s - loss: 0.1660 - accuracy: 0.9085\n",
      "1682/5349 [========>.....................] - ETA: 2s - loss: 0.1662 - accuracy: 0.9082\n",
      "1877/5349 [=========>....................] - ETA: 2s - loss: 0.1659 - accuracy: 0.9085\n",
      "2071/5349 [==========>...................] - ETA: 1s - loss: 0.1659 - accuracy: 0.9085\n",
      "2240/5349 [===========>..................] - ETA: 1s - loss: 0.1662 - accuracy: 0.9083\n",
      "2415/5349 [============>.................] - ETA: 1s - loss: 0.1661 - accuracy: 0.9084\n",
      "2598/5349 [=============>................] - ETA: 1s - loss: 0.1662 - accuracy: 0.9084\n",
      "2788/5349 [==============>...............] - ETA: 1s - loss: 0.1663 - accuracy: 0.9085\n",
      "2874/5349 [===============>..............] - ETA: 1s - loss: 0.1662 - accuracy: 0.9086\n",
      "3040/5349 [================>.............] - ETA: 1s - loss: 0.1663 - accuracy: 0.9085\n",
      "3222/5349 [=================>............] - ETA: 1s - loss: 0.1660 - accuracy: 0.9088\n",
      "3363/5349 [=================>............] - ETA: 1s - loss: 0.1661 - accuracy: 0.9086\n",
      "3523/5349 [==================>...........] - ETA: 1s - loss: 0.1661 - accuracy: 0.9086\n",
      "3697/5349 [===================>..........] - ETA: 0s - loss: 0.1661 - accuracy: 0.9085\n",
      "3975/5349 [=====================>........] - ETA: 0s - loss: 0.1661 - accuracy: 0.9084\n",
      "4158/5349 [======================>.......] - ETA: 0s - loss: 0.1661 - accuracy: 0.9085\n",
      "4323/5349 [=======================>......] - ETA: 0s - loss: 0.1661 - accuracy: 0.9085\n",
      "4495/5349 [========================>.....] - ETA: 0s - loss: 0.1660 - accuracy: 0.9085\n",
      "4658/5349 [=========================>....] - ETA: 0s - loss: 0.1660 - accuracy: 0.9085\n",
      "4845/5349 [==========================>...] - ETA: 0s - loss: 0.1661 - accuracy: 0.9084\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.1661 - accuracy: 0.9085\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.1661 - accuracy: 0.9085\n",
      "\u001B[36m(train_DNN pid=6156)\u001B[0m Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-27 11:56:52,372\tERROR tune_controller.py:1331 -- Trial task failed for trial train_DNN_906fd_00021\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(InvalidArgumentError): \u001B[36mray::ImplicitFunc.train()\u001B[39m (pid=6156, ip=127.0.0.1, actor_id=68de7f97320a2127df67cbf701000000, repr=train_DNN)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/finnbeckmann/uni/DLLabs/lab2/utilities.py\", line 154, in train_DNN\n",
      "    model.fit(X_train, y_train,\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
      "    except TypeError as e:\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node gradient_tape/binary_crossentropy/Reshape defined at (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/threading.py\", line 1032, in _bootstrap\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "\n",
      "  File \"/Users/finnbeckmann/uni/DLLabs/lab2/utilities.py\", line 154, in train_DNN\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1381, in step_function\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1370, in run_step\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1151, in train_step\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/optimizers/legacy/optimizer_v2.py\", line 591, in minimize\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/optimizers/legacy/optimizer_v2.py\", line 649, in _compute_gradients\n",
      "\n",
      "  File \"/opt/miniconda3/envs/DLLabs/lib/python3.12/site-packages/tf_keras/src/optimizers/legacy/optimizer_v2.py\", line 525, in _get_gradients\n",
      "\n",
      "desired shape must be a DT_INT32 or DT_INT64 vector, not a float\n",
      "\t [[{{node gradient_tape/binary_crossentropy/Reshape}}]] [Op:__inference_train_function_1823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/5349 [..............................] - ETA: 32:47 - loss: 0.6812 - accuracy: 0.7400\n",
      "  57/5349 [..............................] - ETA: 4s - loss: 0.5294 - accuracy: 0.8477   \n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 30:34 - loss: 0.5855 - accuracy: 0.7900\n",
      " 196/5349 [>.............................] - ETA: 2s - loss: 0.5206 - accuracy: 0.8430\n",
      " 420/5349 [=>............................] - ETA: 2s - loss: 0.4946 - accuracy: 0.8431\n",
      " 640/5349 [==>...........................] - ETA: 2s - loss: 0.4795 - accuracy: 0.8432\n",
      " 866/5349 [===>..........................] - ETA: 2s - loss: 0.4714 - accuracy: 0.8420\n",
      "1206/5349 [=====>........................] - ETA: 1s - loss: 0.4634 - accuracy: 0.8413\n",
      "1436/5349 [=======>......................] - ETA: 1s - loss: 0.4605 - accuracy: 0.8406\n",
      "1601/5349 [=======>......................] - ETA: 1s - loss: 0.4587 - accuracy: 0.8403\n",
      "1812/5349 [=========>....................] - ETA: 1s - loss: 0.4569 - accuracy: 0.8400\n",
      "2036/5349 [==========>...................] - ETA: 1s - loss: 0.4550 - accuracy: 0.8400\n",
      "2253/5349 [===========>..................] - ETA: 1s - loss: 0.4523 - accuracy: 0.8407\n",
      "2442/5349 [============>.................] - ETA: 1s - loss: 0.4521 - accuracy: 0.8402\n",
      "2642/5349 [=============>................] - ETA: 1s - loss: 0.4507 - accuracy: 0.8404\n",
      "2932/5349 [===============>..............] - ETA: 1s - loss: 0.4493 - accuracy: 0.8405\n",
      "3127/5349 [================>.............] - ETA: 1s - loss: 0.4488 - accuracy: 0.8404\n",
      "3315/5349 [=================>............] - ETA: 0s - loss: 0.4481 - accuracy: 0.8405\n",
      "3515/5349 [==================>...........] - ETA: 0s - loss: 0.4472 - accuracy: 0.8407\n",
      "3717/5349 [===================>..........] - ETA: 0s - loss: 0.4467 - accuracy: 0.8407\n",
      "3926/5349 [=====================>........] - ETA: 0s - loss: 0.4462 - accuracy: 0.8407\n",
      "4091/5349 [=====================>........] - ETA: 0s - loss: 0.4461 - accuracy: 0.8405\n",
      "4372/5349 [=======================>......] - ETA: 0s - loss: 0.4459 - accuracy: 0.8403\n",
      "4572/5349 [========================>.....] - ETA: 0s - loss: 0.4456 - accuracy: 0.8404\n",
      "4787/5349 [=========================>....] - ETA: 0s - loss: 0.4449 - accuracy: 0.8406\n",
      "4994/5349 [===========================>..] - ETA: 0s - loss: 0.4447 - accuracy: 0.8405\n",
      "5207/5349 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.8405\n",
      "5303/5349 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 5s 861us/step - loss: 0.4441 - accuracy: 0.8406 - val_loss: 0.4381 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 2/20\n",
      " 148/5349 [..............................] - ETA: 3s - loss: 0.4373 - accuracy: 0.8410\n",
      " 307/5349 [>.............................] - ETA: 3s - loss: 0.4360 - accuracy: 0.8418\n",
      " 521/5349 [=>............................] - ETA: 2s - loss: 0.4343 - accuracy: 0.8428\n",
      " 712/5349 [==>...........................] - ETA: 2s - loss: 0.4322 - accuracy: 0.8440\n",
      " 928/5349 [====>.........................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8432\n",
      "1142/5349 [=====>........................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8424\n",
      "1362/5349 [======>.......................] - ETA: 2s - loss: 0.4366 - accuracy: 0.8414\n",
      "1574/5349 [=======>......................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8411\n",
      "1794/5349 [=========>....................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8409\n",
      "2002/5349 [==========>...................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8409\n",
      "2331/5349 [============>.................] - ETA: 1s - loss: 0.4385 - accuracy: 0.8403\n",
      "2549/5349 [=============>................] - ETA: 1s - loss: 0.4388 - accuracy: 0.8400\n",
      "2769/5349 [==============>...............] - ETA: 1s - loss: 0.4382 - accuracy: 0.8404\n",
      "2984/5349 [===============>..............] - ETA: 1s - loss: 0.4384 - accuracy: 0.8403\n",
      "3208/5349 [================>.............] - ETA: 1s - loss: 0.4382 - accuracy: 0.8404\n",
      "3407/5349 [==================>...........] - ETA: 0s - loss: 0.4380 - accuracy: 0.8405\n",
      "3604/5349 [===================>..........] - ETA: 0s - loss: 0.4379 - accuracy: 0.8406\n",
      "3777/5349 [====================>.........] - ETA: 0s - loss: 0.4376 - accuracy: 0.8407\n",
      "3994/5349 [=====================>........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8408\n",
      "4210/5349 [======================>.......] - ETA: 0s - loss: 0.4375 - accuracy: 0.8408\n",
      "4539/5349 [========================>.....] - ETA: 0s - loss: 0.4379 - accuracy: 0.8406\n",
      "4748/5349 [=========================>....] - ETA: 0s - loss: 0.4378 - accuracy: 0.8406\n",
      "4970/5349 [==========================>...] - ETA: 0s - loss: 0.4378 - accuracy: 0.8406\n",
      "5185/5349 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8408\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 667us/step - loss: 0.4378 - accuracy: 0.8406 - val_loss: 0.4378 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.4221 - accuracy: 0.8500\n",
      " 182/5349 [>.............................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8428\n",
      " 383/5349 [=>............................] - ETA: 2s - loss: 0.4403 - accuracy: 0.8390\n",
      " 612/5349 [==>...........................] - ETA: 2s - loss: 0.4379 - accuracy: 0.8405\n",
      " 846/5349 [===>..........................] - ETA: 2s - loss: 0.4361 - accuracy: 0.8415\n",
      "1058/5349 [====>.........................] - ETA: 2s - loss: 0.4361 - accuracy: 0.8415\n",
      "1257/5349 [======>.......................] - ETA: 1s - loss: 0.4366 - accuracy: 0.8412\n",
      "1471/5349 [=======>......................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8412\n",
      "1822/5349 [=========>....................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8407\n",
      "1996/5349 [==========>...................] - ETA: 1s - loss: 0.4367 - accuracy: 0.8412\n",
      "2208/5349 [===========>..................] - ETA: 1s - loss: 0.4371 - accuracy: 0.8409\n",
      "2437/5349 [============>.................] - ETA: 1s - loss: 0.4373 - accuracy: 0.8408\n",
      "2670/5349 [=============>................] - ETA: 1s - loss: 0.4365 - accuracy: 0.8413\n",
      "2891/5349 [===============>..............] - ETA: 1s - loss: 0.4367 - accuracy: 0.8411\n",
      "3103/5349 [================>.............] - ETA: 1s - loss: 0.4367 - accuracy: 0.8412\n",
      "3319/5349 [=================>............] - ETA: 0s - loss: 0.4365 - accuracy: 0.8413\n",
      "3413/5349 [==================>...........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8413\n",
      "3637/5349 [===================>..........] - ETA: 0s - loss: 0.4366 - accuracy: 0.8412\n",
      "3865/5349 [====================>.........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8411\n",
      "4077/5349 [=====================>........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8411\n",
      "4302/5349 [=======================>......] - ETA: 0s - loss: 0.4367 - accuracy: 0.8411\n",
      "4526/5349 [========================>.....] - ETA: 0s - loss: 0.4372 - accuracy: 0.8408\n",
      "4746/5349 [=========================>....] - ETA: 0s - loss: 0.4373 - accuracy: 0.8408\n",
      "4904/5349 [==========================>...] - ETA: 0s - loss: 0.4370 - accuracy: 0.8409\n",
      "5009/5349 [===========================>..] - ETA: 0s - loss: 0.4369 - accuracy: 0.8410\n",
      "5224/5349 [============================>.] - ETA: 0s - loss: 0.4371 - accuracy: 0.8408\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.4375 - accuracy: 0.8406 - val_loss: 0.4375 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 4/20\n",
      "  97/5349 [..............................] - ETA: 2s - loss: 0.4333 - accuracy: 0.8431\n",
      " 313/5349 [>.............................] - ETA: 2s - loss: 0.4349 - accuracy: 0.8421\n",
      " 514/5349 [=>............................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8412\n",
      " 694/5349 [==>...........................] - ETA: 2s - loss: 0.4375 - accuracy: 0.8405\n",
      " 937/5349 [====>.........................] - ETA: 2s - loss: 0.4370 - accuracy: 0.8408\n",
      "1055/5349 [====>.........................] - ETA: 2s - loss: 0.4378 - accuracy: 0.8403\n",
      "1283/5349 [======>.......................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8406\n",
      "1524/5349 [=======>......................] - ETA: 1s - loss: 0.4383 - accuracy: 0.8400\n",
      "1761/5349 [========>.....................] - ETA: 1s - loss: 0.4381 - accuracy: 0.8401\n",
      "2000/5349 [==========>...................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8405\n",
      "2221/5349 [===========>..................] - ETA: 1s - loss: 0.4369 - accuracy: 0.8409\n",
      "2466/5349 [============>.................] - ETA: 1s - loss: 0.4377 - accuracy: 0.8404\n",
      "2699/5349 [==============>...............] - ETA: 1s - loss: 0.4375 - accuracy: 0.8405\n",
      "2938/5349 [===============>..............] - ETA: 1s - loss: 0.4374 - accuracy: 0.8406\n",
      "3173/5349 [================>.............] - ETA: 0s - loss: 0.4374 - accuracy: 0.8405\n",
      "3524/5349 [==================>...........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8406\n",
      "3735/5349 [===================>..........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "3971/5349 [=====================>........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "4162/5349 [======================>.......] - ETA: 0s - loss: 0.4372 - accuracy: 0.8407\n",
      "4385/5349 [=======================>......] - ETA: 0s - loss: 0.4374 - accuracy: 0.8405\n",
      "4597/5349 [========================>.....] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "4816/5349 [==========================>...] - ETA: 0s - loss: 0.4376 - accuracy: 0.8404\n",
      "4918/5349 [==========================>...] - ETA: 0s - loss: 0.4377 - accuracy: 0.8403\n",
      "5120/5349 [===========================>..] - ETA: 0s - loss: 0.4375 - accuracy: 0.8405\n",
      "5341/5349 [============================>.] - ETA: 0s - loss: 0.4372 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 628us/step - loss: 0.4372 - accuracy: 0.8406 - val_loss: 0.4372 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.5379 - accuracy: 0.7800\n",
      " 220/5349 [>.............................] - ETA: 2s - loss: 0.4352 - accuracy: 0.8418\n",
      " 442/5349 [=>............................] - ETA: 2s - loss: 0.4341 - accuracy: 0.8424\n",
      " 657/5349 [==>...........................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8427\n",
      " 880/5349 [===>..........................] - ETA: 2s - loss: 0.4366 - accuracy: 0.8409\n",
      "1094/5349 [=====>........................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8411\n",
      "1311/5349 [======>.......................] - ETA: 1s - loss: 0.4373 - accuracy: 0.8405\n",
      "1528/5349 [=======>......................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8404\n",
      "1750/5349 [========>.....................] - ETA: 1s - loss: 0.4374 - accuracy: 0.8404\n",
      "1965/5349 [==========>...................] - ETA: 1s - loss: 0.4375 - accuracy: 0.8403\n",
      "2073/5349 [==========>...................] - ETA: 1s - loss: 0.4370 - accuracy: 0.8406\n",
      "2294/5349 [===========>..................] - ETA: 1s - loss: 0.4362 - accuracy: 0.8411\n",
      "2484/5349 [============>.................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8414\n",
      "2711/5349 [==============>...............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8411\n",
      "2908/5349 [===============>..............] - ETA: 1s - loss: 0.4357 - accuracy: 0.8414\n",
      "3129/5349 [================>.............] - ETA: 1s - loss: 0.4364 - accuracy: 0.8410\n",
      "3347/5349 [=================>............] - ETA: 0s - loss: 0.4362 - accuracy: 0.8411\n",
      "3571/5349 [===================>..........] - ETA: 0s - loss: 0.4361 - accuracy: 0.8411\n",
      "3787/5349 [====================>.........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8410\n",
      "4077/5349 [=====================>........] - ETA: 0s - loss: 0.4367 - accuracy: 0.8408\n",
      "4261/5349 [======================>.......] - ETA: 0s - loss: 0.4373 - accuracy: 0.8404\n",
      "4470/5349 [========================>.....] - ETA: 0s - loss: 0.4374 - accuracy: 0.8403\n",
      "4672/5349 [=========================>....] - ETA: 0s - loss: 0.4373 - accuracy: 0.8404\n",
      "4893/5349 [==========================>...] - ETA: 0s - loss: 0.4371 - accuracy: 0.8405\n",
      "5102/5349 [===========================>..] - ETA: 0s - loss: 0.4370 - accuracy: 0.8406\n",
      "5324/5349 [============================>.] - ETA: 0s - loss: 0.4369 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 647us/step - loss: 0.4369 - accuracy: 0.8406 - val_loss: 0.4369 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.4875 - accuracy: 0.8100\n",
      " 222/5349 [>.............................] - ETA: 2s - loss: 0.4384 - accuracy: 0.8396\n",
      " 340/5349 [>.............................] - ETA: 2s - loss: 0.4406 - accuracy: 0.8383\n",
      " 420/5349 [=>............................] - ETA: 3s - loss: 0.4395 - accuracy: 0.8389\n",
      " 521/5349 [=>............................] - ETA: 3s - loss: 0.4387 - accuracy: 0.8394\n",
      " 575/5349 [==>...........................] - ETA: 3s - loss: 0.4381 - accuracy: 0.8398\n",
      " 716/5349 [===>..........................] - ETA: 3s - loss: 0.4376 - accuracy: 0.8401\n",
      " 879/5349 [===>..........................] - ETA: 3s - loss: 0.4352 - accuracy: 0.8416\n",
      "1019/5349 [====>.........................] - ETA: 3s - loss: 0.4347 - accuracy: 0.8419\n",
      "1125/5349 [=====>........................] - ETA: 3s - loss: 0.4354 - accuracy: 0.8414\n",
      "1243/5349 [=====>........................] - ETA: 3s - loss: 0.4358 - accuracy: 0.8412\n",
      "1427/5349 [=======>......................] - ETA: 2s - loss: 0.4358 - accuracy: 0.8412\n",
      "1556/5349 [=======>......................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8414\n",
      "1638/5349 [========>.....................] - ETA: 2s - loss: 0.4352 - accuracy: 0.8415\n",
      "1768/5349 [========>.....................] - ETA: 2s - loss: 0.4352 - accuracy: 0.8415\n",
      "1881/5349 [=========>....................] - ETA: 2s - loss: 0.4348 - accuracy: 0.8418\n",
      "2065/5349 [==========>...................] - ETA: 2s - loss: 0.4353 - accuracy: 0.8414\n",
      "2275/5349 [===========>..................] - ETA: 2s - loss: 0.4357 - accuracy: 0.8412\n",
      "2491/5349 [============>.................] - ETA: 1s - loss: 0.4354 - accuracy: 0.8414\n",
      "2682/5349 [==============>...............] - ETA: 1s - loss: 0.4356 - accuracy: 0.8413\n",
      "2892/5349 [===============>..............] - ETA: 1s - loss: 0.4355 - accuracy: 0.8413\n",
      "3103/5349 [================>.............] - ETA: 1s - loss: 0.4360 - accuracy: 0.8410\n",
      "3209/5349 [================>.............] - ETA: 1s - loss: 0.4364 - accuracy: 0.8408\n",
      "3409/5349 [==================>...........] - ETA: 1s - loss: 0.4361 - accuracy: 0.8409\n",
      "3591/5349 [===================>..........] - ETA: 1s - loss: 0.4361 - accuracy: 0.8409\n",
      "3811/5349 [====================>.........] - ETA: 0s - loss: 0.4363 - accuracy: 0.8408\n",
      "4007/5349 [=====================>........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8407\n",
      "4228/5349 [======================>.......] - ETA: 0s - loss: 0.4367 - accuracy: 0.8406\n",
      "4429/5349 [=======================>......] - ETA: 0s - loss: 0.4370 - accuracy: 0.8404\n",
      "4583/5349 [========================>.....] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "4656/5349 [=========================>....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "4672/5349 [=========================>....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8405\n",
      "4768/5349 [=========================>....] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "4822/5349 [==========================>...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "4855/5349 [==========================>...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "4887/5349 [==========================>...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "4922/5349 [==========================>...] - ETA: 0s - loss: 0.4369 - accuracy: 0.8404\n",
      "4951/5349 [==========================>...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "4964/5349 [==========================>...] - ETA: 0s - loss: 0.4368 - accuracy: 0.8405\n",
      "5029/5349 [===========================>..] - ETA: 0s - loss: 0.4370 - accuracy: 0.8404\n",
      "5070/5349 [===========================>..] - ETA: 0s - loss: 0.4371 - accuracy: 0.8403\n",
      "5117/5349 [===========================>..] - ETA: 0s - loss: 0.4370 - accuracy: 0.8403\n",
      "5179/5349 [============================>.] - ETA: 0s - loss: 0.4369 - accuracy: 0.8404\n",
      "5249/5349 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.8405\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.8406\n",
      "5347/5349 [============================>.] - ETA: 0s - loss: 0.4366 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.4366 - accuracy: 0.8406 - val_loss: 0.4366 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 7/20\n",
      " 100/5349 [..............................] - ETA: 2s - loss: 0.4291 - accuracy: 0.8450\n",
      " 335/5349 [>.............................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8414\n",
      " 568/5349 [==>...........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8406\n",
      " 760/5349 [===>..........................] - ETA: 2s - loss: 0.4352 - accuracy: 0.8413\n",
      " 977/5349 [====>.........................] - ETA: 2s - loss: 0.4335 - accuracy: 0.8423\n",
      "1186/5349 [=====>........................] - ETA: 1s - loss: 0.4341 - accuracy: 0.8420\n",
      "1293/5349 [======>.......................] - ETA: 1s - loss: 0.4349 - accuracy: 0.8415\n",
      "1511/5349 [=======>......................] - ETA: 1s - loss: 0.4344 - accuracy: 0.8418\n",
      "1723/5349 [========>.....................] - ETA: 1s - loss: 0.4344 - accuracy: 0.8418\n",
      "1940/5349 [=========>....................] - ETA: 1s - loss: 0.4350 - accuracy: 0.8414\n",
      "2154/5349 [===========>..................] - ETA: 1s - loss: 0.4354 - accuracy: 0.8412\n",
      "2339/5349 [============>.................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8409\n",
      "2534/5349 [=============>................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8407\n",
      "2743/5349 [==============>...............] - ETA: 1s - loss: 0.4365 - accuracy: 0.8405\n",
      "2927/5349 [===============>..............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8407\n",
      "3122/5349 [================>.............] - ETA: 1s - loss: 0.4362 - accuracy: 0.8407\n",
      "3402/5349 [==================>...........] - ETA: 0s - loss: 0.4364 - accuracy: 0.8405\n",
      "3625/5349 [===================>..........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8407\n",
      "3839/5349 [====================>.........] - ETA: 0s - loss: 0.4358 - accuracy: 0.8409\n",
      "4062/5349 [=====================>........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8409\n",
      "4276/5349 [======================>.......] - ETA: 0s - loss: 0.4356 - accuracy: 0.8410\n",
      "4501/5349 [========================>.....] - ETA: 0s - loss: 0.4357 - accuracy: 0.8409\n",
      "4716/5349 [=========================>....] - ETA: 0s - loss: 0.4360 - accuracy: 0.8408\n",
      "4938/5349 [==========================>...] - ETA: 0s - loss: 0.4361 - accuracy: 0.8407\n",
      "5152/5349 [===========================>..] - ETA: 0s - loss: 0.4363 - accuracy: 0.8406\n",
      "5261/5349 [============================>.] - ETA: 0s - loss: 0.4363 - accuracy: 0.8405\n",
      "5349/5349 [==============================] - 3s 650us/step - loss: 0.4362 - accuracy: 0.8406 - val_loss: 0.4362 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 8/20\n",
      " 108/5349 [..............................] - ETA: 2s - loss: 0.4315 - accuracy: 0.8433\n",
      " 330/5349 [>.............................] - ETA: 2s - loss: 0.4341 - accuracy: 0.8418\n",
      " 536/5349 [==>...........................] - ETA: 2s - loss: 0.4329 - accuracy: 0.8425\n",
      " 750/5349 [===>..........................] - ETA: 2s - loss: 0.4363 - accuracy: 0.8404\n",
      " 954/5349 [====>.........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8404\n",
      "1157/5349 [=====>........................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8412\n",
      "1464/5349 [=======>......................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8406\n",
      "1664/5349 [========>.....................] - ETA: 1s - loss: 0.4351 - accuracy: 0.8411\n",
      "1872/5349 [=========>....................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8409\n",
      "2027/5349 [==========>...................] - ETA: 1s - loss: 0.4347 - accuracy: 0.8414\n",
      "2175/5349 [===========>..................] - ETA: 1s - loss: 0.4348 - accuracy: 0.8413\n",
      "2363/5349 [============>.................] - ETA: 1s - loss: 0.4350 - accuracy: 0.8412\n",
      "2564/5349 [=============>................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8410\n",
      "2663/5349 [=============>................] - ETA: 1s - loss: 0.4351 - accuracy: 0.8411\n",
      "2857/5349 [===============>..............] - ETA: 1s - loss: 0.4354 - accuracy: 0.8410\n",
      "3066/5349 [================>.............] - ETA: 1s - loss: 0.4352 - accuracy: 0.8411\n",
      "3245/5349 [=================>............] - ETA: 1s - loss: 0.4353 - accuracy: 0.8410\n",
      "3450/5349 [==================>...........] - ETA: 0s - loss: 0.4355 - accuracy: 0.8409\n",
      "3654/5349 [===================>..........] - ETA: 0s - loss: 0.4359 - accuracy: 0.8406\n",
      "3852/5349 [====================>.........] - ETA: 0s - loss: 0.4356 - accuracy: 0.8408\n",
      "4050/5349 [=====================>........] - ETA: 0s - loss: 0.4357 - accuracy: 0.8407\n",
      "4265/5349 [======================>.......] - ETA: 0s - loss: 0.4357 - accuracy: 0.8407\n",
      "4556/5349 [========================>.....] - ETA: 0s - loss: 0.4359 - accuracy: 0.8406\n",
      "4774/5349 [=========================>....] - ETA: 0s - loss: 0.4359 - accuracy: 0.8406\n",
      "4989/5349 [==========================>...] - ETA: 0s - loss: 0.4360 - accuracy: 0.8405\n",
      "5212/5349 [============================>.] - ETA: 0s - loss: 0.4358 - accuracy: 0.8406\n",
      "5311/5349 [============================>.] - ETA: 0s - loss: 0.4359 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 743us/step - loss: 0.4358 - accuracy: 0.8406 - val_loss: 0.4357 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.3876 - accuracy: 0.8700\n",
      " 170/5349 [..............................] - ETA: 3s - loss: 0.4357 - accuracy: 0.8405\n",
      " 373/5349 [=>............................] - ETA: 2s - loss: 0.4347 - accuracy: 0.8412\n",
      " 571/5349 [==>...........................] - ETA: 2s - loss: 0.4334 - accuracy: 0.8419\n",
      " 782/5349 [===>..........................] - ETA: 2s - loss: 0.4331 - accuracy: 0.8421\n",
      "1097/5349 [=====>........................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8409\n",
      "1308/5349 [======>.......................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8409\n",
      "1495/5349 [=======>......................] - ETA: 1s - loss: 0.4347 - accuracy: 0.8411\n",
      "1715/5349 [========>.....................] - ETA: 1s - loss: 0.4348 - accuracy: 0.8410\n",
      "1920/5349 [=========>....................] - ETA: 1s - loss: 0.4352 - accuracy: 0.8408\n",
      "2124/5349 [==========>...................] - ETA: 1s - loss: 0.4358 - accuracy: 0.8405\n",
      "2325/5349 [============>.................] - ETA: 1s - loss: 0.4361 - accuracy: 0.8403\n",
      "2532/5349 [=============>................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8404\n",
      "2640/5349 [=============>................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8406\n",
      "2837/5349 [==============>...............] - ETA: 1s - loss: 0.4354 - accuracy: 0.8407\n",
      "3042/5349 [================>.............] - ETA: 1s - loss: 0.4351 - accuracy: 0.8408\n",
      "3247/5349 [=================>............] - ETA: 1s - loss: 0.4352 - accuracy: 0.8408\n",
      "3461/5349 [==================>...........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "3640/5349 [===================>..........] - ETA: 0s - loss: 0.4352 - accuracy: 0.8408\n",
      "3856/5349 [====================>.........] - ETA: 0s - loss: 0.4350 - accuracy: 0.8409\n",
      "4031/5349 [=====================>........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "4343/5349 [=======================>......] - ETA: 0s - loss: 0.4349 - accuracy: 0.8409\n",
      "4556/5349 [========================>.....] - ETA: 0s - loss: 0.4350 - accuracy: 0.8409\n",
      "4777/5349 [=========================>....] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "4894/5349 [==========================>...] - ETA: 0s - loss: 0.4353 - accuracy: 0.8407\n",
      "4984/5349 [==========================>...] - ETA: 0s - loss: 0.4353 - accuracy: 0.8407\n",
      "4999/5349 [===========================>..] - ETA: 0s - loss: 0.4352 - accuracy: 0.8407\n",
      "5043/5349 [===========================>..] - ETA: 0s - loss: 0.4353 - accuracy: 0.8407\n",
      "5101/5349 [===========================>..] - ETA: 0s - loss: 0.4350 - accuracy: 0.8408\n",
      "5156/5349 [===========================>..] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "5189/5349 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "5224/5349 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "5256/5349 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8408\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8407\n",
      "5329/5349 [============================>.] - ETA: 0s - loss: 0.4353 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.4353 - accuracy: 0.8406 - val_loss: 0.4353 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 10/20\n",
      " 102/5349 [..............................] - ETA: 2s - loss: 0.4368 - accuracy: 0.8396\n",
      " 323/5349 [>.............................] - ETA: 2s - loss: 0.4355 - accuracy: 0.8404\n",
      " 662/5349 [==>...........................] - ETA: 2s - loss: 0.4374 - accuracy: 0.8392\n",
      " 883/5349 [===>..........................] - ETA: 2s - loss: 0.4367 - accuracy: 0.8396\n",
      "1096/5349 [=====>........................] - ETA: 1s - loss: 0.4373 - accuracy: 0.8393\n",
      "1266/5349 [======>.......................] - ETA: 1s - loss: 0.4368 - accuracy: 0.8396\n",
      "1475/5349 [=======>......................] - ETA: 1s - loss: 0.4359 - accuracy: 0.8401\n",
      "1683/5349 [========>.....................] - ETA: 1s - loss: 0.4352 - accuracy: 0.8405\n",
      "1955/5349 [=========>....................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8402\n",
      "2162/5349 [===========>..................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8403\n",
      "2369/5349 [============>.................] - ETA: 1s - loss: 0.4350 - accuracy: 0.8406\n",
      "2571/5349 [=============>................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8403\n",
      "2789/5349 [==============>...............] - ETA: 1s - loss: 0.4359 - accuracy: 0.8400\n",
      "2996/5349 [===============>..............] - ETA: 1s - loss: 0.4356 - accuracy: 0.8402\n",
      "3203/5349 [================>.............] - ETA: 1s - loss: 0.4355 - accuracy: 0.8403\n",
      "3399/5349 [==================>...........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8407\n",
      "3695/5349 [===================>..........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8407\n",
      "3863/5349 [====================>.........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8405\n",
      "4055/5349 [=====================>........] - ETA: 0s - loss: 0.4353 - accuracy: 0.8404\n",
      "4230/5349 [======================>.......] - ETA: 0s - loss: 0.4354 - accuracy: 0.8403\n",
      "4433/5349 [=======================>......] - ETA: 0s - loss: 0.4356 - accuracy: 0.8402\n",
      "4631/5349 [========================>.....] - ETA: 0s - loss: 0.4351 - accuracy: 0.8405\n",
      "4946/5349 [==========================>...] - ETA: 0s - loss: 0.4349 - accuracy: 0.8406\n",
      "5159/5349 [===========================>..] - ETA: 0s - loss: 0.4347 - accuracy: 0.8407\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 672us/step - loss: 0.4348 - accuracy: 0.8406 - val_loss: 0.4347 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.4190 - accuracy: 0.8500\n",
      " 199/5349 [>.............................] - ETA: 2s - loss: 0.4376 - accuracy: 0.8387\n",
      " 418/5349 [=>............................] - ETA: 2s - loss: 0.4369 - accuracy: 0.8392\n",
      " 626/5349 [==>...........................] - ETA: 2s - loss: 0.4365 - accuracy: 0.8394\n",
      " 835/5349 [===>..........................] - ETA: 2s - loss: 0.4372 - accuracy: 0.8390\n",
      "1036/5349 [====>.........................] - ETA: 2s - loss: 0.4359 - accuracy: 0.8398\n",
      "1341/5349 [======>.......................] - ETA: 1s - loss: 0.4351 - accuracy: 0.8402\n",
      "1533/5349 [=======>......................] - ETA: 1s - loss: 0.4360 - accuracy: 0.8397\n",
      "1743/5349 [========>.....................] - ETA: 1s - loss: 0.4348 - accuracy: 0.8404\n",
      "1942/5349 [=========>....................] - ETA: 1s - loss: 0.4349 - accuracy: 0.8403\n",
      "2161/5349 [===========>..................] - ETA: 1s - loss: 0.4353 - accuracy: 0.8401\n",
      "2376/5349 [============>.................] - ETA: 1s - loss: 0.4356 - accuracy: 0.8399\n",
      "2588/5349 [=============>................] - ETA: 1s - loss: 0.4355 - accuracy: 0.8400\n",
      "2677/5349 [==============>...............] - ETA: 1s - loss: 0.4356 - accuracy: 0.8399\n",
      "2889/5349 [===============>..............] - ETA: 1s - loss: 0.4354 - accuracy: 0.8400\n",
      "3091/5349 [================>.............] - ETA: 1s - loss: 0.4352 - accuracy: 0.8401\n",
      "3291/5349 [=================>............] - ETA: 1s - loss: 0.4352 - accuracy: 0.8401\n",
      "3500/5349 [==================>...........] - ETA: 0s - loss: 0.4351 - accuracy: 0.8402\n",
      "3694/5349 [===================>..........] - ETA: 0s - loss: 0.4348 - accuracy: 0.8403\n",
      "3902/5349 [====================>.........] - ETA: 0s - loss: 0.4346 - accuracy: 0.8404\n",
      "4099/5349 [=====================>........] - ETA: 0s - loss: 0.4343 - accuracy: 0.8406\n",
      "4306/5349 [=======================>......] - ETA: 0s - loss: 0.4342 - accuracy: 0.8407\n",
      "4506/5349 [========================>.....] - ETA: 0s - loss: 0.4342 - accuracy: 0.8406\n",
      "4832/5349 [==========================>...] - ETA: 0s - loss: 0.4342 - accuracy: 0.8407\n",
      "5033/5349 [===========================>..] - ETA: 0s - loss: 0.4342 - accuracy: 0.8406\n",
      "5229/5349 [============================>.] - ETA: 0s - loss: 0.4342 - accuracy: 0.8407\n",
      "5310/5349 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 709us/step - loss: 0.4342 - accuracy: 0.8406 - val_loss: 0.4340 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 12/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4354 - accuracy: 0.8400\n",
      " 216/5349 [>.............................] - ETA: 2s - loss: 0.4354 - accuracy: 0.8397\n",
      " 330/5349 [>.............................] - ETA: 3s - loss: 0.4355 - accuracy: 0.8396\n",
      " 469/5349 [=>............................] - ETA: 3s - loss: 0.4335 - accuracy: 0.8408\n",
      " 688/5349 [==>...........................] - ETA: 3s - loss: 0.4343 - accuracy: 0.8403\n",
      " 885/5349 [===>..........................] - ETA: 2s - loss: 0.4338 - accuracy: 0.8406\n",
      "1102/5349 [=====>........................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8405\n",
      "1311/5349 [======>.......................] - ETA: 2s - loss: 0.4334 - accuracy: 0.8409\n",
      "1527/5349 [=======>......................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8399\n",
      "1724/5349 [========>.....................] - ETA: 2s - loss: 0.4348 - accuracy: 0.8400\n",
      "1915/5349 [=========>....................] - ETA: 1s - loss: 0.4345 - accuracy: 0.8402\n",
      "2230/5349 [===========>..................] - ETA: 1s - loss: 0.4341 - accuracy: 0.8404\n",
      "2447/5349 [============>.................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8407\n",
      "2631/5349 [=============>................] - ETA: 1s - loss: 0.4338 - accuracy: 0.8406\n",
      "2847/5349 [==============>...............] - ETA: 1s - loss: 0.4333 - accuracy: 0.8409\n",
      "3036/5349 [================>.............] - ETA: 1s - loss: 0.4333 - accuracy: 0.8409\n",
      "3256/5349 [=================>............] - ETA: 1s - loss: 0.4333 - accuracy: 0.8408\n",
      "3464/5349 [==================>...........] - ETA: 0s - loss: 0.4336 - accuracy: 0.8407\n",
      "3678/5349 [===================>..........] - ETA: 0s - loss: 0.4332 - accuracy: 0.8409\n",
      "3990/5349 [=====================>........] - ETA: 0s - loss: 0.4329 - accuracy: 0.8410\n",
      "4214/5349 [======================>.......] - ETA: 0s - loss: 0.4330 - accuracy: 0.8410\n",
      "4413/5349 [=======================>......] - ETA: 0s - loss: 0.4329 - accuracy: 0.8410\n",
      "4536/5349 [========================>.....] - ETA: 0s - loss: 0.4331 - accuracy: 0.8409\n",
      "4615/5349 [========================>.....] - ETA: 0s - loss: 0.4331 - accuracy: 0.8409\n",
      "4653/5349 [=========================>....] - ETA: 0s - loss: 0.4331 - accuracy: 0.8409\n",
      "4683/5349 [=========================>....] - ETA: 0s - loss: 0.4332 - accuracy: 0.8409\n",
      "4760/5349 [=========================>....] - ETA: 0s - loss: 0.4332 - accuracy: 0.8408\n",
      "4800/5349 [=========================>....] - ETA: 0s - loss: 0.4332 - accuracy: 0.8409\n",
      "4832/5349 [==========================>...] - ETA: 0s - loss: 0.4332 - accuracy: 0.8409\n",
      "4843/5349 [==========================>...] - ETA: 0s - loss: 0.4331 - accuracy: 0.8409\n",
      "4889/5349 [==========================>...] - ETA: 0s - loss: 0.4332 - accuracy: 0.8408\n",
      "4914/5349 [==========================>...] - ETA: 0s - loss: 0.4333 - accuracy: 0.8408\n",
      "4949/5349 [==========================>...] - ETA: 0s - loss: 0.4334 - accuracy: 0.8407\n",
      "4986/5349 [==========================>...] - ETA: 0s - loss: 0.4335 - accuracy: 0.8407\n",
      "5023/5349 [===========================>..] - ETA: 0s - loss: 0.4335 - accuracy: 0.8406\n",
      "5064/5349 [===========================>..] - ETA: 0s - loss: 0.4336 - accuracy: 0.8406\n",
      "5119/5349 [===========================>..] - ETA: 0s - loss: 0.4335 - accuracy: 0.8407\n",
      "5163/5349 [===========================>..] - ETA: 0s - loss: 0.4335 - accuracy: 0.8407\n",
      "5184/5349 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8407\n",
      "5204/5349 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8407\n",
      "5230/5349 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8407\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.8407\n",
      "5323/5349 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8407\n",
      "5345/5349 [============================>.] - ETA: 0s - loss: 0.4335 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.4335 - accuracy: 0.8406 - val_loss: 0.4333 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.4338 - accuracy: 0.8400\n",
      " 215/5349 [>.............................] - ETA: 2s - loss: 0.4375 - accuracy: 0.8379\n",
      " 434/5349 [=>............................] - ETA: 2s - loss: 0.4370 - accuracy: 0.8382\n",
      " 635/5349 [==>...........................] - ETA: 2s - loss: 0.4350 - accuracy: 0.8394\n",
      " 739/5349 [===>..........................] - ETA: 2s - loss: 0.4364 - accuracy: 0.8386\n",
      " 956/5349 [====>.........................] - ETA: 2s - loss: 0.4337 - accuracy: 0.8402\n",
      "1166/5349 [=====>........................] - ETA: 1s - loss: 0.4340 - accuracy: 0.8400\n",
      "1382/5349 [======>.......................] - ETA: 1s - loss: 0.4337 - accuracy: 0.8402\n",
      "1558/5349 [=======>......................] - ETA: 1s - loss: 0.4326 - accuracy: 0.8409\n",
      "1767/5349 [========>.....................] - ETA: 1s - loss: 0.4329 - accuracy: 0.8406\n",
      "1980/5349 [==========>...................] - ETA: 1s - loss: 0.4332 - accuracy: 0.8405\n",
      "2196/5349 [===========>..................] - ETA: 1s - loss: 0.4339 - accuracy: 0.8400\n",
      "2508/5349 [=============>................] - ETA: 1s - loss: 0.4333 - accuracy: 0.8404\n",
      "2725/5349 [==============>...............] - ETA: 1s - loss: 0.4335 - accuracy: 0.8402\n",
      "2920/5349 [===============>..............] - ETA: 1s - loss: 0.4334 - accuracy: 0.8403\n",
      "3141/5349 [================>.............] - ETA: 1s - loss: 0.4330 - accuracy: 0.8406\n",
      "3354/5349 [=================>............] - ETA: 0s - loss: 0.4329 - accuracy: 0.8406\n",
      "3576/5349 [===================>..........] - ETA: 0s - loss: 0.4330 - accuracy: 0.8405\n",
      "3794/5349 [====================>.........] - ETA: 0s - loss: 0.4330 - accuracy: 0.8405\n",
      "4018/5349 [=====================>........] - ETA: 0s - loss: 0.4329 - accuracy: 0.8406\n",
      "4128/5349 [======================>.......] - ETA: 0s - loss: 0.4329 - accuracy: 0.8405\n",
      "4344/5349 [=======================>......] - ETA: 0s - loss: 0.4328 - accuracy: 0.8406\n",
      "4567/5349 [========================>.....] - ETA: 0s - loss: 0.4328 - accuracy: 0.8406\n",
      "4782/5349 [=========================>....] - ETA: 0s - loss: 0.4329 - accuracy: 0.8405\n",
      "5004/5349 [===========================>..] - ETA: 0s - loss: 0.4327 - accuracy: 0.8406\n",
      "5221/5349 [============================>.] - ETA: 0s - loss: 0.4326 - accuracy: 0.8407\n",
      "5333/5349 [============================>.] - ETA: 0s - loss: 0.4326 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 657us/step - loss: 0.4327 - accuracy: 0.8406 - val_loss: 0.4323 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 14/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.4979 - accuracy: 0.8000\n",
      " 218/5349 [>.............................] - ETA: 2s - loss: 0.4351 - accuracy: 0.8389\n",
      " 436/5349 [=>............................] - ETA: 2s - loss: 0.4336 - accuracy: 0.8397\n",
      " 647/5349 [==>...........................] - ETA: 2s - loss: 0.4328 - accuracy: 0.8402\n",
      " 867/5349 [===>..........................] - ETA: 2s - loss: 0.4340 - accuracy: 0.8395\n",
      "1084/5349 [=====>........................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8397\n",
      "1306/5349 [======>.......................] - ETA: 1s - loss: 0.4339 - accuracy: 0.8395\n",
      "1517/5349 [=======>......................] - ETA: 1s - loss: 0.4336 - accuracy: 0.8397\n",
      "1629/5349 [========>.....................] - ETA: 1s - loss: 0.4335 - accuracy: 0.8397\n",
      "1849/5349 [=========>....................] - ETA: 1s - loss: 0.4324 - accuracy: 0.8404\n",
      "2044/5349 [==========>...................] - ETA: 1s - loss: 0.4322 - accuracy: 0.8405\n",
      "2260/5349 [===========>..................] - ETA: 1s - loss: 0.4321 - accuracy: 0.8406\n",
      "2467/5349 [============>.................] - ETA: 1s - loss: 0.4321 - accuracy: 0.8406\n",
      "2681/5349 [==============>...............] - ETA: 1s - loss: 0.4321 - accuracy: 0.8405\n",
      "2959/5349 [===============>..............] - ETA: 1s - loss: 0.4327 - accuracy: 0.8401\n",
      "3152/5349 [================>.............] - ETA: 1s - loss: 0.4325 - accuracy: 0.8402\n",
      "3331/5349 [=================>............] - ETA: 0s - loss: 0.4323 - accuracy: 0.8403\n",
      "3463/5349 [==================>...........] - ETA: 0s - loss: 0.4322 - accuracy: 0.8404\n",
      "3659/5349 [===================>..........] - ETA: 0s - loss: 0.4322 - accuracy: 0.8404\n",
      "3873/5349 [====================>.........] - ETA: 0s - loss: 0.4319 - accuracy: 0.8405\n",
      "4082/5349 [=====================>........] - ETA: 0s - loss: 0.4322 - accuracy: 0.8404\n",
      "4284/5349 [=======================>......] - ETA: 0s - loss: 0.4318 - accuracy: 0.8406\n",
      "4474/5349 [========================>.....] - ETA: 0s - loss: 0.4319 - accuracy: 0.8405\n",
      "4694/5349 [=========================>....] - ETA: 0s - loss: 0.4317 - accuracy: 0.8406\n",
      "5013/5349 [===========================>..] - ETA: 0s - loss: 0.4318 - accuracy: 0.8406\n",
      "5231/5349 [============================>.] - ETA: 0s - loss: 0.4318 - accuracy: 0.8406\n",
      "5319/5349 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 4s 703us/step - loss: 0.4316 - accuracy: 0.8406 - val_loss: 0.4312 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 15/20\n",
      " 111/5349 [..............................] - ETA: 2s - loss: 0.4334 - accuracy: 0.8392\n",
      " 334/5349 [>.............................] - ETA: 2s - loss: 0.4354 - accuracy: 0.8380\n",
      " 401/5349 [=>............................] - ETA: 3s - loss: 0.4342 - accuracy: 0.8387\n",
      " 532/5349 [=>............................] - ETA: 3s - loss: 0.4340 - accuracy: 0.8388\n",
      " 730/5349 [===>..........................] - ETA: 2s - loss: 0.4326 - accuracy: 0.8396\n",
      " 905/5349 [====>.........................] - ETA: 2s - loss: 0.4331 - accuracy: 0.8393\n",
      "1096/5349 [=====>........................] - ETA: 2s - loss: 0.4322 - accuracy: 0.8398\n",
      "1279/5349 [======>.......................] - ETA: 2s - loss: 0.4307 - accuracy: 0.8407\n",
      "1461/5349 [=======>......................] - ETA: 2s - loss: 0.4295 - accuracy: 0.8415\n",
      "1567/5349 [=======>......................] - ETA: 2s - loss: 0.4295 - accuracy: 0.8415\n",
      "1770/5349 [========>.....................] - ETA: 2s - loss: 0.4302 - accuracy: 0.8410\n",
      "1954/5349 [=========>....................] - ETA: 1s - loss: 0.4300 - accuracy: 0.8411\n",
      "2114/5349 [==========>...................] - ETA: 1s - loss: 0.4298 - accuracy: 0.8412\n",
      "2302/5349 [===========>..................] - ETA: 1s - loss: 0.4304 - accuracy: 0.8408\n",
      "2443/5349 [============>.................] - ETA: 1s - loss: 0.4306 - accuracy: 0.8408\n",
      "2620/5349 [=============>................] - ETA: 1s - loss: 0.4307 - accuracy: 0.8407\n",
      "2818/5349 [==============>...............] - ETA: 1s - loss: 0.4310 - accuracy: 0.8405\n",
      "2980/5349 [===============>..............] - ETA: 1s - loss: 0.4308 - accuracy: 0.8406\n",
      "3281/5349 [=================>............] - ETA: 1s - loss: 0.4304 - accuracy: 0.8408\n",
      "3448/5349 [==================>...........] - ETA: 1s - loss: 0.4304 - accuracy: 0.8408\n",
      "3611/5349 [===================>..........] - ETA: 1s - loss: 0.4306 - accuracy: 0.8407\n",
      "3818/5349 [====================>.........] - ETA: 0s - loss: 0.4308 - accuracy: 0.8405\n",
      "4026/5349 [=====================>........] - ETA: 0s - loss: 0.4307 - accuracy: 0.8405\n",
      "4212/5349 [======================>.......] - ETA: 0s - loss: 0.4307 - accuracy: 0.8405\n",
      "4350/5349 [=======================>......] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4390/5349 [=======================>......] - ETA: 0s - loss: 0.4306 - accuracy: 0.8406\n",
      "4481/5349 [========================>.....] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4550/5349 [========================>.....] - ETA: 0s - loss: 0.4308 - accuracy: 0.8405\n",
      "4580/5349 [========================>.....] - ETA: 0s - loss: 0.4307 - accuracy: 0.8405\n",
      "4604/5349 [========================>.....] - ETA: 0s - loss: 0.4307 - accuracy: 0.8405\n",
      "4635/5349 [========================>.....] - ETA: 0s - loss: 0.4306 - accuracy: 0.8406\n",
      "4694/5349 [=========================>....] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4731/5349 [=========================>....] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4772/5349 [=========================>....] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4811/5349 [=========================>....] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4895/5349 [==========================>...] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "4947/5349 [==========================>...] - ETA: 0s - loss: 0.4304 - accuracy: 0.8406\n",
      "5011/5349 [===========================>..] - ETA: 0s - loss: 0.4304 - accuracy: 0.8407\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.4304 - accuracy: 0.8406\n",
      "5093/5349 [===========================>..] - ETA: 0s - loss: 0.4304 - accuracy: 0.8406\n",
      "5126/5349 [===========================>..] - ETA: 0s - loss: 0.4303 - accuracy: 0.8407\n",
      "5166/5349 [===========================>..] - ETA: 0s - loss: 0.4303 - accuracy: 0.8407\n",
      "5215/5349 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8407\n",
      "5240/5349 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8406\n",
      "5316/5349 [============================>.] - ETA: 0s - loss: 0.4305 - accuracy: 0.8406\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.4304 - accuracy: 0.8406 - val_loss: 0.4299 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 16/20\n",
      " 101/5349 [..............................] - ETA: 2s - loss: 0.4241 - accuracy: 0.8442\n",
      " 302/5349 [>.............................] - ETA: 2s - loss: 0.4280 - accuracy: 0.8417\n",
      " 507/5349 [=>............................] - ETA: 2s - loss: 0.4293 - accuracy: 0.8408\n",
      " 717/5349 [===>..........................] - ETA: 2s - loss: 0.4302 - accuracy: 0.8403\n",
      "1045/5349 [====>.........................] - ETA: 2s - loss: 0.4307 - accuracy: 0.8399\n",
      "1244/5349 [=====>........................] - ETA: 1s - loss: 0.4301 - accuracy: 0.8403\n",
      "1447/5349 [=======>......................] - ETA: 1s - loss: 0.4313 - accuracy: 0.8395\n",
      "1620/5349 [========>.....................] - ETA: 1s - loss: 0.4305 - accuracy: 0.8400\n",
      "1788/5349 [=========>....................] - ETA: 1s - loss: 0.4307 - accuracy: 0.8399\n",
      "1971/5349 [==========>...................] - ETA: 1s - loss: 0.4309 - accuracy: 0.8397\n",
      "2180/5349 [===========>..................] - ETA: 1s - loss: 0.4306 - accuracy: 0.8399\n",
      "2392/5349 [============>.................] - ETA: 1s - loss: 0.4303 - accuracy: 0.8400\n",
      "2552/5349 [=============>................] - ETA: 1s - loss: 0.4302 - accuracy: 0.8401\n",
      "2756/5349 [==============>...............] - ETA: 1s - loss: 0.4298 - accuracy: 0.8403\n",
      "3077/5349 [================>.............] - ETA: 1s - loss: 0.4292 - accuracy: 0.8407\n",
      "3291/5349 [=================>............] - ETA: 1s - loss: 0.4296 - accuracy: 0.8404\n",
      "3506/5349 [==================>...........] - ETA: 0s - loss: 0.4294 - accuracy: 0.8405\n",
      "3726/5349 [===================>..........] - ETA: 0s - loss: 0.4294 - accuracy: 0.8405\n",
      "3916/5349 [====================>.........] - ETA: 0s - loss: 0.4293 - accuracy: 0.8405\n",
      "4134/5349 [======================>.......] - ETA: 0s - loss: 0.4293 - accuracy: 0.8405\n",
      "4355/5349 [=======================>......] - ETA: 0s - loss: 0.4295 - accuracy: 0.8404\n",
      "4576/5349 [========================>.....] - ETA: 0s - loss: 0.4292 - accuracy: 0.8405\n",
      "4797/5349 [=========================>....] - ETA: 0s - loss: 0.4290 - accuracy: 0.8406\n",
      "5017/5349 [===========================>..] - ETA: 0s - loss: 0.4289 - accuracy: 0.8407\n",
      "5240/5349 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 660us/step - loss: 0.4289 - accuracy: 0.8406 - val_loss: 0.4281 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4606 - accuracy: 0.8200\n",
      " 219/5349 [>.............................] - ETA: 2s - loss: 0.4293 - accuracy: 0.8398\n",
      " 438/5349 [=>............................] - ETA: 2s - loss: 0.4316 - accuracy: 0.8384\n",
      " 658/5349 [==>...........................] - ETA: 2s - loss: 0.4302 - accuracy: 0.8392\n",
      " 856/5349 [===>..........................] - ETA: 2s - loss: 0.4283 - accuracy: 0.8403\n",
      "1078/5349 [=====>........................] - ETA: 1s - loss: 0.4282 - accuracy: 0.8404\n",
      "1299/5349 [======>.......................] - ETA: 1s - loss: 0.4278 - accuracy: 0.8406\n",
      "1468/5349 [=======>......................] - ETA: 1s - loss: 0.4277 - accuracy: 0.8406\n",
      "1687/5349 [========>.....................] - ETA: 1s - loss: 0.4275 - accuracy: 0.8407\n",
      "1796/5349 [=========>....................] - ETA: 1s - loss: 0.4278 - accuracy: 0.8406\n",
      "2015/5349 [==========>...................] - ETA: 1s - loss: 0.4280 - accuracy: 0.8404\n",
      "2236/5349 [===========>..................] - ETA: 1s - loss: 0.4278 - accuracy: 0.8405\n",
      "2463/5349 [============>.................] - ETA: 1s - loss: 0.4275 - accuracy: 0.8406\n",
      "2678/5349 [==============>...............] - ETA: 1s - loss: 0.4277 - accuracy: 0.8405\n",
      "2893/5349 [===============>..............] - ETA: 1s - loss: 0.4274 - accuracy: 0.8406\n",
      "3115/5349 [================>.............] - ETA: 1s - loss: 0.4271 - accuracy: 0.8408\n",
      "3337/5349 [=================>............] - ETA: 0s - loss: 0.4273 - accuracy: 0.8407\n",
      "3560/5349 [==================>...........] - ETA: 0s - loss: 0.4271 - accuracy: 0.8407\n",
      "3782/5349 [====================>.........] - ETA: 0s - loss: 0.4272 - accuracy: 0.8407\n",
      "4004/5349 [=====================>........] - ETA: 0s - loss: 0.4273 - accuracy: 0.8406\n",
      "4335/5349 [=======================>......] - ETA: 0s - loss: 0.4271 - accuracy: 0.8407\n",
      "4528/5349 [========================>.....] - ETA: 0s - loss: 0.4273 - accuracy: 0.8405\n",
      "4747/5349 [=========================>....] - ETA: 0s - loss: 0.4271 - accuracy: 0.8406\n",
      "4971/5349 [==========================>...] - ETA: 0s - loss: 0.4273 - accuracy: 0.8405\n",
      "5187/5349 [============================>.] - ETA: 0s - loss: 0.4270 - accuracy: 0.8406\n",
      "5296/5349 [============================>.] - ETA: 0s - loss: 0.4269 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 3s 647us/step - loss: 0.4270 - accuracy: 0.8406 - val_loss: 0.4260 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.4745 - accuracy: 0.8100\n",
      " 204/5349 [>.............................] - ETA: 2s - loss: 0.4297 - accuracy: 0.8381\n",
      " 383/5349 [=>............................] - ETA: 2s - loss: 0.4266 - accuracy: 0.8401\n",
      " 564/5349 [==>...........................] - ETA: 2s - loss: 0.4276 - accuracy: 0.8394\n",
      " 749/5349 [===>..........................] - ETA: 2s - loss: 0.4286 - accuracy: 0.8388\n",
      " 948/5349 [====>.........................] - ETA: 2s - loss: 0.4276 - accuracy: 0.8394\n",
      "1171/5349 [=====>........................] - ETA: 2s - loss: 0.4274 - accuracy: 0.8395\n",
      "1389/5349 [======>.......................] - ETA: 2s - loss: 0.4273 - accuracy: 0.8395\n",
      "1453/5349 [=======>......................] - ETA: 2s - loss: 0.4276 - accuracy: 0.8393\n",
      "1582/5349 [=======>......................] - ETA: 2s - loss: 0.4270 - accuracy: 0.8396\n",
      "1792/5349 [=========>....................] - ETA: 1s - loss: 0.4271 - accuracy: 0.8396\n",
      "2009/5349 [==========>...................] - ETA: 1s - loss: 0.4261 - accuracy: 0.8402\n",
      "2224/5349 [===========>..................] - ETA: 1s - loss: 0.4261 - accuracy: 0.8401\n",
      "2436/5349 [============>.................] - ETA: 1s - loss: 0.4253 - accuracy: 0.8406\n",
      "2651/5349 [=============>................] - ETA: 1s - loss: 0.4255 - accuracy: 0.8404\n",
      "2860/5349 [===============>..............] - ETA: 1s - loss: 0.4254 - accuracy: 0.8405\n",
      "3070/5349 [================>.............] - ETA: 1s - loss: 0.4243 - accuracy: 0.8411\n",
      "3290/5349 [=================>............] - ETA: 1s - loss: 0.4247 - accuracy: 0.8408\n",
      "3505/5349 [==================>...........] - ETA: 0s - loss: 0.4248 - accuracy: 0.8407\n",
      "3614/5349 [===================>..........] - ETA: 0s - loss: 0.4248 - accuracy: 0.8407\n",
      "3826/5349 [====================>.........] - ETA: 0s - loss: 0.4252 - accuracy: 0.8404\n",
      "4044/5349 [=====================>........] - ETA: 0s - loss: 0.4251 - accuracy: 0.8405\n",
      "4163/5349 [======================>.......] - ETA: 0s - loss: 0.4248 - accuracy: 0.8406\n",
      "4324/5349 [=======================>......] - ETA: 0s - loss: 0.4249 - accuracy: 0.8405\n",
      "4541/5349 [========================>.....] - ETA: 0s - loss: 0.4247 - accuracy: 0.8406\n",
      "4695/5349 [=========================>....] - ETA: 0s - loss: 0.4248 - accuracy: 0.8405\n",
      "4916/5349 [==========================>...] - ETA: 0s - loss: 0.4250 - accuracy: 0.8404\n",
      "5143/5349 [===========================>..] - ETA: 0s - loss: 0.4248 - accuracy: 0.8404\n",
      "5250/5349 [============================>.] - ETA: 0s - loss: 0.4245 - accuracy: 0.8406\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.4245 - accuracy: 0.8406 - val_loss: 0.4232 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 19/20\n",
      "   1/5349 [..............................] - ETA: 33s - loss: 0.3929 - accuracy: 0.8600\n",
      "  20/5349 [..............................] - ETA: 14s - loss: 0.4200 - accuracy: 0.8425\n",
      "  29/5349 [..............................] - ETA: 23s - loss: 0.4185 - accuracy: 0.8434\n",
      "  39/5349 [..............................] - ETA: 25s - loss: 0.4196 - accuracy: 0.8428\n",
      " 105/5349 [..............................] - ETA: 14s - loss: 0.4317 - accuracy: 0.8352\n",
      " 204/5349 [>.............................] - ETA: 9s - loss: 0.4231 - accuracy: 0.8406 \n",
      " 275/5349 [>.............................] - ETA: 9s - loss: 0.4216 - accuracy: 0.8415\n",
      " 342/5349 [>.............................] - ETA: 8s - loss: 0.4244 - accuracy: 0.8397\n",
      " 488/5349 [=>............................] - ETA: 6s - loss: 0.4243 - accuracy: 0.8397\n",
      " 692/5349 [==>...........................] - ETA: 5s - loss: 0.4229 - accuracy: 0.8406\n",
      " 981/5349 [====>.........................] - ETA: 4s - loss: 0.4212 - accuracy: 0.8416\n",
      "1202/5349 [=====>........................] - ETA: 3s - loss: 0.4208 - accuracy: 0.8418\n",
      "1425/5349 [======>.......................] - ETA: 3s - loss: 0.4210 - accuracy: 0.8416\n",
      "1650/5349 [========>.....................] - ETA: 2s - loss: 0.4203 - accuracy: 0.8421\n",
      "1879/5349 [=========>....................] - ETA: 2s - loss: 0.4205 - accuracy: 0.8418\n",
      "2115/5349 [==========>...................] - ETA: 2s - loss: 0.4215 - accuracy: 0.8412\n",
      "2344/5349 [============>.................] - ETA: 1s - loss: 0.4219 - accuracy: 0.8409\n",
      "2566/5349 [=============>................] - ETA: 1s - loss: 0.4226 - accuracy: 0.8404\n",
      "2789/5349 [==============>...............] - ETA: 1s - loss: 0.4230 - accuracy: 0.8401\n",
      "3024/5349 [===============>..............] - ETA: 1s - loss: 0.4230 - accuracy: 0.8400\n",
      "3251/5349 [=================>............] - ETA: 1s - loss: 0.4229 - accuracy: 0.8401\n",
      "3597/5349 [===================>..........] - ETA: 1s - loss: 0.4224 - accuracy: 0.8403\n",
      "3823/5349 [====================>.........] - ETA: 0s - loss: 0.4219 - accuracy: 0.8406\n",
      "4048/5349 [=====================>........] - ETA: 0s - loss: 0.4215 - accuracy: 0.8407\n",
      "4253/5349 [======================>.......] - ETA: 0s - loss: 0.4212 - accuracy: 0.8409\n",
      "4454/5349 [=======================>......] - ETA: 0s - loss: 0.4212 - accuracy: 0.8409\n",
      "4663/5349 [=========================>....] - ETA: 0s - loss: 0.4214 - accuracy: 0.8407\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.4216 - accuracy: 0.8406\n",
      "5095/5349 [===========================>..] - ETA: 0s - loss: 0.4214 - accuracy: 0.8406\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.4212 - accuracy: 0.8407\n",
      "5349/5349 [==============================] - 4s 738us/step - loss: 0.4213 - accuracy: 0.8406 - val_loss: 0.4195 - val_accuracy: 0.8405\n",
      "\u001B[36m(train_DNN pid=6167)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.4225 - accuracy: 0.8400\n",
      "  97/5349 [..............................] - ETA: 2s - loss: 0.4185 - accuracy: 0.8412\n",
      " 296/5349 [>.............................] - ETA: 2s - loss: 0.4203 - accuracy: 0.8400\n",
      " 477/5349 [=>............................] - ETA: 2s - loss: 0.4188 - accuracy: 0.8409\n",
      " 676/5349 [==>...........................] - ETA: 2s - loss: 0.4178 - accuracy: 0.8415\n",
      " 829/5349 [===>..........................] - ETA: 2s - loss: 0.4190 - accuracy: 0.8406\n",
      "1021/5349 [====>.........................] - ETA: 2s - loss: 0.4186 - accuracy: 0.8409\n",
      "1209/5349 [=====>........................] - ETA: 2s - loss: 0.4181 - accuracy: 0.8411\n",
      "1387/5349 [======>.......................] - ETA: 2s - loss: 0.4173 - accuracy: 0.8416\n",
      "1609/5349 [========>.....................] - ETA: 1s - loss: 0.4168 - accuracy: 0.8419\n",
      "1832/5349 [=========>....................] - ETA: 1s - loss: 0.4166 - accuracy: 0.8419\n",
      "2047/5349 [==========>...................] - ETA: 1s - loss: 0.4168 - accuracy: 0.8417\n",
      "2156/5349 [===========>..................] - ETA: 1s - loss: 0.4171 - accuracy: 0.8415\n",
      "2366/5349 [============>.................] - ETA: 1s - loss: 0.4174 - accuracy: 0.8412\n",
      "2585/5349 [=============>................] - ETA: 1s - loss: 0.4173 - accuracy: 0.8413\n",
      "2807/5349 [==============>...............] - ETA: 1s - loss: 0.4177 - accuracy: 0.8409\n",
      "3022/5349 [===============>..............] - ETA: 1s - loss: 0.4176 - accuracy: 0.8409\n",
      "3242/5349 [=================>............] - ETA: 1s - loss: 0.4175 - accuracy: 0.8409\n",
      "3465/5349 [==================>...........] - ETA: 0s - loss: 0.4176 - accuracy: 0.8408\n",
      "3684/5349 [===================>..........] - ETA: 0s - loss: 0.4180 - accuracy: 0.8405\n",
      "3884/5349 [====================>.........] - ETA: 0s - loss: 0.4179 - accuracy: 0.8405\n",
      "4101/5349 [======================>.......] - ETA: 0s - loss: 0.4176 - accuracy: 0.8407\n",
      "4324/5349 [=======================>......] - ETA: 0s - loss: 0.4172 - accuracy: 0.8408\n",
      "4546/5349 [========================>.....] - ETA: 0s - loss: 0.4170 - accuracy: 0.8409\n",
      "4876/5349 [==========================>...] - ETA: 0s - loss: 0.4169 - accuracy: 0.8408\n",
      "5079/5349 [===========================>..] - ETA: 0s - loss: 0.4170 - accuracy: 0.8407\n",
      "5303/5349 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8407\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 1/20\n",
      "   1/5349 [..............................] - ETA: 27:08 - loss: 0.7597 - accuracy: 0.0800\n",
      "  75/5349 [..............................] - ETA: 10s - loss: 0.7200 - accuracy: 0.3307\n",
      " 136/5349 [..............................] - ETA: 10s - loss: 0.7020 - accuracy: 0.5193\n",
      " 216/5349 [>.............................] - ETA: 8s - loss: 0.6809 - accuracy: 0.6342\n",
      " 344/5349 [>.............................] - ETA: 6s - loss: 0.6549 - accuracy: 0.7104\n",
      " 470/5349 [=>............................] - ETA: 6s - loss: 0.6339 - accuracy: 0.7454\n",
      " 619/5349 [==>...........................] - ETA: 5s - loss: 0.6124 - accuracy: 0.7685\n",
      " 737/5349 [===>..........................] - ETA: 4s - loss: 0.5960 - accuracy: 0.7817\n",
      " 818/5349 [===>..........................] - ETA: 4s - loss: 0.5858 - accuracy: 0.7886\n",
      " 963/5349 [====>.........................] - ETA: 4s - loss: 0.5683 - accuracy: 0.7975\n",
      "1075/5349 [=====>........................] - ETA: 4s - loss: 0.5554 - accuracy: 0.8028\n",
      "1153/5349 [=====>........................] - ETA: 4s - loss: 0.5468 - accuracy: 0.8058\n",
      "1316/5349 [======>.......................] - ETA: 3s - loss: 0.5290 - accuracy: 0.8118\n",
      "1411/5349 [======>.......................] - ETA: 3s - loss: 0.5194 - accuracy: 0.8143\n",
      "1621/5349 [========>.....................] - ETA: 3s - loss: 0.4985 - accuracy: 0.8193\n",
      "1833/5349 [=========>....................] - ETA: 2s - loss: 0.4797 - accuracy: 0.8228\n",
      "2034/5349 [==========>...................] - ETA: 2s - loss: 0.4632 - accuracy: 0.8258\n",
      "2192/5349 [===========>..................] - ETA: 2s - loss: 0.4505 - accuracy: 0.8285\n",
      "2358/5349 [============>.................] - ETA: 2s - loss: 0.4389 - accuracy: 0.8307\n",
      "2476/5349 [============>.................] - ETA: 2s - loss: 0.4309 - accuracy: 0.8319\n",
      "2634/5349 [=============>................] - ETA: 2s - loss: 0.4207 - accuracy: 0.8337\n",
      "2794/5349 [==============>...............] - ETA: 1s - loss: 0.4109 - accuracy: 0.8353\n",
      "2929/5349 [===============>..............] - ETA: 1s - loss: 0.4033 - accuracy: 0.8366\n",
      "2965/5349 [===============>..............] - ETA: 1s - loss: 0.4013 - accuracy: 0.8368\n",
      "3045/5349 [================>.............] - ETA: 1s - loss: 0.3970 - accuracy: 0.8375\n",
      "3189/5349 [================>.............] - ETA: 1s - loss: 0.3895 - accuracy: 0.8386\n",
      "3324/5349 [=================>............] - ETA: 1s - loss: 0.3829 - accuracy: 0.8397\n",
      "3384/5349 [=================>............] - ETA: 1s - loss: 0.3798 - accuracy: 0.8403\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.3731 - accuracy: 0.8416\n",
      "3704/5349 [===================>..........] - ETA: 1s - loss: 0.3660 - accuracy: 0.8434\n",
      "3863/5349 [====================>.........] - ETA: 1s - loss: 0.3596 - accuracy: 0.8452\n",
      "3918/5349 [====================>.........] - ETA: 1s - loss: 0.3576 - accuracy: 0.8458\n",
      "4017/5349 [=====================>........] - ETA: 1s - loss: 0.3538 - accuracy: 0.8470\n",
      "4176/5349 [======================>.......] - ETA: 0s - loss: 0.3483 - accuracy: 0.8488\n",
      "4314/5349 [=======================>......] - ETA: 0s - loss: 0.3437 - accuracy: 0.8504\n",
      "4410/5349 [=======================>......] - ETA: 0s - loss: 0.3406 - accuracy: 0.8514\n",
      "4620/5349 [========================>.....] - ETA: 0s - loss: 0.3342 - accuracy: 0.8535\n",
      "4718/5349 [=========================>....] - ETA: 0s - loss: 0.3313 - accuracy: 0.8543\n",
      "4932/5349 [==========================>...] - ETA: 0s - loss: 0.3256 - accuracy: 0.8562\n",
      "5149/5349 [===========================>..] - ETA: 0s - loss: 0.3200 - accuracy: 0.8581\n",
      "5346/5349 [============================>.] - ETA: 0s - loss: 0.3152 - accuracy: 0.8598\n",
      "5349/5349 [==============================] - 11s 2ms/step - loss: 0.3151 - accuracy: 0.8598 - val_loss: 0.1920 - val_accuracy: 0.9025\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 10s - loss: 0.1246 - accuracy: 0.9600\n",
      "  92/5349 [..............................] - ETA: 5s - loss: 0.1955 - accuracy: 0.9013\n",
      " 184/5349 [>.............................] - ETA: 5s - loss: 0.1928 - accuracy: 0.9030\n",
      " 261/5349 [>.............................] - ETA: 5s - loss: 0.1928 - accuracy: 0.9030\n",
      " 358/5349 [=>............................] - ETA: 5s - loss: 0.1922 - accuracy: 0.9033\n",
      " 401/5349 [=>............................] - ETA: 6s - loss: 0.1911 - accuracy: 0.9043\n",
      " 407/5349 [=>............................] - ETA: 7s - loss: 0.1911 - accuracy: 0.9044\n",
      " 543/5349 [==>...........................] - ETA: 6s - loss: 0.1954 - accuracy: 0.9038\n",
      " 837/5349 [===>..........................] - ETA: 4s - loss: 0.1922 - accuracy: 0.9043\n",
      "1031/5349 [====>.........................] - ETA: 4s - loss: 0.1906 - accuracy: 0.9045\n",
      "1201/5349 [=====>........................] - ETA: 3s - loss: 0.1897 - accuracy: 0.9048\n",
      "1406/5349 [======>.......................] - ETA: 3s - loss: 0.1890 - accuracy: 0.9047\n",
      "1609/5349 [========>.....................] - ETA: 2s - loss: 0.1885 - accuracy: 0.9047\n",
      "1786/5349 [=========>....................] - ETA: 2s - loss: 0.1882 - accuracy: 0.9045\n",
      "1987/5349 [==========>...................] - ETA: 2s - loss: 0.1877 - accuracy: 0.9045\n",
      "2154/5349 [===========>..................] - ETA: 2s - loss: 0.1869 - accuracy: 0.9048\n",
      "2424/5349 [============>.................] - ETA: 2s - loss: 0.1860 - accuracy: 0.9049\n",
      "2565/5349 [=============>................] - ETA: 1s - loss: 0.1859 - accuracy: 0.9049\n",
      "2722/5349 [==============>...............] - ETA: 1s - loss: 0.1854 - accuracy: 0.9050\n",
      "2901/5349 [===============>..............] - ETA: 1s - loss: 0.1852 - accuracy: 0.9050\n",
      "3132/5349 [================>.............] - ETA: 1s - loss: 0.1844 - accuracy: 0.9054\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1838 - accuracy: 0.9056\n",
      "3538/5349 [==================>...........] - ETA: 1s - loss: 0.1834 - accuracy: 0.9057\n",
      "3687/5349 [===================>..........] - ETA: 1s - loss: 0.1834 - accuracy: 0.9057\n",
      "3771/5349 [====================>.........] - ETA: 1s - loss: 0.1831 - accuracy: 0.9058\n",
      "3863/5349 [====================>.........] - ETA: 0s - loss: 0.1829 - accuracy: 0.9058\n",
      "3951/5349 [=====================>........] - ETA: 0s - loss: 0.1827 - accuracy: 0.9059\n",
      "4053/5349 [=====================>........] - ETA: 0s - loss: 0.1825 - accuracy: 0.9061\n",
      "4163/5349 [======================>.......] - ETA: 0s - loss: 0.1825 - accuracy: 0.9060\n",
      "4254/5349 [======================>.......] - ETA: 0s - loss: 0.1823 - accuracy: 0.9060\n",
      "4340/5349 [=======================>......] - ETA: 0s - loss: 0.1822 - accuracy: 0.9060\n",
      "4389/5349 [=======================>......] - ETA: 0s - loss: 0.1822 - accuracy: 0.9060\n",
      "4449/5349 [=======================>......] - ETA: 0s - loss: 0.1821 - accuracy: 0.9060\n",
      "4533/5349 [========================>.....] - ETA: 0s - loss: 0.1819 - accuracy: 0.9061\n",
      "4653/5349 [=========================>....] - ETA: 0s - loss: 0.1818 - accuracy: 0.9061\n",
      "4767/5349 [=========================>....] - ETA: 0s - loss: 0.1818 - accuracy: 0.9060\n",
      "4907/5349 [==========================>...] - ETA: 0s - loss: 0.1816 - accuracy: 0.9060\n",
      "5080/5349 [===========================>..] - ETA: 0s - loss: 0.1814 - accuracy: 0.9060\n",
      "5178/5349 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9060\n",
      "5279/5349 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9060\n",
      "5349/5349 [==============================] - 5s 941us/step - loss: 0.1811 - accuracy: 0.9061 - val_loss: 0.1734 - val_accuracy: 0.9077\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 3/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.2128 - accuracy: 0.8900\n",
      " 205/5349 [>.............................] - ETA: 2s - loss: 0.1751 - accuracy: 0.9071\n",
      " 539/5349 [==>...........................] - ETA: 2s - loss: 0.1737 - accuracy: 0.9075\n",
      " 750/5349 [===>..........................] - ETA: 2s - loss: 0.1737 - accuracy: 0.9070\n",
      " 987/5349 [====>.........................] - ETA: 1s - loss: 0.1727 - accuracy: 0.9076\n",
      "1210/5349 [=====>........................] - ETA: 1s - loss: 0.1719 - accuracy: 0.9086\n",
      "1441/5349 [=======>......................] - ETA: 1s - loss: 0.1715 - accuracy: 0.9088\n",
      "1668/5349 [========>.....................] - ETA: 1s - loss: 0.1715 - accuracy: 0.9089\n",
      "1875/5349 [=========>....................] - ETA: 1s - loss: 0.1709 - accuracy: 0.9092\n",
      "2083/5349 [==========>...................] - ETA: 1s - loss: 0.1711 - accuracy: 0.9089\n",
      "2258/5349 [===========>..................] - ETA: 1s - loss: 0.1721 - accuracy: 0.9084\n",
      "2582/5349 [=============>................] - ETA: 1s - loss: 0.1721 - accuracy: 0.9081\n",
      "2774/5349 [==============>...............] - ETA: 1s - loss: 0.1720 - accuracy: 0.9081\n",
      "2970/5349 [===============>..............] - ETA: 1s - loss: 0.1722 - accuracy: 0.9078\n",
      "3190/5349 [================>.............] - ETA: 1s - loss: 0.1719 - accuracy: 0.9080\n",
      "3424/5349 [==================>...........] - ETA: 0s - loss: 0.1717 - accuracy: 0.9080\n",
      "3658/5349 [===================>..........] - ETA: 0s - loss: 0.1717 - accuracy: 0.9081\n",
      "3879/5349 [====================>.........] - ETA: 0s - loss: 0.1714 - accuracy: 0.9083\n",
      "4071/5349 [=====================>........] - ETA: 0s - loss: 0.1714 - accuracy: 0.9083\n",
      "4387/5349 [=======================>......] - ETA: 0s - loss: 0.1716 - accuracy: 0.9081\n",
      "4615/5349 [========================>.....] - ETA: 0s - loss: 0.1713 - accuracy: 0.9081\n",
      "4854/5349 [==========================>...] - ETA: 0s - loss: 0.1711 - accuracy: 0.9084\n",
      "5084/5349 [===========================>..] - ETA: 0s - loss: 0.1711 - accuracy: 0.9084\n",
      "5280/5349 [============================>.] - ETA: 0s - loss: 0.1709 - accuracy: 0.9085\n",
      "5349/5349 [==============================] - 4s 674us/step - loss: 0.1708 - accuracy: 0.9085 - val_loss: 0.1673 - val_accuracy: 0.9096\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1668 - accuracy: 0.9100\n",
      " 104/5349 [..............................] - ETA: 5s - loss: 0.1661 - accuracy: 0.9094\n",
      " 115/5349 [..............................] - ETA: 6s - loss: 0.1672 - accuracy: 0.9088\n",
      " 179/5349 [>.............................] - ETA: 7s - loss: 0.1663 - accuracy: 0.9104\n",
      " 312/5349 [>.............................] - ETA: 5s - loss: 0.1644 - accuracy: 0.9102\n",
      " 481/5349 [=>............................] - ETA: 4s - loss: 0.1657 - accuracy: 0.9083\n",
      " 699/5349 [==>...........................] - ETA: 3s - loss: 0.1667 - accuracy: 0.9084\n",
      " 922/5349 [====>.........................] - ETA: 3s - loss: 0.1666 - accuracy: 0.9088\n",
      "1037/5349 [====>.........................] - ETA: 2s - loss: 0.1664 - accuracy: 0.9088\n",
      "1262/5349 [======>.......................] - ETA: 2s - loss: 0.1661 - accuracy: 0.9091\n",
      "1493/5349 [=======>......................] - ETA: 2s - loss: 0.1662 - accuracy: 0.9092\n",
      "1729/5349 [========>.....................] - ETA: 2s - loss: 0.1671 - accuracy: 0.9092\n",
      "1964/5349 [==========>...................] - ETA: 1s - loss: 0.1670 - accuracy: 0.9094\n",
      "2187/5349 [===========>..................] - ETA: 1s - loss: 0.1670 - accuracy: 0.9093\n",
      "2415/5349 [============>.................] - ETA: 1s - loss: 0.1673 - accuracy: 0.9093\n",
      "2633/5349 [=============>................] - ETA: 1s - loss: 0.1669 - accuracy: 0.9097\n",
      "2948/5349 [===============>..............] - ETA: 1s - loss: 0.1668 - accuracy: 0.9100\n",
      "3179/5349 [================>.............] - ETA: 1s - loss: 0.1667 - accuracy: 0.9100\n",
      "3366/5349 [=================>............] - ETA: 1s - loss: 0.1668 - accuracy: 0.9099\n",
      "3567/5349 [===================>..........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9098\n",
      "3737/5349 [===================>..........] - ETA: 0s - loss: 0.1670 - accuracy: 0.9096\n",
      "3948/5349 [=====================>........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9098\n",
      "4186/5349 [======================>.......] - ETA: 0s - loss: 0.1667 - accuracy: 0.9098\n",
      "4334/5349 [=======================>......] - ETA: 0s - loss: 0.1665 - accuracy: 0.9100\n",
      "4383/5349 [=======================>......] - ETA: 0s - loss: 0.1664 - accuracy: 0.9100\n",
      "4399/5349 [=======================>......] - ETA: 0s - loss: 0.1664 - accuracy: 0.9101\n",
      "4417/5349 [=======================>......] - ETA: 0s - loss: 0.1664 - accuracy: 0.9100\n",
      "4457/5349 [=======================>......] - ETA: 0s - loss: 0.1664 - accuracy: 0.9101\n",
      "4466/5349 [========================>.....] - ETA: 0s - loss: 0.1664 - accuracy: 0.9100\n",
      "4484/5349 [========================>.....] - ETA: 0s - loss: 0.1664 - accuracy: 0.9100\n",
      "4516/5349 [========================>.....] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "4567/5349 [========================>.....] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "4611/5349 [========================>.....] - ETA: 0s - loss: 0.1662 - accuracy: 0.9102\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "4705/5349 [=========================>....] - ETA: 0s - loss: 0.1662 - accuracy: 0.9102\n",
      "4748/5349 [=========================>....] - ETA: 0s - loss: 0.1662 - accuracy: 0.9102\n",
      "4802/5349 [=========================>....] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "4854/5349 [==========================>...] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "4899/5349 [==========================>...] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "4953/5349 [==========================>...] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "4996/5349 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "5023/5349 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "5062/5349 [===========================>..] - ETA: 0s - loss: 0.1662 - accuracy: 0.9102\n",
      "5140/5349 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "5155/5349 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "5175/5349 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9101\n",
      "5207/5349 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "5213/5349 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "5271/5349 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "5291/5349 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9102\n",
      "5321/5349 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9103\n",
      "5338/5349 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9103\n",
      "5349/5349 [==============================] - 9s 2ms/step - loss: 0.1662 - accuracy: 0.9103 - val_loss: 0.1636 - val_accuracy: 0.9118\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 5/20\n",
      "  63/5349 [..............................] - ETA: 4s - loss: 0.1666 - accuracy: 0.9108 \n",
      "  89/5349 [..............................] - ETA: 6s - loss: 0.1656 - accuracy: 0.9120\n",
      " 176/5349 [..............................] - ETA: 5s - loss: 0.1625 - accuracy: 0.9127\n",
      " 351/5349 [>.............................] - ETA: 4s - loss: 0.1621 - accuracy: 0.9137\n",
      " 540/5349 [==>...........................] - ETA: 3s - loss: 0.1628 - accuracy: 0.9123\n",
      " 755/5349 [===>..........................] - ETA: 3s - loss: 0.1626 - accuracy: 0.9126\n",
      " 960/5349 [====>.........................] - ETA: 2s - loss: 0.1639 - accuracy: 0.9117\n",
      "1268/5349 [======>.......................] - ETA: 2s - loss: 0.1641 - accuracy: 0.9115\n",
      "1485/5349 [=======>......................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9112\n",
      "1700/5349 [========>.....................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9110\n",
      "1938/5349 [=========>....................] - ETA: 1s - loss: 0.1648 - accuracy: 0.9109\n",
      "2177/5349 [===========>..................] - ETA: 1s - loss: 0.1647 - accuracy: 0.9109\n",
      "2415/5349 [============>.................] - ETA: 1s - loss: 0.1643 - accuracy: 0.9114\n",
      "2659/5349 [=============>................] - ETA: 1s - loss: 0.1638 - accuracy: 0.9117\n",
      "2888/5349 [===============>..............] - ETA: 1s - loss: 0.1638 - accuracy: 0.9119\n",
      "3128/5349 [================>.............] - ETA: 1s - loss: 0.1635 - accuracy: 0.9120\n",
      "3486/5349 [==================>...........] - ETA: 0s - loss: 0.1638 - accuracy: 0.9119\n",
      "3721/5349 [===================>..........] - ETA: 0s - loss: 0.1640 - accuracy: 0.9118\n",
      "3957/5349 [=====================>........] - ETA: 0s - loss: 0.1639 - accuracy: 0.9118\n",
      "4185/5349 [======================>.......] - ETA: 0s - loss: 0.1638 - accuracy: 0.9118\n",
      "4407/5349 [=======================>......] - ETA: 0s - loss: 0.1635 - accuracy: 0.9120\n",
      "4578/5349 [========================>.....] - ETA: 0s - loss: 0.1633 - accuracy: 0.9120\n",
      "4778/5349 [=========================>....] - ETA: 0s - loss: 0.1633 - accuracy: 0.9120\n",
      "5012/5349 [===========================>..] - ETA: 0s - loss: 0.1632 - accuracy: 0.9120\n",
      "5236/5349 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9121\n",
      "5349/5349 [==============================] - 4s 739us/step - loss: 0.1629 - accuracy: 0.9121 - val_loss: 0.1610 - val_accuracy: 0.9132\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 6/20\n",
      " 116/5349 [..............................] - ETA: 2s - loss: 0.1605 - accuracy: 0.9119\n",
      " 329/5349 [>.............................] - ETA: 2s - loss: 0.1618 - accuracy: 0.9127\n",
      " 558/5349 [==>...........................] - ETA: 2s - loss: 0.1619 - accuracy: 0.9126\n",
      " 773/5349 [===>..........................] - ETA: 2s - loss: 0.1621 - accuracy: 0.9124\n",
      " 997/5349 [====>.........................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9130\n",
      "1225/5349 [=====>........................] - ETA: 1s - loss: 0.1609 - accuracy: 0.9129\n",
      "1339/5349 [======>.......................] - ETA: 1s - loss: 0.1614 - accuracy: 0.9127\n",
      "1568/5349 [=======>......................] - ETA: 1s - loss: 0.1610 - accuracy: 0.9127\n",
      "1777/5349 [========>.....................] - ETA: 1s - loss: 0.1612 - accuracy: 0.9127\n",
      "2006/5349 [==========>...................] - ETA: 1s - loss: 0.1613 - accuracy: 0.9125\n",
      "2189/5349 [===========>..................] - ETA: 1s - loss: 0.1616 - accuracy: 0.9124\n",
      "2400/5349 [============>.................] - ETA: 1s - loss: 0.1615 - accuracy: 0.9126\n",
      "2597/5349 [=============>................] - ETA: 1s - loss: 0.1615 - accuracy: 0.9126\n",
      "2802/5349 [==============>...............] - ETA: 1s - loss: 0.1619 - accuracy: 0.9123\n",
      "2903/5349 [===============>..............] - ETA: 1s - loss: 0.1618 - accuracy: 0.9123\n",
      "3115/5349 [================>.............] - ETA: 1s - loss: 0.1615 - accuracy: 0.9124\n",
      "3316/5349 [=================>............] - ETA: 0s - loss: 0.1613 - accuracy: 0.9125\n",
      "3545/5349 [==================>...........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9126\n",
      "3762/5349 [====================>.........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9128\n",
      "3900/5349 [====================>.........] - ETA: 0s - loss: 0.1610 - accuracy: 0.9130\n",
      "4100/5349 [=====================>........] - ETA: 0s - loss: 0.1609 - accuracy: 0.9131\n",
      "4323/5349 [=======================>......] - ETA: 0s - loss: 0.1608 - accuracy: 0.9132\n",
      "4560/5349 [========================>.....] - ETA: 0s - loss: 0.1609 - accuracy: 0.9131\n",
      "4799/5349 [=========================>....] - ETA: 0s - loss: 0.1608 - accuracy: 0.9132\n",
      "5146/5349 [===========================>..] - ETA: 0s - loss: 0.1605 - accuracy: 0.9135\n",
      "5266/5349 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9135\n",
      "5349/5349 [==============================] - 4s 794us/step - loss: 0.1605 - accuracy: 0.9135 - val_loss: 0.1589 - val_accuracy: 0.9147\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 7/20\n",
      "  87/5349 [..............................] - ETA: 3s - loss: 0.1627 - accuracy: 0.9103\n",
      " 187/5349 [>.............................] - ETA: 4s - loss: 0.1604 - accuracy: 0.9124\n",
      " 223/5349 [>.............................] - ETA: 6s - loss: 0.1599 - accuracy: 0.9129\n",
      " 250/5349 [>.............................] - ETA: 7s - loss: 0.1605 - accuracy: 0.9124\n",
      " 312/5349 [>.............................] - ETA: 7s - loss: 0.1597 - accuracy: 0.9127\n",
      " 331/5349 [>.............................] - ETA: 7s - loss: 0.1600 - accuracy: 0.9124\n",
      " 372/5349 [=>............................] - ETA: 8s - loss: 0.1606 - accuracy: 0.9125\n",
      " 432/5349 [=>............................] - ETA: 8s - loss: 0.1607 - accuracy: 0.9132\n",
      " 459/5349 [=>............................] - ETA: 8s - loss: 0.1597 - accuracy: 0.9140\n",
      " 471/5349 [=>............................] - ETA: 9s - loss: 0.1596 - accuracy: 0.9143\n",
      " 519/5349 [=>............................] - ETA: 9s - loss: 0.1593 - accuracy: 0.9150 \n",
      " 574/5349 [==>...........................] - ETA: 9s - loss: 0.1592 - accuracy: 0.9151\n",
      " 647/5349 [==>...........................] - ETA: 9s - loss: 0.1593 - accuracy: 0.9151\n",
      " 683/5349 [==>...........................] - ETA: 9s - loss: 0.1590 - accuracy: 0.9155\n",
      " 729/5349 [===>..........................] - ETA: 9s - loss: 0.1597 - accuracy: 0.9150\n",
      " 742/5349 [===>..........................] - ETA: 9s - loss: 0.1595 - accuracy: 0.9151\n",
      " 752/5349 [===>..........................] - ETA: 10s - loss: 0.1596 - accuracy: 0.9151\n",
      " 758/5349 [===>..........................] - ETA: 10s - loss: 0.1595 - accuracy: 0.9151\n",
      " 791/5349 [===>..........................] - ETA: 10s - loss: 0.1592 - accuracy: 0.9150\n",
      " 843/5349 [===>..........................] - ETA: 10s - loss: 0.1591 - accuracy: 0.9151\n",
      " 863/5349 [===>..........................] - ETA: 10s - loss: 0.1588 - accuracy: 0.9153\n",
      " 897/5349 [====>.........................] - ETA: 10s - loss: 0.1588 - accuracy: 0.9152\n",
      " 939/5349 [====>.........................] - ETA: 10s - loss: 0.1586 - accuracy: 0.9151\n",
      " 983/5349 [====>.........................] - ETA: 10s - loss: 0.1590 - accuracy: 0.9148\n",
      "1014/5349 [====>.........................] - ETA: 10s - loss: 0.1591 - accuracy: 0.9147\n",
      "1044/5349 [====>.........................] - ETA: 10s - loss: 0.1591 - accuracy: 0.9149\n",
      "1091/5349 [=====>........................] - ETA: 10s - loss: 0.1594 - accuracy: 0.9147\n",
      "1129/5349 [=====>........................] - ETA: 10s - loss: 0.1595 - accuracy: 0.9146\n",
      "1166/5349 [=====>........................] - ETA: 10s - loss: 0.1594 - accuracy: 0.9146\n",
      "1232/5349 [=====>........................] - ETA: 10s - loss: 0.1590 - accuracy: 0.9149\n",
      "1274/5349 [======>.......................] - ETA: 9s - loss: 0.1590 - accuracy: 0.9148 \n",
      "1324/5349 [======>.......................] - ETA: 9s - loss: 0.1590 - accuracy: 0.9148\n",
      "1373/5349 [======>.......................] - ETA: 9s - loss: 0.1591 - accuracy: 0.9147\n",
      "1488/5349 [=======>......................] - ETA: 8s - loss: 0.1592 - accuracy: 0.9148\n",
      "1611/5349 [========>.....................] - ETA: 8s - loss: 0.1594 - accuracy: 0.9146\n",
      "1736/5349 [========>.....................] - ETA: 7s - loss: 0.1598 - accuracy: 0.9144\n",
      "1874/5349 [=========>....................] - ETA: 6s - loss: 0.1596 - accuracy: 0.9145\n",
      "1959/5349 [=========>....................] - ETA: 6s - loss: 0.1597 - accuracy: 0.9144\n",
      "2186/5349 [===========>..................] - ETA: 5s - loss: 0.1593 - accuracy: 0.9146\n",
      "2449/5349 [============>.................] - ETA: 4s - loss: 0.1596 - accuracy: 0.9146\n",
      "2703/5349 [==============>...............] - ETA: 3s - loss: 0.1595 - accuracy: 0.9147\n",
      "2962/5349 [===============>..............] - ETA: 3s - loss: 0.1593 - accuracy: 0.9146\n",
      "3217/5349 [=================>............] - ETA: 2s - loss: 0.1591 - accuracy: 0.9147\n",
      "3482/5349 [==================>...........] - ETA: 2s - loss: 0.1589 - accuracy: 0.9147\n",
      "3687/5349 [===================>..........] - ETA: 2s - loss: 0.1590 - accuracy: 0.9146\n",
      "3913/5349 [====================>.........] - ETA: 1s - loss: 0.1591 - accuracy: 0.9144\n",
      "4141/5349 [======================>.......] - ETA: 1s - loss: 0.1590 - accuracy: 0.9144\n",
      "4377/5349 [=======================>......] - ETA: 1s - loss: 0.1591 - accuracy: 0.9142\n",
      "4729/5349 [=========================>....] - ETA: 0s - loss: 0.1590 - accuracy: 0.9143\n",
      "4983/5349 [==========================>...] - ETA: 0s - loss: 0.1588 - accuracy: 0.9144\n",
      "5240/5349 [============================>.] - ETA: 0s - loss: 0.1587 - accuracy: 0.9145\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1587 - accuracy: 0.9145 - val_loss: 0.1572 - val_accuracy: 0.9152\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.2039 - accuracy: 0.9000\n",
      " 172/5349 [..............................] - ETA: 3s - loss: 0.1581 - accuracy: 0.9148\n",
      " 341/5349 [>.............................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9148\n",
      " 551/5349 [==>...........................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9157\n",
      " 664/5349 [==>...........................] - ETA: 2s - loss: 0.1571 - accuracy: 0.9152\n",
      " 951/5349 [====>.........................] - ETA: 2s - loss: 0.1569 - accuracy: 0.9153\n",
      "1126/5349 [=====>........................] - ETA: 2s - loss: 0.1568 - accuracy: 0.9153\n",
      "1356/5349 [======>.......................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9150\n",
      "1597/5349 [=======>......................] - ETA: 2s - loss: 0.1570 - accuracy: 0.9154\n",
      "1833/5349 [=========>....................] - ETA: 1s - loss: 0.1574 - accuracy: 0.9151\n",
      "2074/5349 [==========>...................] - ETA: 1s - loss: 0.1574 - accuracy: 0.9151\n",
      "2282/5349 [===========>..................] - ETA: 1s - loss: 0.1577 - accuracy: 0.9148\n",
      "2505/5349 [=============>................] - ETA: 1s - loss: 0.1575 - accuracy: 0.9150\n",
      "2743/5349 [==============>...............] - ETA: 1s - loss: 0.1576 - accuracy: 0.9148\n",
      "3104/5349 [================>.............] - ETA: 1s - loss: 0.1577 - accuracy: 0.9148\n",
      "3328/5349 [=================>............] - ETA: 0s - loss: 0.1575 - accuracy: 0.9150\n",
      "3562/5349 [==================>...........] - ETA: 0s - loss: 0.1575 - accuracy: 0.9150\n",
      "3777/5349 [====================>.........] - ETA: 0s - loss: 0.1574 - accuracy: 0.9150\n",
      "3982/5349 [=====================>........] - ETA: 0s - loss: 0.1574 - accuracy: 0.9150\n",
      "4205/5349 [======================>.......] - ETA: 0s - loss: 0.1571 - accuracy: 0.9151\n",
      "4441/5349 [=======================>......] - ETA: 0s - loss: 0.1572 - accuracy: 0.9151\n",
      "4679/5349 [=========================>....] - ETA: 0s - loss: 0.1571 - accuracy: 0.9150\n",
      "5007/5349 [===========================>..] - ETA: 0s - loss: 0.1572 - accuracy: 0.9150\n",
      "5240/5349 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9151\n",
      "5349/5349 [==============================] - 3s 642us/step - loss: 0.1571 - accuracy: 0.9151 - val_loss: 0.1558 - val_accuracy: 0.9159\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 9/20\n",
      " 114/5349 [..............................] - ETA: 2s - loss: 0.1568 - accuracy: 0.9159\n",
      " 344/5349 [>.............................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9158\n",
      " 573/5349 [==>...........................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9151\n",
      " 807/5349 [===>..........................] - ETA: 1s - loss: 0.1562 - accuracy: 0.9151\n",
      "1049/5349 [====>.........................] - ETA: 1s - loss: 0.1564 - accuracy: 0.9152\n",
      "1287/5349 [======>.......................] - ETA: 1s - loss: 0.1562 - accuracy: 0.9157\n",
      "1531/5349 [=======>......................] - ETA: 1s - loss: 0.1562 - accuracy: 0.9159\n",
      "1762/5349 [========>.....................] - ETA: 1s - loss: 0.1558 - accuracy: 0.9160\n",
      "2118/5349 [==========>...................] - ETA: 1s - loss: 0.1561 - accuracy: 0.9158\n",
      "2358/5349 [============>.................] - ETA: 1s - loss: 0.1559 - accuracy: 0.9158\n",
      "2601/5349 [=============>................] - ETA: 1s - loss: 0.1560 - accuracy: 0.9157\n",
      "2840/5349 [==============>...............] - ETA: 1s - loss: 0.1557 - accuracy: 0.9160\n",
      "3079/5349 [================>.............] - ETA: 0s - loss: 0.1558 - accuracy: 0.9159\n",
      "3320/5349 [=================>............] - ETA: 0s - loss: 0.1557 - accuracy: 0.9160\n",
      "3561/5349 [==================>...........] - ETA: 0s - loss: 0.1561 - accuracy: 0.9157\n",
      "3785/5349 [====================>.........] - ETA: 0s - loss: 0.1561 - accuracy: 0.9157\n",
      "3988/5349 [=====================>........] - ETA: 0s - loss: 0.1561 - accuracy: 0.9157\n",
      "4316/5349 [=======================>......] - ETA: 0s - loss: 0.1560 - accuracy: 0.9155\n",
      "4531/5349 [========================>.....] - ETA: 0s - loss: 0.1559 - accuracy: 0.9156\n",
      "4744/5349 [=========================>....] - ETA: 0s - loss: 0.1560 - accuracy: 0.9155\n",
      "4915/5349 [==========================>...] - ETA: 0s - loss: 0.1560 - accuracy: 0.9155\n",
      "5083/5349 [===========================>..] - ETA: 0s - loss: 0.1557 - accuracy: 0.9157\n",
      "5233/5349 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9156\n",
      "5323/5349 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9155\n",
      "5349/5349 [==============================] - 4s 730us/step - loss: 0.1559 - accuracy: 0.9156 - val_loss: 0.1547 - val_accuracy: 0.9164\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 10/20\n",
      " 100/5349 [..............................] - ETA: 2s - loss: 0.1564 - accuracy: 0.9148\n",
      " 283/5349 [>.............................] - ETA: 2s - loss: 0.1527 - accuracy: 0.9167\n",
      " 399/5349 [=>............................] - ETA: 3s - loss: 0.1533 - accuracy: 0.9166\n",
      " 463/5349 [=>............................] - ETA: 3s - loss: 0.1533 - accuracy: 0.9169\n",
      " 594/5349 [==>...........................] - ETA: 3s - loss: 0.1531 - accuracy: 0.9166\n",
      " 705/5349 [==>...........................] - ETA: 3s - loss: 0.1539 - accuracy: 0.9161\n",
      " 851/5349 [===>..........................] - ETA: 3s - loss: 0.1543 - accuracy: 0.9162\n",
      "1030/5349 [====>.........................] - ETA: 2s - loss: 0.1544 - accuracy: 0.9159\n",
      "1261/5349 [======>.......................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9159\n",
      "1604/5349 [=======>......................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9160\n",
      "1811/5349 [=========>....................] - ETA: 2s - loss: 0.1552 - accuracy: 0.9159\n",
      "2039/5349 [==========>...................] - ETA: 1s - loss: 0.1551 - accuracy: 0.9159\n",
      "2270/5349 [===========>..................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9161\n",
      "2505/5349 [=============>................] - ETA: 1s - loss: 0.1550 - accuracy: 0.9159\n",
      "2715/5349 [==============>...............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9158\n",
      "2870/5349 [===============>..............] - ETA: 1s - loss: 0.1553 - accuracy: 0.9156\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1552 - accuracy: 0.9156\n",
      "2981/5349 [===============>..............] - ETA: 1s - loss: 0.1551 - accuracy: 0.9157\n",
      "3049/5349 [================>.............] - ETA: 1s - loss: 0.1550 - accuracy: 0.9158\n",
      "3113/5349 [================>.............] - ETA: 1s - loss: 0.1549 - accuracy: 0.9160\n",
      "3155/5349 [================>.............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9160\n",
      "3191/5349 [================>.............] - ETA: 1s - loss: 0.1549 - accuracy: 0.9160\n",
      "3239/5349 [=================>............] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "3311/5349 [=================>............] - ETA: 1s - loss: 0.1550 - accuracy: 0.9158\n",
      "3394/5349 [==================>...........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "3447/5349 [==================>...........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "3491/5349 [==================>...........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "3544/5349 [==================>...........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "3597/5349 [===================>..........] - ETA: 1s - loss: 0.1550 - accuracy: 0.9159\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.1550 - accuracy: 0.9159\n",
      "3657/5349 [===================>..........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "3695/5349 [===================>..........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9159\n",
      "3757/5349 [====================>.........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9160\n",
      "3809/5349 [====================>.........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "3839/5349 [====================>.........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "3875/5349 [====================>.........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "3910/5349 [====================>.........] - ETA: 1s - loss: 0.1549 - accuracy: 0.9158\n",
      "3955/5349 [=====================>........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "4016/5349 [=====================>........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "4064/5349 [=====================>........] - ETA: 1s - loss: 0.1548 - accuracy: 0.9158\n",
      "4119/5349 [======================>.......] - ETA: 1s - loss: 0.1548 - accuracy: 0.9159\n",
      "4153/5349 [======================>.......] - ETA: 1s - loss: 0.1548 - accuracy: 0.9158\n",
      "4194/5349 [======================>.......] - ETA: 1s - loss: 0.1548 - accuracy: 0.9158\n",
      "4258/5349 [======================>.......] - ETA: 1s - loss: 0.1549 - accuracy: 0.9157\n",
      "4395/5349 [=======================>......] - ETA: 1s - loss: 0.1547 - accuracy: 0.9159\n",
      "4535/5349 [========================>.....] - ETA: 0s - loss: 0.1548 - accuracy: 0.9158\n",
      "4676/5349 [=========================>....] - ETA: 0s - loss: 0.1548 - accuracy: 0.9159\n",
      "4799/5349 [=========================>....] - ETA: 0s - loss: 0.1547 - accuracy: 0.9160\n",
      "4882/5349 [==========================>...] - ETA: 0s - loss: 0.1548 - accuracy: 0.9159\n",
      "5132/5349 [===========================>..] - ETA: 0s - loss: 0.1547 - accuracy: 0.9159\n",
      "5262/5349 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9159\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1548 - accuracy: 0.9159 - val_loss: 0.1537 - val_accuracy: 0.9166\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 11/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1511 - accuracy: 0.9300\n",
      " 210/5349 [>.............................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9165\n",
      " 398/5349 [=>............................] - ETA: 2s - loss: 0.1560 - accuracy: 0.9160\n",
      " 579/5349 [==>...........................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9165\n",
      " 695/5349 [==>...........................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9166\n",
      " 804/5349 [===>..........................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9163\n",
      " 957/5349 [====>.........................] - ETA: 2s - loss: 0.1540 - accuracy: 0.9165\n",
      "1088/5349 [=====>........................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9165\n",
      "1148/5349 [=====>........................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9166\n",
      "1277/5349 [======>.......................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9166\n",
      "1426/5349 [======>.......................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9165\n",
      "1561/5349 [=======>......................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9164\n",
      "1746/5349 [========>.....................] - ETA: 2s - loss: 0.1536 - accuracy: 0.9164\n",
      "1837/5349 [=========>....................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9162\n",
      "1895/5349 [=========>....................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9161\n",
      "2052/5349 [==========>...................] - ETA: 2s - loss: 0.1541 - accuracy: 0.9159\n",
      "2236/5349 [===========>..................] - ETA: 2s - loss: 0.1541 - accuracy: 0.9160\n",
      "2470/5349 [============>.................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9159\n",
      "2708/5349 [==============>...............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9158\n",
      "2923/5349 [===============>..............] - ETA: 1s - loss: 0.1545 - accuracy: 0.9159\n",
      "3152/5349 [================>.............] - ETA: 1s - loss: 0.1546 - accuracy: 0.9158\n",
      "3376/5349 [=================>............] - ETA: 1s - loss: 0.1541 - accuracy: 0.9162\n",
      "3615/5349 [===================>..........] - ETA: 1s - loss: 0.1540 - accuracy: 0.9163\n",
      "3854/5349 [====================>.........] - ETA: 0s - loss: 0.1543 - accuracy: 0.9161\n",
      "4089/5349 [=====================>........] - ETA: 0s - loss: 0.1541 - accuracy: 0.9162\n",
      "4434/5349 [=======================>......] - ETA: 0s - loss: 0.1540 - accuracy: 0.9163\n",
      "4639/5349 [=========================>....] - ETA: 0s - loss: 0.1540 - accuracy: 0.9163\n",
      "4849/5349 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.9163\n",
      "5076/5349 [===========================>..] - ETA: 0s - loss: 0.1540 - accuracy: 0.9162\n",
      "5304/5349 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9163\n",
      "5349/5349 [==============================] - 4s 717us/step - loss: 0.1539 - accuracy: 0.9163 - val_loss: 0.1529 - val_accuracy: 0.9170\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 12/20\n",
      " 113/5349 [..............................] - ETA: 2s - loss: 0.1593 - accuracy: 0.9132\n",
      " 347/5349 [>.............................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9152\n",
      " 464/5349 [=>............................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9148\n",
      " 704/5349 [==>...........................] - ETA: 1s - loss: 0.1545 - accuracy: 0.9160\n",
      " 943/5349 [====>.........................] - ETA: 1s - loss: 0.1537 - accuracy: 0.9166\n",
      "1163/5349 [=====>........................] - ETA: 1s - loss: 0.1537 - accuracy: 0.9163\n",
      "1386/5349 [======>.......................] - ETA: 1s - loss: 0.1537 - accuracy: 0.9161\n",
      "1611/5349 [========>.....................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9159\n",
      "1842/5349 [=========>....................] - ETA: 1s - loss: 0.1538 - accuracy: 0.9160\n",
      "2064/5349 [==========>...................] - ETA: 1s - loss: 0.1537 - accuracy: 0.9160\n",
      "2292/5349 [===========>..................] - ETA: 1s - loss: 0.1536 - accuracy: 0.9162\n",
      "2524/5349 [=============>................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9164\n",
      "2709/5349 [==============>...............] - ETA: 1s - loss: 0.1532 - accuracy: 0.9167\n",
      "2827/5349 [==============>...............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9168\n",
      "3050/5349 [================>.............] - ETA: 1s - loss: 0.1529 - accuracy: 0.9169\n",
      "3280/5349 [=================>............] - ETA: 0s - loss: 0.1529 - accuracy: 0.9168\n",
      "3518/5349 [==================>...........] - ETA: 0s - loss: 0.1530 - accuracy: 0.9166\n",
      "3747/5349 [====================>.........] - ETA: 0s - loss: 0.1528 - accuracy: 0.9169\n",
      "3972/5349 [=====================>........] - ETA: 0s - loss: 0.1526 - accuracy: 0.9171\n",
      "4188/5349 [======================>.......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9169\n",
      "4419/5349 [=======================>......] - ETA: 0s - loss: 0.1528 - accuracy: 0.9169\n",
      "4567/5349 [========================>.....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9169\n",
      "4583/5349 [========================>.....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9168\n",
      "4649/5349 [=========================>....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9168\n",
      "4800/5349 [=========================>....] - ETA: 0s - loss: 0.1529 - accuracy: 0.9168\n",
      "4951/5349 [==========================>...] - ETA: 0s - loss: 0.1529 - accuracy: 0.9168\n",
      "5083/5349 [===========================>..] - ETA: 0s - loss: 0.1530 - accuracy: 0.9167\n",
      "5145/5349 [===========================>..] - ETA: 0s - loss: 0.1531 - accuracy: 0.9166\n",
      "5289/5349 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9166\n",
      "5349/5349 [==============================] - 4s 687us/step - loss: 0.1531 - accuracy: 0.9166 - val_loss: 0.1521 - val_accuracy: 0.9174\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1500 - accuracy: 0.9000\n",
      " 231/5349 [>.............................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9181\n",
      " 467/5349 [=>............................] - ETA: 2s - loss: 0.1511 - accuracy: 0.9183\n",
      " 583/5349 [==>...........................] - ETA: 2s - loss: 0.1523 - accuracy: 0.9179\n",
      " 762/5349 [===>..........................] - ETA: 2s - loss: 0.1523 - accuracy: 0.9176\n",
      " 938/5349 [====>.........................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9168\n",
      "1178/5349 [=====>........................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9168\n",
      "1397/5349 [======>.......................] - ETA: 1s - loss: 0.1530 - accuracy: 0.9169\n",
      "1593/5349 [=======>......................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9169\n",
      "1825/5349 [=========>....................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9171\n",
      "2138/5349 [==========>...................] - ETA: 1s - loss: 0.1525 - accuracy: 0.9171\n",
      "2341/5349 [============>.................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9170\n",
      "2574/5349 [=============>................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9168\n",
      "2801/5349 [==============>...............] - ETA: 1s - loss: 0.1525 - accuracy: 0.9170\n",
      "3020/5349 [===============>..............] - ETA: 1s - loss: 0.1525 - accuracy: 0.9171\n",
      "3242/5349 [=================>............] - ETA: 0s - loss: 0.1523 - accuracy: 0.9171\n",
      "3464/5349 [==================>...........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9171\n",
      "3700/5349 [===================>..........] - ETA: 0s - loss: 0.1524 - accuracy: 0.9171\n",
      "3933/5349 [=====================>........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9172\n",
      "4167/5349 [======================>.......] - ETA: 0s - loss: 0.1523 - accuracy: 0.9172\n",
      "4521/5349 [========================>.....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9171\n",
      "4753/5349 [=========================>....] - ETA: 0s - loss: 0.1523 - accuracy: 0.9171\n",
      "4982/5349 [==========================>...] - ETA: 0s - loss: 0.1522 - accuracy: 0.9172\n",
      "5219/5349 [============================>.] - ETA: 0s - loss: 0.1523 - accuracy: 0.9172\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1524 - accuracy: 0.9171\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1524 - accuracy: 0.9171 - val_loss: 0.1514 - val_accuracy: 0.9178\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 14/20\n",
      "  11/5349 [..............................] - ETA: 29s - loss: 0.1360 - accuracy: 0.9273\n",
      "  85/5349 [..............................] - ETA: 10s - loss: 0.1526 - accuracy: 0.9165\n",
      " 196/5349 [>.............................] - ETA: 7s - loss: 0.1539 - accuracy: 0.9142\n",
      " 274/5349 [>.............................] - ETA: 6s - loss: 0.1531 - accuracy: 0.9146\n",
      " 413/5349 [=>............................] - ETA: 5s - loss: 0.1544 - accuracy: 0.9145\n",
      " 632/5349 [==>...........................] - ETA: 4s - loss: 0.1541 - accuracy: 0.9148\n",
      " 861/5349 [===>..........................] - ETA: 3s - loss: 0.1536 - accuracy: 0.9157\n",
      "1090/5349 [=====>........................] - ETA: 3s - loss: 0.1530 - accuracy: 0.9164\n",
      "1338/5349 [======>.......................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9164\n",
      "1713/5349 [========>.....................] - ETA: 2s - loss: 0.1534 - accuracy: 0.9161\n",
      "1961/5349 [=========>....................] - ETA: 1s - loss: 0.1532 - accuracy: 0.9164\n",
      "2217/5349 [===========>..................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9168\n",
      "2462/5349 [============>.................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9167\n",
      "2721/5349 [==============>...............] - ETA: 1s - loss: 0.1526 - accuracy: 0.9167\n",
      "2973/5349 [===============>..............] - ETA: 1s - loss: 0.1523 - accuracy: 0.9169\n",
      "3231/5349 [=================>............] - ETA: 1s - loss: 0.1523 - accuracy: 0.9169\n",
      "3472/5349 [==================>...........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9170\n",
      "3709/5349 [===================>..........] - ETA: 0s - loss: 0.1524 - accuracy: 0.9168\n",
      "3952/5349 [=====================>........] - ETA: 0s - loss: 0.1522 - accuracy: 0.9171\n",
      "4068/5349 [=====================>........] - ETA: 0s - loss: 0.1521 - accuracy: 0.9171\n",
      "4298/5349 [=======================>......] - ETA: 0s - loss: 0.1518 - accuracy: 0.9173\n",
      "4530/5349 [========================>.....] - ETA: 0s - loss: 0.1518 - accuracy: 0.9173\n",
      "4765/5349 [=========================>....] - ETA: 0s - loss: 0.1518 - accuracy: 0.9173\n",
      "4998/5349 [===========================>..] - ETA: 0s - loss: 0.1517 - accuracy: 0.9175\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9175\n",
      "5349/5349 [==============================] - 4s 687us/step - loss: 0.1517 - accuracy: 0.9175 - val_loss: 0.1508 - val_accuracy: 0.9182\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 15/20\n",
      "  99/5349 [..............................] - ETA: 2s - loss: 0.1460 - accuracy: 0.9209\n",
      " 287/5349 [>.............................] - ETA: 2s - loss: 0.1492 - accuracy: 0.9190\n",
      " 504/5349 [=>............................] - ETA: 2s - loss: 0.1486 - accuracy: 0.9194\n",
      " 742/5349 [===>..........................] - ETA: 2s - loss: 0.1504 - accuracy: 0.9183\n",
      " 984/5349 [====>.........................] - ETA: 2s - loss: 0.1510 - accuracy: 0.9180\n",
      "1219/5349 [=====>........................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9182\n",
      "1442/5349 [=======>......................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9181\n",
      "1564/5349 [=======>......................] - ETA: 1s - loss: 0.1508 - accuracy: 0.9181\n",
      "1804/5349 [=========>....................] - ETA: 1s - loss: 0.1510 - accuracy: 0.9180\n",
      "2045/5349 [==========>...................] - ETA: 1s - loss: 0.1513 - accuracy: 0.9180\n",
      "2284/5349 [===========>..................] - ETA: 1s - loss: 0.1516 - accuracy: 0.9177\n",
      "2526/5349 [=============>................] - ETA: 1s - loss: 0.1515 - accuracy: 0.9177\n",
      "2769/5349 [==============>...............] - ETA: 1s - loss: 0.1513 - accuracy: 0.9178\n",
      "3010/5349 [===============>..............] - ETA: 1s - loss: 0.1515 - accuracy: 0.9177\n",
      "3252/5349 [=================>............] - ETA: 0s - loss: 0.1514 - accuracy: 0.9177\n",
      "3496/5349 [==================>...........] - ETA: 0s - loss: 0.1513 - accuracy: 0.9178\n",
      "3736/5349 [===================>..........] - ETA: 0s - loss: 0.1512 - accuracy: 0.9179\n",
      "3976/5349 [=====================>........] - ETA: 0s - loss: 0.1511 - accuracy: 0.9179\n",
      "4088/5349 [=====================>........] - ETA: 0s - loss: 0.1511 - accuracy: 0.9179\n",
      "4306/5349 [=======================>......] - ETA: 0s - loss: 0.1511 - accuracy: 0.9179\n",
      "4547/5349 [========================>.....] - ETA: 0s - loss: 0.1511 - accuracy: 0.9180\n",
      "4789/5349 [=========================>....] - ETA: 0s - loss: 0.1510 - accuracy: 0.9179\n",
      "5031/5349 [===========================>..] - ETA: 0s - loss: 0.1511 - accuracy: 0.9178\n",
      "5275/5349 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.9178\n",
      "5349/5349 [==============================] - 3s 593us/step - loss: 0.1511 - accuracy: 0.9179 - val_loss: 0.1502 - val_accuracy: 0.9185\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 16/20\n",
      " 120/5349 [..............................] - ETA: 2s - loss: 0.1520 - accuracy: 0.9191\n",
      " 362/5349 [=>............................] - ETA: 2s - loss: 0.1502 - accuracy: 0.9187\n",
      " 605/5349 [==>...........................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9188\n",
      " 831/5349 [===>..........................] - ETA: 1s - loss: 0.1501 - accuracy: 0.9189\n",
      "1069/5349 [====>.........................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9185\n",
      "1309/5349 [======>.......................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9188\n",
      "1548/5349 [=======>......................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9190\n",
      "1784/5349 [=========>....................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9187\n",
      "2005/5349 [==========>...................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9189\n",
      "2241/5349 [===========>..................] - ETA: 1s - loss: 0.1498 - accuracy: 0.9190\n",
      "2478/5349 [============>.................] - ETA: 1s - loss: 0.1499 - accuracy: 0.9189\n",
      "2819/5349 [==============>...............] - ETA: 1s - loss: 0.1501 - accuracy: 0.9187\n",
      "3026/5349 [===============>..............] - ETA: 1s - loss: 0.1503 - accuracy: 0.9184\n",
      "3137/5349 [================>.............] - ETA: 0s - loss: 0.1504 - accuracy: 0.9184\n",
      "3299/5349 [=================>............] - ETA: 0s - loss: 0.1504 - accuracy: 0.9184\n",
      "3509/5349 [==================>...........] - ETA: 0s - loss: 0.1503 - accuracy: 0.9184\n",
      "3692/5349 [===================>..........] - ETA: 0s - loss: 0.1505 - accuracy: 0.9182\n",
      "3901/5349 [====================>.........] - ETA: 0s - loss: 0.1505 - accuracy: 0.9183\n",
      "4087/5349 [=====================>........] - ETA: 0s - loss: 0.1506 - accuracy: 0.9182\n",
      "4281/5349 [=======================>......] - ETA: 0s - loss: 0.1506 - accuracy: 0.9183\n",
      "4570/5349 [========================>.....] - ETA: 0s - loss: 0.1507 - accuracy: 0.9181\n",
      "4802/5349 [=========================>....] - ETA: 0s - loss: 0.1507 - accuracy: 0.9181\n",
      "5019/5349 [===========================>..] - ETA: 0s - loss: 0.1506 - accuracy: 0.9182\n",
      "5232/5349 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9181\n",
      "5340/5349 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9182\n",
      "5349/5349 [==============================] - 4s 825us/step - loss: 0.1505 - accuracy: 0.9182 - val_loss: 0.1497 - val_accuracy: 0.9191\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 17/20\n",
      "  27/5349 [..............................] - ETA: 10s - loss: 0.1485 - accuracy: 0.9170\n",
      "  77/5349 [..............................] - ETA: 10s - loss: 0.1483 - accuracy: 0.9200\n",
      " 136/5349 [..............................] - ETA: 9s - loss: 0.1490 - accuracy: 0.9183 \n",
      " 147/5349 [..............................] - ETA: 11s - loss: 0.1481 - accuracy: 0.9185\n",
      " 176/5349 [..............................] - ETA: 12s - loss: 0.1486 - accuracy: 0.9182\n",
      " 221/5349 [>.............................] - ETA: 12s - loss: 0.1494 - accuracy: 0.9177\n",
      " 237/5349 [>.............................] - ETA: 13s - loss: 0.1491 - accuracy: 0.9180\n",
      " 268/5349 [>.............................] - ETA: 14s - loss: 0.1499 - accuracy: 0.9175\n",
      " 297/5349 [>.............................] - ETA: 14s - loss: 0.1502 - accuracy: 0.9171\n",
      " 346/5349 [>.............................] - ETA: 13s - loss: 0.1514 - accuracy: 0.9165\n",
      " 405/5349 [=>............................] - ETA: 12s - loss: 0.1513 - accuracy: 0.9172\n",
      " 497/5349 [=>............................] - ETA: 11s - loss: 0.1511 - accuracy: 0.9178\n",
      " 544/5349 [==>...........................] - ETA: 11s - loss: 0.1506 - accuracy: 0.9183\n",
      " 575/5349 [==>...........................] - ETA: 11s - loss: 0.1503 - accuracy: 0.9186\n",
      " 594/5349 [==>...........................] - ETA: 12s - loss: 0.1502 - accuracy: 0.9186\n",
      " 614/5349 [==>...........................] - ETA: 12s - loss: 0.1499 - accuracy: 0.9186\n",
      " 640/5349 [==>...........................] - ETA: 13s - loss: 0.1500 - accuracy: 0.9186\n",
      " 676/5349 [==>...........................] - ETA: 13s - loss: 0.1500 - accuracy: 0.9188\n",
      " 695/5349 [==>...........................] - ETA: 13s - loss: 0.1503 - accuracy: 0.9184\n",
      " 740/5349 [===>..........................] - ETA: 13s - loss: 0.1510 - accuracy: 0.9180\n",
      " 772/5349 [===>..........................] - ETA: 13s - loss: 0.1509 - accuracy: 0.9179\n",
      " 792/5349 [===>..........................] - ETA: 13s - loss: 0.1506 - accuracy: 0.9181\n",
      " 847/5349 [===>..........................] - ETA: 12s - loss: 0.1503 - accuracy: 0.9182\n",
      " 878/5349 [===>..........................] - ETA: 12s - loss: 0.1508 - accuracy: 0.9179\n",
      " 908/5349 [====>.........................] - ETA: 12s - loss: 0.1506 - accuracy: 0.9180\n",
      " 923/5349 [====>.........................] - ETA: 12s - loss: 0.1506 - accuracy: 0.9179\n",
      "1014/5349 [====>.........................] - ETA: 11s - loss: 0.1502 - accuracy: 0.9180\n",
      "1056/5349 [====>.........................] - ETA: 11s - loss: 0.1499 - accuracy: 0.9183\n",
      "1106/5349 [=====>........................] - ETA: 11s - loss: 0.1498 - accuracy: 0.9184\n",
      "1149/5349 [=====>........................] - ETA: 11s - loss: 0.1500 - accuracy: 0.9183\n",
      "1247/5349 [=====>........................] - ETA: 10s - loss: 0.1498 - accuracy: 0.9184\n",
      "1390/5349 [======>.......................] - ETA: 9s - loss: 0.1497 - accuracy: 0.9186\n",
      "1554/5349 [=======>......................] - ETA: 8s - loss: 0.1500 - accuracy: 0.9184\n",
      "1700/5349 [========>.....................] - ETA: 7s - loss: 0.1500 - accuracy: 0.9186\n",
      "1853/5349 [=========>....................] - ETA: 6s - loss: 0.1499 - accuracy: 0.9186\n",
      "2089/5349 [==========>...................] - ETA: 5s - loss: 0.1499 - accuracy: 0.9187\n",
      "2461/5349 [============>.................] - ETA: 4s - loss: 0.1503 - accuracy: 0.9185\n",
      "2720/5349 [==============>...............] - ETA: 3s - loss: 0.1503 - accuracy: 0.9185\n",
      "2967/5349 [===============>..............] - ETA: 3s - loss: 0.1501 - accuracy: 0.9186\n",
      "3223/5349 [=================>............] - ETA: 2s - loss: 0.1499 - accuracy: 0.9187\n",
      "3477/5349 [==================>...........] - ETA: 2s - loss: 0.1500 - accuracy: 0.9186\n",
      "3716/5349 [===================>..........] - ETA: 1s - loss: 0.1499 - accuracy: 0.9187\n",
      "3968/5349 [=====================>........] - ETA: 1s - loss: 0.1498 - accuracy: 0.9187\n",
      "4226/5349 [======================>.......] - ETA: 1s - loss: 0.1498 - accuracy: 0.9187\n",
      "4475/5349 [========================>.....] - ETA: 0s - loss: 0.1499 - accuracy: 0.9186\n",
      "4725/5349 [=========================>....] - ETA: 0s - loss: 0.1500 - accuracy: 0.9185\n",
      "4978/5349 [==========================>...] - ETA: 0s - loss: 0.1500 - accuracy: 0.9185\n",
      "5237/5349 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9186\n",
      "5349/5349 [==============================] - 6s 1ms/step - loss: 0.1500 - accuracy: 0.9185 - val_loss: 0.1492 - val_accuracy: 0.9189\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.0888 - accuracy: 0.9500\n",
      " 184/5349 [>.............................] - ETA: 2s - loss: 0.1520 - accuracy: 0.9168\n",
      " 363/5349 [=>............................] - ETA: 2s - loss: 0.1525 - accuracy: 0.9166\n",
      " 539/5349 [==>...........................] - ETA: 2s - loss: 0.1505 - accuracy: 0.9185\n",
      " 745/5349 [===>..........................] - ETA: 2s - loss: 0.1499 - accuracy: 0.9186\n",
      " 955/5349 [====>.........................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9191\n",
      "1193/5349 [=====>........................] - ETA: 2s - loss: 0.1492 - accuracy: 0.9191\n",
      "1435/5349 [=======>......................] - ETA: 1s - loss: 0.1497 - accuracy: 0.9185\n",
      "1791/5349 [=========>....................] - ETA: 1s - loss: 0.1490 - accuracy: 0.9192\n",
      "2028/5349 [==========>...................] - ETA: 1s - loss: 0.1492 - accuracy: 0.9191\n",
      "2265/5349 [===========>..................] - ETA: 1s - loss: 0.1493 - accuracy: 0.9189\n",
      "2503/5349 [=============>................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9193\n",
      "2742/5349 [==============>...............] - ETA: 1s - loss: 0.1489 - accuracy: 0.9194\n",
      "2974/5349 [===============>..............] - ETA: 1s - loss: 0.1488 - accuracy: 0.9195\n",
      "3208/5349 [================>.............] - ETA: 0s - loss: 0.1489 - accuracy: 0.9191\n",
      "3435/5349 [==================>...........] - ETA: 0s - loss: 0.1492 - accuracy: 0.9189\n",
      "3673/5349 [===================>..........] - ETA: 0s - loss: 0.1492 - accuracy: 0.9189\n",
      "3912/5349 [====================>.........] - ETA: 0s - loss: 0.1494 - accuracy: 0.9187\n",
      "4148/5349 [======================>.......] - ETA: 0s - loss: 0.1493 - accuracy: 0.9188\n",
      "4264/5349 [======================>.......] - ETA: 0s - loss: 0.1494 - accuracy: 0.9187\n",
      "4503/5349 [========================>.....] - ETA: 0s - loss: 0.1495 - accuracy: 0.9187\n",
      "4716/5349 [=========================>....] - ETA: 0s - loss: 0.1495 - accuracy: 0.9187\n",
      "4951/5349 [==========================>...] - ETA: 0s - loss: 0.1497 - accuracy: 0.9186\n",
      "5191/5349 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9186\n",
      "5300/5349 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 0.9187\n",
      "5349/5349 [==============================] - 3s 614us/step - loss: 0.1496 - accuracy: 0.9187 - val_loss: 0.1488 - val_accuracy: 0.9191\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 19/20\n",
      " 119/5349 [..............................] - ETA: 2s - loss: 0.1529 - accuracy: 0.9150\n",
      " 352/5349 [>.............................] - ETA: 2s - loss: 0.1495 - accuracy: 0.9182\n",
      " 587/5349 [==>...........................] - ETA: 2s - loss: 0.1476 - accuracy: 0.9199\n",
      " 824/5349 [===>..........................] - ETA: 1s - loss: 0.1474 - accuracy: 0.9202\n",
      " 943/5349 [====>.........................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9198\n",
      "1180/5349 [=====>........................] - ETA: 1s - loss: 0.1480 - accuracy: 0.9197\n",
      "1417/5349 [======>.......................] - ETA: 1s - loss: 0.1482 - accuracy: 0.9196\n",
      "1653/5349 [========>.....................] - ETA: 1s - loss: 0.1476 - accuracy: 0.9202\n",
      "1878/5349 [=========>....................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9195\n",
      "2112/5349 [==========>...................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9198\n",
      "2344/5349 [============>.................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9197\n",
      "2579/5349 [=============>................] - ETA: 1s - loss: 0.1488 - accuracy: 0.9194\n",
      "2807/5349 [==============>...............] - ETA: 1s - loss: 0.1488 - accuracy: 0.9193\n",
      "3027/5349 [===============>..............] - ETA: 1s - loss: 0.1486 - accuracy: 0.9195\n",
      "3185/5349 [================>.............] - ETA: 0s - loss: 0.1486 - accuracy: 0.9194\n",
      "3342/5349 [=================>............] - ETA: 0s - loss: 0.1489 - accuracy: 0.9192\n",
      "3551/5349 [==================>...........] - ETA: 0s - loss: 0.1490 - accuracy: 0.9191\n",
      "3725/5349 [===================>..........] - ETA: 0s - loss: 0.1490 - accuracy: 0.9191\n",
      "3906/5349 [====================>.........] - ETA: 0s - loss: 0.1490 - accuracy: 0.9191\n",
      "4087/5349 [=====================>........] - ETA: 0s - loss: 0.1490 - accuracy: 0.9191\n",
      "4257/5349 [======================>.......] - ETA: 0s - loss: 0.1490 - accuracy: 0.9191\n",
      "4472/5349 [========================>.....] - ETA: 0s - loss: 0.1491 - accuracy: 0.9190\n",
      "4574/5349 [========================>.....] - ETA: 0s - loss: 0.1492 - accuracy: 0.9190\n",
      "4778/5349 [=========================>....] - ETA: 0s - loss: 0.1492 - accuracy: 0.9189\n",
      "5014/5349 [===========================>..] - ETA: 0s - loss: 0.1490 - accuracy: 0.9190\n",
      "5242/5349 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9189\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9189\n",
      "5349/5349 [==============================] - 4s 741us/step - loss: 0.1492 - accuracy: 0.9188 - val_loss: 0.1484 - val_accuracy: 0.9197\n",
      "\u001B[36m(train_DNN pid=6261)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1505 - accuracy: 0.9100\n",
      " 218/5349 [>.............................] - ETA: 2s - loss: 0.1494 - accuracy: 0.9198\n",
      " 334/5349 [>.............................] - ETA: 2s - loss: 0.1490 - accuracy: 0.9193\n",
      " 561/5349 [==>...........................] - ETA: 2s - loss: 0.1480 - accuracy: 0.9199\n",
      " 793/5349 [===>..........................] - ETA: 2s - loss: 0.1475 - accuracy: 0.9202\n",
      "1021/5349 [====>.........................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9194\n",
      "1244/5349 [=====>........................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9195\n",
      "1448/5349 [=======>......................] - ETA: 1s - loss: 0.1485 - accuracy: 0.9195\n",
      "1674/5349 [========>.....................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9191\n",
      "1906/5349 [=========>....................] - ETA: 1s - loss: 0.1486 - accuracy: 0.9194\n",
      "2127/5349 [==========>...................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9193\n",
      "2361/5349 [============>.................] - ETA: 1s - loss: 0.1488 - accuracy: 0.9191\n",
      "2529/5349 [=============>................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9190\n",
      "2564/5349 [=============>................] - ETA: 1s - loss: 0.1487 - accuracy: 0.9190\n",
      "2621/5349 [=============>................] - ETA: 1s - loss: 0.1488 - accuracy: 0.9190\n",
      "2684/5349 [==============>...............] - ETA: 1s - loss: 0.1487 - accuracy: 0.9190\n",
      "2731/5349 [==============>...............] - ETA: 1s - loss: 0.1487 - accuracy: 0.9190\n",
      "2775/5349 [==============>...............] - ETA: 1s - loss: 0.1488 - accuracy: 0.9189\n",
      "2824/5349 [==============>...............] - ETA: 1s - loss: 0.1488 - accuracy: 0.9189\n",
      "2860/5349 [===============>..............] - ETA: 1s - loss: 0.1489 - accuracy: 0.9188\n",
      "2900/5349 [===============>..............] - ETA: 1s - loss: 0.1487 - accuracy: 0.9189\n",
      "2938/5349 [===============>..............] - ETA: 1s - loss: 0.1487 - accuracy: 0.9189\n",
      "2959/5349 [===============>..............] - ETA: 1s - loss: 0.1487 - accuracy: 0.9189\n",
      "3008/5349 [===============>..............] - ETA: 1s - loss: 0.1488 - accuracy: 0.9188\n",
      "3066/5349 [================>.............] - ETA: 1s - loss: 0.1489 - accuracy: 0.9189\n",
      "3099/5349 [================>.............] - ETA: 1s - loss: 0.1489 - accuracy: 0.9188\n",
      "3139/5349 [================>.............] - ETA: 1s - loss: 0.1489 - accuracy: 0.9188\n",
      "3174/5349 [================>.............] - ETA: 1s - loss: 0.1490 - accuracy: 0.9188\n",
      "3221/5349 [=================>............] - ETA: 1s - loss: 0.1491 - accuracy: 0.9187\n",
      "3269/5349 [=================>............] - ETA: 1s - loss: 0.1491 - accuracy: 0.9187\n",
      "3319/5349 [=================>............] - ETA: 1s - loss: 0.1490 - accuracy: 0.9188\n",
      "3378/5349 [=================>............] - ETA: 1s - loss: 0.1490 - accuracy: 0.9188\n",
      "3430/5349 [==================>...........] - ETA: 1s - loss: 0.1491 - accuracy: 0.9187\n",
      "3503/5349 [==================>...........] - ETA: 1s - loss: 0.1490 - accuracy: 0.9188\n",
      "3550/5349 [==================>...........] - ETA: 1s - loss: 0.1489 - accuracy: 0.9188\n",
      "3630/5349 [===================>..........] - ETA: 1s - loss: 0.1488 - accuracy: 0.9189\n",
      "3690/5349 [===================>..........] - ETA: 1s - loss: 0.1488 - accuracy: 0.9190\n",
      "3779/5349 [====================>.........] - ETA: 1s - loss: 0.1489 - accuracy: 0.9189\n",
      "3805/5349 [====================>.........] - ETA: 1s - loss: 0.1489 - accuracy: 0.9190\n",
      "3970/5349 [=====================>........] - ETA: 1s - loss: 0.1488 - accuracy: 0.9190\n",
      "4123/5349 [======================>.......] - ETA: 1s - loss: 0.1488 - accuracy: 0.9190\n",
      "4262/5349 [======================>.......] - ETA: 1s - loss: 0.1489 - accuracy: 0.9190\n",
      "4486/5349 [========================>.....] - ETA: 0s - loss: 0.1488 - accuracy: 0.9191\n",
      "4746/5349 [=========================>....] - ETA: 0s - loss: 0.1489 - accuracy: 0.9191\n",
      "5003/5349 [===========================>..] - ETA: 0s - loss: 0.1489 - accuracy: 0.9191\n",
      "5132/5349 [===========================>..] - ETA: 0s - loss: 0.1488 - accuracy: 0.9191\n",
      "5261/5349 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9191\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 1/20\n",
      "  52/5349 [..............................] - ETA: 5s - loss: 0.7119 - accuracy: 0.4738   \n",
      " 168/5349 [..............................] - ETA: 4s - loss: 0.6745 - accuracy: 0.6371\n",
      " 299/5349 [>.............................] - ETA: 4s - loss: 0.6436 - accuracy: 0.7334\n",
      " 362/5349 [=>............................] - ETA: 4s - loss: 0.6295 - accuracy: 0.7560\n",
      " 429/5349 [=>............................] - ETA: 4s - loss: 0.6152 - accuracy: 0.7736\n",
      " 555/5349 [==>...........................] - ETA: 4s - loss: 0.5914 - accuracy: 0.7950\n",
      " 654/5349 [==>...........................] - ETA: 4s - loss: 0.5750 - accuracy: 0.8057\n",
      " 794/5349 [===>..........................] - ETA: 4s - loss: 0.5529 - accuracy: 0.8177\n",
      " 999/5349 [====>.........................] - ETA: 3s - loss: 0.5243 - accuracy: 0.8297\n",
      "1179/5349 [=====>........................] - ETA: 3s - loss: 0.5026 - accuracy: 0.8368\n",
      "1271/5349 [======>.......................] - ETA: 3s - loss: 0.4926 - accuracy: 0.8395\n",
      "1355/5349 [======>.......................] - ETA: 3s - loss: 0.4838 - accuracy: 0.8420\n",
      "1377/5349 [======>.......................] - ETA: 3s - loss: 0.4816 - accuracy: 0.8425\n",
      "1436/5349 [=======>......................] - ETA: 3s - loss: 0.4759 - accuracy: 0.8439\n",
      "1465/5349 [=======>......................] - ETA: 3s - loss: 0.4734 - accuracy: 0.8445\n",
      "1505/5349 [=======>......................] - ETA: 4s - loss: 0.4697 - accuracy: 0.8453\n",
      "1529/5349 [=======>......................] - ETA: 4s - loss: 0.4675 - accuracy: 0.8458\n",
      "1586/5349 [=======>......................] - ETA: 4s - loss: 0.4624 - accuracy: 0.8470\n",
      "1624/5349 [========>.....................] - ETA: 4s - loss: 0.4592 - accuracy: 0.8478\n",
      "1659/5349 [========>.....................] - ETA: 4s - loss: 0.4562 - accuracy: 0.8486\n",
      "1680/5349 [========>.....................] - ETA: 4s - loss: 0.4545 - accuracy: 0.8490\n",
      "1723/5349 [========>.....................] - ETA: 4s - loss: 0.4510 - accuracy: 0.8497\n",
      "1746/5349 [========>.....................] - ETA: 4s - loss: 0.4493 - accuracy: 0.8500\n",
      "1778/5349 [========>.....................] - ETA: 4s - loss: 0.4467 - accuracy: 0.8508\n",
      "1802/5349 [=========>....................] - ETA: 4s - loss: 0.4449 - accuracy: 0.8510\n",
      "1831/5349 [=========>....................] - ETA: 4s - loss: 0.4426 - accuracy: 0.8514\n",
      "1874/5349 [=========>....................] - ETA: 5s - loss: 0.4394 - accuracy: 0.8521\n",
      "1900/5349 [=========>....................] - ETA: 5s - loss: 0.4376 - accuracy: 0.8526\n",
      "1937/5349 [=========>....................] - ETA: 5s - loss: 0.4351 - accuracy: 0.8530\n",
      "1966/5349 [==========>...................] - ETA: 5s - loss: 0.4329 - accuracy: 0.8537\n",
      "2005/5349 [==========>...................] - ETA: 5s - loss: 0.4302 - accuracy: 0.8542\n",
      "2029/5349 [==========>...................] - ETA: 5s - loss: 0.4287 - accuracy: 0.8545\n",
      "2048/5349 [==========>...................] - ETA: 5s - loss: 0.4274 - accuracy: 0.8548\n",
      "2090/5349 [==========>...................] - ETA: 5s - loss: 0.4247 - accuracy: 0.8553\n",
      "2127/5349 [==========>...................] - ETA: 5s - loss: 0.4225 - accuracy: 0.8557\n",
      "2165/5349 [===========>..................] - ETA: 5s - loss: 0.4201 - accuracy: 0.8564\n",
      "2205/5349 [===========>..................] - ETA: 5s - loss: 0.4176 - accuracy: 0.8569\n",
      "2234/5349 [===========>..................] - ETA: 5s - loss: 0.4160 - accuracy: 0.8572\n",
      "2282/5349 [===========>..................] - ETA: 5s - loss: 0.4130 - accuracy: 0.8579\n",
      "2337/5349 [============>.................] - ETA: 5s - loss: 0.4098 - accuracy: 0.8587\n",
      "2448/5349 [============>.................] - ETA: 4s - loss: 0.4037 - accuracy: 0.8599\n",
      "2484/5349 [============>.................] - ETA: 4s - loss: 0.4017 - accuracy: 0.8604\n",
      "2537/5349 [=============>................] - ETA: 4s - loss: 0.3989 - accuracy: 0.8610\n",
      "2583/5349 [=============>................] - ETA: 4s - loss: 0.3966 - accuracy: 0.8616\n",
      "2681/5349 [==============>...............] - ETA: 4s - loss: 0.3916 - accuracy: 0.8627\n",
      "2833/5349 [==============>...............] - ETA: 4s - loss: 0.3845 - accuracy: 0.8642\n",
      "2988/5349 [===============>..............] - ETA: 3s - loss: 0.3777 - accuracy: 0.8656\n",
      "3164/5349 [================>.............] - ETA: 3s - loss: 0.3708 - accuracy: 0.8668\n",
      "3441/5349 [==================>...........] - ETA: 2s - loss: 0.3606 - accuracy: 0.8688\n",
      "3620/5349 [===================>..........] - ETA: 2s - loss: 0.3546 - accuracy: 0.8699\n",
      "3797/5349 [====================>.........] - ETA: 2s - loss: 0.3490 - accuracy: 0.8711\n",
      "3964/5349 [=====================>........] - ETA: 1s - loss: 0.3442 - accuracy: 0.8721\n",
      "4143/5349 [======================>.......] - ETA: 1s - loss: 0.3393 - accuracy: 0.8729\n",
      "4324/5349 [=======================>......] - ETA: 1s - loss: 0.3345 - accuracy: 0.8740\n",
      "4507/5349 [========================>.....] - ETA: 1s - loss: 0.3302 - accuracy: 0.8747\n",
      "4708/5349 [=========================>....] - ETA: 0s - loss: 0.3255 - accuracy: 0.8757\n",
      "4888/5349 [==========================>...] - ETA: 0s - loss: 0.3216 - accuracy: 0.8766\n",
      "5074/5349 [===========================>..] - ETA: 0s - loss: 0.3177 - accuracy: 0.8774\n",
      "5295/5349 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.8784\n",
      "5349/5349 [==============================] - 9s 2ms/step - loss: 0.3125 - accuracy: 0.8785 - val_loss: 0.2365 - val_accuracy: 0.8547\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 2/20\n",
      "   1/5349 [..............................] - ETA: 7s - loss: 0.1988 - accuracy: 0.9100\n",
      " 149/5349 [..............................] - ETA: 3s - loss: 0.2107 - accuracy: 0.8983\n",
      " 310/5349 [>.............................] - ETA: 3s - loss: 0.2120 - accuracy: 0.8980\n",
      " 480/5349 [=>............................] - ETA: 3s - loss: 0.2116 - accuracy: 0.8984\n",
      " 661/5349 [==>...........................] - ETA: 2s - loss: 0.2108 - accuracy: 0.8992\n",
      " 841/5349 [===>..........................] - ETA: 2s - loss: 0.2099 - accuracy: 0.8999\n",
      "1025/5349 [====>.........................] - ETA: 2s - loss: 0.2086 - accuracy: 0.9008\n",
      "1117/5349 [=====>........................] - ETA: 2s - loss: 0.2083 - accuracy: 0.9008\n",
      "1282/5349 [======>.......................] - ETA: 2s - loss: 0.2074 - accuracy: 0.9009\n",
      "1459/5349 [=======>......................] - ETA: 2s - loss: 0.2071 - accuracy: 0.9006\n",
      "1628/5349 [========>.....................] - ETA: 2s - loss: 0.2065 - accuracy: 0.9008\n",
      "1806/5349 [=========>....................] - ETA: 2s - loss: 0.2060 - accuracy: 0.9009\n",
      "1981/5349 [==========>...................] - ETA: 1s - loss: 0.2056 - accuracy: 0.9009\n",
      "2160/5349 [===========>..................] - ETA: 1s - loss: 0.2052 - accuracy: 0.9008\n",
      "2314/5349 [===========>..................] - ETA: 1s - loss: 0.2049 - accuracy: 0.9008\n",
      "2463/5349 [============>.................] - ETA: 1s - loss: 0.2042 - accuracy: 0.9012\n",
      "2605/5349 [=============>................] - ETA: 1s - loss: 0.2040 - accuracy: 0.9010\n",
      "2694/5349 [==============>...............] - ETA: 1s - loss: 0.2035 - accuracy: 0.9013\n",
      "2879/5349 [===============>..............] - ETA: 1s - loss: 0.2027 - accuracy: 0.9016\n",
      "3044/5349 [================>.............] - ETA: 1s - loss: 0.2021 - accuracy: 0.9018\n",
      "3205/5349 [================>.............] - ETA: 1s - loss: 0.2016 - accuracy: 0.9021\n",
      "3289/5349 [=================>............] - ETA: 1s - loss: 0.2012 - accuracy: 0.9024\n",
      "3380/5349 [=================>............] - ETA: 1s - loss: 0.2009 - accuracy: 0.9025\n",
      "3472/5349 [==================>...........] - ETA: 1s - loss: 0.2007 - accuracy: 0.9025\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.2003 - accuracy: 0.9027\n",
      "3867/5349 [====================>.........] - ETA: 0s - loss: 0.1998 - accuracy: 0.9027\n",
      "4045/5349 [=====================>........] - ETA: 0s - loss: 0.1992 - accuracy: 0.9029\n",
      "4183/5349 [======================>.......] - ETA: 0s - loss: 0.1989 - accuracy: 0.9031\n",
      "4331/5349 [=======================>......] - ETA: 0s - loss: 0.1986 - accuracy: 0.9031\n",
      "4507/5349 [========================>.....] - ETA: 0s - loss: 0.1981 - accuracy: 0.9032\n",
      "4683/5349 [=========================>....] - ETA: 0s - loss: 0.1977 - accuracy: 0.9033\n",
      "4864/5349 [==========================>...] - ETA: 0s - loss: 0.1973 - accuracy: 0.9035\n",
      "5014/5349 [===========================>..] - ETA: 0s - loss: 0.1968 - accuracy: 0.9037\n",
      "5173/5349 [============================>.] - ETA: 0s - loss: 0.1965 - accuracy: 0.9039\n",
      "5253/5349 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9039\n",
      "5334/5349 [============================>.] - ETA: 0s - loss: 0.1962 - accuracy: 0.9039\n",
      "5349/5349 [==============================] - 5s 858us/step - loss: 0.1961 - accuracy: 0.9039 - val_loss: 0.1885 - val_accuracy: 0.9099\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 3/20\n",
      "  79/5349 [..............................] - ETA: 3s - loss: 0.1847 - accuracy: 0.9059\n",
      " 162/5349 [..............................] - ETA: 3s - loss: 0.1837 - accuracy: 0.9077\n",
      " 319/5349 [>.............................] - ETA: 3s - loss: 0.1849 - accuracy: 0.9058\n",
      " 480/5349 [=>............................] - ETA: 3s - loss: 0.1844 - accuracy: 0.9061\n",
      " 641/5349 [==>...........................] - ETA: 2s - loss: 0.1838 - accuracy: 0.9063\n",
      " 789/5349 [===>..........................] - ETA: 2s - loss: 0.1839 - accuracy: 0.9064\n",
      " 916/5349 [====>.........................] - ETA: 2s - loss: 0.1838 - accuracy: 0.9066\n",
      " 975/5349 [====>.........................] - ETA: 3s - loss: 0.1839 - accuracy: 0.9066\n",
      "1030/5349 [====>.........................] - ETA: 3s - loss: 0.1837 - accuracy: 0.9067\n",
      "1133/5349 [=====>........................] - ETA: 3s - loss: 0.1838 - accuracy: 0.9064\n",
      "1189/5349 [=====>........................] - ETA: 3s - loss: 0.1835 - accuracy: 0.9066\n",
      "1268/5349 [======>.......................] - ETA: 3s - loss: 0.1835 - accuracy: 0.9065\n",
      "1368/5349 [======>.......................] - ETA: 3s - loss: 0.1835 - accuracy: 0.9064\n",
      "1501/5349 [=======>......................] - ETA: 3s - loss: 0.1832 - accuracy: 0.9066\n",
      "1542/5349 [=======>......................] - ETA: 3s - loss: 0.1831 - accuracy: 0.9066\n",
      "1659/5349 [========>.....................] - ETA: 3s - loss: 0.1828 - accuracy: 0.9067\n",
      "1741/5349 [========>.....................] - ETA: 3s - loss: 0.1827 - accuracy: 0.9069\n",
      "1824/5349 [=========>....................] - ETA: 3s - loss: 0.1826 - accuracy: 0.9070\n",
      "1957/5349 [=========>....................] - ETA: 3s - loss: 0.1826 - accuracy: 0.9067\n",
      "2105/5349 [==========>...................] - ETA: 2s - loss: 0.1825 - accuracy: 0.9069\n",
      "2256/5349 [===========>..................] - ETA: 2s - loss: 0.1820 - accuracy: 0.9073\n",
      "2404/5349 [============>.................] - ETA: 2s - loss: 0.1820 - accuracy: 0.9072\n",
      "2626/5349 [=============>................] - ETA: 2s - loss: 0.1816 - accuracy: 0.9074\n",
      "2780/5349 [==============>...............] - ETA: 2s - loss: 0.1814 - accuracy: 0.9075\n",
      "2929/5349 [===============>..............] - ETA: 1s - loss: 0.1814 - accuracy: 0.9075\n",
      "3062/5349 [================>.............] - ETA: 1s - loss: 0.1813 - accuracy: 0.9076\n",
      "3145/5349 [================>.............] - ETA: 1s - loss: 0.1810 - accuracy: 0.9078\n",
      "3219/5349 [=================>............] - ETA: 1s - loss: 0.1808 - accuracy: 0.9079\n",
      "3273/5349 [=================>............] - ETA: 1s - loss: 0.1807 - accuracy: 0.9079\n",
      "3296/5349 [=================>............] - ETA: 1s - loss: 0.1807 - accuracy: 0.9079\n",
      "3360/5349 [=================>............] - ETA: 1s - loss: 0.1807 - accuracy: 0.9079\n",
      "3410/5349 [==================>...........] - ETA: 1s - loss: 0.1807 - accuracy: 0.9079\n",
      "3433/5349 [==================>...........] - ETA: 1s - loss: 0.1806 - accuracy: 0.9079\n",
      "3457/5349 [==================>...........] - ETA: 1s - loss: 0.1806 - accuracy: 0.9079\n",
      "3484/5349 [==================>...........] - ETA: 1s - loss: 0.1806 - accuracy: 0.9079\n",
      "3501/5349 [==================>...........] - ETA: 1s - loss: 0.1806 - accuracy: 0.9079\n",
      "3544/5349 [==================>...........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9080\n",
      "3565/5349 [==================>...........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3599/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3625/5349 [===================>..........] - ETA: 1s - loss: 0.1806 - accuracy: 0.9079\n",
      "3635/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3641/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3672/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3700/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3710/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9079\n",
      "3722/5349 [===================>..........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9080\n",
      "3757/5349 [====================>.........] - ETA: 1s - loss: 0.1805 - accuracy: 0.9080\n",
      "3780/5349 [====================>.........] - ETA: 1s - loss: 0.1804 - accuracy: 0.9080\n",
      "3783/5349 [====================>.........] - ETA: 1s - loss: 0.1804 - accuracy: 0.9080\n",
      "3788/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3793/5349 [====================>.........] - ETA: 2s - loss: 0.1805 - accuracy: 0.9080\n",
      "3816/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3830/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3849/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3857/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3868/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3877/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3902/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3903/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9079\n",
      "3909/5349 [====================>.........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3937/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3948/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3961/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "3977/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "4016/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "4020/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "4037/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "4053/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9080\n",
      "4064/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9079\n",
      "4086/5349 [=====================>........] - ETA: 2s - loss: 0.1804 - accuracy: 0.9079\n",
      "4110/5349 [======================>.......] - ETA: 2s - loss: 0.1803 - accuracy: 0.9079\n",
      "4120/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9079\n",
      "4134/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9079\n",
      "4139/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9079\n",
      "4156/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9078\n",
      "4158/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9078\n",
      "4188/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9078\n",
      "4225/5349 [======================>.......] - ETA: 2s - loss: 0.1804 - accuracy: 0.9078\n",
      "4259/5349 [======================>.......] - ETA: 2s - loss: 0.1803 - accuracy: 0.9078\n",
      "4287/5349 [=======================>......] - ETA: 2s - loss: 0.1802 - accuracy: 0.9079\n",
      "4333/5349 [=======================>......] - ETA: 1s - loss: 0.1802 - accuracy: 0.9079\n",
      "4366/5349 [=======================>......] - ETA: 1s - loss: 0.1802 - accuracy: 0.9078\n",
      "4387/5349 [=======================>......] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4403/5349 [=======================>......] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4427/5349 [=======================>......] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4459/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4484/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9078\n",
      "4528/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9078\n",
      "4541/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9078\n",
      "4557/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9078\n",
      "4587/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4609/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4627/5349 [========================>.....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9079\n",
      "4645/5349 [=========================>....] - ETA: 1s - loss: 0.1801 - accuracy: 0.9078\n",
      "4675/5349 [=========================>....] - ETA: 1s - loss: 0.1800 - accuracy: 0.9079\n",
      "4727/5349 [=========================>....] - ETA: 1s - loss: 0.1799 - accuracy: 0.9079\n",
      "4797/5349 [=========================>....] - ETA: 1s - loss: 0.1798 - accuracy: 0.9080\n",
      "4876/5349 [==========================>...] - ETA: 0s - loss: 0.1797 - accuracy: 0.9080\n",
      "4940/5349 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.9080\n",
      "5081/5349 [===========================>..] - ETA: 0s - loss: 0.1795 - accuracy: 0.9080\n",
      "5234/5349 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9080\n",
      "5326/5349 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.9081\n",
      "5349/5349 [==============================] - 13s 2ms/step - loss: 0.1793 - accuracy: 0.9081 - val_loss: 0.1767 - val_accuracy: 0.9127\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 4/20\n",
      "   1/5349 [..............................] - ETA: 8s - loss: 0.2228 - accuracy: 0.9100\n",
      "  78/5349 [..............................] - ETA: 7s - loss: 0.1778 - accuracy: 0.9085\n",
      " 228/5349 [>.............................] - ETA: 5s - loss: 0.1754 - accuracy: 0.9084\n",
      " 388/5349 [=>............................] - ETA: 4s - loss: 0.1758 - accuracy: 0.9079\n",
      " 496/5349 [=>............................] - ETA: 4s - loss: 0.1749 - accuracy: 0.9087\n",
      " 609/5349 [==>...........................] - ETA: 4s - loss: 0.1748 - accuracy: 0.9087\n",
      " 767/5349 [===>..........................] - ETA: 3s - loss: 0.1751 - accuracy: 0.9083\n",
      " 905/5349 [====>.........................] - ETA: 3s - loss: 0.1746 - accuracy: 0.9085\n",
      "1059/5349 [====>.........................] - ETA: 3s - loss: 0.1743 - accuracy: 0.9091\n",
      "1224/5349 [=====>........................] - ETA: 3s - loss: 0.1741 - accuracy: 0.9093\n",
      "1393/5349 [======>.......................] - ETA: 3s - loss: 0.1739 - accuracy: 0.9094\n",
      "1558/5349 [=======>......................] - ETA: 2s - loss: 0.1739 - accuracy: 0.9094\n",
      "1642/5349 [========>.....................] - ETA: 2s - loss: 0.1736 - accuracy: 0.9096\n",
      "1807/5349 [=========>....................] - ETA: 2s - loss: 0.1737 - accuracy: 0.9096\n",
      "1981/5349 [==========>...................] - ETA: 2s - loss: 0.1735 - accuracy: 0.9098\n",
      "2145/5349 [===========>..................] - ETA: 2s - loss: 0.1733 - accuracy: 0.9098\n",
      "2322/5349 [============>.................] - ETA: 2s - loss: 0.1735 - accuracy: 0.9097\n",
      "2494/5349 [============>.................] - ETA: 1s - loss: 0.1735 - accuracy: 0.9095\n",
      "2652/5349 [=============>................] - ETA: 1s - loss: 0.1734 - accuracy: 0.9095\n",
      "2825/5349 [==============>...............] - ETA: 1s - loss: 0.1733 - accuracy: 0.9096\n",
      "3068/5349 [================>.............] - ETA: 1s - loss: 0.1730 - accuracy: 0.9097\n",
      "3232/5349 [=================>............] - ETA: 1s - loss: 0.1728 - accuracy: 0.9099\n",
      "3384/5349 [=================>............] - ETA: 1s - loss: 0.1726 - accuracy: 0.9101\n",
      "3553/5349 [==================>...........] - ETA: 1s - loss: 0.1727 - accuracy: 0.9100\n",
      "3720/5349 [===================>..........] - ETA: 1s - loss: 0.1724 - accuracy: 0.9101\n",
      "3892/5349 [====================>.........] - ETA: 0s - loss: 0.1723 - accuracy: 0.9101\n",
      "4057/5349 [=====================>........] - ETA: 0s - loss: 0.1722 - accuracy: 0.9102\n",
      "4222/5349 [======================>.......] - ETA: 0s - loss: 0.1721 - accuracy: 0.9101\n",
      "4390/5349 [=======================>......] - ETA: 0s - loss: 0.1721 - accuracy: 0.9100\n",
      "4454/5349 [=======================>......] - ETA: 0s - loss: 0.1721 - accuracy: 0.9101\n",
      "4544/5349 [========================>.....] - ETA: 0s - loss: 0.1720 - accuracy: 0.9101\n",
      "4659/5349 [=========================>....] - ETA: 0s - loss: 0.1719 - accuracy: 0.9101\n",
      "4763/5349 [=========================>....] - ETA: 0s - loss: 0.1719 - accuracy: 0.9101\n",
      "4877/5349 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.9101\n",
      "4964/5349 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.9101\n",
      "5071/5349 [===========================>..] - ETA: 0s - loss: 0.1717 - accuracy: 0.9101\n",
      "5218/5349 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9101\n",
      "5304/5349 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9101\n",
      "5342/5349 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9101\n",
      "5349/5349 [==============================] - 10s 2ms/step - loss: 0.1716 - accuracy: 0.9101 - val_loss: 0.1718 - val_accuracy: 0.9135\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 5/20\n",
      "   1/5349 [..............................] - ETA: 11s - loss: 0.1810 - accuracy: 0.9000\n",
      " 117/5349 [..............................] - ETA: 4s - loss: 0.1704 - accuracy: 0.9093\n",
      " 257/5349 [>.............................] - ETA: 4s - loss: 0.1694 - accuracy: 0.9107\n",
      " 468/5349 [=>............................] - ETA: 3s - loss: 0.1674 - accuracy: 0.9123\n",
      " 645/5349 [==>...........................] - ETA: 3s - loss: 0.1688 - accuracy: 0.9113\n",
      " 820/5349 [===>..........................] - ETA: 3s - loss: 0.1689 - accuracy: 0.9113\n",
      " 995/5349 [====>.........................] - ETA: 2s - loss: 0.1686 - accuracy: 0.9118\n",
      "1171/5349 [=====>........................] - ETA: 2s - loss: 0.1684 - accuracy: 0.9117\n",
      "1353/5349 [======>.......................] - ETA: 2s - loss: 0.1684 - accuracy: 0.9119\n",
      "1538/5349 [=======>......................] - ETA: 2s - loss: 0.1687 - accuracy: 0.9115\n",
      "1725/5349 [========>.....................] - ETA: 2s - loss: 0.1681 - accuracy: 0.9119\n",
      "2014/5349 [==========>...................] - ETA: 1s - loss: 0.1679 - accuracy: 0.9116\n",
      "2204/5349 [===========>..................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9115\n",
      "2394/5349 [============>.................] - ETA: 1s - loss: 0.1681 - accuracy: 0.9114\n",
      "2580/5349 [=============>................] - ETA: 1s - loss: 0.1680 - accuracy: 0.9113\n",
      "2763/5349 [==============>...............] - ETA: 1s - loss: 0.1684 - accuracy: 0.9110\n",
      "2962/5349 [===============>..............] - ETA: 1s - loss: 0.1682 - accuracy: 0.9110\n",
      "3168/5349 [================>.............] - ETA: 1s - loss: 0.1682 - accuracy: 0.9110\n",
      "3369/5349 [=================>............] - ETA: 1s - loss: 0.1681 - accuracy: 0.9109\n",
      "3568/5349 [===================>..........] - ETA: 1s - loss: 0.1681 - accuracy: 0.9109\n",
      "3774/5349 [====================>.........] - ETA: 0s - loss: 0.1681 - accuracy: 0.9108\n",
      "3976/5349 [=====================>........] - ETA: 0s - loss: 0.1679 - accuracy: 0.9110\n",
      "4228/5349 [======================>.......] - ETA: 0s - loss: 0.1679 - accuracy: 0.9109\n",
      "4350/5349 [=======================>......] - ETA: 0s - loss: 0.1680 - accuracy: 0.9109\n",
      "4492/5349 [========================>.....] - ETA: 0s - loss: 0.1681 - accuracy: 0.9108\n",
      "4664/5349 [=========================>....] - ETA: 0s - loss: 0.1681 - accuracy: 0.9109\n",
      "4795/5349 [=========================>....] - ETA: 0s - loss: 0.1679 - accuracy: 0.9109\n",
      "4932/5349 [==========================>...] - ETA: 0s - loss: 0.1678 - accuracy: 0.9110\n",
      "5032/5349 [===========================>..] - ETA: 0s - loss: 0.1679 - accuracy: 0.9110\n",
      "5080/5349 [===========================>..] - ETA: 0s - loss: 0.1678 - accuracy: 0.9110\n",
      "5172/5349 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9110\n",
      "5281/5349 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9111\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9111\n",
      "5349/5349 [==============================] - 4s 798us/step - loss: 0.1676 - accuracy: 0.9112 - val_loss: 0.1669 - val_accuracy: 0.9142\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 6/20\n",
      "   1/5349 [..............................] - ETA: 5s - loss: 0.1243 - accuracy: 0.9500\n",
      " 190/5349 [>.............................] - ETA: 2s - loss: 0.1634 - accuracy: 0.9137\n",
      " 378/5349 [=>............................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9125\n",
      " 567/5349 [==>...........................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9123\n",
      " 759/5349 [===>..........................] - ETA: 2s - loss: 0.1644 - accuracy: 0.9118\n",
      " 952/5349 [====>.........................] - ETA: 2s - loss: 0.1645 - accuracy: 0.9117\n",
      "1140/5349 [=====>........................] - ETA: 2s - loss: 0.1646 - accuracy: 0.9115\n",
      "1332/5349 [======>.......................] - ETA: 2s - loss: 0.1647 - accuracy: 0.9114\n",
      "1503/5349 [=======>......................] - ETA: 2s - loss: 0.1651 - accuracy: 0.9114\n",
      "1688/5349 [========>.....................] - ETA: 1s - loss: 0.1647 - accuracy: 0.9118\n",
      "1784/5349 [=========>....................] - ETA: 1s - loss: 0.1647 - accuracy: 0.9118\n",
      "1971/5349 [==========>...................] - ETA: 1s - loss: 0.1645 - accuracy: 0.9121\n",
      "2159/5349 [===========>..................] - ETA: 1s - loss: 0.1646 - accuracy: 0.9119\n",
      "2351/5349 [============>.................] - ETA: 1s - loss: 0.1649 - accuracy: 0.9116\n",
      "2491/5349 [============>.................] - ETA: 1s - loss: 0.1648 - accuracy: 0.9117\n",
      "2664/5349 [=============>................] - ETA: 1s - loss: 0.1645 - accuracy: 0.9118\n",
      "2839/5349 [==============>...............] - ETA: 1s - loss: 0.1646 - accuracy: 0.9118\n",
      "3016/5349 [===============>..............] - ETA: 1s - loss: 0.1646 - accuracy: 0.9118\n",
      "3191/5349 [================>.............] - ETA: 1s - loss: 0.1647 - accuracy: 0.9117\n",
      "3374/5349 [=================>............] - ETA: 1s - loss: 0.1647 - accuracy: 0.9116\n",
      "3563/5349 [==================>...........] - ETA: 0s - loss: 0.1647 - accuracy: 0.9116\n",
      "3846/5349 [====================>.........] - ETA: 0s - loss: 0.1645 - accuracy: 0.9117\n",
      "4039/5349 [=====================>........] - ETA: 0s - loss: 0.1645 - accuracy: 0.9116\n",
      "4223/5349 [======================>.......] - ETA: 0s - loss: 0.1647 - accuracy: 0.9116\n",
      "4411/5349 [=======================>......] - ETA: 0s - loss: 0.1645 - accuracy: 0.9116\n",
      "4598/5349 [========================>.....] - ETA: 0s - loss: 0.1646 - accuracy: 0.9116\n",
      "4760/5349 [=========================>....] - ETA: 0s - loss: 0.1645 - accuracy: 0.9116\n",
      "4949/5349 [==========================>...] - ETA: 0s - loss: 0.1646 - accuracy: 0.9116\n",
      "5137/5349 [===========================>..] - ETA: 0s - loss: 0.1645 - accuracy: 0.9117\n",
      "5324/5349 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9118\n",
      "5349/5349 [==============================] - 5s 880us/step - loss: 0.1644 - accuracy: 0.9117 - val_loss: 0.1650 - val_accuracy: 0.9146\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 7/20\n",
      "   1/5349 [..............................] - ETA: 8s - loss: 0.1342 - accuracy: 0.9200\n",
      " 147/5349 [..............................] - ETA: 3s - loss: 0.1561 - accuracy: 0.9172\n",
      " 337/5349 [>.............................] - ETA: 3s - loss: 0.1615 - accuracy: 0.9124\n",
      " 499/5349 [=>............................] - ETA: 2s - loss: 0.1608 - accuracy: 0.9136\n",
      " 761/5349 [===>..........................] - ETA: 2s - loss: 0.1600 - accuracy: 0.9150\n",
      " 934/5349 [====>.........................] - ETA: 2s - loss: 0.1602 - accuracy: 0.9151\n",
      "1112/5349 [=====>........................] - ETA: 2s - loss: 0.1606 - accuracy: 0.9145\n",
      "1297/5349 [======>.......................] - ETA: 2s - loss: 0.1614 - accuracy: 0.9138\n",
      "1486/5349 [=======>......................] - ETA: 2s - loss: 0.1613 - accuracy: 0.9139\n",
      "1672/5349 [========>.....................] - ETA: 2s - loss: 0.1616 - accuracy: 0.9137\n",
      "1857/5349 [=========>....................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9133\n",
      "2030/5349 [==========>...................] - ETA: 1s - loss: 0.1624 - accuracy: 0.9130\n",
      "2217/5349 [===========>..................] - ETA: 1s - loss: 0.1628 - accuracy: 0.9127\n",
      "2446/5349 [============>.................] - ETA: 1s - loss: 0.1623 - accuracy: 0.9129\n",
      "2515/5349 [=============>................] - ETA: 1s - loss: 0.1623 - accuracy: 0.9130\n",
      "2562/5349 [=============>................] - ETA: 1s - loss: 0.1622 - accuracy: 0.9130\n",
      "2612/5349 [=============>................] - ETA: 1s - loss: 0.1622 - accuracy: 0.9131\n",
      "2659/5349 [=============>................] - ETA: 1s - loss: 0.1622 - accuracy: 0.9130\n",
      "2691/5349 [==============>...............] - ETA: 1s - loss: 0.1623 - accuracy: 0.9130\n",
      "2721/5349 [==============>...............] - ETA: 1s - loss: 0.1623 - accuracy: 0.9130\n",
      "2750/5349 [==============>...............] - ETA: 2s - loss: 0.1623 - accuracy: 0.9130\n",
      "2784/5349 [==============>...............] - ETA: 2s - loss: 0.1623 - accuracy: 0.9130\n",
      "2808/5349 [==============>...............] - ETA: 2s - loss: 0.1623 - accuracy: 0.9130\n",
      "2823/5349 [==============>...............] - ETA: 2s - loss: 0.1623 - accuracy: 0.9130\n",
      "2863/5349 [===============>..............] - ETA: 2s - loss: 0.1623 - accuracy: 0.9130\n",
      "2921/5349 [===============>..............] - ETA: 2s - loss: 0.1624 - accuracy: 0.9129\n",
      "2982/5349 [===============>..............] - ETA: 2s - loss: 0.1625 - accuracy: 0.9128\n",
      "3011/5349 [===============>..............] - ETA: 2s - loss: 0.1625 - accuracy: 0.9128\n",
      "3038/5349 [================>.............] - ETA: 2s - loss: 0.1626 - accuracy: 0.9128\n",
      "3068/5349 [================>.............] - ETA: 2s - loss: 0.1626 - accuracy: 0.9127\n",
      "3084/5349 [================>.............] - ETA: 2s - loss: 0.1626 - accuracy: 0.9127\n",
      "3129/5349 [================>.............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9126\n",
      "3142/5349 [================>.............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9127\n",
      "3179/5349 [================>.............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9126\n",
      "3203/5349 [================>.............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9126\n",
      "3235/5349 [=================>............] - ETA: 2s - loss: 0.1628 - accuracy: 0.9125\n",
      "3294/5349 [=================>............] - ETA: 2s - loss: 0.1628 - accuracy: 0.9125\n",
      "3299/5349 [=================>............] - ETA: 2s - loss: 0.1628 - accuracy: 0.9125\n",
      "3324/5349 [=================>............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9126\n",
      "3359/5349 [=================>............] - ETA: 2s - loss: 0.1627 - accuracy: 0.9126\n",
      "3379/5349 [=================>............] - ETA: 2s - loss: 0.1626 - accuracy: 0.9126\n",
      "3388/5349 [==================>...........] - ETA: 2s - loss: 0.1626 - accuracy: 0.9126\n",
      "3407/5349 [==================>...........] - ETA: 2s - loss: 0.1626 - accuracy: 0.9126\n",
      "3448/5349 [==================>...........] - ETA: 2s - loss: 0.1626 - accuracy: 0.9127\n",
      "3480/5349 [==================>...........] - ETA: 2s - loss: 0.1625 - accuracy: 0.9128\n",
      "3535/5349 [==================>...........] - ETA: 2s - loss: 0.1625 - accuracy: 0.9128\n",
      "3557/5349 [==================>...........] - ETA: 2s - loss: 0.1625 - accuracy: 0.9128\n",
      "3578/5349 [===================>..........] - ETA: 2s - loss: 0.1626 - accuracy: 0.9128\n",
      "3600/5349 [===================>..........] - ETA: 2s - loss: 0.1625 - accuracy: 0.9128\n",
      "3671/5349 [===================>..........] - ETA: 2s - loss: 0.1625 - accuracy: 0.9129\n",
      "3714/5349 [===================>..........] - ETA: 2s - loss: 0.1624 - accuracy: 0.9129\n",
      "3767/5349 [====================>.........] - ETA: 2s - loss: 0.1624 - accuracy: 0.9130\n",
      "3796/5349 [====================>.........] - ETA: 2s - loss: 0.1624 - accuracy: 0.9130\n",
      "3841/5349 [====================>.........] - ETA: 2s - loss: 0.1625 - accuracy: 0.9129\n",
      "3885/5349 [====================>.........] - ETA: 2s - loss: 0.1624 - accuracy: 0.9130\n",
      "3949/5349 [=====================>........] - ETA: 2s - loss: 0.1624 - accuracy: 0.9130\n",
      "4058/5349 [=====================>........] - ETA: 1s - loss: 0.1625 - accuracy: 0.9129\n",
      "4199/5349 [======================>.......] - ETA: 1s - loss: 0.1625 - accuracy: 0.9129\n",
      "4269/5349 [======================>.......] - ETA: 1s - loss: 0.1624 - accuracy: 0.9130\n",
      "4438/5349 [=======================>......] - ETA: 1s - loss: 0.1623 - accuracy: 0.9131\n",
      "4580/5349 [========================>.....] - ETA: 1s - loss: 0.1623 - accuracy: 0.9130\n",
      "4773/5349 [=========================>....] - ETA: 0s - loss: 0.1623 - accuracy: 0.9130\n",
      "4972/5349 [==========================>...] - ETA: 0s - loss: 0.1624 - accuracy: 0.9129\n",
      "5169/5349 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.9127\n",
      "5344/5349 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9127\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1626 - accuracy: 0.9127 - val_loss: 0.1624 - val_accuracy: 0.9148\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 8/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1999 - accuracy: 0.9100\n",
      " 150/5349 [..............................] - ETA: 3s - loss: 0.1647 - accuracy: 0.9123\n",
      " 307/5349 [>.............................] - ETA: 3s - loss: 0.1617 - accuracy: 0.9128\n",
      " 485/5349 [=>............................] - ETA: 3s - loss: 0.1622 - accuracy: 0.9132\n",
      " 654/5349 [==>...........................] - ETA: 2s - loss: 0.1609 - accuracy: 0.9138\n",
      " 807/5349 [===>..........................] - ETA: 2s - loss: 0.1616 - accuracy: 0.9137\n",
      " 987/5349 [====>.........................] - ETA: 2s - loss: 0.1614 - accuracy: 0.9137\n",
      "1150/5349 [=====>........................] - ETA: 2s - loss: 0.1614 - accuracy: 0.9135\n",
      "1237/5349 [=====>........................] - ETA: 2s - loss: 0.1615 - accuracy: 0.9135\n",
      "1415/5349 [======>.......................] - ETA: 2s - loss: 0.1617 - accuracy: 0.9134\n",
      "1593/5349 [=======>......................] - ETA: 2s - loss: 0.1613 - accuracy: 0.9135\n",
      "1763/5349 [========>.....................] - ETA: 2s - loss: 0.1615 - accuracy: 0.9132\n",
      "1910/5349 [=========>....................] - ETA: 2s - loss: 0.1613 - accuracy: 0.9133\n",
      "2077/5349 [==========>...................] - ETA: 1s - loss: 0.1610 - accuracy: 0.9134\n",
      "2247/5349 [===========>..................] - ETA: 1s - loss: 0.1611 - accuracy: 0.9133\n",
      "2418/5349 [============>.................] - ETA: 1s - loss: 0.1614 - accuracy: 0.9131\n",
      "2596/5349 [=============>................] - ETA: 1s - loss: 0.1609 - accuracy: 0.9135\n",
      "2774/5349 [==============>...............] - ETA: 1s - loss: 0.1610 - accuracy: 0.9135\n",
      "3050/5349 [================>.............] - ETA: 1s - loss: 0.1611 - accuracy: 0.9133\n",
      "3235/5349 [=================>............] - ETA: 1s - loss: 0.1610 - accuracy: 0.9134\n",
      "3411/5349 [==================>...........] - ETA: 1s - loss: 0.1611 - accuracy: 0.9133\n",
      "3581/5349 [===================>..........] - ETA: 1s - loss: 0.1609 - accuracy: 0.9133\n",
      "3743/5349 [===================>..........] - ETA: 0s - loss: 0.1606 - accuracy: 0.9135\n",
      "3921/5349 [====================>.........] - ETA: 0s - loss: 0.1609 - accuracy: 0.9132\n",
      "4081/5349 [=====================>........] - ETA: 0s - loss: 0.1610 - accuracy: 0.9131\n",
      "4203/5349 [======================>.......] - ETA: 0s - loss: 0.1611 - accuracy: 0.9130\n",
      "4354/5349 [=======================>......] - ETA: 0s - loss: 0.1611 - accuracy: 0.9130\n",
      "4590/5349 [========================>.....] - ETA: 0s - loss: 0.1610 - accuracy: 0.9130\n",
      "4738/5349 [=========================>....] - ETA: 0s - loss: 0.1610 - accuracy: 0.9130\n",
      "4896/5349 [==========================>...] - ETA: 0s - loss: 0.1609 - accuracy: 0.9131\n",
      "5045/5349 [===========================>..] - ETA: 0s - loss: 0.1610 - accuracy: 0.9130\n",
      "5170/5349 [===========================>..] - ETA: 0s - loss: 0.1611 - accuracy: 0.9129\n",
      "5323/5349 [============================>.] - ETA: 0s - loss: 0.1610 - accuracy: 0.9129\n",
      "5349/5349 [==============================] - 4s 806us/step - loss: 0.1609 - accuracy: 0.9130 - val_loss: 0.1605 - val_accuracy: 0.9154\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 9/20\n",
      "   1/5349 [..............................] - ETA: 3s - loss: 0.1287 - accuracy: 0.9500\n",
      " 182/5349 [>.............................] - ETA: 2s - loss: 0.1607 - accuracy: 0.9140\n",
      " 366/5349 [=>............................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9143\n",
      " 547/5349 [==>...........................] - ETA: 2s - loss: 0.1596 - accuracy: 0.9138\n",
      " 729/5349 [===>..........................] - ETA: 2s - loss: 0.1598 - accuracy: 0.9138\n",
      " 823/5349 [===>..........................] - ETA: 2s - loss: 0.1594 - accuracy: 0.9141\n",
      "1012/5349 [====>.........................] - ETA: 2s - loss: 0.1600 - accuracy: 0.9136\n",
      "1196/5349 [=====>........................] - ETA: 2s - loss: 0.1598 - accuracy: 0.9141\n",
      "1381/5349 [======>.......................] - ETA: 2s - loss: 0.1592 - accuracy: 0.9142\n",
      "1561/5349 [=======>......................] - ETA: 2s - loss: 0.1596 - accuracy: 0.9139\n",
      "1746/5349 [========>.....................] - ETA: 1s - loss: 0.1602 - accuracy: 0.9134\n",
      "1935/5349 [=========>....................] - ETA: 1s - loss: 0.1605 - accuracy: 0.9129\n",
      "2121/5349 [==========>...................] - ETA: 1s - loss: 0.1602 - accuracy: 0.9133\n",
      "2309/5349 [===========>..................] - ETA: 1s - loss: 0.1605 - accuracy: 0.9131\n",
      "2494/5349 [============>.................] - ETA: 1s - loss: 0.1606 - accuracy: 0.9129\n",
      "2587/5349 [=============>................] - ETA: 1s - loss: 0.1607 - accuracy: 0.9128\n",
      "2769/5349 [==============>...............] - ETA: 1s - loss: 0.1607 - accuracy: 0.9129\n",
      "2945/5349 [===============>..............] - ETA: 1s - loss: 0.1606 - accuracy: 0.9129\n",
      "3125/5349 [================>.............] - ETA: 1s - loss: 0.1605 - accuracy: 0.9129\n",
      "3303/5349 [=================>............] - ETA: 1s - loss: 0.1605 - accuracy: 0.9130\n",
      "3470/5349 [==================>...........] - ETA: 1s - loss: 0.1604 - accuracy: 0.9131\n",
      "3646/5349 [===================>..........] - ETA: 0s - loss: 0.1602 - accuracy: 0.9133\n",
      "3678/5349 [===================>..........] - ETA: 0s - loss: 0.1602 - accuracy: 0.9133\n",
      "3823/5349 [====================>.........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9133\n",
      "4006/5349 [=====================>........] - ETA: 0s - loss: 0.1602 - accuracy: 0.9132\n",
      "4188/5349 [======================>.......] - ETA: 0s - loss: 0.1602 - accuracy: 0.9132\n",
      "4357/5349 [=======================>......] - ETA: 0s - loss: 0.1600 - accuracy: 0.9133\n",
      "4531/5349 [========================>.....] - ETA: 0s - loss: 0.1600 - accuracy: 0.9134\n",
      "4712/5349 [=========================>....] - ETA: 0s - loss: 0.1600 - accuracy: 0.9133\n",
      "4884/5349 [==========================>...] - ETA: 0s - loss: 0.1599 - accuracy: 0.9134\n",
      "5058/5349 [===========================>..] - ETA: 0s - loss: 0.1598 - accuracy: 0.9135\n",
      "5320/5349 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.9136\n",
      "5349/5349 [==============================] - 8s 2ms/step - loss: 0.1597 - accuracy: 0.9136 - val_loss: 0.1613 - val_accuracy: 0.9151\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 10/20\n",
      "  18/5349 [..............................] - ETA: 15s - loss: 0.1556 - accuracy: 0.9100\n",
      "  49/5349 [..............................] - ETA: 17s - loss: 0.1521 - accuracy: 0.9192\n",
      "  85/5349 [..............................] - ETA: 16s - loss: 0.1561 - accuracy: 0.9148\n",
      " 211/5349 [>.............................] - ETA: 9s - loss: 0.1551 - accuracy: 0.9161 \n",
      " 352/5349 [>.............................] - ETA: 6s - loss: 0.1555 - accuracy: 0.9160\n",
      " 561/5349 [==>...........................] - ETA: 5s - loss: 0.1567 - accuracy: 0.9151\n",
      " 733/5349 [===>..........................] - ETA: 4s - loss: 0.1571 - accuracy: 0.9148\n",
      " 912/5349 [====>.........................] - ETA: 4s - loss: 0.1578 - accuracy: 0.9140\n",
      "1073/5349 [=====>........................] - ETA: 3s - loss: 0.1570 - accuracy: 0.9149\n",
      "1200/5349 [=====>........................] - ETA: 3s - loss: 0.1574 - accuracy: 0.9146\n",
      "1368/5349 [======>.......................] - ETA: 3s - loss: 0.1582 - accuracy: 0.9138\n",
      "1543/5349 [=======>......................] - ETA: 3s - loss: 0.1585 - accuracy: 0.9136\n",
      "1717/5349 [========>.....................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9135\n",
      "1897/5349 [=========>....................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9133\n",
      "2087/5349 [==========>...................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9134\n",
      "2248/5349 [===========>..................] - ETA: 2s - loss: 0.1585 - accuracy: 0.9135\n",
      "2521/5349 [=============>................] - ETA: 2s - loss: 0.1589 - accuracy: 0.9134\n",
      "2709/5349 [==============>...............] - ETA: 1s - loss: 0.1587 - accuracy: 0.9136\n",
      "2904/5349 [===============>..............] - ETA: 1s - loss: 0.1590 - accuracy: 0.9136\n",
      "3096/5349 [================>.............] - ETA: 1s - loss: 0.1589 - accuracy: 0.9136\n",
      "3278/5349 [=================>............] - ETA: 1s - loss: 0.1588 - accuracy: 0.9136\n",
      "3465/5349 [==================>...........] - ETA: 1s - loss: 0.1590 - accuracy: 0.9135\n",
      "3657/5349 [===================>..........] - ETA: 1s - loss: 0.1593 - accuracy: 0.9132\n",
      "3858/5349 [====================>.........] - ETA: 0s - loss: 0.1592 - accuracy: 0.9133\n",
      "4052/5349 [=====================>........] - ETA: 0s - loss: 0.1590 - accuracy: 0.9135\n",
      "4243/5349 [======================>.......] - ETA: 0s - loss: 0.1590 - accuracy: 0.9135\n",
      "4536/5349 [========================>.....] - ETA: 0s - loss: 0.1589 - accuracy: 0.9135\n",
      "4712/5349 [=========================>....] - ETA: 0s - loss: 0.1589 - accuracy: 0.9134\n",
      "4890/5349 [==========================>...] - ETA: 0s - loss: 0.1589 - accuracy: 0.9135\n",
      "5060/5349 [===========================>..] - ETA: 0s - loss: 0.1588 - accuracy: 0.9136\n",
      "5213/5349 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9136\n",
      "5297/5349 [============================>.] - ETA: 0s - loss: 0.1587 - accuracy: 0.9137\n",
      "5349/5349 [==============================] - 5s 854us/step - loss: 0.1587 - accuracy: 0.9137 - val_loss: 0.1592 - val_accuracy: 0.9155\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 11/20\n",
      "  73/5349 [..............................] - ETA: 3s - loss: 0.1559 - accuracy: 0.9137\n",
      " 227/5349 [>.............................] - ETA: 3s - loss: 0.1567 - accuracy: 0.9147\n",
      " 366/5349 [=>............................] - ETA: 3s - loss: 0.1577 - accuracy: 0.9146\n",
      " 551/5349 [==>...........................] - ETA: 3s - loss: 0.1584 - accuracy: 0.9136\n",
      " 740/5349 [===>..........................] - ETA: 2s - loss: 0.1588 - accuracy: 0.9131\n",
      " 925/5349 [====>.........................] - ETA: 2s - loss: 0.1587 - accuracy: 0.9133\n",
      "1203/5349 [=====>........................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9133\n",
      "1388/5349 [======>.......................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9135\n",
      "1576/5349 [=======>......................] - ETA: 2s - loss: 0.1586 - accuracy: 0.9135\n",
      "1761/5349 [========>.....................] - ETA: 2s - loss: 0.1584 - accuracy: 0.9136\n",
      "1945/5349 [=========>....................] - ETA: 1s - loss: 0.1585 - accuracy: 0.9135\n",
      "2146/5349 [===========>..................] - ETA: 1s - loss: 0.1583 - accuracy: 0.9136\n",
      "2255/5349 [===========>..................] - ETA: 1s - loss: 0.1584 - accuracy: 0.9136\n",
      "2425/5349 [============>.................] - ETA: 1s - loss: 0.1582 - accuracy: 0.9138\n",
      "2597/5349 [=============>................] - ETA: 1s - loss: 0.1583 - accuracy: 0.9137\n",
      "2772/5349 [==============>...............] - ETA: 1s - loss: 0.1583 - accuracy: 0.9139\n",
      "2950/5349 [===============>..............] - ETA: 1s - loss: 0.1582 - accuracy: 0.9140\n",
      "3134/5349 [================>.............] - ETA: 1s - loss: 0.1581 - accuracy: 0.9140\n",
      "3203/5349 [================>.............] - ETA: 1s - loss: 0.1581 - accuracy: 0.9140\n",
      "3341/5349 [=================>............] - ETA: 1s - loss: 0.1581 - accuracy: 0.9139\n",
      "3520/5349 [==================>...........] - ETA: 1s - loss: 0.1580 - accuracy: 0.9140\n",
      "3708/5349 [===================>..........] - ETA: 1s - loss: 0.1579 - accuracy: 0.9140\n",
      "3888/5349 [====================>.........] - ETA: 0s - loss: 0.1578 - accuracy: 0.9140\n",
      "4072/5349 [=====================>........] - ETA: 0s - loss: 0.1579 - accuracy: 0.9140\n",
      "4197/5349 [======================>.......] - ETA: 0s - loss: 0.1578 - accuracy: 0.9140\n",
      "4287/5349 [=======================>......] - ETA: 0s - loss: 0.1579 - accuracy: 0.9139\n",
      "4441/5349 [=======================>......] - ETA: 0s - loss: 0.1577 - accuracy: 0.9140\n",
      "4685/5349 [=========================>....] - ETA: 0s - loss: 0.1578 - accuracy: 0.9140\n",
      "4844/5349 [==========================>...] - ETA: 0s - loss: 0.1577 - accuracy: 0.9141\n",
      "5002/5349 [===========================>..] - ETA: 0s - loss: 0.1577 - accuracy: 0.9141\n",
      "5167/5349 [===========================>..] - ETA: 0s - loss: 0.1576 - accuracy: 0.9141\n",
      "5336/5349 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 0.9141\n",
      "5349/5349 [==============================] - 5s 985us/step - loss: 0.1576 - accuracy: 0.9141 - val_loss: 0.1578 - val_accuracy: 0.9160\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 12/20\n",
      "  87/5349 [..............................] - ETA: 6s - loss: 0.1583 - accuracy: 0.9148\n",
      " 184/5349 [>.............................] - ETA: 5s - loss: 0.1561 - accuracy: 0.9172\n",
      " 305/5349 [>.............................] - ETA: 5s - loss: 0.1562 - accuracy: 0.9163\n",
      " 411/5349 [=>............................] - ETA: 4s - loss: 0.1569 - accuracy: 0.9160\n",
      " 519/5349 [=>............................] - ETA: 4s - loss: 0.1572 - accuracy: 0.9151\n",
      " 615/5349 [==>...........................] - ETA: 4s - loss: 0.1578 - accuracy: 0.9146\n",
      " 733/5349 [===>..........................] - ETA: 4s - loss: 0.1571 - accuracy: 0.9154\n",
      " 943/5349 [====>.........................] - ETA: 4s - loss: 0.1574 - accuracy: 0.9149\n",
      "1137/5349 [=====>........................] - ETA: 3s - loss: 0.1576 - accuracy: 0.9148\n",
      "1326/5349 [======>.......................] - ETA: 3s - loss: 0.1577 - accuracy: 0.9144\n",
      "1421/5349 [======>.......................] - ETA: 3s - loss: 0.1576 - accuracy: 0.9144\n",
      "1492/5349 [=======>......................] - ETA: 3s - loss: 0.1574 - accuracy: 0.9144\n",
      "1516/5349 [=======>......................] - ETA: 3s - loss: 0.1573 - accuracy: 0.9145\n",
      "1564/5349 [=======>......................] - ETA: 3s - loss: 0.1575 - accuracy: 0.9146\n",
      "1594/5349 [=======>......................] - ETA: 3s - loss: 0.1574 - accuracy: 0.9146\n",
      "1623/5349 [========>.....................] - ETA: 3s - loss: 0.1573 - accuracy: 0.9147\n",
      "1649/5349 [========>.....................] - ETA: 4s - loss: 0.1574 - accuracy: 0.9146\n",
      "1716/5349 [========>.....................] - ETA: 4s - loss: 0.1576 - accuracy: 0.9144\n",
      "1745/5349 [========>.....................] - ETA: 4s - loss: 0.1576 - accuracy: 0.9143\n",
      "1815/5349 [=========>....................] - ETA: 4s - loss: 0.1573 - accuracy: 0.9145\n",
      "1844/5349 [=========>....................] - ETA: 4s - loss: 0.1572 - accuracy: 0.9145\n",
      "1885/5349 [=========>....................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9146\n",
      "1942/5349 [=========>....................] - ETA: 4s - loss: 0.1571 - accuracy: 0.9145\n",
      "1958/5349 [=========>....................] - ETA: 4s - loss: 0.1571 - accuracy: 0.9145\n",
      "1996/5349 [==========>...................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9145\n",
      "2023/5349 [==========>...................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9145\n",
      "2055/5349 [==========>...................] - ETA: 4s - loss: 0.1569 - accuracy: 0.9145\n",
      "2085/5349 [==========>...................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9145\n",
      "2138/5349 [==========>...................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9144\n",
      "2169/5349 [===========>..................] - ETA: 4s - loss: 0.1569 - accuracy: 0.9144\n",
      "2203/5349 [===========>..................] - ETA: 4s - loss: 0.1569 - accuracy: 0.9144\n",
      "2229/5349 [===========>..................] - ETA: 4s - loss: 0.1570 - accuracy: 0.9144\n",
      "2259/5349 [===========>..................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9145\n",
      "2287/5349 [===========>..................] - ETA: 4s - loss: 0.1569 - accuracy: 0.9145\n",
      "2303/5349 [===========>..................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9145\n",
      "2335/5349 [============>.................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9145\n",
      "2365/5349 [============>.................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9146\n",
      "2394/5349 [============>.................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9145\n",
      "2426/5349 [============>.................] - ETA: 4s - loss: 0.1567 - accuracy: 0.9146\n",
      "2460/5349 [============>.................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9145\n",
      "2500/5349 [=============>................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9146\n",
      "2532/5349 [=============>................] - ETA: 4s - loss: 0.1567 - accuracy: 0.9145\n",
      "2620/5349 [=============>................] - ETA: 4s - loss: 0.1568 - accuracy: 0.9145\n",
      "2743/5349 [==============>...............] - ETA: 4s - loss: 0.1567 - accuracy: 0.9146\n",
      "2887/5349 [===============>..............] - ETA: 4s - loss: 0.1569 - accuracy: 0.9144\n",
      "2957/5349 [===============>..............] - ETA: 3s - loss: 0.1568 - accuracy: 0.9144\n",
      "3112/5349 [================>.............] - ETA: 3s - loss: 0.1570 - accuracy: 0.9143\n",
      "3287/5349 [=================>............] - ETA: 3s - loss: 0.1569 - accuracy: 0.9144\n",
      "3457/5349 [==================>...........] - ETA: 2s - loss: 0.1570 - accuracy: 0.9143\n",
      "3575/5349 [===================>..........] - ETA: 2s - loss: 0.1569 - accuracy: 0.9144\n",
      "3703/5349 [===================>..........] - ETA: 2s - loss: 0.1570 - accuracy: 0.9143\n",
      "3822/5349 [====================>.........] - ETA: 2s - loss: 0.1569 - accuracy: 0.9143\n",
      "3949/5349 [=====================>........] - ETA: 1s - loss: 0.1569 - accuracy: 0.9142\n",
      "4173/5349 [======================>.......] - ETA: 1s - loss: 0.1568 - accuracy: 0.9144\n",
      "4310/5349 [=======================>......] - ETA: 1s - loss: 0.1568 - accuracy: 0.9144\n",
      "4441/5349 [=======================>......] - ETA: 1s - loss: 0.1569 - accuracy: 0.9144\n",
      "4585/5349 [========================>.....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9144\n",
      "4654/5349 [=========================>....] - ETA: 0s - loss: 0.1568 - accuracy: 0.9144\n",
      "4783/5349 [=========================>....] - ETA: 0s - loss: 0.1569 - accuracy: 0.9143\n",
      "4985/5349 [==========================>...] - ETA: 0s - loss: 0.1569 - accuracy: 0.9143\n",
      "5177/5349 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9142\n",
      "5270/5349 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9143\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1569 - accuracy: 0.9143 - val_loss: 0.1569 - val_accuracy: 0.9161\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 13/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1267 - accuracy: 0.9300\n",
      " 178/5349 [..............................] - ETA: 2s - loss: 0.1547 - accuracy: 0.9167\n",
      " 318/5349 [>.............................] - ETA: 3s - loss: 0.1557 - accuracy: 0.9158\n",
      " 497/5349 [=>............................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9155\n",
      " 678/5349 [==>...........................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9146\n",
      " 840/5349 [===>..........................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9151\n",
      "1007/5349 [====>.........................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9153\n",
      "1097/5349 [=====>........................] - ETA: 2s - loss: 0.1560 - accuracy: 0.9149\n",
      "1276/5349 [======>.......................] - ETA: 2s - loss: 0.1566 - accuracy: 0.9147\n",
      "1452/5349 [=======>......................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9147\n",
      "1512/5349 [=======>......................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9146\n",
      "1568/5349 [=======>......................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9149\n",
      "1678/5349 [========>.....................] - ETA: 2s - loss: 0.1564 - accuracy: 0.9148\n",
      "1739/5349 [========>.....................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9148\n",
      "1798/5349 [=========>....................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9148\n",
      "1883/5349 [=========>....................] - ETA: 2s - loss: 0.1565 - accuracy: 0.9146\n",
      "2037/5349 [==========>...................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9146\n",
      "2141/5349 [===========>..................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9147\n",
      "2374/5349 [============>.................] - ETA: 2s - loss: 0.1563 - accuracy: 0.9145\n",
      "2528/5349 [=============>................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9148\n",
      "2675/5349 [==============>...............] - ETA: 1s - loss: 0.1561 - accuracy: 0.9148\n",
      "2825/5349 [==============>...............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9150\n",
      "3001/5349 [===============>..............] - ETA: 1s - loss: 0.1557 - accuracy: 0.9151\n",
      "3165/5349 [================>.............] - ETA: 1s - loss: 0.1557 - accuracy: 0.9152\n",
      "3351/5349 [=================>............] - ETA: 1s - loss: 0.1558 - accuracy: 0.9151\n",
      "3533/5349 [==================>...........] - ETA: 1s - loss: 0.1558 - accuracy: 0.9150\n",
      "3657/5349 [===================>..........] - ETA: 1s - loss: 0.1558 - accuracy: 0.9149\n",
      "3747/5349 [====================>.........] - ETA: 1s - loss: 0.1558 - accuracy: 0.9149\n",
      "3771/5349 [====================>.........] - ETA: 1s - loss: 0.1559 - accuracy: 0.9148\n",
      "3831/5349 [====================>.........] - ETA: 1s - loss: 0.1560 - accuracy: 0.9148\n",
      "3890/5349 [====================>.........] - ETA: 1s - loss: 0.1559 - accuracy: 0.9148\n",
      "3927/5349 [=====================>........] - ETA: 1s - loss: 0.1559 - accuracy: 0.9147\n",
      "3961/5349 [=====================>........] - ETA: 1s - loss: 0.1560 - accuracy: 0.9147\n",
      "4010/5349 [=====================>........] - ETA: 1s - loss: 0.1561 - accuracy: 0.9147\n",
      "4048/5349 [=====================>........] - ETA: 1s - loss: 0.1562 - accuracy: 0.9145\n",
      "4075/5349 [=====================>........] - ETA: 1s - loss: 0.1563 - accuracy: 0.9144\n",
      "4104/5349 [======================>.......] - ETA: 1s - loss: 0.1563 - accuracy: 0.9145\n",
      "4147/5349 [======================>.......] - ETA: 1s - loss: 0.1562 - accuracy: 0.9146\n",
      "4202/5349 [======================>.......] - ETA: 1s - loss: 0.1562 - accuracy: 0.9146\n",
      "4216/5349 [======================>.......] - ETA: 1s - loss: 0.1563 - accuracy: 0.9145\n",
      "4245/5349 [======================>.......] - ETA: 1s - loss: 0.1563 - accuracy: 0.9145\n",
      "4270/5349 [======================>.......] - ETA: 1s - loss: 0.1563 - accuracy: 0.9145\n",
      "4298/5349 [=======================>......] - ETA: 1s - loss: 0.1563 - accuracy: 0.9145\n",
      "4337/5349 [=======================>......] - ETA: 1s - loss: 0.1562 - accuracy: 0.9145\n",
      "4376/5349 [=======================>......] - ETA: 0s - loss: 0.1563 - accuracy: 0.9145\n",
      "4427/5349 [=======================>......] - ETA: 0s - loss: 0.1562 - accuracy: 0.9145\n",
      "4443/5349 [=======================>......] - ETA: 0s - loss: 0.1562 - accuracy: 0.9145\n",
      "4463/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9145\n",
      "4499/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9145\n",
      "4529/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4559/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4593/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4620/5349 [========================>.....] - ETA: 0s - loss: 0.1561 - accuracy: 0.9147\n",
      "4635/5349 [========================>.....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4672/5349 [=========================>....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4703/5349 [=========================>....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4740/5349 [=========================>....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9147\n",
      "4749/5349 [=========================>....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4774/5349 [=========================>....] - ETA: 0s - loss: 0.1562 - accuracy: 0.9146\n",
      "4880/5349 [==========================>...] - ETA: 0s - loss: 0.1562 - accuracy: 0.9147\n",
      "5002/5349 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.9147\n",
      "5107/5349 [===========================>..] - ETA: 0s - loss: 0.1562 - accuracy: 0.9147\n",
      "5221/5349 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9147\n",
      "5301/5349 [============================>.] - ETA: 0s - loss: 0.1562 - accuracy: 0.9147\n",
      "5349/5349 [==============================] - 8s 2ms/step - loss: 0.1562 - accuracy: 0.9147 - val_loss: 0.1558 - val_accuracy: 0.9161\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 14/20\n",
      "  67/5349 [..............................] - ETA: 4s - loss: 0.1602 - accuracy: 0.9113 \n",
      " 213/5349 [>.............................] - ETA: 4s - loss: 0.1573 - accuracy: 0.9142\n",
      " 380/5349 [=>............................] - ETA: 3s - loss: 0.1568 - accuracy: 0.9143\n",
      " 574/5349 [==>...........................] - ETA: 3s - loss: 0.1565 - accuracy: 0.9148\n",
      " 700/5349 [==>...........................] - ETA: 3s - loss: 0.1558 - accuracy: 0.9151\n",
      " 861/5349 [===>..........................] - ETA: 3s - loss: 0.1557 - accuracy: 0.9150\n",
      "1035/5349 [====>.........................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9151\n",
      "1205/5349 [=====>........................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9149\n",
      "1381/5349 [======>.......................] - ETA: 2s - loss: 0.1558 - accuracy: 0.9147\n",
      "1652/5349 [========>.....................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9141\n",
      "1826/5349 [=========>....................] - ETA: 2s - loss: 0.1561 - accuracy: 0.9143\n",
      "1993/5349 [==========>...................] - ETA: 2s - loss: 0.1557 - accuracy: 0.9147\n",
      "2168/5349 [===========>..................] - ETA: 1s - loss: 0.1557 - accuracy: 0.9146\n",
      "2349/5349 [============>.................] - ETA: 1s - loss: 0.1555 - accuracy: 0.9147\n",
      "2502/5349 [=============>................] - ETA: 1s - loss: 0.1554 - accuracy: 0.9146\n",
      "2675/5349 [==============>...............] - ETA: 1s - loss: 0.1552 - accuracy: 0.9148\n",
      "2854/5349 [===============>..............] - ETA: 1s - loss: 0.1554 - accuracy: 0.9147\n",
      "3033/5349 [================>.............] - ETA: 1s - loss: 0.1554 - accuracy: 0.9147\n",
      "3195/5349 [================>.............] - ETA: 1s - loss: 0.1554 - accuracy: 0.9147\n",
      "3272/5349 [=================>............] - ETA: 1s - loss: 0.1556 - accuracy: 0.9146\n",
      "3449/5349 [==================>...........] - ETA: 1s - loss: 0.1556 - accuracy: 0.9146\n",
      "3621/5349 [===================>..........] - ETA: 1s - loss: 0.1557 - accuracy: 0.9145\n",
      "3796/5349 [====================>.........] - ETA: 0s - loss: 0.1558 - accuracy: 0.9145\n",
      "3979/5349 [=====================>........] - ETA: 0s - loss: 0.1557 - accuracy: 0.9147\n",
      "4167/5349 [======================>.......] - ETA: 0s - loss: 0.1555 - accuracy: 0.9148\n",
      "4347/5349 [=======================>......] - ETA: 0s - loss: 0.1556 - accuracy: 0.9148\n",
      "4523/5349 [========================>.....] - ETA: 0s - loss: 0.1556 - accuracy: 0.9148\n",
      "4708/5349 [=========================>....] - ETA: 0s - loss: 0.1556 - accuracy: 0.9148\n",
      "4892/5349 [==========================>...] - ETA: 0s - loss: 0.1556 - accuracy: 0.9147\n",
      "5165/5349 [===========================>..] - ETA: 0s - loss: 0.1555 - accuracy: 0.9148\n",
      "5339/5349 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9148\n",
      "5349/5349 [==============================] - 4s 790us/step - loss: 0.1555 - accuracy: 0.9148 - val_loss: 0.1553 - val_accuracy: 0.9161\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 15/20\n",
      "  93/5349 [..............................] - ETA: 2s - loss: 0.1604 - accuracy: 0.9115\n",
      " 275/5349 [>.............................] - ETA: 2s - loss: 0.1591 - accuracy: 0.9125\n",
      " 466/5349 [=>............................] - ETA: 2s - loss: 0.1583 - accuracy: 0.9133\n",
      " 558/5349 [==>...........................] - ETA: 2s - loss: 0.1574 - accuracy: 0.9144\n",
      " 725/5349 [===>..........................] - ETA: 2s - loss: 0.1566 - accuracy: 0.9146\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9150\n",
      "1101/5349 [=====>........................] - ETA: 2s - loss: 0.1559 - accuracy: 0.9148\n",
      "1278/5349 [======>.......................] - ETA: 2s - loss: 0.1562 - accuracy: 0.9146\n",
      "1447/5349 [=======>......................] - ETA: 2s - loss: 0.1556 - accuracy: 0.9149\n",
      "1609/5349 [========>.....................] - ETA: 2s - loss: 0.1555 - accuracy: 0.9148\n",
      "1785/5349 [=========>....................] - ETA: 2s - loss: 0.1553 - accuracy: 0.9149\n",
      "1957/5349 [=========>....................] - ETA: 1s - loss: 0.1557 - accuracy: 0.9146\n",
      "2130/5349 [==========>...................] - ETA: 1s - loss: 0.1557 - accuracy: 0.9146\n",
      "2377/5349 [============>.................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9149\n",
      "2549/5349 [=============>................] - ETA: 1s - loss: 0.1552 - accuracy: 0.9150\n",
      "2733/5349 [==============>...............] - ETA: 1s - loss: 0.1551 - accuracy: 0.9150\n",
      "2908/5349 [===============>..............] - ETA: 1s - loss: 0.1551 - accuracy: 0.9151\n",
      "3079/5349 [================>.............] - ETA: 1s - loss: 0.1551 - accuracy: 0.9150\n",
      "3247/5349 [=================>............] - ETA: 1s - loss: 0.1552 - accuracy: 0.9150\n",
      "3416/5349 [==================>...........] - ETA: 1s - loss: 0.1552 - accuracy: 0.9150\n",
      "3589/5349 [===================>..........] - ETA: 1s - loss: 0.1550 - accuracy: 0.9150\n",
      "3765/5349 [====================>.........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9148\n",
      "3948/5349 [=====================>........] - ETA: 0s - loss: 0.1551 - accuracy: 0.9150\n",
      "4161/5349 [======================>.......] - ETA: 0s - loss: 0.1551 - accuracy: 0.9151\n",
      "4317/5349 [=======================>......] - ETA: 0s - loss: 0.1550 - accuracy: 0.9151\n",
      "4491/5349 [========================>.....] - ETA: 0s - loss: 0.1552 - accuracy: 0.9151\n",
      "4668/5349 [=========================>....] - ETA: 0s - loss: 0.1551 - accuracy: 0.9151\n",
      "4847/5349 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9151\n",
      "5028/5349 [===========================>..] - ETA: 0s - loss: 0.1551 - accuracy: 0.9151\n",
      "5214/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9151\n",
      "5307/5349 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9151\n",
      "5349/5349 [==============================] - 4s 800us/step - loss: 0.1551 - accuracy: 0.9151 - val_loss: 0.1556 - val_accuracy: 0.9162\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 16/20\n",
      "   1/5349 [..............................] - ETA: 6s - loss: 0.1779 - accuracy: 0.9100\n",
      " 156/5349 [..............................] - ETA: 3s - loss: 0.1554 - accuracy: 0.9117\n",
      " 324/5349 [>.............................] - ETA: 3s - loss: 0.1535 - accuracy: 0.9140\n",
      " 508/5349 [=>............................] - ETA: 2s - loss: 0.1541 - accuracy: 0.9143\n",
      " 682/5349 [==>...........................] - ETA: 2s - loss: 0.1542 - accuracy: 0.9147\n",
      " 958/5349 [====>.........................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9159\n",
      "1122/5349 [=====>........................] - ETA: 2s - loss: 0.1535 - accuracy: 0.9158\n",
      "1302/5349 [======>.......................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9154\n",
      "1489/5349 [=======>......................] - ETA: 2s - loss: 0.1540 - accuracy: 0.9153\n",
      "1673/5349 [========>.....................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9154\n",
      "1858/5349 [=========>....................] - ETA: 1s - loss: 0.1540 - accuracy: 0.9152\n",
      "2034/5349 [==========>...................] - ETA: 1s - loss: 0.1542 - accuracy: 0.9150\n",
      "2217/5349 [===========>..................] - ETA: 1s - loss: 0.1543 - accuracy: 0.9149\n",
      "2404/5349 [============>.................] - ETA: 1s - loss: 0.1540 - accuracy: 0.9152\n",
      "2594/5349 [=============>................] - ETA: 1s - loss: 0.1543 - accuracy: 0.9151\n",
      "2875/5349 [===============>..............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9151\n",
      "3055/5349 [================>.............] - ETA: 1s - loss: 0.1543 - accuracy: 0.9152\n",
      "3238/5349 [=================>............] - ETA: 1s - loss: 0.1544 - accuracy: 0.9151\n",
      "3414/5349 [==================>...........] - ETA: 1s - loss: 0.1543 - accuracy: 0.9151\n",
      "3589/5349 [===================>..........] - ETA: 0s - loss: 0.1543 - accuracy: 0.9151\n",
      "3751/5349 [====================>.........] - ETA: 0s - loss: 0.1543 - accuracy: 0.9151\n",
      "3883/5349 [====================>.........] - ETA: 0s - loss: 0.1545 - accuracy: 0.9150\n",
      "4035/5349 [=====================>........] - ETA: 0s - loss: 0.1546 - accuracy: 0.9150\n",
      "4176/5349 [======================>.......] - ETA: 0s - loss: 0.1547 - accuracy: 0.9149\n",
      "4412/5349 [=======================>......] - ETA: 0s - loss: 0.1544 - accuracy: 0.9151\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.1544 - accuracy: 0.9151\n",
      "4707/5349 [=========================>....] - ETA: 0s - loss: 0.1544 - accuracy: 0.9152\n",
      "4862/5349 [==========================>...] - ETA: 0s - loss: 0.1545 - accuracy: 0.9151\n",
      "5027/5349 [===========================>..] - ETA: 0s - loss: 0.1545 - accuracy: 0.9151\n",
      "5195/5349 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9151\n",
      "5298/5349 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9150\n",
      "5349/5349 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9150\n",
      "5349/5349 [==============================] - 4s 809us/step - loss: 0.1546 - accuracy: 0.9150 - val_loss: 0.1546 - val_accuracy: 0.9164\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 17/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1557 - accuracy: 0.9400\n",
      " 181/5349 [>.............................] - ETA: 2s - loss: 0.1545 - accuracy: 0.9140\n",
      " 359/5349 [=>............................] - ETA: 2s - loss: 0.1541 - accuracy: 0.9149\n",
      " 544/5349 [==>...........................] - ETA: 2s - loss: 0.1541 - accuracy: 0.9151\n",
      " 710/5349 [==>...........................] - ETA: 2s - loss: 0.1542 - accuracy: 0.9151\n",
      " 912/5349 [====>.........................] - ETA: 2s - loss: 0.1541 - accuracy: 0.9153\n",
      "1064/5349 [====>.........................] - ETA: 2s - loss: 0.1537 - accuracy: 0.9154\n",
      "1232/5349 [=====>........................] - ETA: 2s - loss: 0.1534 - accuracy: 0.9155\n",
      "1406/5349 [======>.......................] - ETA: 2s - loss: 0.1532 - accuracy: 0.9158\n",
      "1580/5349 [=======>......................] - ETA: 2s - loss: 0.1538 - accuracy: 0.9154\n",
      "1739/5349 [========>.....................] - ETA: 2s - loss: 0.1534 - accuracy: 0.9158\n",
      "1912/5349 [=========>....................] - ETA: 2s - loss: 0.1533 - accuracy: 0.9158\n",
      "2085/5349 [==========>...................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9157\n",
      "2241/5349 [===========>..................] - ETA: 1s - loss: 0.1536 - accuracy: 0.9157\n",
      "2404/5349 [============>.................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9157\n",
      "2651/5349 [=============>................] - ETA: 1s - loss: 0.1537 - accuracy: 0.9158\n",
      "2828/5349 [==============>...............] - ETA: 1s - loss: 0.1536 - accuracy: 0.9159\n",
      "2998/5349 [===============>..............] - ETA: 1s - loss: 0.1537 - accuracy: 0.9158\n",
      "3159/5349 [================>.............] - ETA: 1s - loss: 0.1539 - accuracy: 0.9157\n",
      "3340/5349 [=================>............] - ETA: 1s - loss: 0.1541 - accuracy: 0.9156\n",
      "3518/5349 [==================>...........] - ETA: 1s - loss: 0.1541 - accuracy: 0.9157\n",
      "3697/5349 [===================>..........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9158\n",
      "3875/5349 [====================>.........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9158\n",
      "3924/5349 [=====================>........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9158\n",
      "4071/5349 [=====================>........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9157\n",
      "4233/5349 [======================>.......] - ETA: 0s - loss: 0.1542 - accuracy: 0.9155\n",
      "4392/5349 [=======================>......] - ETA: 0s - loss: 0.1543 - accuracy: 0.9155\n",
      "4533/5349 [========================>.....] - ETA: 0s - loss: 0.1542 - accuracy: 0.9156\n",
      "4665/5349 [=========================>....] - ETA: 0s - loss: 0.1541 - accuracy: 0.9156\n",
      "4819/5349 [==========================>...] - ETA: 0s - loss: 0.1541 - accuracy: 0.9157\n",
      "4960/5349 [==========================>...] - ETA: 0s - loss: 0.1540 - accuracy: 0.9157\n",
      "5030/5349 [===========================>..] - ETA: 0s - loss: 0.1540 - accuracy: 0.9157\n",
      "5177/5349 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9156\n",
      "5343/5349 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9156\n",
      "5349/5349 [==============================] - 4s 835us/step - loss: 0.1540 - accuracy: 0.9156 - val_loss: 0.1545 - val_accuracy: 0.9163\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 18/20\n",
      "   1/5349 [..............................] - ETA: 55s - loss: 0.1084 - accuracy: 0.9500\n",
      "  47/5349 [..............................] - ETA: 13s - loss: 0.1553 - accuracy: 0.9147\n",
      " 121/5349 [..............................] - ETA: 9s - loss: 0.1541 - accuracy: 0.9162 \n",
      " 287/5349 [>.............................] - ETA: 5s - loss: 0.1527 - accuracy: 0.9172\n",
      " 453/5349 [=>............................] - ETA: 4s - loss: 0.1547 - accuracy: 0.9156\n",
      " 631/5349 [==>...........................] - ETA: 3s - loss: 0.1541 - accuracy: 0.9160\n",
      " 798/5349 [===>..........................] - ETA: 3s - loss: 0.1543 - accuracy: 0.9155\n",
      " 980/5349 [====>.........................] - ETA: 3s - loss: 0.1542 - accuracy: 0.9156\n",
      "1255/5349 [======>.......................] - ETA: 2s - loss: 0.1550 - accuracy: 0.9147\n",
      "1433/5349 [=======>......................] - ETA: 2s - loss: 0.1549 - accuracy: 0.9148\n",
      "1613/5349 [========>.....................] - ETA: 2s - loss: 0.1546 - accuracy: 0.9151\n",
      "1795/5349 [=========>....................] - ETA: 2s - loss: 0.1543 - accuracy: 0.9150\n",
      "1978/5349 [==========>...................] - ETA: 2s - loss: 0.1542 - accuracy: 0.9151\n",
      "2151/5349 [===========>..................] - ETA: 2s - loss: 0.1539 - accuracy: 0.9153\n",
      "2336/5349 [============>.................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9152\n",
      "2517/5349 [=============>................] - ETA: 1s - loss: 0.1541 - accuracy: 0.9152\n",
      "2703/5349 [==============>...............] - ETA: 1s - loss: 0.1538 - accuracy: 0.9155\n",
      "2884/5349 [===============>..............] - ETA: 1s - loss: 0.1538 - accuracy: 0.9154\n",
      "3067/5349 [================>.............] - ETA: 1s - loss: 0.1538 - accuracy: 0.9154\n",
      "3247/5349 [=================>............] - ETA: 1s - loss: 0.1537 - accuracy: 0.9156\n",
      "3339/5349 [=================>............] - ETA: 1s - loss: 0.1537 - accuracy: 0.9156\n",
      "3505/5349 [==================>...........] - ETA: 1s - loss: 0.1537 - accuracy: 0.9157\n",
      "3657/5349 [===================>..........] - ETA: 1s - loss: 0.1537 - accuracy: 0.9157\n",
      "3799/5349 [====================>.........] - ETA: 0s - loss: 0.1535 - accuracy: 0.9159\n",
      "3965/5349 [=====================>........] - ETA: 0s - loss: 0.1535 - accuracy: 0.9158\n",
      "4142/5349 [======================>.......] - ETA: 0s - loss: 0.1533 - accuracy: 0.9159\n",
      "4325/5349 [=======================>......] - ETA: 0s - loss: 0.1532 - accuracy: 0.9161\n",
      "4500/5349 [========================>.....] - ETA: 0s - loss: 0.1536 - accuracy: 0.9158\n",
      "4680/5349 [=========================>....] - ETA: 0s - loss: 0.1536 - accuracy: 0.9158\n",
      "4860/5349 [==========================>...] - ETA: 0s - loss: 0.1537 - accuracy: 0.9156\n",
      "4947/5349 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.9155\n",
      "5104/5349 [===========================>..] - ETA: 0s - loss: 0.1536 - accuracy: 0.9156\n",
      "5265/5349 [============================>.] - ETA: 0s - loss: 0.1535 - accuracy: 0.9157\n",
      "5349/5349 [==============================] - 4s 835us/step - loss: 0.1535 - accuracy: 0.9157 - val_loss: 0.1544 - val_accuracy: 0.9162\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 19/20\n",
      "  89/5349 [..............................] - ETA: 2s - loss: 0.1464 - accuracy: 0.9197\n",
      " 254/5349 [>.............................] - ETA: 3s - loss: 0.1519 - accuracy: 0.9157\n",
      " 286/5349 [>.............................] - ETA: 4s - loss: 0.1525 - accuracy: 0.9148\n",
      " 433/5349 [=>............................] - ETA: 4s - loss: 0.1537 - accuracy: 0.9146\n",
      " 601/5349 [==>...........................] - ETA: 3s - loss: 0.1529 - accuracy: 0.9158\n",
      " 748/5349 [===>..........................] - ETA: 3s - loss: 0.1525 - accuracy: 0.9160\n",
      " 886/5349 [===>..........................] - ETA: 3s - loss: 0.1523 - accuracy: 0.9162\n",
      "1055/5349 [====>.........................] - ETA: 3s - loss: 0.1517 - accuracy: 0.9169\n",
      "1280/5349 [======>.......................] - ETA: 2s - loss: 0.1519 - accuracy: 0.9168\n",
      "1463/5349 [=======>......................] - ETA: 2s - loss: 0.1517 - accuracy: 0.9169\n",
      "1632/5349 [========>.....................] - ETA: 2s - loss: 0.1516 - accuracy: 0.9172\n",
      "1800/5349 [=========>....................] - ETA: 2s - loss: 0.1520 - accuracy: 0.9170\n",
      "1980/5349 [==========>...................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9168\n",
      "2124/5349 [==========>...................] - ETA: 2s - loss: 0.1526 - accuracy: 0.9165\n",
      "2282/5349 [===========>..................] - ETA: 2s - loss: 0.1529 - accuracy: 0.9162\n",
      "2424/5349 [============>.................] - ETA: 1s - loss: 0.1530 - accuracy: 0.9161\n",
      "2585/5349 [=============>................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9161\n",
      "2736/5349 [==============>...............] - ETA: 1s - loss: 0.1527 - accuracy: 0.9161\n",
      "2956/5349 [===============>..............] - ETA: 1s - loss: 0.1528 - accuracy: 0.9160\n",
      "3073/5349 [================>.............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9158\n",
      "3171/5349 [================>.............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9158\n",
      "3286/5349 [=================>............] - ETA: 1s - loss: 0.1530 - accuracy: 0.9159\n",
      "3428/5349 [==================>...........] - ETA: 1s - loss: 0.1529 - accuracy: 0.9159\n",
      "3589/5349 [===================>..........] - ETA: 1s - loss: 0.1530 - accuracy: 0.9159\n",
      "3768/5349 [====================>.........] - ETA: 1s - loss: 0.1529 - accuracy: 0.9160\n",
      "3949/5349 [=====================>........] - ETA: 0s - loss: 0.1530 - accuracy: 0.9161\n",
      "4212/5349 [======================>.......] - ETA: 0s - loss: 0.1530 - accuracy: 0.9160\n",
      "4385/5349 [=======================>......] - ETA: 0s - loss: 0.1531 - accuracy: 0.9159\n",
      "4562/5349 [========================>.....] - ETA: 0s - loss: 0.1531 - accuracy: 0.9159\n",
      "4747/5349 [=========================>....] - ETA: 0s - loss: 0.1531 - accuracy: 0.9159\n",
      "4931/5349 [==========================>...] - ETA: 0s - loss: 0.1531 - accuracy: 0.9159\n",
      "5109/5349 [===========================>..] - ETA: 0s - loss: 0.1532 - accuracy: 0.9158\n",
      "5287/5349 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9158\n",
      "5349/5349 [==============================] - 5s 887us/step - loss: 0.1531 - accuracy: 0.9159 - val_loss: 0.1532 - val_accuracy: 0.9164\n",
      "\u001B[36m(train_DNN pid=6312)\u001B[0m Epoch 20/20\n",
      "   1/5349 [..............................] - ETA: 4s - loss: 0.1847 - accuracy: 0.8800\n",
      " 167/5349 [..............................] - ETA: 3s - loss: 0.1496 - accuracy: 0.9171\n",
      " 330/5349 [>.............................] - ETA: 3s - loss: 0.1512 - accuracy: 0.9174\n",
      " 515/5349 [=>............................] - ETA: 2s - loss: 0.1511 - accuracy: 0.9175\n",
      " 701/5349 [==>...........................] - ETA: 2s - loss: 0.1503 - accuracy: 0.9184\n",
      " 874/5349 [===>..........................] - ETA: 2s - loss: 0.1509 - accuracy: 0.9178\n",
      "1052/5349 [====>.........................] - ETA: 2s - loss: 0.1519 - accuracy: 0.9169\n",
      "1224/5349 [=====>........................] - ETA: 2s - loss: 0.1518 - accuracy: 0.9171\n",
      "1312/5349 [======>.......................] - ETA: 2s - loss: 0.1522 - accuracy: 0.9164\n",
      "1481/5349 [=======>......................] - ETA: 2s - loss: 0.1521 - accuracy: 0.9164\n",
      "1656/5349 [========>.....................] - ETA: 2s - loss: 0.1521 - accuracy: 0.9167\n",
      "1837/5349 [=========>....................] - ETA: 2s - loss: 0.1524 - accuracy: 0.9166\n",
      "2015/5349 [==========>...................] - ETA: 1s - loss: 0.1523 - accuracy: 0.9165\n",
      "2189/5349 [===========>..................] - ETA: 1s - loss: 0.1528 - accuracy: 0.9160\n",
      "2350/5349 [============>.................] - ETA: 1s - loss: 0.1527 - accuracy: 0.9161\n",
      "2497/5349 [=============>................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9161\n",
      "2670/5349 [=============>................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9162\n",
      "2845/5349 [==============>...............] - ETA: 1s - loss: 0.1527 - accuracy: 0.9161\n",
      "2927/5349 [===============>..............] - ETA: 1s - loss: 0.1529 - accuracy: 0.9159\n",
      "3109/5349 [================>.............] - ETA: 1s - loss: 0.1531 - accuracy: 0.9159\n",
      "3272/5349 [=================>............] - ETA: 1s - loss: 0.1529 - accuracy: 0.9161\n",
      "3404/5349 [==================>...........] - ETA: 1s - loss: 0.1528 - accuracy: 0.9162\n",
      "3585/5349 [===================>..........] - ETA: 1s - loss: 0.1528 - accuracy: 0.9161\n",
      "3754/5349 [====================>.........] - ETA: 0s - loss: 0.1527 - accuracy: 0.9161\n",
      "3908/5349 [====================>.........] - ETA: 0s - loss: 0.1528 - accuracy: 0.9160\n",
      "4089/5349 [=====================>........] - ETA: 0s - loss: 0.1528 - accuracy: 0.9161\n",
      "4223/5349 [======================>.......] - ETA: 0s - loss: 0.1528 - accuracy: 0.9161\n",
      "4401/5349 [=======================>......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9161\n",
      "4658/5349 [=========================>....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9161\n",
      "4832/5349 [==========================>...] - ETA: 0s - loss: 0.1527 - accuracy: 0.9162\n",
      "4970/5349 [==========================>...] - ETA: 0s - loss: 0.1526 - accuracy: 0.9162\n",
      "5050/5349 [===========================>..] - ETA: 0s - loss: 0.1526 - accuracy: 0.9162\n",
      "5188/5349 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9161\n",
      "5266/5349 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-27 12:02:45,193\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/finnbeckmann/uni/DLLabs/ray/DNN_hp_tuning' in 0.0205s.\n",
      "2026-02-27 12:02:45,207\tERROR tune.py:1037 -- Trials did not complete: [train_DNN_906fd_00009, train_DNN_906fd_00014, train_DNN_906fd_00021]\n",
      "2026-02-27 12:02:45,207\tINFO tune.py:1041 -- Total run time: 2267.96 seconds (2267.86 seconds for the tuning loop).\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T11:03:02.336218Z",
     "start_time": "2026-02-27T11:03:01.740334Z"
    }
   },
   "source": [
    "# Show the best hyper parameter configuration that was found\n",
    "best_trial = results.get_best_result(metric=\"mean_accuracy\", mode='max')\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.metrics['keras_info']['val_loss']:0.8f}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.metrics['keras_info']['val_accuracy']:0.8f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'act_fun': 'relu', 'optimizer': 'adam', 'use_bn': True, 'n_hidden_layers': 4, 'n_hidden_units': 30, 'loss': <tf_keras.src.losses.BinaryCrossentropy object at 0x3507f10d0>, 'learning_rate': 0.001, 'use_dropout': False, 'use_custom_dropout': False, 'use_variational_layer': False, 'input_shape': (93,)}\n",
      "Best trial final validation loss: 0.15746838\n",
      "Best trial final validation accuracy: 0.93753529\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Uncertainty quantification\n",
    "\n",
    "In the next sections you will explore three methods for model uncertainty estimation:\n",
    "- Monte Carlo dropout where we take advantage of the dropout layer during inference time.\n",
    "- Cross validation where we train several models on different splits of data.\n",
    "- Bayesian neural networks (BNN) where we modify our model definition to allow the model to learn distributions over weights and the output. \n",
    "\n",
    "**!Note**: through the next sections, use your best model configuration that you found through hyper parameter tuning (either manual or automatic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Dropout uncertainty**\n",
    "\n",
    "Dropout can also be used during testing, to obtain an estimate of the model uncertainty. Since dropout will randomly remove connections, the network will produce different results every time the same (test) data is put into the network. This technique is called Monte Carlo dropout. For more information, see this [paper](http://proceedings.mlr.press/v48/gal16.pdf)\n",
    "\n",
    "To achieve this, we need to redefine the Keras Dropout. This was already done for you and it is available in `utilities.py` under `myDropout`. Adapt the `build_DNN` function to two boolean arguments, use_dropout and use_custom_dropout; add a standard Dropout layer if use_dropout is true, add a `myDropout` layer if use_custom_dropout is true.\n",
    "\n",
    "Run the same test data through the trained network 100 times, with dropout turned on. \n"
   ]
  },
  {
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-02-27T11:06:17.519828Z",
     "start_time": "2026-02-27T11:03:26.977859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Your best training parameters\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "input_shape = (Xtrain.shape[1],)\n",
    "loss = BinaryCrossentropy()\n",
    "learning_rate = 0.001\n",
    "hidden_layers = best_trial.config[\"n_hidden_layers\"]\n",
    "hidden_units = best_trial.config[\"n_hidden_units\"]\n",
    "act_fun = best_trial.config[\"act_fun\"]\n",
    "optimizer = best_trial.config[\"optimizer\"]\n",
    "use_bn = best_trial.config[\"use_bn\"]\n",
    "\n",
    "# Build and train model\n",
    "model10 = build_DNN(input_shape=input_shape,\n",
    "                    n_hidden_layers=hidden_layers,\n",
    "                    n_hidden_units=hidden_units,\n",
    "                    loss=loss,\n",
    "                    learning_rate=learning_rate,\n",
    "                    act_fun=act_fun,\n",
    "                    optimizer=optimizer,\n",
    "                    use_bn=use_bn,\n",
    "                    use_dropout=True,\n",
    "                    use_custom_dropout=True)\n",
    "\n",
    "history10 = model10.fit(Xtrain, Ytrain,\n",
    "                        validation_data=(Xval, Yval),\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        class_weight=class_weights)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5349/5349 [==============================] - 19s 3ms/step - loss: 0.2313 - accuracy: 0.8985 - val_loss: 0.2191 - val_accuracy: 0.9113\n",
      "Epoch 2/20\n",
      "5349/5349 [==============================] - 9s 2ms/step - loss: 0.1837 - accuracy: 0.9097 - val_loss: 0.2244 - val_accuracy: 0.9112\n",
      "Epoch 3/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1801 - accuracy: 0.9114 - val_loss: 0.2225 - val_accuracy: 0.9142\n",
      "Epoch 4/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1770 - accuracy: 0.9121 - val_loss: 0.2201 - val_accuracy: 0.9143\n",
      "Epoch 5/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1786 - accuracy: 0.9124 - val_loss: 0.2225 - val_accuracy: 0.9139\n",
      "Epoch 6/20\n",
      "5349/5349 [==============================] - 9s 2ms/step - loss: 0.1755 - accuracy: 0.9131 - val_loss: 0.2185 - val_accuracy: 0.9150\n",
      "Epoch 7/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1766 - accuracy: 0.9128 - val_loss: 0.2231 - val_accuracy: 0.9137\n",
      "Epoch 8/20\n",
      "5349/5349 [==============================] - 8s 2ms/step - loss: 0.1737 - accuracy: 0.9133 - val_loss: 0.2199 - val_accuracy: 0.9138\n",
      "Epoch 9/20\n",
      "5349/5349 [==============================] - 9s 2ms/step - loss: 0.1748 - accuracy: 0.9131 - val_loss: 0.2176 - val_accuracy: 0.9150\n",
      "Epoch 10/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1734 - accuracy: 0.9137 - val_loss: 0.2213 - val_accuracy: 0.9143\n",
      "Epoch 11/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1753 - accuracy: 0.9138 - val_loss: 0.2191 - val_accuracy: 0.9151\n",
      "Epoch 12/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1733 - accuracy: 0.9138 - val_loss: 0.2122 - val_accuracy: 0.9145\n",
      "Epoch 13/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1733 - accuracy: 0.9141 - val_loss: 0.2182 - val_accuracy: 0.9154\n",
      "Epoch 14/20\n",
      "5349/5349 [==============================] - 8s 2ms/step - loss: 0.1737 - accuracy: 0.9141 - val_loss: 0.2183 - val_accuracy: 0.9149\n",
      "Epoch 15/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1736 - accuracy: 0.9140 - val_loss: 0.2083 - val_accuracy: 0.9154\n",
      "Epoch 16/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1721 - accuracy: 0.9145 - val_loss: 0.2102 - val_accuracy: 0.9155\n",
      "Epoch 17/20\n",
      "5349/5349 [==============================] - 8s 1ms/step - loss: 0.1751 - accuracy: 0.9141 - val_loss: 0.2153 - val_accuracy: 0.9158\n",
      "Epoch 18/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1724 - accuracy: 0.9143 - val_loss: 0.2161 - val_accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1725 - accuracy: 0.9143 - val_loss: 0.2160 - val_accuracy: 0.9158\n",
      "Epoch 20/20\n",
      "5349/5349 [==============================] - 7s 1ms/step - loss: 0.1720 - accuracy: 0.9147 - val_loss: 0.2168 - val_accuracy: 0.9157\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T11:17:00.140049Z",
     "start_time": "2026-02-27T11:16:55.697997Z"
    }
   },
   "source": [
    "# Run this cell a few times to evalute the model on test data, \n",
    "# if you get slightly different test accuracy every time, Dropout during testing is working\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = model10.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "print('Test accuracy: %.8f' % score[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.91503769\n"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T11:23:22.582963Z",
     "start_time": "2026-02-27T11:17:01.542615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# === Your code here =========================\n",
    "# ============================================\n",
    "# Run the testing 100 times, and save the accuracies in an array\n",
    "accuracies = [model10.evaluate(Xtest, Ytest, verbose=0)[1] for _ in range(100)]\n",
    "\n",
    "# Calculate and print mean and std of accuracies\n",
    "print(\"Mean accuracy: %.8f\" % np.mean(accuracies))\n",
    "print(\"Standard deviation: %.8f\" % np.std(accuracies))\n",
    "\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.91492615\n",
      "Standard deviation: 0.00006802\n"
     ]
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **4.2: Cross validation uncertainty**\n",
    "\n",
    "Cross validation (CV) is often used to evaluate a model, by training and testing using different subsets of the data it is possible to get the uncertainty as the standard deviation over folds. We here use a [help function from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) to setup the CV. Use 10 folds with shuffling, random state 1234.\n",
    "\n",
    "Note: We here assume that you have found the best hyper parameters, so here the data are only split into training and testing, no validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T15:53:14.705129Z",
     "start_time": "2026-02-27T15:49:57.172300Z"
    }
   },
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_state = 1234\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Define 10-fold cross validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "\n",
    "# Define where to save the test accuracies\n",
    "test_accuracies = []\n",
    "best_config = best_trial.config\n",
    "\n",
    "# Loop over cross validation folds\n",
    "for i, (idx_train, idx_test) in enumerate(skf.split(Xtrain, Ytrain)):\n",
    "    print(f\"CV iteration {i}\")\n",
    "\n",
    "    Xtrain_k, Ytrain_k = Xtrain[idx_train], Ytrain[idx_train]\n",
    "    Xtest_k, Ytest_k = Xtrain[idx_test], Ytrain[idx_test]\n",
    "\n",
    "    # Calculate class weights for current split (remember to call the function using the input variable names e.g. class_weight='balanced', etc.)\n",
    "    classes = np.unique(Ytrain_k)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=Ytrain_k)\n",
    "    class_weights = dict(zip(classes, weights))\n",
    "\n",
    "    # Rebuild the DNN model, to not continue training on the previously trained model\n",
    "    model_k = build_DNN(input_shape=best_config[\"input_shape\"],\n",
    "                        n_hidden_layers=best_config[\"n_hidden_layers\"],\n",
    "                        n_hidden_units=best_config[\"n_hidden_units\"],\n",
    "                        loss=best_config[\"loss\"],\n",
    "                        learning_rate=best_config[\"learning_rate\"],\n",
    "                        act_fun=best_config[\"act_fun\"],\n",
    "                        optimizer=best_config[\"optimizer\"],\n",
    "                        use_bn=best_config[\"use_bn\"],\n",
    "                        use_dropout=best_config[\"use_dropout\"],\n",
    "                        use_custom_dropout=best_config[\"use_custom_dropout\"])\n",
    "\n",
    "    # Fit the model with training set and class weights for this fold\n",
    "    history_k = model_k.fit(Xtrain_k, Ytrain_k,\n",
    "                            epochs=30,\n",
    "                            batch_size=10000,\n",
    "                            verbose=1,\n",
    "                            class_weight=class_weights)\n",
    "\n",
    "    # Evaluate the model using the test set for this fold\n",
    "    score = model_k.evaluate(Xtest_k, Ytest_k, verbose=0)\n",
    "\n",
    "    # Save the test accuracy in an array\n",
    "    test_accuracies.append(score[1])\n",
    "    print(\"Accuracy: %.8f\" % score[1])\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV iteration 0\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.3887 - accuracy: 0.8635\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.2272 - accuracy: 0.9038\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1936 - accuracy: 0.9128\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1804 - accuracy: 0.9150\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1727 - accuracy: 0.9157\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1681 - accuracy: 0.9164\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1645 - accuracy: 0.9172\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1616 - accuracy: 0.9175\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1595 - accuracy: 0.9177\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1575 - accuracy: 0.9179\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1554 - accuracy: 0.9181\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1528 - accuracy: 0.9186\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1499 - accuracy: 0.9195\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1473 - accuracy: 0.9214\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1439 - accuracy: 0.9236\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1410 - accuracy: 0.9262\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1387 - accuracy: 0.9277\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1401 - accuracy: 0.9271\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1364 - accuracy: 0.9287\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1352 - accuracy: 0.9298\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1325 - accuracy: 0.9311\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1307 - accuracy: 0.9319\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.9320\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1304 - accuracy: 0.9320\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1287 - accuracy: 0.9329\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1268 - accuracy: 0.9337\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1273 - accuracy: 0.9336\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1287 - accuracy: 0.9326\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1250 - accuracy: 0.9342\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1251 - accuracy: 0.9345\n",
      "Accuracy: 0.93176293\n",
      "CV iteration 1\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.3995 - accuracy: 0.8351\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.2550 - accuracy: 0.9014\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2125 - accuracy: 0.9104\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1912 - accuracy: 0.9148\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1787 - accuracy: 0.9154\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1705 - accuracy: 0.9159\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1645 - accuracy: 0.9168\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1594 - accuracy: 0.9178\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1551 - accuracy: 0.9195\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1512 - accuracy: 0.9215\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1469 - accuracy: 0.9243\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1425 - accuracy: 0.9266\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1420 - accuracy: 0.9271\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1421 - accuracy: 0.9268\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1376 - accuracy: 0.9292\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1357 - accuracy: 0.9298\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1345 - accuracy: 0.9303\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1317 - accuracy: 0.9314\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1308 - accuracy: 0.9320\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1299 - accuracy: 0.9325\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1287 - accuracy: 0.9328\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1327 - accuracy: 0.9320\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1402 - accuracy: 0.9276\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1288 - accuracy: 0.9330\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9333\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1267 - accuracy: 0.9336\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1261 - accuracy: 0.9339\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1264 - accuracy: 0.9337\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1258 - accuracy: 0.9341\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1254 - accuracy: 0.9341\n",
      "Accuracy: 0.93357635\n",
      "CV iteration 2\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.3798 - accuracy: 0.8721\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.2333 - accuracy: 0.9005\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2005 - accuracy: 0.9126\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1849 - accuracy: 0.9150\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1759 - accuracy: 0.9156\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1698 - accuracy: 0.9161\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1654 - accuracy: 0.9168\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1621 - accuracy: 0.9174\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1589 - accuracy: 0.9177\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1557 - accuracy: 0.9182\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1530 - accuracy: 0.9192\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1501 - accuracy: 0.9205\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1465 - accuracy: 0.9230\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1437 - accuracy: 0.9253\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1417 - accuracy: 0.9269\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1395 - accuracy: 0.9284\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1384 - accuracy: 0.9285\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1349 - accuracy: 0.9302\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1361 - accuracy: 0.9299\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1322 - accuracy: 0.9316\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1301 - accuracy: 0.9324\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1302 - accuracy: 0.9324\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1302 - accuracy: 0.9323\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1296 - accuracy: 0.9329\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1310 - accuracy: 0.9318\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1273 - accuracy: 0.9334\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1255 - accuracy: 0.9345\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1268 - accuracy: 0.9343\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1257 - accuracy: 0.9343\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1277 - accuracy: 0.9337\n",
      "Accuracy: 0.93424940\n",
      "CV iteration 3\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.4469 - accuracy: 0.8753\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.2402 - accuracy: 0.8940\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2025 - accuracy: 0.9102\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1855 - accuracy: 0.9143\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1760 - accuracy: 0.9160\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1702 - accuracy: 0.9166\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1657 - accuracy: 0.9172\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1627 - accuracy: 0.9174\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1597 - accuracy: 0.9178\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1570 - accuracy: 0.9182\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1545 - accuracy: 0.9188\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1518 - accuracy: 0.9200\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1507 - accuracy: 0.9206\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1471 - accuracy: 0.9224\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1467 - accuracy: 0.9230\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1438 - accuracy: 0.9244\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1414 - accuracy: 0.9260\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1399 - accuracy: 0.9268\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1390 - accuracy: 0.9276\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9286\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1367 - accuracy: 0.9288\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1350 - accuracy: 0.9295\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1335 - accuracy: 0.9303\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1331 - accuracy: 0.9306\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1328 - accuracy: 0.9309\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1311 - accuracy: 0.9316\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1302 - accuracy: 0.9319\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1305 - accuracy: 0.9319\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1364 - accuracy: 0.9301\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1309 - accuracy: 0.9318\n",
      "Accuracy: 0.92806131\n",
      "CV iteration 4\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.4539 - accuracy: 0.8179\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.2911 - accuracy: 0.9053\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2268 - accuracy: 0.9115\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1957 - accuracy: 0.9139\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1805 - accuracy: 0.9155\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1718 - accuracy: 0.9164\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1661 - accuracy: 0.9168\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1609 - accuracy: 0.9177\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1573 - accuracy: 0.9186\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1539 - accuracy: 0.9197\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1532 - accuracy: 0.9204\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1498 - accuracy: 0.9214\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1463 - accuracy: 0.9234\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1440 - accuracy: 0.9250\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1421 - accuracy: 0.9259\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1400 - accuracy: 0.9274\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1382 - accuracy: 0.9285\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9293\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1351 - accuracy: 0.9303\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9307\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1365 - accuracy: 0.9302\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1333 - accuracy: 0.9310\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1332 - accuracy: 0.9310\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9325\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1292 - accuracy: 0.9330\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1281 - accuracy: 0.9333\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1280 - accuracy: 0.9336\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1266 - accuracy: 0.9340\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1259 - accuracy: 0.9343\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1262 - accuracy: 0.9340\n",
      "Accuracy: 0.93518412\n",
      "CV iteration 5\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.4333 - accuracy: 0.8501\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.2612 - accuracy: 0.9009\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.2138 - accuracy: 0.9090\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1936 - accuracy: 0.9126\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1816 - accuracy: 0.9144\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1739 - accuracy: 0.9155\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1686 - accuracy: 0.9162\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1649 - accuracy: 0.9172\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1617 - accuracy: 0.9176\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1585 - accuracy: 0.9180\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1557 - accuracy: 0.9184\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1531 - accuracy: 0.9185\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1504 - accuracy: 0.9204\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1473 - accuracy: 0.9220\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1447 - accuracy: 0.9243\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1420 - accuracy: 0.9262\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1405 - accuracy: 0.9276\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1391 - accuracy: 0.9282\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1372 - accuracy: 0.9290\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1351 - accuracy: 0.9304\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1328 - accuracy: 0.9315\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1344 - accuracy: 0.9307\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1308 - accuracy: 0.9322\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1303 - accuracy: 0.9327\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1347 - accuracy: 0.9313\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1310 - accuracy: 0.9323\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1278 - accuracy: 0.9333\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1283 - accuracy: 0.9334\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1271 - accuracy: 0.9339\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1262 - accuracy: 0.9339\n",
      "Accuracy: 0.93542600\n",
      "CV iteration 6\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 9ms/step - loss: 0.4066 - accuracy: 0.8611\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 0s 9ms/step - loss: 0.2320 - accuracy: 0.8948\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2002 - accuracy: 0.9095\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1850 - accuracy: 0.9131\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1765 - accuracy: 0.9149\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1709 - accuracy: 0.9160\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1670 - accuracy: 0.9169\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1644 - accuracy: 0.9171\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1621 - accuracy: 0.9174\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1603 - accuracy: 0.9176\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1577 - accuracy: 0.9178\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1552 - accuracy: 0.9180\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1523 - accuracy: 0.9187\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1491 - accuracy: 0.9203\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1460 - accuracy: 0.9226\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1439 - accuracy: 0.9243\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1413 - accuracy: 0.9261\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1407 - accuracy: 0.9266\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1375 - accuracy: 0.9282\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1379 - accuracy: 0.9279\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1352 - accuracy: 0.9297\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9308\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1335 - accuracy: 0.9304\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1301 - accuracy: 0.9319\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1302 - accuracy: 0.9323\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1301 - accuracy: 0.9321\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1280 - accuracy: 0.9329\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1310 - accuracy: 0.9324\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 0.1281 - accuracy: 0.9333\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.1280 - accuracy: 0.9330\n",
      "Accuracy: 0.93394905\n",
      "CV iteration 7\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.3554 - accuracy: 0.8701\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.2282 - accuracy: 0.9023\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1962 - accuracy: 0.9108\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1815 - accuracy: 0.9137\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1730 - accuracy: 0.9149\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1673 - accuracy: 0.9155\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1636 - accuracy: 0.9158\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1598 - accuracy: 0.9163\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1566 - accuracy: 0.9168\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1539 - accuracy: 0.9176\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1506 - accuracy: 0.9200\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.1474 - accuracy: 0.9224\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1461 - accuracy: 0.9239\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1427 - accuracy: 0.9255\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1394 - accuracy: 0.9277\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1376 - accuracy: 0.9288\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1350 - accuracy: 0.9299\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1347 - accuracy: 0.9302\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1345 - accuracy: 0.9302\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1350 - accuracy: 0.9301\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1314 - accuracy: 0.9318\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1297 - accuracy: 0.9322\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1288 - accuracy: 0.9328\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1298 - accuracy: 0.9321\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1271 - accuracy: 0.9331\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1266 - accuracy: 0.9336\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1273 - accuracy: 0.9336\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 18ms/step - loss: 0.1282 - accuracy: 0.9326\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1290 - accuracy: 0.9325\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1266 - accuracy: 0.9336\n",
      "Accuracy: 0.93260294\n",
      "CV iteration 8\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.3882 - accuracy: 0.8748\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 0s 10ms/step - loss: 0.2355 - accuracy: 0.8989\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 0.2005 - accuracy: 0.9092\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1829 - accuracy: 0.9134\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1732 - accuracy: 0.9151\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1672 - accuracy: 0.9162\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 10ms/step - loss: 0.1625 - accuracy: 0.9173\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1591 - accuracy: 0.9177\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1555 - accuracy: 0.9185\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1538 - accuracy: 0.9193\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1493 - accuracy: 0.9211\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1468 - accuracy: 0.9231\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1441 - accuracy: 0.9245\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1416 - accuracy: 0.9263\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1404 - accuracy: 0.9269\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1400 - accuracy: 0.9276\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1351 - accuracy: 0.9301\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1338 - accuracy: 0.9308\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1327 - accuracy: 0.9314\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1314 - accuracy: 0.9319\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.1301 - accuracy: 0.9324\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 20ms/step - loss: 0.1314 - accuracy: 0.9322\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 0.1294 - accuracy: 0.9326\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 19ms/step - loss: 0.1274 - accuracy: 0.9337\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1276 - accuracy: 0.9336\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1301 - accuracy: 0.9326\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1290 - accuracy: 0.9328\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1254 - accuracy: 0.9344\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 19ms/step - loss: 0.1260 - accuracy: 0.9345\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1260 - accuracy: 0.9347\n",
      "Accuracy: 0.92927516\n",
      "CV iteration 9\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.4015 - accuracy: 0.8561\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.2356 - accuracy: 0.8972\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.2008 - accuracy: 0.9078\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1849 - accuracy: 0.9126\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1754 - accuracy: 0.9151\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1698 - accuracy: 0.9157\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1662 - accuracy: 0.9162\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1626 - accuracy: 0.9171\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1604 - accuracy: 0.9174\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1578 - accuracy: 0.9178\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1554 - accuracy: 0.9180\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1533 - accuracy: 0.9184\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1530 - accuracy: 0.9186\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1504 - accuracy: 0.9192\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1493 - accuracy: 0.9203\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1465 - accuracy: 0.9215\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1450 - accuracy: 0.9227\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1428 - accuracy: 0.9239\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1424 - accuracy: 0.9249\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1406 - accuracy: 0.9257\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1383 - accuracy: 0.9274\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9284\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1350 - accuracy: 0.9296\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1335 - accuracy: 0.9304\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 12ms/step - loss: 0.1331 - accuracy: 0.9305\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1312 - accuracy: 0.9317\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1305 - accuracy: 0.9319\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1306 - accuracy: 0.9320\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1308 - accuracy: 0.9319\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 11ms/step - loss: 0.1284 - accuracy: 0.9332\n",
      "Accuracy: 0.93333209\n"
     ]
    }
   ],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T15:53:28.402422Z",
     "start_time": "2026-02-27T15:53:28.077495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Mean accuracy: %.8f\" % np.mean(test_accuracies))\n",
    "print(\"Standard deviation: %.8f\" % np.std(test_accuracies))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.93274193\n",
      "Standard deviation: 0.00229885\n"
     ]
    }
   ],
   "execution_count": 217
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3 Bayesian neural networks (BNN)**\n",
    "\n",
    "Instead of mimicking Bayesian inference through MC dropout (see more details in this [paper](https://proceedings.mlr.press/v48/gal16.html)), what if we could build a model that can inherently give us a way to probe both model uncertainty (i.e. [epistemic uncertainty](https://link.springer.com/article/10.1007/s10994-021-05946-3) cause by few training samples) and data uncertainty (i.e. [aleatoric uncertainty](https://link.springer.com/article/10.1007/s10994-021-05946-3))? \n",
    "\n",
    "One way to achieve this is to train models to learn distributions over weights in the layers and over the output. This can be achieved by using TenssorFlow probability (see the [documentation](https://www.tensorflow.org/probability) for an in-depth description of all the functionalities). In this example we will only scratch the surface of the capabilities that a probabilistic deep learning approach has to offer, by addressing only model uncertainty. \n",
    "\n",
    "To start with, think about a BNN as an extension of your classical DNN, where during training instead of learning a weights for each 'connection' in the network, we ask the model to lean a distribution. After model training, during inference time, we sample from the learned distributions to obtain the weights used in the model in the forward pass. The modifications that we have to implement in our `build_DNN` function are the following:\n",
    "- Substitute the hidden `Dense` layers with [`DenseVariational`](https://www.tensorflow.org/probability/api_docs/python/tfp/layers/DenseVariational) layers (this can be found under tensorflow-probability.layers). Do not forget to specify the `kl_weight` as 1/ number of iterations per epoch ([reference](https://arxiv.org/abs/1505.05424)). \n",
    "- Define the prior weights distribution (`make_prior_fn` input in the `DenseVariational`): this is the distribution that we expect the weights to have prior having seen the data. In this example we will not train the prior distribution.\n",
    "- Define the posterior weights distribution (`make_posterior_fn` input in the `DenseVariational`): this is the distribution that we expect the model to learn during training. Since we do not know at priory which is the posterior distribution, we let it be very general (i.e. multivariate Gaussian distribution) which parameters are learned by the model. \n",
    "\n",
    "You will find the `BNN_prior` and `BNN_posterior` defined for you in the `utilities.py` file. Update the `build_DNN` to accept a new boolean input `use_variational_layer` that when true substitutes the hidden `Dense` layers with the `DenseVariational` layers. \n",
    "\n",
    "**!NOTE** As you will see, training the BNN model is more computationally demanding and is more prone to over-fitting. Reduce the learning rate and increase the number of epochs to address this issue.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "17. (MC dropout) What is the mean and the standard deviation of the test accuracy after evaluating the model on 100 times?\n",
    "18. (CV) What is the mean and the standard deviation of the test accuracy?\n",
    "19. (CV) What is the main advantage of dropout compared to CV for estimating test uncertainty? The difference may not be so large in this notebook, but imagine that you have a network that takes 24 hours to train.\n",
    "20. (BNN) Build the BNN model and look at the number of parameters. Is there a difference between the previous DNN and the BNN? Why is that?\n",
    "21. (BNN) Without training the model, evaluate the model a twice on the validation set: do you obtain the same validation accuracy? Why\n",
    "22. Think of at least one advantage and one disadvantage for each of the three uncertainty estimation methods.\n",
    "    \n",
    "    \n",
    "#### **<span style=\"color:green\">Answer</span>**\n",
    "17. Mean accuracy: 0.91492615; Standard deviation: 0.00006802\n",
    "18. Mean accuracy: 0.93274193; Standard deviation: 0.00229885\n",
    "19. In CV the model needs to be retrained k times - comptutationally expensive\n",
    "20. Trainable parameters: 5115556; prior and posterior make amount of parameters explode (2x more params per weight)\n",
    "21. No, accuracy changes due to different samples from posterior\n",
    "22. - MC Dropout: (+) Fast at test time ; (-) random connections are being dropped which might have a positive impact on the model\n",
    "    - CV: (+) Robust and simple ; (-) expensive, since more models have to be trained\n",
    "    - BNN: (+) utilizes bayesian uncertainty ; (-) training unstable and slower, more parameters\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T11:47:03.983649Z",
     "start_time": "2026-02-27T11:47:03.704180Z"
    }
   },
   "cell_type": "code",
   "source": "best_config",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act_fun': 'relu',\n",
       " 'optimizer': 'adam',\n",
       " 'use_bn': True,\n",
       " 'n_hidden_layers': 4,\n",
       " 'n_hidden_units': 30,\n",
       " 'loss': <tf_keras.src.losses.BinaryCrossentropy at 0x3507f10d0>,\n",
       " 'learning_rate': 0.001,\n",
       " 'use_dropout': False,\n",
       " 'use_custom_dropout': False,\n",
       " 'use_variational_layer': False,\n",
       " 'input_shape': (93,)}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T12:20:22.281671Z",
     "start_time": "2026-02-27T12:17:47.462810Z"
    }
   },
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "from utilities import build_DNN\n",
    "\n",
    "# Your best training parameters\n",
    "batch_size = 10000\n",
    "epochs = 50  # increased\n",
    "\n",
    "# Build and train model\n",
    "model11 = build_DNN(input_shape=best_config[\"input_shape\"],\n",
    "                    n_hidden_layers=best_config[\"n_hidden_layers\"],\n",
    "                    n_hidden_units=best_config[\"n_hidden_units\"],\n",
    "                    loss=best_config[\"loss\"],\n",
    "                    learning_rate=best_config[\"learning_rate\"],\n",
    "                    act_fun=best_config[\"act_fun\"],\n",
    "                    use_bn=best_config[\"use_bn\"],\n",
    "                    use_dropout=best_config[\"use_dropout\"],\n",
    "                    use_custom_dropout=best_config[\"use_custom_dropout\"],\n",
    "                    use_variational_layer=True,\n",
    "                    kl_weight=(1 / Xtrain.shape[0]))\n",
    "\n",
    "history11 = model11.fit(Xtrain, Ytrain,\n",
    "                        validation_data=(Xval, Yval),\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        class_weight=class_weights,\n",
    "                        verbose=1,)\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 5s 68ms/step - loss: 0.8875 - accuracy: 0.5656 - val_loss: 1.0020 - val_accuracy: 0.6389\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.8362 - accuracy: 0.6168 - val_loss: 0.8189 - val_accuracy: 0.5591\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 0.8234 - accuracy: 0.5301 - val_loss: 0.7723 - val_accuracy: 0.5421\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7871 - accuracy: 0.5330 - val_loss: 0.7576 - val_accuracy: 0.5119\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7783 - accuracy: 0.5647 - val_loss: 0.7056 - val_accuracy: 0.5884\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7842 - accuracy: 0.5143 - val_loss: 0.7370 - val_accuracy: 0.4961\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.7945 - accuracy: 0.4505 - val_loss: 0.7375 - val_accuracy: 0.6019\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.7669 - accuracy: 0.4886 - val_loss: 0.7176 - val_accuracy: 0.5522\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7689 - accuracy: 0.4574 - val_loss: 0.7686 - val_accuracy: 0.4443\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7447 - accuracy: 0.5156 - val_loss: 0.7805 - val_accuracy: 0.4395\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7527 - accuracy: 0.4310 - val_loss: 0.7141 - val_accuracy: 0.5704\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.7305 - accuracy: 0.4462 - val_loss: 0.7329 - val_accuracy: 0.4800\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7362 - accuracy: 0.4078 - val_loss: 0.7524 - val_accuracy: 0.4714\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7225 - accuracy: 0.4441 - val_loss: 0.7820 - val_accuracy: 0.3766\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.7260 - accuracy: 0.3886 - val_loss: 0.7481 - val_accuracy: 0.4393\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.7017 - accuracy: 0.4323 - val_loss: 0.7787 - val_accuracy: 0.3861\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7013 - accuracy: 0.4464 - val_loss: 0.7725 - val_accuracy: 0.3925\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7055 - accuracy: 0.4444 - val_loss: 0.7396 - val_accuracy: 0.5238\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7206 - accuracy: 0.3783 - val_loss: 0.7945 - val_accuracy: 0.3639\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 3s 60ms/step - loss: 0.7109 - accuracy: 0.3431 - val_loss: 0.7745 - val_accuracy: 0.3636\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7133 - accuracy: 0.3705 - val_loss: 0.7531 - val_accuracy: 0.3777\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.7121 - accuracy: 0.3954 - val_loss: 0.7590 - val_accuracy: 0.4313\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.7070 - accuracy: 0.3667 - val_loss: 0.7823 - val_accuracy: 0.3659\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 3s 60ms/step - loss: 0.6986 - accuracy: 0.4179 - val_loss: 0.7956 - val_accuracy: 0.3500\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7100 - accuracy: 0.3622 - val_loss: 0.7871 - val_accuracy: 0.4375\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.6881 - accuracy: 0.3779 - val_loss: 0.7809 - val_accuracy: 0.4123\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.7101 - accuracy: 0.3717 - val_loss: 0.8456 - val_accuracy: 0.3218\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.6955 - accuracy: 0.3641 - val_loss: 0.8103 - val_accuracy: 0.4140\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.6933 - accuracy: 0.3776 - val_loss: 0.8088 - val_accuracy: 0.3615\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.6760 - accuracy: 0.4909 - val_loss: 0.7530 - val_accuracy: 0.4982\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.6796 - accuracy: 0.4076 - val_loss: 0.7539 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 3s 60ms/step - loss: 0.6926 - accuracy: 0.3899 - val_loss: 0.7881 - val_accuracy: 0.3589\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.6735 - accuracy: 0.4341 - val_loss: 0.7513 - val_accuracy: 0.4787\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.6943 - accuracy: 0.3594 - val_loss: 0.7749 - val_accuracy: 0.4271\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.6829 - accuracy: 0.4282 - val_loss: 0.7816 - val_accuracy: 0.5037\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 0.6905 - accuracy: 0.4305 - val_loss: 0.8079 - val_accuracy: 0.4159\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.6868 - accuracy: 0.3930 - val_loss: 0.8024 - val_accuracy: 0.4712\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.6963 - accuracy: 0.3715 - val_loss: 0.7835 - val_accuracy: 0.4853\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.6900 - accuracy: 0.4003 - val_loss: 0.7822 - val_accuracy: 0.4304\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.6869 - accuracy: 0.4022 - val_loss: 0.7867 - val_accuracy: 0.4163\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.6725 - accuracy: 0.4420 - val_loss: 0.8235 - val_accuracy: 0.3225\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.6851 - accuracy: 0.4065 - val_loss: 0.7651 - val_accuracy: 0.5061\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.6852 - accuracy: 0.4329 - val_loss: 0.8174 - val_accuracy: 0.4046\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.6811 - accuracy: 0.4076 - val_loss: 0.8009 - val_accuracy: 0.4101\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.6618 - accuracy: 0.4746 - val_loss: 0.7768 - val_accuracy: 0.5103\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.6779 - accuracy: 0.4038 - val_loss: 0.8027 - val_accuracy: 0.4339\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.6691 - accuracy: 0.4420 - val_loss: 0.7757 - val_accuracy: 0.4994\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.6823 - accuracy: 0.4207 - val_loss: 0.8116 - val_accuracy: 0.3844\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.6562 - accuracy: 0.4922 - val_loss: 0.7807 - val_accuracy: 0.4413\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.6711 - accuracy: 0.4741 - val_loss: 0.8135 - val_accuracy: 0.4106\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T14:36:18.606834Z",
     "start_time": "2026-02-27T14:36:17.993412Z"
    }
   },
   "cell_type": "code",
   "source": "model11.summary()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_variational_74 (Dens  (None, 30)                3896235   \n",
      " eVariational)                                                   \n",
      "                                                                 \n",
      " batch_normalization_132 (B  (None, 30)                120       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_109 (Activation  (None, 30)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_variational_75 (Dens  (None, 30)                406350    \n",
      " eVariational)                                                   \n",
      "                                                                 \n",
      " batch_normalization_133 (B  (None, 30)                120       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_110 (Activation  (None, 30)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_variational_76 (Dens  (None, 30)                406350    \n",
      " eVariational)                                                   \n",
      "                                                                 \n",
      " batch_normalization_134 (B  (None, 30)                120       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_111 (Activation  (None, 30)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_variational_77 (Dens  (None, 30)                406350    \n",
      " eVariational)                                                   \n",
      "                                                                 \n",
      " batch_normalization_135 (B  (None, 30)                120       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_112 (Activation  (None, 30)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_302 (Dense)           (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5115796 (19.52 MB)\n",
      "Trainable params: 5115556 (19.51 MB)\n",
      "Non-trainable params: 240 (960.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T14:18:42.615873Z",
     "start_time": "2026-02-27T14:18:41.944690Z"
    }
   },
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history11)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 208
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have done for the MC dropout uncertainty estimation, run the evaluation on the test set 100 times and show the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-27T14:48:59.077021Z",
     "start_time": "2026-02-27T14:37:30.038468Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# === Your code here =========================\n",
    "# ============================================\n",
    "# Run the testing 100 times, and save the accuracies in an array\n",
    "\n",
    "n_runs = 10\n",
    "\n",
    "# Define where to save the test accuracies\n",
    "test_accuracies = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    # predict the test set\n",
    "    pred = model11.evaluate(Xtest, Ytest, verbose=0)\n",
    "\n",
    "    # Save predictions\n",
    "    test_accuracies.append(pred[1])\n",
    "\n",
    "# Calculate and print mean and std of accuracies\n",
    "print(\"Mean accuracy: %.8f\" % np.mean(test_accuracies))\n",
    "print(\"Standard deviation: %.8f\" % np.std(test_accuracies))\n",
    "# ============================================"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.47558179\n",
      "Standard deviation: 0.00293949\n"
     ]
    }
   ],
   "execution_count": 214
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: DNN for regression\n",
    "\n",
    "A similar DNN can be used for regression, instead of classification.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "23. How would you change the DNN used in this lab in order to use it for regression instead?\n",
    "\n",
    "#### **<span style=\"color:green\">Answer</span>**\n",
    "23. Remove the sigmoid activation function in the last layer to make the model regressive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "Send in this jupyter notebook, with answers to all questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "732a83_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
